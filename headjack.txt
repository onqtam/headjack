
Computable context

Episodes & other creations should get their concept id

Competition - 1-of-N

We can let humans rank respurces for various topics

Participatory - flow - in one with the environment
Everything is salient
Connectedness
Agency
Meaning


> "The Domain Name Server (DNS) is the Achilles heel of the Web." - [Tim Berners-Lee](https://www.brainyquote.com/quotes/tim_bernerslee_373104)


We are so limited - we should be able to sort and filter spotify episodes based on views/engagement. All these apps provide us a limited sandboxed environment


we need a shared view of reality and the ability to coordinate around that view of reality
we need social media that is rewarding synthesis of ideas
what if we rewarded those who find divisive fault lines and bridge the gap?


what if we could tag/annotate content where human faces are using filters - or at least that we think its happening?
what if we could choose that the recommender AIs do not show us faces with artificial filters (annotated as such by others) - wouldn't that disincentivize the use of such filters?
Obviously this isn't thought through completely - it could turn out bad if the annotation isn't reliable - its just trying to illustrate a point.
we could use AI to detect this instead of human annotation & reactions
we can have a lot more choice in what is being promoted in media


What if we could tell recommender algorithms to avoid content about dieting for example? why not be able to include/exclude based on such types?


The current social media arms race is in harvesting attention & going to the bottom of the brain stem. What if the nature of competition is changed and the ones that offer the most choice for users win?


we can crowdsource a ranking of bad UI mechanics that should be avoided in media and use that to inform which apps & algorithms we use
the stopping queue has been removed since the invention of the endless feed scrolling mechanic - what if there was a checklist of bad UI decisions that all apps are ranked against?


what if we could analyze any piece of media for the degree of use of loaded/manipulative language?



Its all about choice.


why can't we crowdsource "top 10 videos that everyone should watch"


all journalism suffers from
- gelman amnesia   https://theportal.wiki/wiki/The_Gell-Mann_Amnesia_Effect
- cherry picking - reality is a lot more complex
- framing / frame control & russell conjugation - what is vs how to feel about what is - this should be an anti signal
We should be less reliant on narratives and more on data



translating language to graphs of data is messy and hard - what if we first constructed our belief graphs & thesis explicitly and then used AI to generate us presenting our version of the story in the most coherent way possible? What if we shifted creation to explicit node-based software first before anything else?
what leads to what, what the probabilities are.
just like writing forces us to think, the next level is constructing such graphs in forcing us to think
But until now we haven't had the option to turn such graphs into other types of consumable media
imagine how we can edit a graph and re-render the final media output to reflect that
we could even generate media that summarizes the changes of the graph throughout time - "generate change report in X format"



What if we could debug / fact-check the logic in our graph circuits - perhaps by checking specific assumptions around other external fact databases?


We’d be able to “view source” for the AI-generated summaries

We’d be able to query where else specific facts (semantic triples) are mentioned

“The need for structure”

A graph has many ways to be traversed so we could ask AIs to generate a few versions so that we can pick. Our we could draw a pathing for linguistic linearization

The generated linearized/serialized output could have an automatically generated mapping so that we can see which regions correspond to which parts of the graph with some highlighting and we could have both displayed side by side in a synchronized “playback”

People can have fine-grained control such as annotating specific nodes to be skipped from the serialization or to signal importance to them so that the AI adds more emphasis on them
Imagine integrating this in a movie-maker-like software with a timeline widget

We could compute the similarity of views if they were in such graph forms

If we can annotate facts and claims then we’d be able to track the provenance of ideas - or at least view their first occurance

We should be thinking in diagrams, graphs and state machines - mind mapping is superior for comprehension and retention of information compared to linearized text - we can augment/upgrade/automate our linguistics for the first time

the future of script writing is graph creation, where refactoring and shuffling things around is just a matter of moving around & reconnecting subgraphs

Linearization/serialization of ideas in language inevitably loses details, precision and connections

The source should always be a graph because our minds represent knowledge and ideas as graphs - even though we communicate through serialization.

The only way for serialization to language to not lose any details, connections & nuance in complex ideas is to be overly verbose and incomprehensible by humans.

the next version of tweets will be small graphs, accompanied by representations in a few media forms for different consumption options

language evolved hundreds of thousands of years ago - its about time we upgraded from it

the better we annotate content - the more discoverable it will be. People don't put #hashtags without a good reason - however they are extremely limited

we could (partially) pattern-match our thoughts

This is how we should think about humans in the giang global graph:
https://www.youtube.com/watch?v=V0XfleKJSXM
History of Ethereum 2013-2018 (Git Visualization)
gource - git visualization

the semantic web was held back by the host-centric model and the lack of stable decentralized identities to which we could link/join data

reviving the semantic web

web 3.0 is a graph of identities & events in the cloud - beyond the confines of the host-centric web

accounts have their own concept/noun space with identifiers from 1 and upwards
others can define onthologies that use those concepts
others can make equivalence maps between onthologies & concepts

imagine modelling the case around TikTok as a graph/tree


Social media 1.0 is a capitalistic artifact of gradient descent. Social media 2.0 is the Metaverse where data has no boundries

Wikipedia 2.0 will be a crowdsourced knowledge graph

with common shared knowledge graphs we could do impact analysis for event prioritization and also root cause analysis and other graphs that perhaps represent someone's essay/thoughts could refer to the main shared graph - acting as an extension to it that can be considered in the context of the whole & analyzed

the semantic web is about replacing the statistical and sporadic links in the web with something actually meaningful and unambiguous & semantic

formal language, predicate/first-order logic, 


what if we had different knobs to tune the availability of content - not just likes/dislikes

not facts/concepts/rules - assertions!

what if we could crowdsource something like Cyc?
https://www.youtube.com/watch?v=kwYaj-1EVJ0

What if wikipedia was a common knowledge graph with different possible views for it?



concern: its impossible to have updated views & indexes for every aggregate with a big enough different filtration criteria, but its important for any view to be possible, so that eventually it gets calculated & surfaces



unlike text, structured data is easily aggregatable for the purpose of visualization through graphs & charts which makes it easily comprehensible


The current social apps exploit our social reciprocity - x follows you - follow them back! We should rethink our types of connections and the amount of persuation and manipulation apps can do to us

Can’t be evil - tiktok in 2022 was running jn russia without the ability to view foreign content and russians could not post content about the war

Cant be evil - searcc result manipulation and bias

Perspective expansion vs perspective division/separation/certainty

We are what we eat but we are also what we watch

in the current web your interactions lead to better recommendations and better ads. In an open world your interactions would enable all kinds of insight that anyone could surface
open & shared knowledge graphs would unlock unimaginable services & insight - part of the cold start problem is lack of access to a knowledge graph
knowledge graphs bring context
ontological engineering would be required for proper knowledge graphs...

in entity resolution (if records from different data sources represent the same entity) consistency is key, and so is brevity/compactness


what if your inputs (likes/votes/etc) weren't seen in the feeds of your followers (as explicit comments or whatever) but could still affect them - as in curating content for them?







> "If you want to find the secrets of the universe, think in terms of energy, frequency and vibration." - [Nikola Tesla](https://www.goodreads.com/quotes/361785-if-you-want-to-find-the-secrets-of-the-universe)

> "If you want to find the secrets of the Metaverse, think in terms of identities, events & graphs/relations." - [Nikola Tesla](https://www.goodreads.com/quotes/361785-if-you-want-to-find-the-secrets-of-the-universe)






We should be able to relate things and look for relations/references - example:
The YouTube playlist [`"Journey into information theory | Computer Science | Khan Academy"`](https://www.youtube.com/playlist?list=PLSQl0a2vh4HC9lvrBhVt4UUkhzpp3N5_x) by the creators of the videos is out of order, but someone made another playlist [`"Journey into information theory (in order)"`](https://www.youtube.com/playlist?list=PLq2EDMGUqkHHjHLhp88RY-e5mN7uGMP75) that is in proper order. We should be able to see all references for the original playlist when viewing it and filter them and more easily discover the fixed playlist









anonymity - reducing the cost of defection



relevance realization


hyper agents (extremely influential individuals & entities) need to be held to higher standards & have more scrutiny


current social media has a choice architecture in the UI that's misaligned with users - they're solely optimizing for engagement & time spent - the goals of people

we take the agency we have in search engines for granted (we explicitly type what we're looking for), but we've completely abdicated agency in the feeds that feed us information in social media - we ought to have a choice there as well
In search we are looking for something and want control. But aren't we looking for something in our feeds as well? Why not have more agency - even if it leads to less time spent on the app?


what if we could provide alternative names for content in a crowdsourced way - one that is less clickbait-y?
aligning incentives.


The perpetual AMA


there's a sociological asymmetry of power - those that produce data and those that have access to it


Stack overflow questions can have their titles changed/edited by someone other than the author with the goal of making it more precise - why not do the same for videos & all other kinds of content?

we can compute truthfulness - or at least levels of alignment to a set of beliefs


a bottom-up global governance system can only be built on top of a shared identity layer, trust, reputation & immutable history


what if we could annotate what's being said in text/video with semantic triplets and then being able to check those facts/assumptions against another database or set of facts by our choosing?


Names can have an index and subdomains can refer to the names by idx - vbuterin should be in the state once even if rhere is a vbuterin.com and a vbuterin.eth - names are created once and reused by idx



AI classification isn’t scalable enough and can be ambiguous

Why NFTs are overhyped - but VCs and attestations are not

Due to the scale-free effect there will be a power law distribution for the IDs being used - there will be a convergence - just like imdb movie ids are used in many places

The metaverse is where your entire digital trail resides and underneath that is identity

Meme: fork in the road: host-centric status quo vs SSI and content addressing

Social media is not about pictures of what we ate - its a global coordination substrate



what about flagging an HR person as spammy? that should have its own specialized message type


Signing with a private ley requires it to always be loaded - for every new event
Contrast that to auth tokens - they are created once and reused many times - only the point of creation needs the highest security

A true social network allows data, events and identities to be linked in any way imaginable - today’s platforms are a lowest common denominator with hard constraints on how they can be extended

We’ve never had a true social network

Guaranteed resolvability




shared context - common knowledge - enables more efficient communication
we communicate more efficiently within groups when we have inside jokes
we build dictionaries for efficient communication

duplicated content & concepts leads to less common knowledge as it is harder/impossible to join the data and produce aggregated views - leading to fractured views

context collapse
https://en.wikipedia.org/wiki/Context_collapse

if we deduplicate most of the information and concepts our attention will be less fractured and we'd have more common knowledge
common knowledge is a critical component in cooperation

freeform text adds entropy and ambiguity due to the context collapse in the open web where strangers interact with each other without sharing the same cultural & linguistic backgrounds

https://en.wikipedia.org/wiki/Common_knowledge



"deduplication & giving everything an ID"




the endgame

abstract meritocracy
the internet government
jamie joyce
what if technology could enable people to represent themselves and directly participate in federal legislative government themselves - politics without polititians

we can separate political ideas from people and representatives
what if we could inform our politics with such soft online governance in an abstract meritocracy

representative democracy is vulnerable

A bold idea to replace politicians | César Hidalgo
https://www.youtube.com/watch?v=CyGWML6cI_k

<iframe width="560" height="315" src="https://www.youtube.com/embed/CyGWML6cI_k" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen></iframe>

representative polititians are packages and are full of compromises

what if we could submit all our views & morals and feed that through aggregation algorithms that then score different policies to determine which ones should be chosen? And what if all this data was anonymized and yet public so anyone can re-do the aggregates?
What if we could pull ZK credentials for different criteria from our real identity and input those (in some anonymized fashion) into the aggregation algorithm?

This algorithm can be public & open source



The third attractor is bottom-up emergent order

Current social media is stupefying us



we can bridge/bring along/transfer/extend VCs to the anonymized set of votes
something could guide or estimate how deanonymizable we become depending on the ZK VCs we bridge




we could have a quiz and give VCs to people that pass it and only count their votes in polls






reducing information entropy - the level of surprise
but aren't we actually reducing the ambiguity?
bringing order
reducing the symbol space

reducing the vocabulary of common knowledge


The Metaverse is an MMO (massively multiplayer online) freeform information network - a giant global graph - a metabrain
https://en.wikipedia.org/wiki/Massively_multiplayer_online_game

massively multiplayer online relational database

There will be SQL interfaces on top of all of the data

think in terms of relations & joinability

https://en.wikipedia.org/wiki/Semantic_network


> "Any organization that designs a system (defined broadly) will produce a design whose structure is a copy of the organization's communication structure." - [Melvin E. Conway](https://en.wikipedia.org/wiki/Conway%27s_law)



Notifications from social networks are hideously engineered to get you to get back in the app - we need to separate IDMs from apps



Sensemaking chapter - video replies without interlinking specific moments is just primitive
How do we debunk stuff?
Moonlanding faked?
Ancient technology in egypt? Give links as evidence




What if people subscribed to specific types of events by others, in effect guiding them what to produce - even if they aren't already? If you saw that 90% of the interest in you is in financial opinions and not just shitposting - wouldn't you opine? Although this is a form of audience capture






chapter: what journalism would look like
== RESURRECTING/REVIVING/REINVENTING/reimagining JOURNALISM w/ reputation
- digital investigative journalism could be quantifiable & codified as algorithms - the role of people could be in building such algorithms/classifiers (which could be chained/imported like in DeSci) & narration
- anyone should be able to make new classifiers and apps should be free to use (or allow the use of) such classifiers
- we can co-create the mechanism for sorting through ideas publicly and directing capital what to be fixed next
- we need to be able to surface any kind of signal from public data
- we can have a trail (in the web of trust & sequence of events) of who was fraudulently trying to shut off an idea - this can act as an incentive to not publicly try to lie. we need to build the reputation machine, but one where reputation is multi-dimensional and we all participate & compete for competence in different aspects & verticals of society
- every nation and every official in the top seats of governments should have a public account with identity tied to his broadcasted public actions
- any public claim can be backed up by an accompanying algorithm that surfaces the signal behind the claim. And there's a record of which other identities are used as sources for the input data, and if the algo is indeed what it's said out to be
- Give the people the tools they want
- Competing knowledge graphs that you plug into Troogle (truth google)- see where they differ in what is true (left vs right?) - point from balaji
- imagine the kind of wikipedia we could build on top of the ledger of record
    https://en.wikipedia.org/wiki/Wikipedia:Reliable_sources
    https://en.wikipedia.org/wiki/Wikipedia:Wikipedia_is_a_mainstream_encyclopedia
- With open data we can be more data driven and less narrative driven

be able to choose a truth provider & even selectively override entries

we should be able to apply something like birdwatch on the entire web - not just on tweets. We need software composability




heatmaps





imagine being able to crowdsource debate requests with specific people and see a ranking of which debates are most desired





when youtube removes a video of yours - it should still be available by you.

boosting the competent through ranking their public information & track record objectively & transparently
we need to build the public introspection tool




imagine browsing the public web like it was your personal files in your apps and drives - having total control of how you store and group that data. This could be the case with the public web. And we could advertise what kind of filters & grouping options we prefer with public messages which are not options. we can crowdsource preference and show which things are preferred. We can end the binary duopoly in politics by making all opinions and interests unbundled from each other


services will no longer have the host-centric model to point to as the reason for siloing data - just the fact that we would give an address to our documents that is beyond any specific host is enough of a reason for the nature of competition to change


Global vs local for the feed - locality of information & notifications!

Section: certifiable (verifiable?) credentials and attestations



granularity of verification? many verticals? a bouquet of attestations



we should be able to request all inputs that went into an aggregate and verify the calculation locally ourselves



Community-centric

twitter has different subcommunities (FinTwit,AudioTwit,CT) - specialized UIs can have value flow embedded in them so different & unique business models could be used



imagine being able to select a subset of all accounts worldwide and train a GPT on that subset of human knowledge & opinions



what if apps have to explicitly pay to infra for their data to be stored?


deduplicating concepts and reusing them increases the efficiency & compactness of information. Common knowledge as unique concept/noun identifiers allows us to communicate more substance and interlink everything better
Common knowledge is important for efficient communication

concepts! not nouns
https://en.wikipedia.org/wiki/Concept

context collapse - lack of provenance & the chain of custody of facts

we have the opportunity to deduplicate common knowledge (concepts, nouns, etc). into a set of unique stable identifiers


youtube's reaction to swarm downvoting is "remove the count". This system allows you to filter the count any way you want







reaction videos
Jillian Michaels: Don't believe the keto diet hype | Big Think
https://www.youtube.com/watch?v=LOPOcBVzm7s
How do we determine if that video is correct? How do we browse the reactions?
HOW WOULD YOU KNOW there are reactions if you didn't explicitly search for them ?!
https://www.youtube.com/results?search_query=jillian+michaels+keto+reaction
The Keto and Low Carb High Fat revolution is entirely enabled by the internet and is a response to the complete failure and corruption of the FDA

The internet is rife with (deliberate) misinformation

a long video citing a bunch of external documents - we should be able to react differently to each and every external citation and have a discussion about each of them







████████████████████████████████████████████████ REAL TODO:



████████████████████████████████████████████████ Notes from the 2nd half of November

100 ways to describe Headjack:
- not engineered for a % of the market - engineered for the entire market
- cheaper, faster, better
- Headjack's block/content explorer is the next Google
- the real cloud - beyond physical hosts
- Moving everyone on a shared identity layer needs to happen only once. It's a matter of time. Why not simply look at the best protocol in terms of merits and shoot with it?
- Lets create the theoretically most secure and scalable solution to this problem.
- Lets tell the best story of why it's necessary.
- And let's not botch the tokenomics.
- The timestamp machine
- The universal network effect
- Untransferrable property rights for data
- fixing competition in media







- "the successor to E-mail" in what really is headjack
An extension of email
Extending email to a broadcasting protocol
this identity layer is the successor to email
the successor to email - instead of base layer of cyberspace
DNS+Email+RSS






████████████████████████████████████████████████ other

interoperability
https://balajis.com/yes-you-may-need-a-blockchain/

competition & horizontal gene transfer
https://twitter.com/sreeramkannan/status/1573832256577224705


- make all quotes with the right [source] and try to use highlights

███ page about VCs

- add "(fractal)" to
    possibilities.html#intra-document-addressing
    names_and_paths.html#addressing-within-content


███ points & phrasing:

- todo: Streams and composability
    https://cdixon.mirror.xyz/Ie8BQeiM1JTJkKISPVaAao88-XVMoHsdUAtcnS9_Jbs
    https://twitter.com/naval/status/1444366754650656770


███ diagrams:

https://sequencediagram.org/
mermaidjs diagram?

- NOT INVERTED pyramid - identifier, profile info & preferences, generated content/created

- User funnel diagram with multiple possible ways to end up in the system
- complete flow of an action from creation to displaying in apps
    - pipeline of publishing and ingesting an event

███ research:
- https://a16z.com/2022/04/21/investing-in-spruce/
- https://www.hello.coop/#user-faqs
- https://www.sismo.io/
- https://ethdos.xyz/blog
- verifiable credentials - chains that aim to do solely that are a ghost town - Headjack is a confluence of many things with synergies.
    https://www.dock.io/
    https://www.dock.io/post/decentralized-identity
    https://docknetwork.github.io/sdk/tutorials/tutorial_anoncreds.html
    https://docknetwork.github.io/sdk/tutorials/concepts_private_delegation.html
    https://blog.dock.io/exposing-bad-actors-behind-anonymity-with-traceable-credentials/

SISMO !!! and ethdos !!!
https://twitter.com/shreyjaineth/status/1590310990876659712

https://www.lfph.io/wp-content/uploads/2021/02/Verifiable-Credentials-Flavors-Explained.pdf






We can rearchitect/rewire the entire web!
https://i.kym-cdn.com/entries/icons/facebook/000/022/524/tumblr_o16n2kBlpX1ta3qyvo1_1280.jpg

announcement: this is what I've been working on for the past 1 year
https://twitter.com/gainzy222/status/1474761079179907079


- make a glossary page
    https://spec.dsnp.org/Reference/Glossary.html
    what is an anchor:
        https://blog.ceramic.network/key-revocation-in-self-certifying-protocols/#key-revocation-in-ceramic
        https://research.csiro.au/blockchainpatterns/general-patterns/self-sovereign-identity-patterns/anchoring-to-blockchain/





- TODO: do a graphic for the 4 types of headjack use cases:
    https://twitter.com/TrungTPhan/status/1545413848886169602



- data centric page -  mention interoperability & composability
TODO: Ambition => composability => link to possibilities





merkle tree pic:
https://miro.medium.com/max/1174/1*prtcx2rVQZmX9oZcyrC_gQ.png




████████████████████████████████████████████████ starkware & zk stuff:

ZK Whiteboard Sessions - Module One: What is a SNARK? by Dan Boneh
https://www.youtube.com/watch?v=h-94UhJLeck

VERY GOOD!!!
read onwards from "Type of ZKPs (STARKs and SNARKs) and How They Work"
https://zeeprime.capital/part-1-Can-We-Kill-Moloch-ZK-Basics-and-Virtual-Machines

very good talk?
ZKP Workshop 2022: Dan Boneh - Constructing Modern SNARKS
https://www.youtube.com/watch?v=6psLQv5Hf_I

https://www.notboring.co/p/zero-knowledge

https://appliedzkp.org/
https://semaphore.appliedzkp.org/

https://www.researchgate.net/publication/221355016_How_to_Explain_Zero-Knowledge_Protocols_to_Your_Children

https://github.com/noir-lang/noir

https://pseudotheos.mirror.xyz/Q9154CY9CFaPzy6AgSlek8-ZBA_kSF_93MTKk-opHRw

GREAT piece/overview about appchains
https://medium.com/1kxnetwork/application-specific-blockchains-9a36511c832


https://medium.com/@VitalikButerin/quadratic-arithmetic-programs-from-zero-to-hero-f6d558cea649

Vitaly Yakovlev - Starknet dApps: How we built DeFi 3.0 with Cairo
https://www.youtube.com/watch?v=v-TsuOxgOqM

https://twitter.com/sreeramkannan/status/1548377279058743304

https://twitter.com/sreeramkannan/status/1563615609925304320

https://blog.nil.foundation/2022/07/01/starknet-integration.html

https://twitter.com/sreeramkannan/status/1558986641116499968

https://twitter.com/bkiepuszewski/status/1559900576888004609


https://twitter.com/jon_charb/status/1555403452485861377
https://members.delphidigital.io/reports/the-complete-guide-to-rollups

https://twitter.com/jneu_net/status/1563199820742811649


https://twitter.com/a16z/status/1555949616406732800


https://a16zcrypto.com/measuring-snark-performance-frontends-backends-and-the-future/
https://www.youtube.com/watch?v=tg6lKPdR_e4
https://www.youtube.com/watch?v=cMAI7g3UcoI
https://people.cs.georgetown.edu/jthaler/ProofsArgsAndZK.pdf


OMGOMGOMG use the UTXO model for parallel processing
https://twitter.com/eshita/status/1546911467936440320




https://twitter.com/jon_charb/status/1555403452485861377
https://members.delphidigital.io/reports/the-complete-guide-to-rollups

https://vitalik.ca/general/2022/08/04/zkevm.html
^^ explainer on all the zk EVMs

TODO: ask Sreeram how 2 million dydx tx fit into 10 mb/s of DA:
https://twitter.com/apolynya/status/1517137629334056960



https://www.youtube.com/watch?v=VKo00zQT0-E
https://twitter.com/Scroll_ZKP/status/1554060160674701315
https://twitter.com/Scroll_Intern_/status/1554643436531499008

https://www.youtube.com/watch?v=4asIQyWwGko


https://medium.com/starkware/starknet-alpha-2-4aa116f0ecfc


https://twitter.com/bkiepuszewski/status/1540793333295075329
https://twitter.com/gluk64/status/1539953204900790272
https://twitter.com/gluk64/status/1539953208486936580
https://twitter.com/gluk64/status/1539953212148654080
https://twitter.com/gluk64
- start collecting notes about different solutions - like starkware having vendor lock-in!

https://blog.celestia.org/introducing-sovereign-rollups-to-developers/

- ask starkware about cairo, zkEVM, Solidity & the Eth state merkle patricia trie
    https://discord.com/channels/793094838509764618/793094838987128844/997172632321544194
    https://discord.com/channels/793094838509764618/793094838987128844/997349007808536616


- read about ZK
    https://blog.matter-labs.io/zksync-2-0-hello-ethereum-ca48588de179
    ask pseudotheos about the zkEVM
        https://twitter.com/messages/743025386720747520-1458046241644892163
    https://www.youtube.com/watch?v=DT8g3veR17k
    https://consensys.net/blog/blockchain-explained/zero-knowledge-proofs-starks-vs-snarks/
    https://docs.zksync.io/zkevm/#general
    https://mirror.xyz/toddz.eth/8HPDEpf7FbirLbXJFeEfI719hN0w-VKITSs1NUgyFFE
    https://www.alchemy.com/overviews/zkevm
    https://www.google.com/search?q=zkevm&oq=zkevm&aqs=chrome.0.69i59j0i512l4j69i61l3.859j0j7&sourceid=chrome&ie=UTF-8
- read the celestia links in blockchain.md
    https://www.youtube.com/watch?v=6uLlTLE7qrQ&list=PLM-Xjhvin-uWN9ov74srLZIuJsbRSc2ou
    https://www.youtube.com/watch?v=4L30t_6JBAg
    https://www.youtube.com/watch?v=TyJp4pqB6u4
    https://blog.matter-labs.io/evaluating-ethereum-l2-scaling-solutions-a-comparison-framework-b6b2f410f955
    https://blog.matter-labs.io/zkrollup-vs-validium-starkex-5614e38bc263
- the hard forking question
    - also understand what enshrining means
        https://twitter.com/apolynya/status/1507586019171835905
        https://twitter.com/apolynya/status/1511623759786307586
        https://forums.minaprotocol.com/t/enshrined-rollups-in-core-protocol/5676
        https://www.google.com/search?q=what+is+an+enshrined+rollup&oq=what+is+an+enshrined+rollup&aqs=chrome..69i57j33i160l4.4439j0j7&sourceid=chrome&ie=UTF-8
    https://www.reddit.com/r/ethereum/comments/vrx9xe/comment/if7auu7/


https://twitter.com/fuellabs_/status/1480674488077275136




████████████████████████████████████████████████ on the Ethereum state trie

BIG PROBLEM: eth state limits in terms of tps & slowing throughput?
Péter Szilágyi - Ethereum in numbers: Where TPS meets physics
https://www.youtube.com/watch?v=TdsaVoJiy3g

https://github.com/cosmos/cosmos-sdk/issues/6071

https://www.youtube.com/results?search_query=ethereum+state+trie+growth

https://ethereum.org/en/developers/tutorials/merkle-proofs-for-offline-data-integrity/

https://blog.ethereum.org/2015/11/15/merkling-in-ethereum/

https://ethereum-magicians.org/t/protocol-changes-to-bound-witness-size/3885

https://mirprotocol.org/blog/Reducing-state-size-on-Mir

https://www.google.com/search?q=cosmos+state+account+merkle+proof&sxsrf=ALiCzsYYRr3PldZfQdWeqKJqNDjV6ger5A%3A1657725685322&ei=9eLOYsyNE-yGxc8P4ciC0Ao&ved=0ahUKEwiM3O60lfb4AhVsQ_EDHWGkAKoQ4dUDCA4&uact=5&oq=cosmos+state+account+merkle+proof&gs_lcp=Cgdnd3Mtd2l6EANKBAhBGAFKBAhGGABQ4wFYpAhg_QloAXAAeACAAcUBiAGmCZIBAzAuOJgBAKABAcABAQ&sclient=gws-wiz

https://medium.com/@eiki1212/ethereum-state-trie-architecture-explained-a30237009d4e


"Fifth, Ethereum storage layout carries a huge overhead. The Ethereum storage layout highly relies on Keccak and a huge MPT[4], both of them are not zk-friendly and have a huge proving overhead. For example, Keccak hash is 1000x larger than Poseidon hash in circuit. However, if you replace Keccak with another hash, it will cause some compatibility problems for the existing Ethereum infrastructure."
https://scroll.io/blog/zkEVM


Accounts are integers and the state tree should reflect that - doesnt need to be a trie based on crypto addresses


████████████████████████████████████████████████ EigenLayr



concern for using ETH instead of native token for staking
https://twitter.com/sreeramkannan/status/1555425874828095488


1.3mb/s data availability for celestia requires 1gb/s speed

- unsure:
    - not sure if the historic record of blocks should be:
        - incentivized
            - perhaps for Headjack it should be baked into the protocol the way Arweave does it?
        - not incentivized
        - scrapped altogether - and put historic hashes in the actual state - making it bigger
    - what finality guarantees do I want?
    - throughput requirements
    - big question regarding scale: should the interest graph go on-chain?
        - historical storage not necessary about the state of the interst graph - only for the proofs for anchored content (merkle root + IPFS CID)
        - in-protocol incentivization?
            https://polynya.medium.com/the-endgame-bottleneck-historical-storage-e83c101d2a7c


- transition path for my project? different DA layer and moving away from the EigenLayr smart contracts?

- DataLayr
    - is the DA layer shared by all rollups using DataLayr and will they fight for resources?
        - will many separate rollups on DataLayr share the same 10MB/s of DA throughput that has been achieved on the testnet with 100 nodes?
    - direct IPs and not using a p2p layer?
        - could DataLayr have been p2p and without public IPs?
        - how come DoS attacks are avoided too? mentioned here: https://youtu.be/OtUOXTqrSyg?t=1542

- Q: why is it hard to hard-fork a standalone chain but easier if consensus & DA are coming from Celestia?
https://twitter.com/jon_charb/status/1546501640827568128


██████ unsorted


There should be a vision for how others can capitalize on the opportunity and be the heroes


start with the problems in each page?


We need more feedback and error correction


Making physical location obsolete for the digital world


DEFRAGMENTATION !!!
Solution to the disjoint documents saved by IDMs - compaction through re-publication?
Separate messages into header and payload so that only the header could be stored for deleted items - but it would contain the metadata such as “reply_to” uri and its own uri for example



what if you used your own IDM but authorized a commercial IDM as a proxy for yours - to aggregate your actions along with those of others such that less fees are paid? or this is nonsense? there should be a way to proxy at least some bits to your own server...


streaming platforms will know how much you've watched something. They could sell that data. Apps that request it and mediate it could anonymize the user somehow? But the streaming service will have a direct IP connection with the user - unless the app acts as a bandwidth proxy?



what happens to auth tokens if you change your IDM?


What if IDMs issue the integers for credentials and they can upload onchain sparse bitmaps with these ids when revoking on behalf of users?


Think about making monetary settlements with zk proofs on top of ethereum for polls



separating the authorization (signature or authZ token) from the content is beneficial - can cache the authZ token once and reuse it for many data items



problem: fractured identities across platforms
Write about social media aggregator tools for creators - just a bandaid



For old uris where names have changed ownership - can display obsolete names with different color


elly iska6e da iztrie komentar na snimkata si - dori i da moje da bude komentirana drugade s URL... proximity matters...


The two killer apps of crypto are finance and identity, with the latter one not done properly (yet)


Web3 is the end of the host-centric internet


Offchain name registry


What if edits are disallowed from other apps? Then there will be only one entity to ask for updates. This can be a message attribute



What is a broker? IDB and not IDM?



unlocking the potential of the internet



Merging email, instant messaging & publishing - Email 2.0


claim: this is the boldest attempt at reenvisioning the web



ending the host-centric model and linking data to identity enables flexibility to rewire our interaction circuits in any way imaginable

the host-centric model is a hindrance to the evolution & composability of the digital world


"the promise of decentralized identity & media"



Composition in DeFi pales in comparison to the opportunities around data & identity.



can't be evil - reddit's hot/new/top algorithms are no longer public & open source - why not? This makes Reddit as a voting system less democratic and more opaque
recommender systems are voting systems - user choice is effectively a vote that's fed through a feedback loop which affects what gets recommended to others as well. every user choice affects the available choices for others and the algorithms that do that are opaque - this is the opposite of democratic



democratizing access to what is public anyway - ending the host-centric model



2 types of apps: sharing (anyone can download the data) and closed (host-centric)


Youtube is just video on the internet along with a recommender algo - completely unimaginative


The killer feature of digital identity & media is programmability by anyone

@mentions can also be stable! even if names (handles) change ownership



TODO: try this service to read the text out loud?
https://beta.elevenlabs.io/


IDMs could be responsible for producing "streams" of the user activity - by simply referencing all activity from other applications (applications either need to notify the IDMs or IDMs need to monitor everything - for private data they probably need to be explicitly notified?)



can produce ZKPs for off-chain counts & aggregates and submit those to transactional settlement layers as smart contract inputs



the ability to toggle the display of highlights & interlinked objects - turning plain text into a wikipedia-like page



when ingesting data, infrastructure can map the "appId/nonce" pair to "block_height/appId"
