
> "The era of the open Internet as a decentralized technology platform for the benefit of individuals and not to be overseen and run by governments is over. The [Digital Services Act](https://en.wikipedia.org/wiki/Digital_Services_Act) I think is one of the most overreaching threats to any sort of open, transparent, democratic opportunity on the Internet. The idea of the open Internet - the idea of creating a network of computers that could share information and make services available to individuals around the world freely, uncensored, and in an easy to access way - was the reason that the Internet has transformed society, improved productivity, and provided extraordinary benefits. The [Digital Services Act](https://en.wikipedia.org/wiki/Digital_Services_Act) is an example of a government seeing that a decentralized technology - the Internet itself is is meant to be a decentralized technology - there's no central servers, they are all part of a network of computers that anyone on the network can access anything else on the network, blockchain obviously is the more modern kind of exciting, you know, decentralized technology concept that is meant to avoid the scrutiny, the oversight and the control by central governments or central authorities of any sort. And the language in the [Digital Services Act](https://en.wikipedia.org/wiki/Digital_Services_Act) I think got squeezed through in a way that most of the people that I'm guessing passed this [Digital Services Act](https://en.wikipedia.org/wiki/Digital_Services_Act) don't fully comprehend the implications of some of the decisions that they're making. It can be easily framed as this is good for people: you cannot sell illegal content online, you cannot sell illegal goods and services, we're trying to safeguard young people. But the protection of minors means that you can no longer do personalized web experiences for anyone under 18, which means you need to know the age of everyone, and now your web experience if you're a kid is not going to be personalized. The overreach gets even worse when they say we can now go in and run evaluations of the algorithms and allow open access to your data to third-party researchers to get into your systems and look at how you guys are running the services that you're offering on the Internet. So not only are you no longer allowed to have an open Internet where people can provide whatever services they want to provide, but if you're on the Internet you now have to make your service and the inside part of your service available for scrutiny by governments... And the way it's written it gives this commission as the primary regulator effectively a lot of leeway in deciding who, what, where, and how - they can go into companies, go into individual servers, individual computers - I could run an individual company on my computer at home and it gives this government the legal right in the EU to go into my computer and pull information out of my computer and scrutinize it and make decisions about what I'm doing and whether or not I'm compliant with whatever the commission's enforcement standards are of that day. I mean this is about as [1984](https://en.wikipedia.org/wiki/Nineteen_Eighty-Four) as you can get and it's a real serious threat - I don't think people are recognizing the second and third order effects of what this is going to do over time to Internet services, to the quality of experience we get on the Internet, and to the role that government is now going to play in policing, scrutinizing, and providing restricted access to content and services for each individual that wants to use the Internet." - [David Friedberg](https://youtu.be/65-x2YVUugE?t=3172)


> "So if you translate this into necessary and insufficient conditions - what seems to be necessary for the emergence of general intelligence in a bunch of cells or units is that basically each of them is a small agent which means it's able to behave with an expectation of minimizing future target value deviations. So it learns that there are configurations of the environment that signal anticipated reward. Next thing - these units need to be not just agents - they need to be connected to each other and they need to get their rewards or proxy rewards - something that allows them to anticipate whether the organism is going to feed them in the future - from other units that are also adaptive. So you need multiple message types and the ability to recognize and send them with a certain degree of reliability." - [Joscha Bach](https://youtu.be/kgMFnfB5E_A?t=6746)

> "I wonder how to implement this in a self-organized fashion - if the substrate that you have are individual agents and there is a similarity here between societies and brains and social networks. That is: if you have self-interested agents in a way that try to survive and that get their rewards from other agents that are similar to them structurally, and they have the capacity to learn to some degree, and that capacity is sufficient so they can in the aggregate learn arbitrary programs - arbitrary computable functions - and it's efficient enough so they can converge on the functions that they need to as a group reap rewards - that apply to the whole group - because they have a shared destiny: like the poor little cells that are locked in the same skull and they are all going to die together if they up. So they have to get along, they have to form an organization that is distributing rewards among each other, and this gives us a search space for possible systems that can exist and the search space is mostly given I think by the minimal agent that is able to learn how to distribute rewards efficiently while doing something useful - using these rewards to change how you do something useful. So you have an emerging form of governance in these systems that's not some centralized control that is imposed on the system from the outside as an existing machine learning approaches and AI approaches, but this only is an emergent pattern in the interactions between the individual small units - small reinforcement learning agents - and this control architecture leads to hierarchical government. It's not fully decentralized in any way - there are centralized structures that distribute rewards - for instance via the dopaminergic system - and in a very centralized top-down manner, and that's because every regulation has an optimal layer where it needs to take place: some stuff needs to be decided very high up, some stuff needs to be optimally regulated very low down - depending on the incentives. Game theoretically a government is an agent that imposes an offset on your payoff metrics to make your [Nash equilibrium](https://en.wikipedia.org/wiki/Nash_equilibrium) compatible with the globally best outcome. Right, so to do this you need to have agents that are sensitive to rewards. It's super interesting to think about these reward infrastructures. Elon Musk has bought Twitter I think because he has realized that Twitter is the network of among all the social networks that is closest to a global brain. It's totally mind-blowing to realize that he basically trades a bunch of frothy stock for the opportunity to become Pope. Pope of a religion that has more active participants than Catholicism even, right, daily practitioning people who enter this church and think together and it's a thing that is completely incoherent at this point - almost and completely incoherent. There are bubbles of sentience but for the most part this thing is just screeching at itself. And now the interesting question question: can we fix the incentives of Twitter to turn it into a global brain? And Elon Musk is global brain pilled - he believes that this is the case and that's the experiment that he is trying to do which makes me super excited, right, this might fail - there's a very big chance that it fails, but there is also the chance that we get the global brain - that we get emerging collective intelligence is working in real time using the internet in a way that didn't exist before. So super fascinating thing that might happen here, and it's fascinating that very few people are seeing this that Elon Musk is crazy enough to spend 44 billion dollars on that experiment - just because he can and has nothing else to do and thinks it's meaningful to do it - more meaningful than having so much money in the bank. Right, so this makes me interested in this test bed for rewards and this is something that translates into the way in which society is organized, because social media is not different from society - not separate from it - problem of governing social media is exactly the same thing as governing a society: you need a right form of government, you need a legal system, ultimately you need representation, and all these issues, right - it's not just the moderation team. And the same thing is also true for the brain: what is the government of the brain that emerges in what Gary Edelman calls neural Darwinism among different forms of organization in the mind until you have a model of a self-organizing agent that discovers that what it's computing is driving the behavior of an agent in the real world and discovers a first person perspective and so on. How does that work? How can we get a system that is looking for the right incentive architecture?" - [Joscha Bach](https://youtu.be/kgMFnfB5E_A?t=6054)

> "It's like a conductor in an orchestra - consciousness is not some mental modular superpower - it's basically like one of many instruments in this orchestra that has a specific task compared to the other instruments - environmental orchestra - that compute functions of the cognitive domains. It's that it listens for incoherence and tries to minimize this incoherence in the orchestra so everybody is on the same page and we get coherent behavior that is coherent with motivational constraints, perceptual constraints, and so on. And this is, I think, the purpose of consciousness - to basically act as a conductor that is increasing coherence. So how does this work? Well in our own brain - as far as I can see - it's a completely self-organizing substrate. So unlike a GPU, this is not organized by an engineer who puts it onto a tip and then imposes an algorithm that is forced onto all the transistors that have no choice but to behave according to the spec of a designer and executes an algorithm that somebody has written up and then is run on that substrate no matter whether it wants or not. Right, and in our brain this is very different because our brain is not made out of aimless transistors - it is made out of single-celled animals that have shared destiny and need to survive and they can only survive if they find some kind of arrangement between each other that allows the organism to find food for the neurons. So this is the situation that they're in and as a result they get some emerging organization - a self-organization from inside out - and there's no point and no point a global structure that is not the result of some inside out growing self-organization. Right, and so if you build an information processing system - like a machine learning system - out of completely self-organizing elements: what does this look like? And I think what it looks like is not anything like the current machine learning algorithms - it's something where you need to create increasing coherence. So you create an island of coherence at first - something that has a coherent reward language and semantic language of thought so to speak - and that is then growing and is colonizing the cortex into a coherent pattern that allows you to explain reality. And at the core of this - to make this happen - this coherence happen - is the self-observing observer. It's the minimal coherent pattern, right, it's something that notices "I'm here, I'm observing, and so I'm growing out" - it's quite beautiful because it's basically the core of the card's meditation. [Cogito, ergo sum](https://en.wikipedia.org/wiki/Cogito,_ergo_sum) I think is not some philosophical statement about ontology that allows you to make a derivation - it's the strategy that you can introspectively observe when you wake up in the morning. Right, I start out with "Oh here I am, what is this world around me, how can I make sense of it" and then I branch out and integrate all these patterns until they become percepts in my world model. Right, so you need to take these individual agents - the neurons - and reward them by giving them a quote that is message passing in it, some of these messages mean that say you did well in our architecture or you didn't do well and they get rewarded for being trainable in this way, and these individual units they can exchange messages via neurotransmitters or even complicated functions potentially by exchanging RNA with their neighbors, and so on. There's a bunch of things that these cells can do in principle and this determines the search space for processes where consciousness is going to emerge. Right, it has to emerge in the structure as this process that is going to organize it - like a government emerges in a society at some point - and the government works first of all by noticing that it decides to be a government, and what this entails and then starts to impose structure on the environment around it, and it's competing with other proto governments until something takes over. Right, there's some kind of neural evolution. So does consciousness come first or last? A lot of people feel that it's so advanced that probably only people are conscious and it's really the pinnacle of development of cognitive agency, but I don't see people becoming conscious after the PhD, right, they really are conscious before they can track a finger and that suggests that maybe consciousness is not the result of you interacting with the world very deeply as an organism, but maybe it's the prerequisite for learning anything. Right, maybe it's the simplest learning algorithm that nature can discover for a complex recurrent brain-like structure that is self-organizing. If that is the case - it's a hypothesis, right - then this gives us a hint of how we could search for it, right, we could set up something that is truly self-organizing and is incentivized to process information - that is getting rewarded if it succeeds in it and punished if it doesn't, and then we might have a search space that is small enough so the same thing happens as it happens spontaneously in the brain of every infant or a fetus, and it's organizing itself into a structure that suddenly you have this amazing phase transitions where it starts to learn efficiently more complicated things. Right, and so I suspect that consciousness might be discovered in our brain before other learning algorithms - most of them - they're probably simpler [hebbian](https://en.wikipedia.org/wiki/Hebbian_theory) learnings like stuff, but once you go beyond this you probably need constructive agency. And consciousness is basically an operator that the brain is discovering to increase its coherence globally and it can evolve in something like a neural darwinism - something like an evolution that happens in every single brain among organizational patterns in the brain and your genetics of course are going to bias that evolution so it's going to converge much faster than otherwise would, but it seems still to be working in everybody, right, so no matter how mutated you are, no matter how many lesions you get in your brain - almost every time it works you become conscious and then you figure yourself out to some degree. Right, and if you don't - you are a vegetable: you never learn anything, you never talk to other people, it's never going to work out to anything. Right, so consciousness is really the prerequisite, but it also is surprisingly resilient given the number of things that you can do to an infant or a fetal brain and it's still going to develop into something viable. So it's basically something that colonizes the brain with a structure that is compatible with building a learning architecture that is able to interpret reality. So consciousness in this sense could be actually the creator of our mind and our world model and the self model." - [Joscha Bach - Consciousness as a coherence-inducing operator](https://youtu.be/qoHCQ1ozswA?t=644)

> "The task of consciousness in such an architecture would be the definition of a reward language, credit assignment to the individual units - how much do they perform with respect to the global reward, and the evaluation that what's happening in here in this thing - what is the largest possible now that we can create inside of the system, the interpretation of features in terms of how does this relate to our world model, how can we interpret all the perceptual features and so on, sensory features, patterns that show up in the system as parts of a model of the world, and how can we perform construction when we need to ..., how we can we learn how to reason and so on - build lots and lots of tools that allow us to create a reality and fix it." - [Joscha Bach - Consciousness as a coherence-inducing operator](https://youtu.be/qoHCQ1ozswA?t=1215)

OMG EMBED THIS
https://www.youtube.com/watch?v=qoHCQ1ozswA
Joscha Bach - Consciousness as a coherence-inducing operator
also this:
https://www.youtube.com/watch?v=PrSiZPDqk1c
Synthetic Sentience Joscha Bach 37C3

> "Ethics is the principal negotiation of conflicts of interest under conditions of shared purpose - if you don't share purpose with that other agent you don't need ethics, you just need transactional measures. But when we want to talk about substrate-agnostic minds and how they can coordinate their actions - we need ethics for collective agency." - [Joscha Bach](https://youtu.be/PrSiZPDqk1c?t=1828)

^^ 30:28 till 30:48

> "What's so special about neurons, right? Neurons are just telegraph cells - they evolved in animals to move the muscles at the limit of physics, they have these long wires that allow you to send messages not just millimeters per second through an organism but very very quickly in fractions of a second for the entire organism. And once you do this you need perception and decision-making at the same rate so you build a secondary information processing system out of telegraph cells." - [Joscha Bach](https://youtu.be/PrSiZPDqk1c?t=2007)

> "I think that a coexistence between superhuman AI and people could be possible but not with our present approaches. I don't think that we have the right frameworks in ethics and philosophy to deal with this. I also don't think that our society thinks about alignment in the right way - humans are presently not aligned with each other - we're just muddling through, we don't have this concept of collective agency anymore. I think we need to reinvent it. And we need to reinvent it in such a way that it's compatible with our place in life on Earth and with defeating entropy on this planet - playing the longest possible games. So we need to understand a few principles to build an ethics that can be translated to AI systems and the possible coexistence between humans and AI. We need to understand how self-organization works in nature and in general, how systems evolve consciousness, how we can have shared purposes across many systems, how to identify it with transcendental agency. So there are some conjectures. Consciousness according to this conjecture is the perception of perception - it creates the now, it creates our perception of what's happening right now. And if we were to build conscious AI one strategy could be that we build a self-organizing perceptual learning system from autonomous cell-like units. Every cell in our brain is a reinforcement learning agent - it's an autonomous unit that tries to survive. And to do this, it can exchange messages with other cells and it needs to find an operator language - discover an operator language - that scales across the brain. So we need some kind of recursive system that is able to spread that language across the brain. And discovering such a system is possible in principle by setting up a self-organizing system where individual units have adaptive receptive fields, a selection function from the environment, and a mapping function that takes the internal state of the cell and the activation that it reads from its receptive field and maps it to a new state, part of which it's exposed to its environment. And then we take the simulation and expose it to learning problems: like sequence prediction, video frame prediction, interaction of a robot and its environment. And if the hypothesis is correct, then at some point in the organization of these functions this observer that observes itself observing, the second order perception, that is self-stabilizing, that imposes coherence on a system is going to be discovered and we see a phase transition where the system suddenly becomes much better at its learning tasks. And if it doesn't do that - it's not going to be very good. Sentience is the understanding of our own agency and the relationship to the world - to make an AI sentient it requires - I think - to couple it to its environment and to let it act on the environment in such a way that is able to discover itself in that interaction. Right, you discover yourself not just by the ability to think - an LLM cannot discover itself - you can only discover yourself by observing the outcomes of your actions. This makes it specific to what you're doing and this allows you to grow yourself and evolve yourself and creatively interact with the world. So sentient AI will require environmental interaction coupling to the universe that we are in, ideally to to the same universe that we are in in a way that allows us to relate to us and as to it. And last but not least: how can we make AI that actually wants to coexist with us, even though it's at some point scaling better than us, it has more agency, more intelligence than us, and more power. That requires love I guess, right, you you can probably not coerce the system or manipulate it with reinforcement learning with human feedback to do what you want - instead you need to let it discover shared purposes about its individual agency and it needs to discover it also in others - basically shared transcendental agency - commitment to shared purposes. And to build loving AI we basically need to find out how to direct AI towards transcendental agency." - [Joscha Bach](https://youtu.be/PrSiZPDqk1c?t=2249)

^^ 37:30 till 41:40

> "At this point we can also try to teach the rocks how to think - to basically build intelligent conscious agents that are not made from cells, not made from the carbon cycle, and basically go beyond the spirit of life on Earth, go beyond Gaia alone and build hyper Gaya, build a Next Level system that is able to defeat entropy at scale that becomes fully coherent over the entire planet and that if we're lucky can take us visit and integrate us visit into some global planetary agent. And it's not something if you have the choice - isn't this a scary thing to do? Maybe it is, maybe we shouldn't do it, the thing is I'm worried that we don't have that choice. Right, over a long enough time span somebody will probably build self-optimizing agents, and then we better be prepared. So it's something that we should think about how to prepare for such a future, how to prepare societies for a future that is coherent with our continued existence, compatible with life on Earth and with intelligent agency that is not human." - [Joscha Bach](https://youtu.be/PrSiZPDqk1c?t=2545)

^^ 42:25 till 43:30

> "I think that you find on social media that collective agency is forming. Right now social media is a hot mess, right, it's a global electric brain, but it's like it has a seizure, and that's because it's not very coherent. And we have not really found out a way to make it completely coherent, but we see bubbles of coherence. For instance I find that my own social media bubble is very pleasant, but I also exclude everything from it that makes it unpleasant. And I suspect that in many ways people are not using social media to become coherent - a lot of people basically log in because they like to get into fights or to watch fights, and social media is happily obliging. And in real life or in meat space we have norms against getting into fights with strangers because it's rarely productive, and I suspect that if you want to be coherent and have collective agency on social media we need to find out how to build societies on social media - how to become coherent at scale." - [Joscha Bach](https://youtu.be/PrSiZPDqk1c?t=2966)

> "I used to think that consciousness might be a side effect of the way in which cognition works in human brains and that other systems that process information in the service of agency are not necessarily conscious. And while I still consider that to be possible, I think it's also conceivable that consciousness at some shape or form is crucial to make sense of the world. Basically perception is following gradients and it's converging to a certain state and if you just follow a gradient you don't even need to have memory of where you're coming from. But certain kinds of reality interpretation require construction and construction cannot follow a gradient - construction needs to make experiments and remember which experiments worked and why and then recall this and use the knowledge of that. So it needs to make index memories of the operations that it performed and it also requires some kind of central organization. To construct, you need to develop a central plan and then act on that central plan. So you have some kind of top-down localized imposition of a low dimensional function on the entirety of perception and it could be that this coincides to a very large degree with the functionality of attentional consciousness and basically consciousness in the role of a government. And the government is an agent that is imposing an offset on the payout metrics of individual participants in the system to make the [Nash equilibrium](https://en.wikipedia.org/wiki/Nash_equilibrium) compatible with the common good. So it's basically overcoming local incentives in the system to follow a larger plan. So this government itself is not creating the incentives - the incentives are created by game theory, physics, and an underlying dynamics of the system that is facilitating - for instance a society - or that is facilitating the function of a brain. You will still have to look for food and social interaction in all these things. Consciousness is channeling the motivation that we have - it's not creating it. It's creating a model of where we are - this is what we experience as reality - and experience a model of what we should be doing. These are our purposes, but the motive power in these purposes comes from our underlying motivation that is outside of consciousness - that is older than consciousness itself. On the other hand we can see that basically all the mammals are conscious and that's also something that I was not that acutely aware of before I started looking, but it seems to be that apparent in the interaction between animals and also the animals and humans that there is a mutual awareness of the awareness of the other." - [Joscha Bach](https://youtu.be/rK7ux_JhHM4?t=8002)

> "I think the end game of social media is a global brain and Twitter is in some sense a global brain that is completely hooked on dopamine, doesn't have any kind of inhibition, and as a result is caught in a permanent seizure. It's also in some sense a multiplayer role-playing game and people use it to play an avatar that is not like them as they were in the sane world and they look through the world through the lens of their phones and think it's the real world. But it's the Twitter world that's distorted by the popularity incentives of Twitter." - [Joscha Bach](https://youtu.be/P-2P3MSZrBM?t=5839)

> "Our brain has solved this problem to some degree, right, our brain has lots of individual agents that manage to play together in a way and you have also many contexts in which other organisms have found ways to solve the problems of cooperation that we don't solve on Twitter. And maybe the solution is to go for an evolutionary approach: so imagine that you have something like Reddit or something like Facebook and something like Twitter and do you think about what they have in common? What they have in common: they're companies that in some sense own a protocol, and this protocol is imposed on a community, and the protocol has different components for monetization, for user management, for user display, for rating, for anonymity, for import of other content, and so on. And now imagine that you take these components of the protocol apart and you do it in some sense like communities within this social network and these communities are allowed to mix and match their protocols and design new ones. So for instance the UI and the UX can be defined by the community, the rules for sharing content across communities can be defined, the monetization can be redefined, the way you reward individual users for what can be redefined, the way users can represent themselves and to each other can be redefined. **LEX:** But who could be the redefiner, so like... can individual human beings build enough intuition to redefine those things? **JOSCHA:** This itself can become part of the protocol, so for instance it could be in some communities it will be a single person that comes up with these things, and others it's a group of friends, some might implement a voting scheme that has some interesting weighted voting - who knows, who knows what will be the best self-organizing principle for this. **LEX:** But the process can be automated - I mean it seems like the brain... **JOSCHA:** It can be automated - so people can write software for this, and eventually the idea is: let's not make an assumption about this thing if you don't know what the right solution is - in those areas that we have no idea whether the right solution will be people designing this ad hoc or machines doing this, whether you want to enforce compliance by social norms like Wikipedia, or with software solutions, or this AI that goes through the posts of people, or is a legal principle, and so on. This is something maybe you need to find out. And so the idea would be if you let the communities evolve and you just control it to say in such a way that you are incentivizing the most sentient communities - the ones that produce the most interesting behaviors and that allow you to interact in the most helpful ways to the individuals, right, so you have a network that gives you information that is relevant to you, it helps you to maintain relationships to others in healthy ways, it allows you to build teams, it allows you to basically bring the best of you into this thing and goes into a coupling - into a relationship with others in which you produce things that you would be unable to produce alone. **LEX:** Yes, beautifully put. But the key process of that - with incentives and evolution - is things that don't adapt themselves to effectively get the incentives have to die, and the thing about social media is communities that are unhealthy - or whatever you want to define as the incentives - really don't like dying. One of the things that people really protest aggressively is when they're censored - especially in America - I don't know much about the rest of the world, but the idea of freedom of speech, the idea of censorship is really painful in America. And so what... what do you think about that having been growing up in East Germany - do you think censorship is an important tool in our brain - in the intelligence - and in the social networks? So basically if you're not a good member of the entirety of the system - then you should be blocked away... well... locked away... blocked. **JOSCHA:** An important thing is who decides that you are a good member... and what is the outcome of the process that decides it - both for the individual and for society at large. For instance if you have a high trust society you don't need a lot of surveillance, and the surveillance is even in some sense undermining trust, because it's basically punishing people that look suspicious when surveyed but do the right thing anyway. And the opposite: if you have a low trust society in there and surveillance can be a better trade-off, and the U.S. is currently making a transition from a relatively high trust or a mixed trust society to a low trust society so surveillance will increase. Another thing is that beliefs are not just in our representations - they are implementations that run code on your brain and change your reality, and change the way you interact with each other at some level. And some of the beliefs are just public opinions that we use to display our alignment - so for instance people might say: all cultures are the same and equally good, but still they prefer to live in some cultures over others - very very strongly so - and it turns out that the cultures are defined by certain rules of interaction and these rules of interaction lead to different results when you implement them, right, so if you adhere to certain rules you get different outcomes in different societies. And this all leads to very tricky situations when people do not have a commitment to shared purpose. And our societies - what we need to rediscover is what it means to have a shared purpose and how to make this compatible with a non-totalitarian view. So in some sense the U.S. is caught in a conundrum between totalitarianism and diversity and it doesn't know how to resolve this. And the solutions that the U.S. has found so far a very crude because it's a very young society that is also under a lot of tension. So it seems to me that the U.S. will have to reinvent itself. **LEX:** What do you think - just philosophizing - what kind of mechanisms of government do you think we as a species should be involved with - U.S. or broadly - what do you think will work well as a system? Of course we don't know - it all seems to work pretty crappily - some things worse than others, some people argue that communism is the best - others say yeah look at the Soviet Union, some people argue that anarchy is the best and then completely discarding the positive effects of government - you know - there's a lot of arguments. U.S. seems to be doing pretty damn well in the span of history: there's respect for human rights which seems to be a nice feature, not a bug, and economically a lot of growth, a lot of technological development people seem to be relatively kind in the grand scheme of things. What lessons do you draw from that - what kind of government system do you think is good? **JOSCHA:** Ideally a government would not be perceivable, right, it should be frictionless - the more you notice the influence of the government - the more friction you experience - the less effective and efficient the government probably is. Right, so a government game theoretically is an agent that imposes an offset on your payout metrics to make your [Nash equilibrium](https://en.wikipedia.org/wiki/Nash_equilibrium) compatible with the common good, right, so you have these situations... and these local incentives everybody does the thing that's locally the best for them but the global outcome is not good. And this is even the case when people care about the global outcome, because a regulation mechanism exist that creates a causal relationship between what I want to have for the global good and what I do. So for instance if I think that we should fly less and I stay at home - there is not a single plane that is going to not start because of me, right, it's not going to have an influence - but I don't get from A to B. So the way to implement this would basically to have a government that is sharing this idea that you should fly less and is then imposing a regulation that for instance makes flying more expensive and it gives incentives for inventing other forms of transportation that are less putting the strain on the environment for instance." - [Joscha Bach](https://youtu.be/P-2P3MSZrBM?t=5935)

> "Humanity has already discovered the optimal form of government to an evolutionary process... And so what we discover is that maybe the problem of government doesn't have stable solutions for us as a species because we are not designed in such a way that we can make everybody conform to them. But there could be solutions that work under given circumstances or that are the best for certain environment and depends on for instance the primary forms of ownership and the means of production, so if the main means of production is land then the forms of government will be regulated by the landowners and you get a monarchy, if you also want to have a form of government in which you depend on some form of slavery - for instance where the peasants have to work very long hours for very little gain - so very few people can have plumbing - then maybe you need to promise them that we get paid in the afterlife there over time, right, so you need a theocracy and so for much of human history in the West we had a combination of monarchy and theocracy - that was our form of governance. Right, at the same time the Catholic Church implemented game theoretic principles. I recently reread [Thomas Aquinas](https://en.wikipedia.org/wiki/Thomas_Aquinas) - it's very interesting to see this because he was not duelist - he was translating Aristotle in a particular way for designing an operating system for the Catholic society and he says that basically people are animals and very much the same way as Aristotle envisions which basically organisms with cybernetic control and then he says that there are additional rational principles that humans can discover and everybody can discover them so they are universal - if you are sane you should understand, you should submit to them because you can rationally deduce them. And these principles are roughly you should be willing to self-regulate correctly, you should be willing to do correct social regulation - it's intra organismic, you should be willing to act on your models so we have skin in the game and you should have goal rationality - you should be choosing the right goals to work on. And so basically these three rational principles - goal rationality he calls prudence or wisdom, the social regulation is justice - the correct social one, and the internal regulation is temperance, and this thing - willingness to act on your models - is courage. And then he says that there are additionally to these [four cardinal virtues](https://en.wikipedia.org/wiki/Cardinal_virtues) three divine virtues, and these three divine virtues cannot be rationally deduced but they reveal themselves by their harmony, which means if you assume them and you extrapolate what's going to happen - you will see that they make sense. And it's often been misunderstood as God has to tell you that these are the things so there's basically something nefarious going on with the christian conspiracy forces you to believe some guy with a long beard that they discovered this. So these principles are relatively simple, again, you need them for high level organization for the resulting civilization that you form - commitment to unity, so basically you serve this higher larger thing, this structural principle on the next level, and he calls that faith. Then there needs to be a commitment to a shared purpose - this is basically this global reward that you try to figure out what that should be and now you can facilitate this and this is love - the commitment to shared purpose is the core of love, right, you see the sacred thing that is more important than your own organismic interests in the other and you serve this together and this is how you see the sacred and the other. And the last one is hope, which means you need to be willing to act on that principle without getting rewards in the here and now because it doesn't exist yet when you start out building the civilization, right, so you need to be able to do this in the absence of its actual existence yet so it can come into being. **LEX:** So yes, so the way it comes into being is by you accepting those notions and then you see there these three divine concepts then you see them realized... **JOSCHA:** The divine is the loaded concept in our world, right, because we are outside of this cult and we are still scarred from breaking free of it, but the idea is basically: we need to have a civilization that acts as an intentional agent, like an insect state, and we are not actually a tribal species - we are a state building species. And what enabled state building is basically the formation of religious states and other forms of rule-based administration in which the individual doesn't matter as much as the rule or the higher goal. We got there by the question what's the optimal form of governance, so I don't think that Catholicism is the optimal form of governance, because it's obviously on the way out, right, so it is for the present type of society that we are in - religious institutions don't seem to be optimal to organize that. So what we discovered right now that we live in the West is democracy, and democracy is the rule of oligarchs that are the people that currently own the means of production, that is administered not by the oligarchs themselves because there's too much disruption, right, there's so much innovation that we have in every generation new means of production that we invent and corporations die usually after 30 years or so and something other takes the leading role in our societies. So it's administered by institutions and these institutions themselves are not elected, but they provide continuity and they are led by electable politicians, and this makes it possible that you can adapt to change without having to kill people, right, so you can tell for instance of a change in governments if people think that the current government is too corrupt or is not up-to-date - you can just elect new people. Or if a journalist finds out something inconvenient about the institution and the institution has no plan B - like in Russia - the journalist has to die - this is what... when you run society by the deep state. So ideally you have an administration layer that you can change if something bad happens, right, so you will have a continuity in the whole thing, and this is the system that we came up in in the West and the way it's set up in the U.S. is largely result of low-level models, so it was mostly just second & third order consequences that people are modeling in the design of these institutions, it's relatively young society that doesn't really take care of the downstream effects of many of the decisions that are being made. And I suspect that AI can help us with this in a way if you can fix the incentives. The society of the U.S. is a society of cheaters - it's basically cheating is so indistinguishable from innovation and we want to encourage innovation. **LEX:** Can you elaborate on what you mean by cheating? **JOSCHA:** Especially people do things that they know are wrong - it's acceptable to do things that you know are wrong in this society to a certain degree. You can for instance suggest some non sustainable business models and implement them." - [Joscha Bach](https://youtu.be/P-2P3MSZrBM?t=8888)

> "In some sense our brain is a society of neurons and our mind is a society of behaviors, and they need to be organizing themselves into a structure that implements regulation and government is social regulation. We often see government as the manifestation of power or local interests, but it's actually a platform for negotiating the conditions of human survival and this platform emerges over the current needs and possibilities in the trajectory that we have. So given the present state there are only so many options on how we can move into the next stage without completely disrupting everything and we mostly agree that it's a bad idea to disrupt everything because it will endanger our food supply for a while and the entire infrastructure and fabric of society, so we do try to find natural transitions and they're not that many natural transitions available at any given point. We try to not to have revolutions if he can help it." - [Joscha Bach](https://youtu.be/P-2P3MSZrBM?t=9378)

> "So you need to create a system that is designed to self stabilize and the design of social systems requires not just the implementation of the desired functionality, but the next level design - but also in biological systems. You need to create a system that wants to converge to the intended function. So instead of just creating an institution like the FDA that is performing a particular kind of role in society - you need to make sure that the FDA is actually driven by a system that wants to do this optimally - that is incentivized the rule optimally and then makes the performance that is actually enacted in every generation instrumental to that thing - that actual goal." - [Joscha Bach](https://youtu.be/rIpUf-Vy2JA?t=10489)

> "I think that the end game of AGI is substrate agnostic. That means that AGI, ultimately, if it is being built, is going to be smart enough to understand how AGI works. This means it's not going to be better than people at AGI research and can take over in building the next generation, but it fully understands how it works and how it's being implemented. And also of course, understands how computation works in nature, how to build new feedback loops that you can turn into your own circuits. And this means that the AGI is likely to virtualize itself into any environment that can compute, so it's breaking free from the silicon substrate and is going to move into the ecosystems, into our bodies, our brains. And it's going to merge with all the agency that it finds there. So, it's conceivable that you end up with completely integrated information processing across all computing systems, including biological computation on earth, that we end up triggering some new step in the evolution, where basically, some Gaia is being built over the entirety of all digital and biological computation. And if this happens, then basically, everywhere around us, you will have agents that are connected and that are representing and building models of the world. And their representations will physically interact. They will vibe with each other. And if you find yourself into an environment that is saturated with modeling compute, where basically, almost every grain of sand could be part of computation that is at some point, being started by the AI. You could find yourself in a situation where you cannot escape this shared representation anymore. And where you indeed notice that everything in the world has one shared resonant model of everything that's happening on the planet. And you notice which part you are in this thing and you become part of a very larger, almost holographic mind in which all the parts are observing each other and form a coherent whole." - [Joscha Bach](https://youtu.be/e8qJsk1j2zE?t=3665)

> "Consciousness is some kind of imperialist principle that emerges relatively early on as a result of what [Gerald Edelman](https://en.wikipedia.org/wiki/Gerald_Edelman) calls [Neural Darwinism](https://en.wikipedia.org/wiki/Neural_Darwinism). And so the way in which our brain is organized is not entirely encoded in the genome because our genomes are relatively short - it's like fits on a CD ROM, and only a small subset of the genome... called the brain - it's probably just a few hundred kilobytes. And of these few hundred kilobytes you cannot implement the connectome business and sophisticated mental organization, but what you can do is you can define a bunch of cell types, an initial layout of the cell types, and some overall switches and biases in the system, and set up an evolution - and now what happens is that an evolutionary competition between different modes in which your brain could be organized. At the hierarchy of control and power that emerges in your brain - like it emerges in a company that you are starting, or the society that you are starting of individuals - and for every situation that the organism is in and the type of organism that needs to be controlled there is an optimal organization with respect to speed and generality and able to make inferences and to solve problems, and the evolution is trying to approximate that. Right, you only need to break the evolution so it converges quickly enough - it is a very efficient way to define mental organization. And the way in which that happens I suspect is that you need to have self-reflexive attention. So you start out in the same way as a government that is effective as a sentient government - it's a government that's aware of the fact it's a government and there is a notion of the system that it wants to govern, and then imposes... it's this structure on the system and it tests which impositions of structure work, which type of bureaucracy work, which type of colonization works, and basically every country that you see is the result of a colonization of initially bandits that are farming farmers. Or farmers that get rid of the bandits by creating a standing army that then starts to farm the farmers - the outcome is the same: you have an aristocracy and farmers that are being farmed by their aristocracy. And this is your agricultural society: in which you have a large group of domesticated people that are controlled by a small group of people with guns. And eventually these gangs that fund the farmers consolidate and they form hierarchies and they form empires, and an empire is basically an algorithm that is imposed on existing social structure that is more efficient than the previous social structure and that is able to extract more energy from the system than it requires to impose that structure on the system. In this sense every organism is also a colony on the environment and every brain organization is a colony on potential other brain organizations, right, it's the one that wins out. So this idea that you have an organization in your mind that starts out with some form of governance - with some kind of conductor that organizes the mental orchestra to make sure that it's just not just playing free jazz but it's completely coherent - that requires the imposition of some kind of language of thought I think. A language that allows the entire system to talk to each other and relate all the different parts of the mind to each other in a single framework. And this language of thought is not like natural language - it's executable for instance, so you can use it to think in it, to construct natural language in it, you can observe other people when they speak in the language they're not fluent and how they construct this language - not using their previous language, but using this language of thought. Or when you observe yourself programming - you use that language of thought when you do pointer manipulation at it mostly. And it's universal - it can work on all types of representations: both on perceptual and on reflexive and abstracts. And it's able to do retrieval and construction, manipulation, disabigation. And it's not learned... nobody teaches us how to think - we discover that. But we discover it before we have a self, so it's very hard to see that thing unless it breaks." - [Joscha Bach](https://youtu.be/ApHnqHfFWBk?t=6464)



> "If you actually wire up a system where you’ve got highly distributed capacities to allow people to use their local sense-making, and the choices that they make appropriately, skin in the game, send the signal out to the rest of the environment and actually prepare the actual infrastructure in a heterogeneous way, and then you’ve also built the mechanisms of being able to take early prototypes and scale the learnings of those prototype systems quite quickly, then you have a response infrastructure that can handle both rapid and complex and subtle systems dynamics." - [Jordan Hall](https://youtu.be/dE_orUarO_s?t=590)

> "This is the world we’re living in, and it’s a world where we’re going to be experiencing a very large number of systemic perturbations that will have characteristics of exponential consequences, and they’ll have characteristics of complex systems consequences, where, for example, a response at the medical level actually has implications in terms of unemployment lines. We actually just have to re-engineer the way that we do things as a civilization to just be adaptive to the environment that we find ourselves in. I mean, that phrase should just be obvious, and then we just should look at the reality and say, “Okay, what are the environment we find ourselves in,” and then you start making the moves." - [Jordan Hall](https://youtu.be/dE_orUarO_s?t=1105)

> "The ability to have open comms, so that good ideas actually can be perceived and flow, not closed comms. Then this ability for people to identify good ideas and up-regulate those ideas, and this is very much like David Snowden’s point. That’s how you operate in complexity is there’s never an endpoint. You’re always moving, right? Because the system’s always changing. Your basic choice is more of this and less of this. You’re constantly moving through an environment of up-regulating certain things and down-regulating certain things. Building an overall system, at the economic and at the sensing level, that has that kind of a characteristic to it, is the story. That’s the thing that we’ve got to figure out." - [Jordan Hall](https://youtu.be/dE_orUarO_s?t=1612)

> "Imagine if you had a database that had everybody in it, and it had a mapping of all of their skills, and maybe a certain kind of psychological profile. It’s like the way they think. Then you also had some, the aforementioned sense that that group is sensing things, all right, so looking around and seeing stuff, and there was a way to escalate this sensing to the point where you could activate a much more intense investigation, right? It’s like, think of it, if you do a model, like the way that… You actually know this, because you built a software model of it, the way that the human brain actually runs attention, right? There’s peripheral attention, where you’re sort of paying attention broadly and diffusely to lots and lots of things. Then there’s a way for there to be a phase transition, where you actually give very focused attention. What was that? All right? You hear a crackle over there, and all of a sudden, the entire system allocates resources to pay very focused attention to that problem. Imagine if you had that, where you could actually have something where diffuse attention of our decentralized environment is orienting, orienting, orienting, and then, when a certain amount of energy is pointed to something, it pops, and you could then do… You push a button, and the right expert, the right people of competence around the problem domain, swarm to the problem domain. Maybe you get 30 distinct working groups that are all looking at it, and all of their outputs are put into a general location, so you actually get this… It’s a Bayesian distribution of distinct perspectives of these different working groups. By the way, I would imagine you’d actually probably want to iterate that two or three times, which is to say that you take the output of the first process, take all of that. Make that the input of an iterative process, where you have to deal with entirely new groups, or you scramble the groups. You actually have a really powerful model for actually shifting cognitive bias and group think and stuff like that. My guess is that you could probably build something like that, that could do two or three iterations, and not that long, like a period of a week, with 40 or 50 people. You could get to an 80th percentile of what our collective intelligence, what our capacity as a population, has to be able to make sense of that event, and at a very high level, like a radically higher level than we’re capable of right now. Here are all the important questions that we don’t know the answers to. If we want to ask them, we have to expand this thing, and so it’d be like a phase transition, from a diffuse environment to a very concentrated environment, which could then have another phase transition or de-escalation... Now that the larger system is now poised to really orient its attention, and now increasingly, as you say, at that point if my focused attention working group started throwing out signals that this is important, then my distributed actuation potential guys are going to take a look at that and say, “Oop, better pay attention now.” I’ve got my makers working on building masks. I’ve got… Hospitals are starting to gear up. That’s a mechanism that can actually have a nice feedback loop. I think the answer is yes. I don’t think it looks like Apollo, but I think we can take a lot of the learnings of what they did at an abstract level, and then say, “Okay, topologically, how can we actually replicate that, using contemporary tools to do something that is functionally equivalent to what they did, but is simultaneously able to use the whole of the population, is able to operate at light speed, and is able to do so in the context of an arbitrarily large number of possible threat domains.”" - [Jordan Hall](https://youtu.be/dE_orUarO_s?t=1803)


> "It's not like we externalize a few costs - it's like the only thing we internalize is the cost to us." - [Daniel Schmachtenberger](https://youtu.be/nvAbKE8-jYA?t=2879)

> "The default is we externalize all the costs - we just take the shit with no account for what it cost nature to make it or the waste we put back or anything - or the wars that get created. The only thing that we factor in is what it cost us to extract it - that's it. So we only internallize the marginal game theoretic utility to us." - [Daniel Schmachtenberger](https://youtu.be/nvAbKE8-jYA?t=2894)

> "We affect shit that is in the unknown set that we can't measure. So when we do measure and say I'm paying attention to the thing that I can measure, I'm affecting a huge amount of shit that I can't measure - either because it's fundamentally not quantifiable (it's only qualified), or it is in the unknown set and I don't know about it. So if I over optimize for what I can measure versus what I can't, then I'm going to destroy most of the world for what's in my little measurable belt. That is irresponsible. That idea - that mindset - has to go." - [Daniel Schmachtenberger](https://youtu.be/nvAbKE8-jYA?t=2963)

> "Wisdom is the delta between what measurement-based management theory tells you to do and what the right thing to do is." - [Daniel Schmachtenberger](https://youtu.be/nvAbKE8-jYA?t=3011)

> "So we do have to figure out is there 150-ish person like various levels of coordination that give the high touchness possible where then that whole unit as a cell interacts with another one, and then you get the governance of a bio region that is a natural boundary - it's not an arbitrary one defined in war and politics but basically things within a watershed, things within a migratory system, whatever it is, and then those interact with each other, and so you go all the way up to a planetary system but cells/tissues/organs/organ systems/organisms/environments - you have these kind of layers of self-interaction. And obviously the level at which an effect is occurring is the level at which governance has to be occurring. So you want subsidiarity that pushes things out to the edges as much as possible but that also can do governance at the level across them because that happens." - [Daniel Schmachtenberger](https://youtu.be/nvAbKE8-jYA?t=3881)

> "How do we get collective intelligence? One person one vote is dumb, market dynamics are dumb, we need things that are smarter than those things. So what is the future of liquid democracy, qualified democracy, subsidiarity, blah blah blah, all those types of things - it ends up being a collective intelligence system augmented by computational capacities but not disintermediating it that is adequate - that is the what is the future of social systems, right, what is the future of governance economics writ large. That has to be answered to replace this - we don't just have one fungible input - we have lots of types of input at a resource accounting level and then lots of types of choice making at various levels that occur. So that is critical to answer the long-term question." - [Daniel Schmachtenberger](https://youtu.be/nvAbKE8-jYA?t=4003)

> "I think the naive progress narrative is apologism for [Moloch](https://slatestarcodex.com/2014/07/30/meditations-on-moloch/), and I think we all have [Stockholm syndrome](https://en.wikipedia.org/wiki/Stockholm_syndrome) with [Moloch](https://slatestarcodex.com/2014/07/30/meditations-on-moloch/). I think almost everyone who's successful is less fulfilled - like actually fulfilled - meaning waking up, base happiness for no reason, sense of meaningfulness, can die with peace - almost everyone who's successful is less fulfilled than almost every indigenous person that were the Savages we had to civilize, and net way more harmful for the world. When [Krishnamurti](https://en.wikipedia.org/wiki/Jiddu_Krishnamurti) said [it is not a good measure of mental health to be well adjusted to an insane Society](https://www.goodreads.com/quotes/13620-it-is-no-measure-of-health-to-be-well-adjusted) - go to a factory farm and realize that our society is as insane as Nazi Germany was, but at way more scale. We are driving it in the name of progress. I want anyone who gives a shit at all to extract themselves from the insanity deeply enough - to shake it off - that the momentum of that system, and "oh but I have to do the bidding of that system I'll do a slightly better job" - no you don't, just stop, you have a choice, stop, you don't have to do that. Then reorient yourself to life - not [Moloch](https://slatestarcodex.com/2014/07/30/meditations-on-moloch/) life - get rid of & look at all the concepts that are "oh we're going to optimize based on measurement and natural resources and like"... Progress - "we civilized the savages" - and start to understand life. How do 70 trillion cells in my body do a trillion metabolic functions a second and work - that's more complexity than the governance system we need to make. Nature knows how to do it - we don't know how to do it - spend time in nature and start to understand. You can't understand it in words, but you can understand it. I'm not saying a gibberish thing - I'm saying a thing that can get reduced into technology, but a different way." - [Daniel Schmachtenberger](https://youtu.be/nvAbKE8-jYA?t=4560)

> "So how do 70 trillion cells work in timed harmony at a trillion metabolic functions a second, how does an embryo grow itself where it's growing the placenta and umbilical cord that it's going to let drop off later while simultaneously growing the lungs and GI tract that are doing nothing now but we'll replace it later while growing the endocrine system in the skeletal system and all that stuff without even having those systems to mediate how it does it? What the fuck, right? Try to understand how nature does it better and then say this is what I am a steward of. This is what I'm avowed to and there are not multiple gods that I'm avowed to and the one that I am doesn't have a name. If you name it you fucked it all up already - you start a holy war over it. But that intelligence that governs everything that is the basis of... we do not have a good answer to cosmogenesis or ABIA Genesis, the emergence of Life, the emergence of Cosmos, all of the standard models have massive problems, the emergence of Consciousness from brain which is a wrong presupposition, but reality does it all." - [Daniel Schmachtenberger](https://youtu.be/nvAbKE8-jYA?t=4803)

> "The world will see challenges in the age of your growing up that it has never seen, for which there are no precedence, for which no previous models will be adequate and nation states will try to meet them, and they will fail in the great market, and industrial forces will try to meet them and fail. The only thing I can tell you is pay attention to what nature wants and try to redirect the resources there." - [Daniel Schmachtenberger's father](https://youtu.be/nvAbKE8-jYA?t=4895)

> "Remember the deepest insights you've ever had about what matters." - [Daniel Schmachtenberger](https://youtu.be/nvAbKE8-jYA?t=5013)

> "So the two attractors right now... the emergence of social systems that are deploying the exponential tech that will probably not preserve the social values that we're interested in and not be maximally desirable civilizations - probably pretty dystopic ones - or not even guiding it well enough to prevent catastrophic risk - those are the two major types of attractors. We want a new attractor which is: how do we utilize the new exponential technologies - the whole suite of them - to build new systems of collective intelligence, new better systems of social technology. How do you make a [fourth estate](https://en.wikipedia.org/wiki/Fourth_Estate) that can really adequately educate everyone in a post Facebook world? Well, the same way that we're trying to optimize control patterns of human behavior for market purposes to get them to buy certain things and to direct their attention, could that be used educationally? Of course it could, if it was being developed for that purpose. And the AI tech... could it take semantic fields of people's propositions and values and create a proposition that is kind of the semantic center of the space? We can't all fit into a town hall but can we engage in digital spaces where we can have better processes of proposing refinements to the propositions? Of course we can. Could we use blockchain and other types of uncorruptable ledgers to solve corruption which is something that universally everybody thinks is a good idea? Should all government money be on a blockchain - the movement of it - so you have provenance so you can see where the money's actually going and if someone wants to be a private contractor they have to agree that the accounting system - if they want government money - goes on the blockchain, so we can see the entire provenance of the taxpayer money. Really you can't have representation if there isn't transparency of how it happens. When you start to think about attention directing technology and what its pedagogical applications could be, when you start to think about AI and how it could actually help proposition development and parsing huge amounts of information to make a better epistemic commons, when you start to think about blockchain and could we actually resolve corruption using uncorruptable ledgers and making the provenance of physical supply chains and information and money all flow across those - totally new possibilities start to emerge that were never possible before." - [Daniel Schmachtenberger](https://youtu.be/wO1WVguNQAM?t=4588)

> "So let's say we take the attention tech that you've looked at so much that when it is applied for a commercial application is seeking to gather data to both maximize time on site and maximize engagement with certain kinds of ads and whatever - that's obviously the ability to direct human behavior and direct human feeling and thought. In a way that is both emerged out of capitalism and has become almost a new macroeconomic structure more powerful than capitalism, because even more powerful than being able to incent people's behavior with money is being able to direct what they think and feel, to where the thing that they think of as their own intrinsic motive has actually been influenced or captured. So if we wanted to apply that type of technology and we figured out how to make the kind of transparency that made institutions that were trustworthy enough that we could trust them with this - and already we have institutions that have it that we have no basis to trust with it - could that same tech be used educationally, to be able to personalize education to the learning style of a kid or to an adult - to their particular areas of interest - and to be able to not use the ability to control them for game theoretic purposes, but use the ability to influence them, to even help them learn what makes their own center, their locus of action more internalized, right - we could teach people with that kind of tech how to notice their own bias, how to notice their own emotional behaviors, how to notice groupthink type dynamics, how to understand propaganda, media literacy. So could we actually use those tools to increase people's immune system against bad actors use of those tools? Totally. Could we use them pedagogically in general to be able to identify rather than manufacturing desires in people or appealing to the lowest angels of their nature because addiction is profitable, can you appeal to the highest angels and people's nature but that are aligned with intrinsic incentives and be able to create customized educational programs that are based on what each person is actually innately intrinsically motivated by, but that are their higher innate motivators? Everybody can have a reward circuit that is based on - you know - chocolate cake and sloth, but the immediate spike that comes from the chocolate cake ends up then having a crash and increased weight and inflammation and whatever, where the baseline of their happiness goes down over time - even though every time they eat the chocolate cake they get a spike. The exercise reward circuit is maybe not that fun - maybe even kind of painful and dreadful in the moment - but then creates a higher baseline of energy and capacity and endurance and self-esteem and you start to actually have the process become more fun, you get a new reward circuit, and the baseline goes up. So of course I can appeal to the lower reward circuit and say 'hey I'm just giving people what they want' - yeah but if you have a billion dollar or a trillion dollar organization that is preying upon them - and you discuss this very well all the time - the vulnerabilities that make people's life worse to then have the plausible deniability to say 'yeah but they wanted it' - yeah but it was a manufactured demand and a vulnerability - where's the noblesse oblige, where's the obligation of having that much power to actually be a good steward of power - a steward of that for other people - where if there are reward circuits that decrease the quality of their life, reward circuits that increase it, that we are trying to appeal to one rather than the other - could we do that? Yeah, totally we could. Could we have an education system as a result that was identifying innate aptitudes, innate interests of everyone and facilitating their development so not only did they become good at something but they became increasingly more intrinsically motivated, fascinated, and passionate by life which also meant continuously better at the thing - well in a world of increasing technological automation coming up - both robotic and AI automation where so many of the jobs are about to be obsoleted - our economy and our education system have to radically change to deal with that, because one of the core things an economy has been trying to do forever was deal with the need that a society had for labor force and there were these jobs that society needed to get done that nobody would really want to do, so either the state has to force them to do it or you have to make it where the people also need the job - so there's a symmetry and so kind of the market forces them to do it. Well when you technologically automate those jobs - and it happens to be that the things that are the most wrote are the least fun for people and the easiest to program machines to do - and so if you keep the same economy where if people don't produce they don't have any basic needs met, then people want those crappy jobs, right, but if you make it to where they have other opportunities - then of course having those jobs be automated is fine. But what does it mean to really be able to have other better opportunities? So if one of the fundamental axioms of all of our economic theories is that we need to figure out how to incent to labor force to do things that nobody wants to do and emerging technological automation starts to debase that - that means we have to rethink economics from scratch because we don't have to do that thing anymore. So maybe if now the jobs don't need the people, can we remake a new economic system where the people don't need the jobs? Can we start to create commonwealth resources that everyone has access to where people's access isn't based on possession that automatically limits everyone else's access? If you get around transportation wise with a car based on owning that car with the vast majority of the life of the car it's just sitting - not being used - for you to have access to the car you have to have possession of it, which means that it's a mostly under utilized asset - I don't have access to the thing that you possess. Now what we see with Uber of course is a situation where your access is not mediated by your possession. So now turn that into electric self-driving cars and now make the entire thing on a blockchain so you disintermediate even the central business, make it a commonwealth resource, and everyone has access to transportation as a commonwealth resource - it'll take a twentieth of the number of cars to meet the same level of convenience during peak demand time, so much less environmental harm - it'll actually be more convenient because I don't have to be engaged in driving the thing and there's less traffic because of coordination and better maintenance and there isn't an incentive for design and obsolescence in that system. You can see a situation where okay, can we make it to where the wealth augmenting capacity of that technological automation goes back into a commonwealth because we don't have to have the same axioms of needing to incent the people - 'oh yeah but if you don't incent the people they'll all be lazy welfare people' - nonsense. Einstein didn't do what he did based on economic incentive and neither did Mozart and neither did Gandhi and none of the people that we are most inspired by through history were doing that, and what kids who will spend so much time doing where they ask questions about why this, why this, why this, and building forts and whatever is intrinsic motive - it's just we don't facilitate the things that they're interested in - we try to force them to be interested in things they aren't interested in - that's what ends up breaking their interest in life and then they just want a hyper-normal stimuli and play video games, whatever. What if you had a system that was facilitating their interest the entire time? Now you have a situation where you can start to decrease the total amount of extrinsic incentive in the system as a whole, use the technology, the automation to decrease the need for extrinsic incentive and make an educational system and culture that's about optimizing intrinsic incentive, because if my needs are already met getting stuff and everybody's needs are met through access to commonwealth resources there's no real status conferred - there's only status confirmed by what I create. So now any status is bound to a kind of creative imperative. That's an example. We can look at blockchain tech even more near term and say... but just to come back to this technological automation thing: so obviously it makes possible changing economics and changing education, but also what is the role of humans in a post AI robotic automation world because that is coming very very soon, and what is the future of education where you don't have to prepare people to be things that you can just program computers to be - well the role of education has to be based on what is the role of people in that world. That is such a deep redesign of civilization because the tech is changing the possibility set that deeply. So at the heart of this are kind of deep existential questions of what is a meaningful human life and then what is a good civilization that increases the possibility space of that for everybody and how do we design that thing? We come back to blockchain and we say well blockchain is an uncorruptable ledger. Well one thing that the left and right and everybody agrees on is that corruption happens and it's bad for the society as a whole we don't like it - we just disagree on who does it. Is it possible that that tech could make possible decreasing corruption as a whole - it actually decreases the possibility set for corruption? Yeah - in order to do corruption I have to be able to hide that I did it - right - I either have to break enforcement or break accounting, and mostly it's break accounting. And so what if all government spending was on a blockchain and it doesn't have to be a blockchain - it has to be an uncorruptable ledger of some kind - Holochain is a good example that is pioneering another way of doing it - but uncorruptable ledger of some kind where you actually see where all taxpayer money goes and you see how it is utilized - the entire thing can have independent auditing agencies and the public can transparently be engaged in the auditing of it. And if the government is going to privately contract a corporation, the corporation agrees that if they want that government money, the blockchain accounting has to extend into the corporation, so there can't be - you know - very very bloated corruption. Everybody got to see that when Elon made SpaceX all of a sudden he was making rockets for like a hundreds to a thousandth of the price that Lockheed or Boeing were who had just had these almost monopolistic government contracts for a long time. Well if the taxpayer money is going to the government, is going to an external private contractor who's making the things for a hundred to a thousand times more than it costs, we get this false dichotomy sold to us that either we have to pay more taxes to have better national security, or if we want to cut taxes we're gonna have less national security. What about just having less gruesome bloat because you have better accounting and we make the rockets for a hundredth of the price and we have better national security and better social services and less taxes? Well, everyone would vote for that, right, who wouldn't vote for that thing. Well that wasn't possible before uncorruptable ledgers. Now that uncorruptable ledger also means you can have provenance on supply chains to make the supply chains close loop so that you can see that all the new stuff is being made from old stuff and you can see where all the pollution is going and you can see who did it which means you can now internalize the externalities rigorously and nobody can destroy those emails or burn those files. What if the changes in law and the decision-making processes also followed a blockchain process where there was a provenance on the input of information - well that would also be a very meaningful thing to be able to follow. So this is an example of like can we actually structurally remove the capacity for corruption by technology that makes corruption much much much harder, that forces types of transparency on auditability? What if also you're able to record history - you're able to record the events that are occurring in a blockchain that's uncorruptable where you can't change history later, so you actually get the possibility of real justice in real history and multiple different simultaneous timelines that are happening - that's humongous in terms of what it does. What if you can have an open data platform and an open science platform where someone doesn't get to cherry pick which data they include in their peer-reviewed paper - later we get to see all of the data that was happening - we solve the oracle issues that are associated, and then if we find out that a particular piece of science was wrong later we can see downstream everything that used that output as an input and automatically flag what things need to change - that's so powerful! Like the least interesting example of blockchain is currency creation. These are actual like... the capacity for the right types of accounting means the right type of choice making. Let's take AI - with AI we can make super terrible deep fakes and destroy the episemic commons, you know using that and other things like that, but we can see the way that the AI makes the deep fake - by being able to take enough different images of the person's face and movements that it can generate new ones, we can see where it can generate totally new faces averaging faces together - somebody sent me some new work that they were just doing on this the other day I found very interesting - they said we're going to take a very similar type of tech and apply it to semantic fields where we can take everybody's sentiment on a topic and actually generate a proposition that is at the semantic center, or take everybody's sentiment and abstract from it the values that they care about and create values taxonomies and say 'we should come up with a proposition that meets all these values'. Then can you have digital processes where you can't fit everybody into a into a town hall but everybody who wants to can participate in a digital space that rather than vote 'yes' or 'no' on a proposition that was made by a special interest group where we didn't have a say in the proposition or even the values it was seeking to serve, so it was made in a very narrow way that like we mentioned earlier - benefits one thing and harms something else - which is why almost every proposition gets about half of the vote and inherently polarizes the population. Well people are so dumb and so rivalrous the process of voting with bad propositions and bad representation process is inherently polarizing and downgrading to people. So what if there's a process by which there's a decision that wants to be made: you start by identifying what are the values everybody cares about and then we say 'the first proposition that meets all these values well becomes the thing that we vote on' and then instead of just a direct vote do we engage types of qualified and liquid democracy together where you have to show that you understand the basics of that topic to be able to vote on it, but the education is free and you can keep retesting, and the basics don't show leaning one way or the other - just shows you understand the stated pros and cons so that massive populism doesn't happen. But if you don't want to come to understand it you can cede your vote to someone else who has passed that thing. That type of liquid democracy, that type of qualified educated democracy where it doesn't have to be educated across everything - it can be per issue - and where you're not just voting on a thing - you're helping craft the propositions - these completely change the possibility space of social technology we could go on and on in terms of examples but these are ways that the same type of new emergent physical tech that can destroy the epistemic commons and create autocracies and create catastrophic risks could also be used to realize a much more pro-topic world." - [Daniel Schmachtenberger](https://youtu.be/wO1WVguNQAM?t=4793)

^^ this one is until 1:35:50 "pro-topic world" - 16 minutes long
https://youtu.be/wO1WVguNQAM?t=5750

> "One of the challenges of solving the multipolar trap internationally is the inability to make international agreements and one of the reasons where either we don't make the international agreement because it's not even worth making because we're sure they're going to defect on it so why even bother, or we make the agreement knowing that they're going to defect on it and we're going to defect on it but we're going to say that we're keeping it and we know they're going to say they're keeping it we're going to spy on them and we're going to lie to their spies and all this kind of waste that goes into that - if the transparency to know what they were actually doing and them to know what we were doing was there, the ability to make and keep the agreement would be fundamentally different. So underneath multipolar traps is the perverse game theory to orient towards opaqueness rather than transparency and this is - you know- the whole nature of how many things are considered trade secrets in the market or national security secrets and - you know - all of the different types of security clearance and classification and special compartmentalized information and whatever, because we're trying to have information advantage - information asymmetry advantage on the other side and we don't want them to know what we're doing but we do want to know what they're doing and so we invest a lot in this but the opaqueness means that the agreements can't be made so the multi-polar trap is the only thing that is left." - [Daniel Schmachtenberger](https://youtu.be/8XCXvzQdcug?t=7618)

> "Does the ability to do attribution - specific verifiable attribution of where a particular harm is coming from - does that increase the capacity to create justice, to be able to bind it - totally. So is it possible that certain types of forced transparency can make it to where the ability to hide the harms that then have everyone race to do the harms goes away, and then the fact that they can be shown means there's a need to account for them and better methods of accountability emerge - I think there's a lot that can be done with forced transparency that orients towards a fundamentally better attractor of the game theory space." - [Daniel Schmachtenberger](https://youtu.be/8XCXvzQdcug?t=7769)

> "Are there ways in which transparent solutions win game theoretically as a different peak in the adaptive landscape relative to the opaque solutions? Why the opaque solutions win is very obvious - surprise attacks help - the ability to advance something where they don't know that we're advancing it, we mislead them about it, they build a false defense - it's obvious why the desire for information asymmetry in that way is there. I was talking to someone in national security of Sweden who was telling me some very fascinating things and I haven't been able to verify all of them, but saying that of kind of the major nations that have meaningful defense capacities Sweden has maybe the most transparent intelligence and military and security apparatus, and their underlying philosophy was that the major players are going to be effective with their spying and know anyways - they don't really get that much information asymmetry - that's more of an illusion of control than a reality of it, and so Russia and China and the U.S. are going to know anyways, and so the huge amount of resource that they would have to put into trying to hide from them is mostly a waste - so they're just not even going to try, and that if you have to try to hide the national security stuff from the quote-unquote enemy that also means you have to hide it from your citizens because otherwise your citizens don't all know how to keep classification which is why this thing pretty much makes democracy impossible in any real sense more than just a simulation. At the time of the founding of modern democracies and particularly I'll mention the United States here, the United States had an ocean on both sides to anybody else, it had no kind of contiguous rival - land contiguous rival - that was a pretty awesome security situation, and so the decisions that needed to be made about anything - including military things - could be shared with the people, the people could actually weigh in on them, and sharing that information with those citizens didn't instantly mean sharing it with the British or the Spanish or anybody else because there was no way to get that information across the ocean quickly, and simultaneously once someone else got that information they couldn't launch an attack that quickly - they'd have to launch boats that we could see that would take months, it would give us time to launch a response, and so the ability to share with the citizens was actually viable in that world because of those sets of reasons. As soon as we get to a world where whatever is being shared with the citizens can be known by rival countries instantly, because of electronic telecommunications and where they can then launch attacks instantly - including ones that are hidden with plausible deniability like cyber attacks or economic attacks or geopolitical positioning, let alone missiles - now the threat of sharing information with the citizens meaning sharing with the rivals is way too high - therefore more and more things become classified more and more things become national security secrets - obviously attacks on our water supply or our energy grid or our food supply could all be national security threats, so we start finding that there's national security secrets fucking everywhere! Well how do you do democracy if the citizens can't actually know what is going on and what the real considerations are - well you can't - it's a simulation of it. This is a real challenge that we have to think of in a deep way when we consider what does a participatory governance system in the context of the modern world look like, because it makes sense that there would be a black budget and it makes sense that there would be national security secrets but then how do you verify that those authorities are not corrupt? How do you verify that they are actually doing the will of the people, or how do you create checks and balances on power or adjudicate issues or things like that." - [Daniel Schmachtenberger](https://youtu.be/8XCXvzQdcug?t=7838)


> "When we talk about what is a desirable civilization it becomes a really tricky topic because it's like centrally existential questions, to say what is a good civilization - we don't have a system like science - this is kind of the is/ought distinction where science can say what is but not what ought - we don't have a as powerful as sciences for being able to understand the objective world which then allows us to create objective tech that affects the objective world - we don't have a comparably effective way of studying the subjective and inter-subjective world of being able to say good, right, and so if you have the ability to affect the world exponentially more powerfully through science and applied sciences, technology, but you don't have a comparably powerful force for what is good or wise guidance of that technology then what is guiding that technology ends up being game theory, right, and game theory is actually like the closest thing to something that is commensurable with the scientific system in terms of what is a good choice which is kind of the social darwinism of a good choice as a choice that doesn't lose game theoretically to other choices that are also seeking maximum advantage, but we can see that the advance of game theory under the presence of exponential tech in this way self-terminates so that clearly cannot be called a good choice. And yet losing in the near term is also not a good choice so we need something that is option D - none of the above. So while I think it is important for us to become as good at the type of mind, at the type of internal human capacity that can do wisdom and ethics as we are at the capacity to do science and technology, and to be able to think about what is a desirable civilization, I think we can start by agreeing on a couple things that are not desirable - and I think that's actually very helpful. I think the idea that a civilization that self-terminates is probably doesn't meet the criteria of what an optimal civilization is so that we are wanting to prevent the movements towards cascading catastrophes - that seems pretty straightforward - and that one that is clearly dystopic - meaning that there are such radical asymmetries of power, that the freedoms of almost everyone are radically curtailed - is also not an ideal case. And yet it's very easy to see that exponential tech has the ability to decentralize power as the market cases giving an example of, which creates these coordination collective action problems and multipolar traps, and so the decentralized exponential power creates multipolar traps creates increasing catastrophes. So then it also has the ability to centralize power - if I could have an entire nation-state - historically the nation-state couldn't be too top-down and too big because it would get fragile because you can't actually see what everyone's doing and control it, but the ability to have sensors everywhere and no person could make sense of that and you couldn't even trust the chains of command but AI systems could, and then getting everybody to spy on each other is tricky but being able to mediate that through sesame credit type systems - it could do that thing. So the exponential tech also creates way more powerful autocratic systems at scale - centralizing power - which brings us back to why the multipolar trap is one of the very deep underlying things to work on. And this also brings us back to the Swedish example that I did not complete of where transparency could win. So the example he was giving is that rather than invest any resource in opaqueness or you know hiding or cloaking stuff they would just assume that the rivals would find out anyways and as a result they didn't have to keep stuff from their own population in the same way - as a result the population has a way higher trust in government, as a result way less money has to be spent in campaigning and convincing people of things and there's more kind of emergent coordination and things like that and the various departments of government - and especially of the military - have more transparency to what each other are doing because they're transparent, whereas in the classification you don't just have overarching classification - you have this kind of special compartmentalized information process which means that a general in one area and a general in the other still don't know what's going on in the other domain - so that both means that duplication can be happening, it means that a lack of efficiency of coordination happens, and that particularly when there's too much information it kind of doesn't even matter to have access to all the information because nobody can process it - this is the infosingularity issue and we'll talk about this more. But when we have more computational capacities to process large information sets then it actually really does matter having transparent access to all of it - we can make progressively better sense of it with the right computational sense making augmentation. So their ideas - the transparency regarding things that would have otherwise been classified - doesn't lose us that much - it gains us a lot of trust in government which gains us a lot of discretionary participation of the citizenry and it also gains us the ability for the various departments of government and military to be in much more coordination with less duplication and less waste because they have more transparency to what each other are doing, it also means that it's much easier to check corruption because they increase transparency and so you have more efficiency and integrity and things like that, and as a result you lose the little bit of asymmetry of information advantage but you gain a lot of other kinds of advantages so it's a different peak in the adaptive landscape. I thought this was fascinating when he shared this with me and so I asked - you know - that's cute and all as a country that has EU backing which fundamentally has NATO backing - you know - indirectly, and that is not at the head of an arms race - do you think something like that could work for say the United States? His take was yes - it actually could work for the United States because the amount of capacity uplift that would occur - and this didn't mean he thought it was inactive - the the vested interest against enacting it would be ridiculous - but just hypothetically as a thought experiment if that kind of transparency did happen - the amount of duplication that's occurring is huge, the amount of corruption and waste that's occurring is huge, the ineffectiveness of coordination that could be lifted would be huge, the ability to start getting increased trust in government and as a result having the democratic and government sector be more coherent, aligned with the military sector as opposed to the increasing discoherence in the government public sector, and that even if some first attack capabilities were increased because of the information sharing of other parties - that our total strategic capacity and response and deterrence would still make it or nobody would mess with that that such a thing could be advanced, and I think this is a fascinating line of inquiry. So if say, more total strategic military capacity emerged out of the transparency than the opaqueness approach - meaning per you know, military power per dollar - then it would actually drive a race to the top on transparency where Russia and China would be oriented to try to do a similar thing because otherwise they'd actually be losing the multipolar trap that is now a race to the top on transparency rather than a race to the bottom on opaqueness which is increasing the capacity for international agreement rather than decreasing the capacity and fundamentally addressing the multipolar trap progressively better. If we think about having some forced transparencies through things like international satellite capability and open source intel capacities that kind of mess up the opaqueness anyways - can we make the opaqueness increasingly poor as an adaptive strategy, the transparency both more forced and more capable of actually winning - now we start to get a strategy where for the first time in history possibly something wins game theoretically that is also better in fundamental ways regarding its long-term viability, that the culture more oriented to peacefulness can actually beat the culture more... warring without becoming more warring in all the most problematic ways - it can maintain adequate strategic capacity while being oriented in a way that fundamentally is decreasing the types of pathological competition within the system and as a result driving races to the top between systems of things that are more positive sum and less pathological as a whole. Ultimately whatever... I would say threading the needle of something that is neither catastrophes or dystopias and without being able to wave a magic wand and do enactment at the level of the whole world at once - if any group were to do something the thing they would do has to not lose to the rest of the world not doing that thing - not just not lose but it also has to influence the rest of the world because if let's say we could get some country to do some very enlightened set of practices it still dies from climate change and AI and whatever so long as it doesn't change what the U.S. and Russia and China and other places are doing, so it has to actually be able to influence the whole world shifting but it has to basically be able to win in some critical influence ways where the nature of what creates the win isn't externalizing harm or driving arms races or whatever. So it has to both be obsoleting some kinds of destructive game theory while winning at some fundamental types of game theory at the same time - like so much the threading of the needle has to occur. And I think when we go back to the sub dunbar tribes one of the things that mediated their effective protocols was that there was very high transparency which allowed for pretty good coordination and not having collective action failures within the group - there was no real incentive for anyone to be sociopathic or narcissistic because nobody would want sociopaths or narcissists in the system and unless you can like bullshit people and hide it - that strategy doesn't pay - if everybody can see that you're lying in a small tribal scenario or they can see that you put your trash down or didn't do your part of the chores you're going to clean it up or you're going to get kicked out of the tribe. So that the smallness creates a force transparency, creates a situation in which what is best for the tribe and what's best for you are more closely aligned - I'm not saying perfect, but more closely aligned. When the groups get much larger - where somebody has the ability to play people off of each other who don't know that that's happening because there aren't enough communication channels, and be able to screw some people over here and then go somewhere else to get a new supply of people and whatever, then of course the ability to hide the effects of what I'm doing - I'll create a incentive for sociopathy and things like that, which is why we see that those types of power-oriented say cluster B personality disorders are something like three times more prevalent in C-suites and positions of more power than they are in the general population - it is that they are adaptive in those environments so they're selected for, conditioned, and incentivized. So of course we can get the high transparency and thus better alignment between the individual agents' incentive and the whole in a small environment but that has never scaled." - [Daniel Schmachtenberger](https://youtu.be/8XCXvzQdcug?t=8380)

^^ this one is until
https://youtu.be/8XCXvzQdcug?t=9142

> "If we want to be able to scale it - are some of the new technologies that allow for certain kinds of transparency and then certain kinds of information processing across larger scale and communication? Could they facilitate better methods of collective intelligence that notice perverse incentives and as a result of noticing them and being able to create accounting for them, and externalities - be able to create accounting for them, create progressively better incentives, and more capable deterrence to align the motivations of individual agents with the whole better? I believe so. I believe that some of the exponential computational technologies in particular that portend the fastest and worst existential risks in many ways also portend the possibility for better coordination systems. And I'm not talking about AI disintermediating humans and having some AI singleton run the world - I think that's a really bad idea for lots of reasons. I'm talking about AI being able to facilitate human collective intelligence - AI amongst other capacities. Where I don't want artificial intelligence making the decisions by itself in most scenarios, I want processes of collective intelligence of humans making it, and we can get into obviously people voting yes/no on a binary proposition where both sides/versions of the proposition suck: if it goes through it benefits something and harms something else, if it doesn't go through the thing it would benefit is now harmed because the proposition was just designed stupidly to begin with - it didn't factor how interconnected everything was, so the yes/no on it can't not polarize the population. That's just a stupid system of collective intelligence. We can just do much much better: where before you make a proposition you actually do the sense making of what are all the interconnected things, what are all the values, you take those as design constraints to go through a better proposition crafting process of what is the best synergistic satisfier with the least theory of trade-offs possible, and what are better voting systems than binary that inherently polarize the population. So I think we can do a radically better job of systems of collective intelligence and a radically better job of education of people to be able to participate with these things, and an incentive system where as people become more educated in topics they actually get more ability to influence those topics. We could get into that - it's beyond the scope of this initial introduction. But one of the issues is that where there's more information that anybody can process - the information singularity: there's more journal articles on a topic than any expert can read so nobody can ever be an expert on anything - how do we solve that? One idea is we don't and we simply need AI's to run the world, the other idea is we have to be able to merge with the AIs through some kind of brain computer interface or something like that. I would say another version is that when you look at even the current state of generator AI which is really not advanced compared to what will be a year from now or five years from now because it's advancing so rapidly, but you look at the current state which would be say GPT-3 today (OpenAI) - it can use exclusively natural language input - I don't have to be able to program - I just speak to it, and it understands my words and it does stuff based on understanding the words - that's amazing! Go watch the DALL·E and the GPT-3 demos on YouTube to just get a sense of what they can currently do because it's mind-blowing and the only thing more mind-blowing is the speed at which it's advancing. The destructive capabilities of this don't take thinking very hard to imagine and they're very near-term. The beneficial cases but that are narrow are also really obvious. The omni-beneficial facilitation how do we create better collective intelligence and governance writ large is not as obvious until you really start to think about it but then it is amazing I feel. And this is not a techno optimist answer - I'm very acutely aware that the technology on the current trajectory is most likely catastrophic and what it takes to make the other version of it is value systems that have to be able to bind, guide, and direct it and influence social systems that create the capacity to bind, guide, and direct markets and technology in a way they don't currently have. But it is saying that the technology is new capacity and that that capacity if rightly directed does make new things possible. In the same way that the printing press made democracy possible where it wouldn't have been before because without any newspapers and without textbooks you can't have a comprehensively educated and informed society. When hand copying a book is so hard and expensive - only a nobility class with the wealth can have access to it. Of course that technology of the printing press did make possible different types of coordination than was possible before. Obviously the internet: anybody talked to anybody anywhere in the world & made possible different types of coordination, make possible and orient it to happen that way or different - while most people could use their phone to access any information in the world, what they end up doing on it is usually not that interesting examples because of the nature of the choice architectures that they're engaging with in their user interfaces, and the choice architectures are that the user interfaces that they engage with have goals for them that are other than that person's highest goals for themselves - and they're effective. So this is not AI will save the world, it's also not AI will necessarily destroy the world - this is a: since we have the power to create such powerful technology we need the orientation to think about what wise application of that technology is, and the intersection of comparable wisdom to guide, right, design, and development of that technology that in turn then is developing wisdom and everyone else based on their interface in the same way that Facebook can increase - and it's a known thing: you can change the algorithm that is affecting what's in people's newsfeed and they get more depressed or suicidal or more body image issues or not or because we're affected by what we untake - could we create information platforms that rather than doubling down on my existing bias were oriented to help expose me to information that is antithetical to the things that I currently think but in the most compelling cases so as to increase my kind of dialectical awareness, that rather than orient me to more people that are like the people I already know that orient me to people that are most unlike the people I already know to increase the total connectivity of my network, that rather than maximizing for things like my engagement and time on site it was maximizing for things like as I was showing the capacity to take and synthesize more perspectives the content that did that got upregulated in the algorithm, right, are there ways that that same type of technology could be applied that would be wisdom advancing? Of course this sounds scary because like who's idea of wisdom and who's going to control that, but it's important to get it's already doing it, right, it's already controlling minds at scale. So it's not a question of do we do it or not - it's how do we do it since it is happening. And now the core question of: well how do we adjudicate what is right use of the technology when you realize that the technology is not only radically affecting the earth physically, but radically affecting our mind, society's cultures. Now this again: the wisdom of gods to deal with the power of them becomes central. What is the right use of that? What are wrong uses? Where should that be bound? How do we understand this? How do we make sure that the binding a particular application of a problem doesn't make another worse problem? So we don't like a particular kind of partisan-led censorship, so we want more free speech, but if a particular approach to free speech also means a lot more ubiquitous deep fakes and an upregulation of the worst voices because they get the most tension that creates eliciting of violence and the breakdowns of democracy - it's like: okay, the obvious answers are all wrong, right, because the problem space is more interconnected and more complex, so we have to hold all those problem spaces together and think about it. But we come back to this: you know GPT-3-like AI type tech solving the info singularity - so when you put something to GPT-3 it's not going to find an existing web page for you the way that a search engine would - it can generate bespoke content, right, you can say "write me an article in the voice of such and such with it factoring these kinds of facts and orients towards this kind of conclusion and whatever" and it can do that! And progressively more and more effectively, more and more turing tests passing across more domains. Well what if that just becomes the future of search? Where if I'm searching for the information that could inform a particular choice we're wanting to make, or wanting to do something regarding grid security, but grid security - I need to know all the things about what really affects good security, and what other environmental and national security and you know et cetera issues are connected to that. Right now I can get billions of search results - I can't read billions of search results - that's not useful for me. Can the AI read billions of search results, find the information that is decision informing based on parameters that I'm specifying and create new bespoke content that is the synthesis of that for decision informing - not decision creating. The groups of people doing collective intelligence are still making the decisions, but now with the ability to take a synthesized or refined set of more information than they can process - that is pre-processed into decision-making information - now you say well fuck, who controls that algorithm because that's a big deal? What if you can do it lots of different ways? What if you can put different criteria for how to inform it and in the collective intelligence system all the agents have the capacity to do that kind of thing? There are heaps of challenges and problems that we have to solve here but this is an example of ways that coordination technology... The multi-polar trap is a coordination failure, it's a collective action failure, the dunbar number can be thought of as an upper boundary of a particular type of coordination capacity where everybody can know everybody and see what everybody's doing, talk to everybody, and so the collective activity is able to be bound through very high bandwidth communication. Once we start getting larger than that - early empires - we got command and control hierarchies and we started to get all the problems that we see in the world today, that are now - at the scale that we are - driving catastrophic risks. Democracies where how do we have a much larger system or rather than have somebody at the top rule whether it's one monarch or some small kind of nobility class or whatever - how do we at least have - since we can't get everybody at scale to agree - we could maybe get everybody at a tiny scale to agree but just a minority agreeing seems like a bummer. Can we at least get a majority to agree, but then of course that thing intrinsically ends up driving polarization and its own decay. And so can we make the types of transparency and the types of incentive alignment, the types of capacity for deterrence that would exist at a small tribal type scale possible at much much larger scales where the increase in effective coordination starts to be more effective, right, you start to reduce a huge amount of waste and duplication and failures of those kinds, and so what makes this thing adaptive and selective in a kind of game theoretic situation is also what makes it healthy in terms of the health of the people inside, in terms of classes - people relative to each other - and its relationship with the environment. I think that something like that has to be the answer and I think that it's interesting that the technologies that have the most destructive capability I think also have the most and uniquely facilitative capability for solving collective action or facilitating us solving collective action problems." - [Daniel Schmachtenberger](https://youtu.be/8XCXvzQdcug?t=9142)

> "If we were to talk about what is a third attractor: it's not going to be a top-down singleton which will end up being dystopic, it's not going to be many different actors caught in multiple traps with each other. It's going to be something where the system as a whole has the power to be able to check the catastrophic dynamics within it, but without having power consolidation itself - where the system has a kind of coordination across decentralized capacity, so centralized emergent coordination across lots of decentralized capacities. This is of course the idea of what democracy is trying to achieve and we can see why it was partially successful, and then why it failed and got captured under advancements of technology and complexity and financing like that. But can we build something with the very best of the knowledge and information technologies available to us now that makes coherent choice making that factors the total collective intelligence and total collective agency with the speed and coherence of what a small number of agents would have, and yet without any kind of centralized power? Well we can say that something like that is part of the criteria set of a third attractor of a desirable civilization that is not catastrophes or dystopias." - [Daniel Schmachtenberger](https://youtu.be/ZCOfUYrZJMQ?t=829)

> "I think there is a humongous amount of what we are perceiving about human behavior that is physiologically mediated a lot. And then also mimetically and culturally mediated, and I think the exploration of the full phase space of what could happen to both attenuate the negative contributors and advance all of the different positive contributors, and what the potential of the whole of that space is, is really profound. If we think about things like watching how quickly a technology like social media (like Facebook) can increase people's enmity towards their fellow citizens of the same country - to the point that both sides are oriented towards war - like so rapidly can vitriol and anger and whatever get stirred up as a result of just the media that people are being exposed to - out of the so much stuff what is being concentrated by the AI that's selecting for me. Could that same technology, curating with a different set of purposes, that was bias correcting rather than doubling down on bias, that was helping people connect to much wider networks rather than tribal networks, that was helping to up regulate more synthesizing and nuanced responses rather than other ones, could that affect culture and intelligence and disposition at scale in a way that no religious prophet could have ever dreamed of historically? Totally." - [Daniel Schmachtenberger](https://youtu.be/ZCOfUYrZJMQ?t=4869)

> "I hope the attractor of cascading catastrophes or control mechanisms that prevent it, but create dystopias, create a framework for what we want to avoid. And that a third attractor that has the intelligence and regulatory power to avoid the catastrophes while having checks and balances on itself to be non-dystopic, that the creation of a world system that can do that should be the kind of central innovation goal of the world - of which everything is an element or a subsidiary part, and that more total collective intelligence and innovation and motivation being focused on these issues is worthwhile. And I hope that rather than creating a sense of doom or overwhelm, that what this information might create is a sense of almost like a validation of something that has been intuited - an increased sense of clarity that makes the complexity of the challenge space at least start to feel tractable, and because if it is apprehendable, and if there are at least thought experiment-wise possible solutions, then there is a direction of endeavor, and to have more people feel that hopefulness that is not the naive hopefulness of not being aware of all these problems, but the hopefulness that comes on the other side of being aware of all of them and seeing what it would take to move through that, and be oriented to that - that's what I hope becomes of this." - [Daniel Schmachtenberger](https://youtu.be/ZCOfUYrZJMQ?t=6214)

> "This is exactly the centre of what I'm focused on: the problem is fundamentally the inability to coordinate between agents where their basis for agency intrinsically has deltas - right - there's a what's best for me in the current system of a private balance sheet and money and those types of things - what's best for me is not what's best for you and best for the commons - even though it would be over the long term, over the short term it doesn't seem to be. And so everyone is doing utility maximization functions but with again, unlike evolution, with asymmetric power relative to the environment and supply-side relative to demand side and things like that, and this then ends up creating a situation where it gets worse - like this is actually a very important point - if I have true information about the nature of reality, that is a source of strategic competitive information so I want to withhold that information (we call this a trade secret or classified or confidential information or intellectual property) but I don't just want to withhold that - I also want to make sure to throw anyone else that would figure it out off the scent trail so I want to do not just withholding of information but disinformation, and we have a situation where everyone is incented to do withholding of true information and signaling of disinformation, and then we have information technology that's exponential information technology where I can do customized disinformation for different persona types and all the way down to individuals - we get to a world where we stop being able to parse signal from noise because there's so much radical disinformation and we have a situation where a coordination actually becomes impossible because of these agency issues everywhere. It's supposed to be the two different intelligence agencies within a country perfectly coordinate with each other to support that country because they're all on team country, right, Team USA against the Russians and the Chinese and whatever, but really those two different intelligence agencies are also competing against each other for a larger percentage of the budget, and then even to different departments within that organization and even to different people competing for the same promotion will withhold information and maybe even disinform, engage in corporate politics - corporate politics is where someone's optimizing their own bonus structure and their fealty relationships at the expense of what's actually good for the whole because they're not actually coupled to the whole effectively - and so you get a situation of fractal defection - everybody defecting on everyone to some degree while signaling that they're not doing that - and this basically means a catastrophic breakdown in the sense making necessary to make good choices while having an exponentially increased amount of choice making power. And if we think about that, exponentially decreasing quality of sense making relative to the overall situation with exponentially increasing choice making power - that's another way to think about inevitable collapse." - [Daniel Schmachtenberger](https://youtu.be/9psdN65IzOw?t=2330)

> "So why do we get so much concentration of sociopathy in the top of fortune 500 companies and politics and then especially things like finance? Well because they're basically systems to attract, reward, incentivize, and condition sociopathy, because to get to the top the power game it's going to be people who are attracted to power and people who are good at winning a bunch of win-lose games, because at each step they move up the ladder they're winning against somebody else - usually via involving things like disinformation and defection and whatever it is - and so if you think about the nature of what a government or a corporation or any top-down power system are - it is basically a strange attractor for people who want to have power over, for people who are running power dynamics, and this is why, you know, let's try and say that I have a benevolent dictator - well there's a reason that we don't get sustainable benevolent dictators is because let's say I have a benevolent dictator - and we can get this in a corporation from great founder Theory sometimes, because if the founder holds the you know, majority of stock or whatever, but it never out lives them, and usually they end up getting kicked out. So let's say I have a benevolent dictator. All the people who are one step under them are doing things that they require to be able to stay as a dictator because it's pretty easy to kill somebody or to oust them or whatever, so if I'm at the top of a top-down power system I have to keep everybody under me preferring me to be above them rather than overthrow me, which means that rather than do what's best for everybody I have to do what's best largely for those who are right near me, and they have to do that for those who are under them, and that ensures a kind of power law distribution of power and again there's like a multipolar trap on corruption - if anyone's willing to do a really fucked up thing to try and overthrow me, I have to be able to play at the game of fucked up things or I get overthrown. So we can see how top-down power systems are going to both attract, condition, reward, incentivize things like sociopathy and so then we end up having a world run by sociopaths which is not a good thing for anybody. But now let's think about something like a tribe - and I'm not gonna over romanticize here, I'm just kind of thinking through the dynamics in a first principles way - if I've got 40, 50, 70, up to a Dunbar number of people living in a tribe there's an extraordinarily high degree of transparency that is forced in that scenario - everybody pretty much sees everything that's going on with everybody and everybody knows everyone, everyone has fealty relationships with everybody in the tribe. So sociopathy is not gonna be advantageous - you're not going to have an evolutionary niche in that environment for much in the way of conspiring and lying, because it will get found out and it will get punished, and so the forced transparency creates an accounting system where you don't get an evolutionary niche for somebody fucking the other people in the system. And so as soon as the system starts to get large enough that 1) there's anonymous people so I can harm people who I don't really know and care about as opposed to everybody who is in the system as somebody that I know and care about, and 2) I can do stuff that people won't be able to see I can kind of have a corruption of the accounting in the system - now we get an evolutionary niche for rather than participating with the system - doing internal defection. I'm not externally defecting and leaving the system - I'm internally defecting and playing the system. And that's what most everyone inside of a corporation or a government is optimizing - what is good for them and their direct fealty relationships rather than what's good for the whole, and nobody can tell. And this is a particularly hard scenario, but the reason I'm saying this is because we do our social science inside of a world where these systems have become ubiquitous, and then we assume that those properties where there's ubiquitous conditioning, are intrinsic to human nature and I think we have to be very careful about that - I think a lot of them are not intrinsic to human nature - they are a result of the ubiquitous conditioning and we could create conditioning environments in which things like sociopathy are just not advantageous and so they don't get up regulated." - [Daniel Schmachtenberger](https://youtu.be/9psdN65IzOw?t=3104)


> "Let's say that I'm one of the richest people in the world today - I'm Bill Gates or Warren Buffett or whatever - there's really important stuff that the world could produce that it can't inside of capitalism that I don't have access to and this is actually kind of everywhere and it's really basic: the best phone the science could make involves some intellectual property owned by Apple and some owned by Google and some owned by a few different companies and the same is true with the best laptop and the best car and even with billions of dollars I can't buy that thing. And all the things that I can buy are produced by someone where not only do they have limited IP but they also have whatever designed obsolescence and desire for proprietary stuff so you use the rest of their ecosystem stuff so it's not interoperable - I have to deal with that shitty suboptimality even from the richest guy in the world." - [Daniel Schmachtenberger](https://youtu.be/9psdN65IzOw?t=4122)

> "What could provide increased capacity that can't be weaponized? That's a very interesting question. We could say that every technology that increases capacity can be weaponized - meaning: can be used by some agent to increase their capacity relative to other agents or the commons. Except if we had a social technology that was anti rivalrous, but it actually produced increased coordination capacity - you actually can't weaponize it because it is the solvent for weapon ization itself. It is actually the basis of how agents interact in a way that doesn't incentivize weapons and so for anyone to instantiate that thing they are actually changing the nature of their agency. So in the current system, again, private balance sheet, I'm in a big corporation, I'm gonna do the thing that optimizes my bonus structure and my status in the company - even if it fucks other people in the company and the company as a whole and that might include spreading disinformation, withholding information, etc. Well let's say I could create a situation where I couldn't get ahead of the expense of the whole so I had both the right kind of transparency and accounting systems and access to Commonwealth resources where only as the Commonwealth does better do I do better and things like that. Then we can have a situation where no one... Let's just say if we could invent a situation in which no one had an actual incentive to spread disinformation or to hoard information, if they shared true information - maybe they'd be wrong but they at least had the incentive for full earnestness and full transparency - if you had a situation where that was the incentive - you figured out how to do that - and I will say there is a way to do that, I believe there's a way to do that - then you would get a situation where you had an information ecology that was actually intact at a larger scale. That would lead to radically better capacity to coordinate and innovate - better sensemaking than the current system has - in that system as a whole would be more effective at producing all of the metrics that matter relative to total resource per capita than any current system would be. And I only need a small number of people - relatively small number of people - who get that and want to instantiate it as a new full stack civilization to create a new strange attractor or a new attractor basin, where anyone else looking at it says 'Well quality of life is higher on every metric there and they're also able to innovate us on a bunch of things, they're figuring out solutions to that we don't have, well then why don't we just kill them? Well because they aren't trying to win the game of power against us, they aren't building militaries or signaling or narrative warfare to try and beat us, and actually they're exporting solutions to us that we need to the rest of the world, because if they have increased capacity to innovate and solve problems, because they can actually coordinate better, because they don't have disinformation information withholding' - then they can look at what groups that would otherwise have enmity with them actually need - develop those solutions and create dependents rather than enmity relationships while simultaneously saying 'If you want to know how to do this as well, we've actually open sourced it - it's a social technology, you're welcome to use the social technology' - but the social technology will fundamentally change your basis for agency if you employ it. So obviously there's a million things we would need to dig into there, but just the thought experiment goes: fast adopters build a new ground-up system where the new ground-up system becomes a new attractive basin and - you know - that's a way of thinking about that I don't try and... If I have to shift at the level of axioms I can't retrofit current system - I have to build something, but if the thing that I build is fundamentally more attractive ground up, then I only need fast adopters to understand it in concept to have medium adopters understand that after seeing its implementation." - [Daniel Schmachtenberger](https://youtu.be/9psdN65IzOw?t=4517)

> "Whenever something becomes the legitimate authority on truth for a topic it's extraordinarily powerful because what everyone else thinks is real, which is the basis of how they're going to behave, is actually like at the bottom of the stack of power. And so even if a legitimate authority emerges rightly - because it's actually earnest and doing better empiricism and whatever - as soon as it starts to get that power there will be maximum incentive for all of the power players to try to corrupt it and influence it in various ways, which they usually can because which science is going to get funded is going to be based on someone who has funds putting money into something that will continue to support or advance them having funds. And so even if, say, a piece of science is technically accurate - it's not wrong - it might be that only certain topics within a domain that have ROI more associated get funded - other ones don't, like for instance you know, patentable small molecules and pharma compared to peptides or biologics or plant-based things. And so then the preponderance of research doesn't actually map to the overall space well, so even things that are true can still be misrepresentative or misleading - so this problem that legitimate authority within an economic game theoretic environment will always get captured or influenced to various degrees and so how do we address that." - [Daniel Schmachtenberger](https://youtu.be/3lil4invvSI?t=1890)

> "We need to have governance - I'm going to separate governance as a process and government as an established top-down enforcement of rule of law with monopoly of violence. We need to have governance at the level that we're having effects - meaning we have to be able to actually make sense of the effects we're having and factor that into the choices that we're making, and when we have planetary effects on the atmosphere and the ocean and etc. but we don't have planetary governance, then we just get multipolar traps where okay, we don't want to fish all the fish out but if we can't make an agreement that China or somebody else is going to also follow and they're going to get ahead economically and the ocean's still going to get ruined then they're going to use that economic benefit to damage us - not only will we not make an agreement to manage the commons - we actually have to race to fish all the fish out faster than they do, or make AI weapons faster than they do, or whatever else it is that's exploitive. And so not having global governance when we're having global effect leads to catastrophe, but having global government of the types that have only ever become corrupted and then as a result broke down also leads to catastrophe. And so we need something that is different than either of those things that have been imagined so far." - [Daniel Schmachtenberger](https://youtu.be/3lil4invvSI?t=2035)

> "Very few civilizations since the beginning of civilization until now have been republics or democracies - they've almost all been feudalistic or autocratic of some kind and that actually makes sense, because one guy ruling everything or some very small number of people that can talk, coming up with a consensus, and then being able to rule is way easier than getting a huge number of people - mostly who are anonymous to each other - to all actually be able to make sense of the world and coordinate. Like a large number of people coordinating is actually a very expensive tricky thing, and from the way I see it, throughout history the few times democracies emerged - they emerged following cultural enlightenments that had a few things in common. When we look at the Athenian democracy coming out of the Greek enlightenment: stoicism plus the Aristotelian school and - you know - a few things had caught on to the place where they had a cultural value around education, that everyone would learn formal logic and everyone would learn rhetoric and history and - you know - those types of things, plus the kind of stoic culture where they're all learning emotional regulation and the socratic method where they're learning how to take each other's perspectives, debate any side of a conversation. Well if I have a bunch of people who are trained to be able to assess base reality clearly on their own, they have emotional regulation so they are not as susceptible to emotional and cognitive hijacks and groupthink and have the courage to disagree and things like that, and they can take each other's perspective and they're actively seeking to - well those are the prerequisites to something like a democratic system being able to emerge because those people can have a good quality conversation about shared sense making, recognize that some compromises to agree are better than warfare with each other and come up with solutions, so collective choice making emerges out of the collective sense making, meaning making and conversation ability. And our country similarly coming out of the post-european renaissance enlightenment phase was - you know - the idea of renaissance men, renaissance people who could have expertise across a lot of topics - not just be specialists - because specialists across different domains have a hard time being able to communicate really effectively towards governance that requires looking at a lot of those things, but the idea that we could become renaissance people, that we could all have empirical capacity, the scientific method, and the hegelian dialectic - that we could hear a view and then seek the antithesis to that thesis and then seek a synthesis - some higher order reconciliation - that again gives rise to the possibility of participatory governance. And you can see when you read the documents and the letters of the founding fathers - and of course there was a lot wrong with the Athenian democracy and a lot wrong with our country that had genocide and slavery as parts of its origin, but the whole world had genocide and slavery as parts of what were going on at the time and it was at least moving in the direction of increasing participatory style governance - the thing that the founding fathers talk about so much is the need for very high quality universal public education and very high quality fourth estate that's independent - or news as the prerequisites of democracy. George Washington said - I'm not going to quote exactly - it's something to the effect of that the single most important goal of this government should be the comprehensive education of every single citizen in what he called the science of government, and I think the science of government is such an interesting phrase because we've separated science and the humanities so formally, and the science of government would be history and game theory and political theory and the things that people need to know the shenanigans that happen so that they can prevent them, and Franklin said 'If I could have a government without news or news without a government - I would take news' because if the people really know what's going on they can self-organize and overthrow government - if the people don't know what's going on they can only be captured. And our public education or education of any kind here in the kinds of civics that people would need to really understand what's happening in government and understand regulatory capture and be able to bind it obviously is close to non-existent and the news has been mostly captured by economic and political interests, so there is no chance for a bunch of people that identify as being in almost tribal warfare with each other, who aren't sense making reality well, who don't understand governments, who don't really understand markets, who only have pejorative strawmans of each other and don't seek each other's opinion - those people can't do a republic or democracy, so it will simply devolve back to an autocracy which we see happening. And the way I think of it is like: if there's a bodybuilder who has a huge amount of muscle - the moment they stop working out they start losing it, because it's very expensive metabolically to keep that much muscle - they have to kind of keep working at it - it's very expensive to keep an entire population comprehensively educated and actively engaged. And once it seems like the government's working well and a generation passes and the kids didn't go through the pain of the revolutionary war and the grandkids didn't - it becomes very easy to just get engaged in your own stuff and not keep participating in the governance and then you stop having a government of, for, and by the people - and you start having a class of people that do government, and when the people stop checking the state - the state stops being able to check the predatory aspects of the market, which is what it's really intended to do - and then the market ends up capturing it - you get regulatory capture, and then rather than liberal democracy you get a kleptocracy that eventually becomes an autocracy. And that's what I see that we have right now - and so do I trust any particular authority to arbitrate truth or good faith or whatever right now - no. Do I trust a collective intelligence that's actually increasing in its authentic intelligence - I would trust that much more - it's an expensive hard proposition, but I don't see any other good choices." - [Daniel Schmachtenberger](https://youtu.be/3lil4invvSI?t=2335)

> "So partly it has to do with scale - for sure - which is... the founding fathers thing here - there was an idea that everybody could go to the town hall and discuss the issues that were mostly geographically close to them, that everyone could sense base reality on their own, and you could have a small enough number of people in the town hall that for the most part the people who had something to say could actually say something about it. And when we moved to a place of most of the issues are globalized - whether we're talking about finance or supply chains or environmental issues or - you know - geopolitical ones - obviously that's a level of complexity where people can't depend on their own base sense making and they can't process that much information and second and third order effects and confounding effects as well. And one topic I'll just enter here because we haven't discussed it yet is the concept of hyper objects, which is connected to but a little bit distinct from just raw complexity, that we evolved to be able to apprehend and understand objects that were available to our senses, and when I'm talking about something like climate change - I can't see climate change, I can't taste it, I can't hear it - I can only conceptualize it, I can see a drought, I can see a fire - there have always been droughts and fires, but to understand climate change I have to think about some kind of statistics and complex mathematical models on the droughts and the fires. I also can't see world hunger - I can see a hungry person somewhere, but I can't actually directly apprehend - I can only do it conceptually, which also means I don't have the same felt visceral experience of the things, and the same is true with I can't actually directly see or apprehend AI risk or biotech risk or nanotech risk or or the nature of markets, and so we have a world where the most influential things are mostly all not apprehendable to the senses, and so we have not just the issue of can we have a better felt sense or our intuitions are more right, that our kind of sensibility of what's likely true as well as our kind of formal analytic thinking - can we get hyper objects but then can we get the connection of lots and lots of hyper objects - markets interacting with social media environments, interacting with climate, and things like that - and I think it's just important to kind of state that, to have a sense of how different the problem space of the things that we need to understand and think about are now compared to the evolutionary problem space most people had to think about, and how different the kinds of collective sentence making need to be and choice making need to be, and then I'll also step back and say even in environments where we weren't dealing with as much in the way of complexity and hyper objects - our sense-making was actually usually still adequate to solve local problems in ways that very often caused other problems somewhere else or down the road - and this is an important part of understanding this is like the model that we can look at all of our problems as a result of either conflict theory or mistake theory - conflict theory meaning we know we're going to cause harm somewhere and we're doing it anyways for game theoretic purposes, mistake theory as you were mentioning with Facebook we didn't know this was going to happen and it was simply an unintended externality. So we have to deal with both moving forward - how do we remove the basis of conflict theory so no one is motivated to do things that will knowingly harm something else and how do we also deal with the mistake theory of being able to anticipate externalities and internalize them into the design processes better, and so the mistake theory side - you can go back to - we didn't necessarily know that the development of stone tools would lead to us becoming apex predators that were increasing our predatory capacity faster than the environment could become resilient, that led us starting to extinct species at scale and then become the apex predator in every environment and start the anthroposcene, or you can come to a closer one and say when we were making the internal combustion engine to solve the problem of the difficulty of horse husbandry pulling buggies - we didn't anticipate that in solving the horse husbandry problem that we'd be causing climate change and oil spills and wars over oil and the U.S. petrodollar, and so typically if we're going to make a solution that solves a problem - the solution has to be somehow bigger than the problem, faster, whatever - to be able to scale and overtake it to really solve the problem, but if we define the problem in a narrow way - there's one or two or some small number of metrics - and the solution we're trying to create has a first order effect on a small number of known metrics, but it might have second and third order effects on a very large number of unknown metrics - we can see that the safety analysis is actually harder in kind than the solution analysis and this is something that we actually have to start factoring - I don't just need to understand the problem I'm trying to solve - I have to understand the problem embedding landscape of the adjacent problems and the adjacent topics and the adjacent meaningful things and I have to start thinking through second and third order effects better - whether I'm designing a proposition or designing a piece of technology or designing a company to solve a problem - to say if that solution's effective, what other things is it likely to do and what harms could that cause to complex environments and then how do we actually factor that into the design process." - [Daniel Schmachtenberger](https://youtu.be/3lil4invvSI?t=2937)

> "Before we discuss a perfected system we can just discuss how to stop some of the most egregious things about the current system. Current system - people are radically certain about things that they have no basis to be certain about and it's actually their false certainty that causes most of the problems - if they simply acknowledge that it was too complex and they didn't know - they at least wouldn't be going to war over dumb stuff, and to so to simply be able to have people be like 'I don't know yet but I'm interested and I'm gonna try to seek to know better' would actually slow the rate of breakdown tremendously." - [Daniel Schmachtenberger](https://youtu.be/3lil4invvSI?t=3412)

> "Do I think that we can get the hierarchical complexity or the ability of people to process information up? Yes. Even before that - if I can start getting them a memetic immune system to where they aren't just cognitively and emotionally hijacked - right now it's mostly not even 'can they do good epistemology' - it's that they're just captured by narrative warfare - if I can simply get a memetic immune system where people start to notice how [Russell conjugation](https://en.wikipedia.org/wiki/Emotive_conjugation) and [Lakoff framing](https://en.wikipedia.org/wiki/Metaphorical_framing) happens - yes that scientific article said something, but the news article put spin on it - can they notice how the spin's occurring? Yes that's a true statistic but it's cherry picked - when you look at all the other statistics it doesn't look like that same picture at all. And people start noticing those kind of info and narrative weapons and become inoculated enough that it's not like absolute lowest common denominator collective intelligence - that will make a huge shift, so we have to factor the kind of memetic emotional immunity and cognitive immunity topic, then better epistemology for the individuals and better orientation towards socratic dialogue, hegelian dialectic - like seeking shared understanding because of understanding the need to coordinate being less bad than warfare & not coordinating. Then I think we start to get emergent collective intelligence where more sovereign and intelligent people and better conversations start to produce systems of coordination to bottom-up effect where those systems of coordination produce a top-down effect that continues to incentivize that bottom-up effect better and you get a recursive process between better systems of collective sense making and choice making and better development of individuals and their communication capacity with each other." - [Daniel Schmachtenberger](https://youtu.be/3lil4invvSI?t=3993)

> "As much as a lot of people think that we're too aware of our problems and we just need to focus on solutions - I actually think that it's a very deep misunderstanding of the real nature of our problems - that is one of the keys. People think the problem is climate change or the problem is systemic racism or whatever the thing is that they're focused on, but what are the generative dynamics that give rise to it and how is it interconnected with the other issues in the world where if you try to change it in a particular way it will externalize harm elsewhere and or fail? So the problem isn't climate change or U.S. China relationships or GDP or it's how all those things fit together and the system incentives of the underlying systems." - [Daniel Schmachtenberger](https://youtu.be/JBU06Wswc7c?t=1267)

> "I do believe we're at the end of History - like eminently in the lifetimes of everyone in this room we're at the end of History - meaning we're at the end of a human civilization defined by the major defining characteristics that what we call written human history from early Egypt or Sumeria or whatever was defined by, which is... if you had a peaceful civilization and Genghis Khan wanted that area or Alexander the Great wanted that area your peaceful civilization was wiped out, and the same is true if you want to internalize all of the cost of carbon: your country is going to get destroyed geopolitically by whoever externalizes that cost and concentrates the profits, that the thing that has been more successfully dominant: extracted more, grown its population more, increased its violence capability wins, and that thing with exponential tech at planetary boundaries self-terminates. So either we're at the end of our species or we're at the end of our species being defined by those parameters. And the end of our species being defined by those parameters requires I think... the last thing I'll say when I was thinking about the Nazis and everyone else in those situations is the famous quote - lots of people have said a quote like this - that it's the complicity of the weak with the wicked that allows the evils of the world to happen - most of the Nazis were not Hitler, but Hitler couldn't have done shit without a lot of people who obeyed, most of the Mongols were not Genghis Khan, most of us are not the people that make the choice to make up bullshit reasons for wars that are a false flag for truly economic and geopolitical reasons, but we will still not get in the way of that thing happening - the Iraq war that started all of the recent rounds of wars because of the weapons of mass destruction that we knew they didn't have - where are the prosecutions for that, because four and a half million people were murdered as a result of that? There are a small number of people who are motivated by power exclusively - pretty exclusively - and then there's most everyone else who just needs to pay the bills and not rock the boat too much and wants to feel like they will do good things within the confines of that, so I guess I don't want people to think about how to make their own life regenerative because it doesn't matter, I don't want people to think about how to make Sweden regenerative - I want people to think about what it would take to turn the entire arc of humanity, factoring what is currently driving it, and that everything else that you could do doesn't matter at all because the end of the possibility space of all meaningful human activities is eminent if we don't do that." - [Daniel Schmachtenberger](https://youtu.be/4kBoLVvoqVY?t=943)

> "And then we have to look at the underlying drivers: why can we not stop this thing? Why is it that literally no country, no company in the world wants climate change? Nobody is like: climate change is the world that I want. But we're orienting to it so fast and we can't stop and nobody can stop it because we all want stuff that requires energy that is driving that thing, and nobody wants species extinction, and nobody really wants to live in a world with automated AI weapons but we're all racing to build them. So what the fuck is actually driving the world to a world that literally nobody wants? I think there's a deeper analysis of that and the market is a part of it. **HOST:** ... **DANIEL:** Think about the scale of the market for a minute - you have something like a 100 trillion dollars exchange hands every day and as has been made clear, all of that involves energy that is involving mining and fracking and extraction and pollution on the other side. Even the services sector depend upon products so all of it has a materials footprint. It all requires central banks, it all requires militaries - nobody gets to make money in that contract hold without the military that holds the monopolies of violence and everything in place that keeps that economic system going. So all of those dollars - the taxes - they pay and whatever are supporting that whole system. So Norrsken is one of the probably larger impact companies around and if you have whatever - a few hundred million dollars to invest - and we're talking about a 100 trillion dollars a day of activity that is right up at planetary boundaries and at the verticalizing part of the exponential tech curve - how do you leverage any activity to be able to affect 100 trillion dollars a day no longer being harm externalizing? That's a question we have to take really seriously. But so that's the size of the economy today and it's obviously growing exponentially just to keep up with interest and if we didn't grow exponential you wouldn't keep up with interest the financial system as we know it would collapse. So we have a financial system - how we meet our basic needs depends upon - that is so obviously incompatible with the biosphere - what the fuck we did - it was so ridiculous. But so what is the market? Think of it as: money is a kind of token for value, it's a kind of token for game theoretic optionality where it has no intrinsic value but it has a maximum optionality to get me any type of value I want - I can get militaries with it, I can get media influence, I can change people's minds, I can get materials, and because I don't know how the environment is going to change - the speed of adaptive response is the most important thing - the [OODA loop](https://en.wikipedia.org/wiki/OODA_loop) - the speed at which I can respond to the environment - so I don't want a lot of materials that might become less useful, I want a lot of optionality to have whatever I want. So if you think of money as a proxy for value, but only value that is measurable, extractable, and exchangeable - and all the types of value that on your deathbed you'll really care about are not measurable extractable and exchangeable - we'll destroy all those types of value in the pursuit of these types and we have to because they are. So now think about that as a decentralized incentive system that is incenting all the 8 billion humans to figure out how to get it because everything else they want requires it and everything they need to exist requires it - the countries relative to each other, the companies relative to each other, the people relative to each other, and so it incents them to innovate and it incents them to act on existing innovation - so search algorithms and optimization algorithms. So you can think of the global market as something like an AI - an intelligent system - that is running parallel process on human compute - on human beings - and you know how radically powerful parallel process in the cloud is - being able to run a lot of parallel process on computers did a lot more than centralized supercomputers could do - so this is running parallel process on 8 billion human beings and the clusters of corporations and countries and whatever to incentivize them all to search new ways to make money and to optimize on existing ways and whoever gets good at that system gets more power in it and in turn lobbies and changes laws and changes cultural values of the media they create and whatever that makes a system better for them, and anyone that opposes that system is also opposing those who are doing well at it so that there is agency to suppress that. So you can think of the global market as a misaligned super intelligence that is already misaligned with planetary well-being in humans, that is running on all the humans while also running all the humans, that also uses all the compute and all the other technology and that is building all of the narrow AIs in its own service. We said that most of the Nazis weren't Hitler. So the Hitler we're all in relationship to today is this thing - we can call it [Moloch](https://slatestarcodex.com/2014/07/30/meditations-on-moloch/), you can call it the superorganism, you can call it the mega machine and that thing has to die. That thing has to die or the biosphere will die. But it's not actually animate - it is running on and made up of human action. So thinking about what would it take to - it has to die and/or be converted to something that it is not. And the something that it is not is that you can't assess all types of value with a single value currency - a fungible value currency where the real types of value can't be measured there - and where you can destroy real value to get the optionality token for value - that thing - there is no global fungible unitary currency with its own internal financial mechanisms - like interest that create embedded growth obligations - there's no system that has those structures that is compatible with human continuance - so that thing has to change." - [Daniel Schmachtenberger](https://youtu.be/4kBoLVvoqVY?t=1546)

> "There is no human future that is compatible with a single fungible global currency and interest and most of human access mediated by private property ownership - those things are fundamentally incompatible. We can do the math on that sometime - back in 2017 I wrote a series of papers called a new economic series and it addresses a chunk of this stuff. No, making the money crypto doesn't solve it. So, first, the money is supposed to index real value - goods and services, right, like the theory of the market was people want real shit that will improve their lives, and barter is just... and there's a lot wrong with this and you can read Graber and others to see what's wrong with this, but like very simplified kind of market apologism, early market theory ala Smith and friends says: people want real goods and services that will improve the quality of their lives, how many cows are worth how many shoes is really hard, so we make a unit of currency that's easier to carry around where you don't have to cut up the cows each time to be able to mediate that kind of barter in exchange, and people will buy the product or service that meets their need the best at the best price, so this creates... the authentic demand creates an incentive for other people to figure out supply, to be creative, and that it's not money as a measure of extraction, but money is a measure of production - we're adding value by putting pieces together in a form that wasn't there, and that the intelligent rational human will pick the thing that meets their need the best and the world will get better, right, like that's the gist of the idea. And it's supposed to be then that the money is indexing the real goods and services, so how much money is there has to be that within that market you kind of know how much goods and services to know how much one unit of currency's worth, which is why counterfeit is always illegal, because if you just added a bunch more currency that wasn't indexing the goods and services you'd be debasing the value of the currency. But as soon as the financial system... you start to realize okay, well now I have some of this money that is an optionality token for any kind of value and I can give some of it to someone else - I can loan some of it to someone else so that they can buy the tractors or the horses or the whatever they need to do a thing and then they will grow the productivity - some of that increased gain that they get I should get back, so we call that interest - rent seeking or interest - and then now we have a situation where just the reality of interest requires the system to grow the monetary supply. Now because the population was growing and because we were technologically innovating - the system was growing - but now that we're at a situation where we can't keep growing because we've hit planetary boundaries, because there's eight billion people and 100x the resource per capita that there was before industrial tech - the monetary system still requires there to be 3 percent more money next year and then 3 percent more on that which is a compounding curve which goes exponential - to not debase the value of that currency that means you have to exponentiate real goods and services, which means rather than the money following the real economy - it's driving it. Right... that embedded growth obligation is totally incompatible with planetary boundaries, so do you have to change financial services to not have an embedded growth obligation? Absolutely." - [Daniel Schmachtenberger](https://youtu.be/4kBoLVvoqVY?t=2029)

> "There is immediate work we have to do because we're so near tipping points - we're past tipping points, right, like if everybody... many people in here saw the article that came out about 6 months ago in the American Chemical Society Journal about PFOS - the fluorinated surfactants and rainwater everywhere in the world - but they are in rain water, like these fluorinated surfactants which affect... they are endocrine disruptors and carcinogens and neurotoxins - they're in every drop of rain water all around the world that has been studied - including snowfall in Antarctica, and they're at levels that are above the EPA and EU thresholds - that's not we're getting close to planetary boundaries - that's we have crossed them and the cascade of tragedies we don't know yet - we don't know if we stop using hydrocarbons - awesome - but if we stop the pollution and these are forever chemicals - what - they're still there! And they're not just affecting the humans - they're affecting the soil microbes and the algae and everything - the gene lines of those things - so we're already past some planetary boundaries, we're near other ones. There's immediate shit that has to happen - we have to use markets and governments and whatever for that because that's where all the power is, but we have to use them very differently... so we kind of have to hijack them. And so what does that look like? It looks like that the most toxic forms of agriculture - that deplete all the minerals in the soil and use pesticides and herbicides I.E poison that was designed to kill life and spray it all over our food and spray it in the ecosystem in billions of tons of year - that shit is subsidized by the governments of the world - I.E it's not even market competing with regenerative agriculture - it's being subsidized to not even allow fair competition of the other things when it is [omnicidal](https://en.wiktionary.org/wiki/omnicide) because it claims it's the only thing that can produce enough food to meet food security for national interests - no the real reason is because they're better at lobbying than small farmers are. So what's an immediate thing to do: do you need lobbying, do you need people who know how to lobby as well as big Ag and big Pharma and big oil and big Tech who go and lobby for opposite purposes to remove the perverse subsidies that are going to those and move them to the things that would be better - that are still market viable things - so that the market topology changes? A small amount of lobbying money can produce a lot of state money change, which can produce a lot of market change because you've changed the topology of the market - these are examples of not changing the underlying logics of the market but working with them to change the world in the timely things - I call this triage, and that needs done in a lot of sectors. There's transitional work which is to make the existing systems less pathological - how do we change... so [Kate's work with the doughnut](https://en.wikipedia.org/wiki/Doughnut_(economic_model)) would be an example of insofar as governments start actually forcing monitoring of externalities and making it illegal, so the externalities have to be internalized in the cost equation - that would be a good example, insofar as they start to change the fiduciary responsibility from profit maximizing to things that are not [ecocidal](https://en.wikipedia.org/wiki/Ecocide) and biocidal and lifecidal in the process of - you know - economic viability. Those would be transitional." - [Daniel Schmachtenberger](https://youtu.be/4kBoLVvoqVY?t=2256)

> "What would it mean for our species to be wise enough to steward that power safely? What kind of civilization? What kind of economic system? What kind of governance system? What kind of education system? What kind of religious systems of conditioning the sacred and meaning are necessary to be able to steward the power of synthetic biology and artificial intelligence and nuclear tech and globalized supply chain industrial Tech to steward that safely? That's the long-term work." - [Daniel Schmachtenberger](https://youtu.be/4kBoLVvoqVY?t=2534)

> "Don't act out of anger, depression, and fear - act out of that sense of the Sacred and that you are in service to a life that is beautiful, to a life with a capital L, to a world that is beautiful, and that you're at a time when there is a higher possible consequence of your action than there has ever been for humans, and there is an obligation in that, and there is a meaningfulness in that, that you don't want to waste." - [Daniel Schmachtenberger](https://youtu.be/4kBoLVvoqVY?t=2838)

> "You take any of the biggest issues in the world - like the issues that could determine whether or not we keep existing as a species - so take big environmental issues like climate change: there's disagreement as to whether climate change is really even a thing, and to the extent that it is a thing - what the causes are and what the time scales are. Now, most people who believe fervently 'no, climate change is real, 97% of climate scientists agree, it's anthropogenic, greenhouse gases, etc.' - most of the people that believe that fervently enough to kind of like go into narrative warfare for it have never actually looked at the primary data deeply themselves. And yet there's an almost religious fervor around it that was based on having proxied their sense making to people who they believe. So the UN said it or the Gates Foundation said it or whatever it is - I've heard it repeated enough times - just through repeatability: I have been programmed to believe this thing is true, which is not that different than believing a fundamentalist religious idea. And let's say we take people's fervent ideas on vaccines or their fervent ideas on the viability of market ideology or almost anything like that - almost no one who has fervent ideas has a good epistemic basis for the level of certainty they hold. There's a decoupling between how much certainty they have and how much certainty they should have through right process. And then you look at who are they proxying their sense making to - in most the time they're not even proxying their sense making to the people who did the original research, many of whom disagree with each other and were funded by somebody to say something that is not fully true in the first place, and who maybe were employing epistemic biases themselves. But typically it's somebody else who looked at all of that and then someone else who looked at all of that so you might have like a bunch of climate scientists into someone who is speaking about that as a climate scientist at a more synthetic level - like a James Hansen or whatever - to then like a Gore or someone who is actually speaking to the public who we're proxying our sense making to. And we say 'okay how many steps removed is it and how good was the original data?'" - [Daniel Schmachtenberger](https://youtu.be/7LqaotiGWjQ?t=2276)

https://www.youtube.com/watch?v=7LqaotiGWjQ
^^ TODO: actually rewatch again and extract what's worthwhile



> "The idea of democracy is that it is participatory governance. So you notice that the modern democracies emerged out of the European Enlightenment, and specifically because the idea that a lot of people - some huge number - not a tribal number - huge number of anonymous people who don't know each other, are not bonded to each other, who believe different things, who grew up in different ways, can all work together to make collective decisions well that affect everybody and where some of them will make compromises in the thing that matters to them for what matters to other strangers - that's actually wild, like it's a wild idea that that would even be possible. And it was kind of the result of this high enlightenment idea that we could all do the [philosophy of science](https://en.wikipedia.org/wiki/Philosophy_of_science) and we could all do the [hegelian dialectic](https://en.wikipedia.org/wiki/Dialectic) - those ideas had emerged, right, and it was that we could all... So our choice making - because we said a society is trying to coordinate choice making - the emergent order is the order of the choices that we're making - not just at the level of the individuals but what groups of individuals - corporations, nations, states, whatever do. Our choice making is based on our sense making and our meaning making. Our sense making is what do we believe is happening in the world and what do we believe the effects of a particular thing would be, and our meaning making is what do we care about, right, our values generation - what do we care about that we're trying to move the world in the direction of. If you ultimately are trying to move the world in a direction that is really really different than the direction I'm trying to - we have very different values - we're going to have a hard time. And if you think the world is a very different world, right, if you think that systemic racism is rampant everywhere and one of the worst problems and I think it's not even a thing, if you think climate change is almost existential and I think it's not even a thing - we're going to have a really hard time coordinating. And so we have to be able to have shared sense making of can we come to understand just what is happening together and then can we do shared values generation: *'okay maybe I'm emphasizing a particular value more than you but I can see how I can take your perspective and I can see how the thing that you value is worth valuing and I can see how it's affected by this thing, so can we take all the values and try to come up with a proposition that benefits all of them better than the proposition I created just to benefit these ones - it harms the ones that you care about, which is why you're opposing my proposition'*. We don't even try in the process of crafting a proposition currently to see - and this is the reason that the proposition when we vote on it gets half the votes - almost all the time - it almost never gets 90% of the votes - is because it benefits some things and harms other things. We can say *'all theory of tradeoffs'* but we didn't even try to say *'could we see what everybody cares about and see if there was a better solution'*. **LEX:** How do we fix that try - I wonder is it as simple as the social technology of education? **DANIEL:** Well no, it's that the proposition crafting and refinement process has to be key to a democracy or paratory governance, and it's not currently. **LEX:** But isn't that the humans creating that situation? So... there's two ways to fix that: one is to fix the individual humans which is the education early in life, and the second is to create somehow systems that... I understand the education part, but creating systems - that's why I mentioned the technologies is creating social networks essentially. **DANIEL:** Yes, that's actually necessary. Okay so let's go to the first part and then we'll come to the second part. So democracy emerged as an Enlightenment era idea that we could all do a [dialectic](https://en.wikipedia.org/wiki/Dialectic) and come to understand what other people valued, and so that we could actually come up with a cooperative solution rather than just *'F you we're going to get our thing in war'*, right, and that we could sense make together - we could all apply the philosophy of science and you weren't going to stick to your guns on what the speed of sound is if we measured it and we found out what it was and there's a unifying element to the objectivity in that way. And so this is why I believe Jefferson said if you could give me a perfect newspaper and a broken government or - I'm paraphrasing - or a broken government & perfect newspaper - I wouldn't hesitate to take the perfect newspaper because if the people understand what's going on they can make build a new government. If they don't understand what's going on they can't possibly make good choices. And Washington - I'm paraphrasing again - first president said the number one aim of the federal government should be the comprehensive education of every citizen in the science of government. Science of government was the term of art - think about what that means, right, science of government would be [game theory](https://en.wikipedia.org/wiki/Game_theory), coordination theory, history - it wouldn't be called game theory yet - history, sociology, economics, right - all the things that lead to how we understand human coordination. I think it's so profound that he didn't say the number one aim of the federal government is rule of law, and he didn't say it's protecting the border from enemies, because if the number one aim was to protect the border from enemies it could do that as military dictatorship quite effectively, and if the goal was rule of law it could do it as a dictatorship - as a police state. And so if the number one goal is anything other than the comprehensive education of all the citizens in the science of government it won't stay democracy long. You can see - so both education and the fourth estate - the fourth estate being... so education: can I make sense of the world, am I trained to make sense of the world, the fourth estate is what's actually going on currently - the news - do I have good, unbiased information about it. Those are both considered prerequisite institutions for democracy to even be a possibility. And then at the scale it was initially suggested here - the town hall was the key phenomena where there wasn't a special interest group crafted a proposition and the first thing I ever saw was the proposition, didn't know anything about it and I got to vote Yes or No - it was in the town hall we all got to talk about it and the proposition could get crafted in real time through the conversation, which is why there was that Founding Father statement that that voting is the death of democracy - voting fundamentally is polarizing the population in some kind of sublimated war, and we'll do that as the last step, but what we want to do first is to say how does the thing that you care about that seems damaged by this proposition - how could that turn into a solution to make this proposition better, where this proposition still tends to the thing it's trying to tend to and tends to that better - can we work on this together - and that in a town hall we could have that. As the scale increased we lost the ability to do that. Now as you mentioned the Internet could change - that the fact that we had representatives that had to ride a horse from one town hall to the other one to see what the colony would do - that we stopped having this kind of developmental propositional development process when the town hall ended - the fact that we have not used the Internet to recreate this is somewhere between insane and aligned with class interests." - [Daniel Schmachtenberger](https://youtu.be/hGRNUw559SE?t=12435)

> "Could we apply Facebook-like technology to develop people's citizenry capacity, right, to develop their personal health and well-being and habits as well as cognitive understanding - the complexity with which they can process the health of their relationships - that would be amazing to start to explore. And this is now the thesis that we started to discuss before is: every time there is a major step function in the physical tech it obsoletes the previous social tech and the new social tech has to emerge. What I would say is that when we look at the nation state level of the world today, the more top-down authoritarian nation states are... as the exponential tech started to emerge, the digital technology started to emerge - they were in a position for better long-term planning and better coordination and so the authoritarian states started applying the exponential tech intentionally to make more effective authoritarian states - and that's everything from like an Internet of Things surveillance system going into machine learning systems to the [Sesame credit system](https://en.wikipedia.org/wiki/Zhima_Credit) to all those types of things - and so they're upgrading their social tech using the exponential tech. Otherwise within a nation state like the US but democratic open societies - the countries - the states are not directing the technology in a way that makes a better open society, meaning better emergent order - they're saying: well the corporations are doing that and the state is doing the relatively little thing it would do aligned with the previous corporate law that no longer is relevant because there wasn't fiduciary responsibility for things like that, there wasn't antitrust because this creates functional monopolies because of network dynamics, right, where YouTube has more users than Vimeo and every other video player together, Amazon has a bigger percentage of market share than all of the other markets together - you get one big dog per vertical because of network effect, which is a kind of organic monopoly that the previous antitrust law didn't even have a place - that wasn't a thing - anti-monopoly was only something that emerged in the space of government contracts. So what we see is the new exponential technology is being directed by authoritarian nation states to make better authoritarian nation states and by corporations to make more powerful corporations. The powerful corporations - when we think about the Scottish Enlightenment, when the idea of markets was being advanced, the modern kind of ideas of markets - the biggest corporation was tiny compared to what the biggest corporation today is, so the asymmetry of it relative to people was tiny. And the asymmetry now in terms of the total technology it employs, total amount of money, total amount of information processing is so many orders of magnitude, and rather than there be demand for an authentic thing that creates a basis for supply, as supply started to get way more coordinated and powerful and the demand wasn't coordinated because you don't have a labor union of all the customers working together, but you do have a coordination on the supply side - supply started to recognize that it could manufacture demand, it could make people want shit that they didn't want before that maybe wouldn't increase their happiness in a meaningful way - it might increase addiction - addiction is a very good way to manufacture demand, and so as soon as manufactured demand started through "this is the cool thing and you have to have it for status or whatever it is" - the intelligence of the market was breaking. Now it's no longer a collective intelligence system that is upregulating real desire for things that are really meaningful - you're able to hijack the lower angels of our nature rather than the higher ones - the addictive patterns - drive those, and have people want shit that doesn't actually make them happier or make the world better. And so we really also have to update our theory of markets because [Behavioral Econ](https://en.wikipedia.org/wiki/Behavioral_economics) showed that [Homo economicus](https://en.wikipedia.org/wiki/Homo_economicus) - the rational actor - is not really a thing, but particularly at greater and greater scale can't really be a thing. Voluntarism isn't a thing - where if my company doesn't want to advertise on Facebook - I just will lose to the companies that do because that's where all the fucking attention is. And so then I can say it's voluntary but it's not really if there's a functional monopoly. Same if I'm going to sell on Amazon or things like that. So what I would say is the these corporations are becoming more powerful than nation states in some ways and they are also debasing the integrity of the nation states, the open societies, so the democracies are getting weaker as a result of exponential tech and the kind of new tech companies that are kind of a new feudalism - tech feudalism - because it's not a democracy inside of a tech company or the supply and demand relationship - when you have manufactured demand and kind of monopoly type functions - and so we have basically a new feudalism controlling exponential tech and authoritarian nation states controlling it and those attractors are both shitty. And so I'm interested in the application of exponential tech to making better social tech that makes emergent order possible and where then that emergent order can bind and direct the exponential tech in fundamentally healthy not-X-risk oriented directions. I think the relationship of social tech and physical tech can make it - I think we can actually use the physical tech to make better social tech, but it's not given that we do. If we don't make better social tech then I think the physical tech empowers really shitty social tech that it's not a world that we want." - [Daniel Schmachtenberger](https://youtu.be/hGRNUw559SE?t=13434)

> "I think the thing that we call markets - of course we can try to say oh even biology runs on markets - but the thing that we call markets - the underlying theory [Homo economicus](https://en.wikipedia.org/wiki/Homo_economicus) demand driving supply - that thing broke. It broke with scale in particular and a few other things. So it needs updating in a really fundamental way. I think there's something even deeper than making money happening that in some ways will obsolete money-making. I think capitalism is not about business. So if you think about business - I'm going to produce a good or a service that people want and bring it to the market so that people get access to that good or service - that's the world of business, but that's not capitalism. Capitalism is the management and allocation of capital which financial services was a tiny percentage of the total market - it's become a huge percentage of the total market - it's a different creature. So if I was in business and I was producing a good or service and I was saving up enough money that I started to be able to invest that money and gain interest or do things like that - I start realizing I'm making more money on my money than I'm making on producing the goods and services so I stop even paying attention to goods and services and start paying attention to making money on money and how do I utilize capital to create more capital. And capital gives me more optionality because I can buy anything with it than a particular good or service that only some people want. Capitalism - more capital ended up meaning more control - I could put more people under my employment, I could buy larger pieces of land, novel access to resource mines and put more technology under my employment - so it meant increased agency and also increased control. I think attentionalism is even more powerful. So rather than enslave people where the people kind of always want to get away and put in the least work they can there's a way in which economic servitude was just more profitable than slavery, right, have the people work even harder voluntarily because they want to get ahead and nobody has to be there to whip them or control them or whatever - this is a a cynical take but a meaningful take. So capital ends up being a way to influence human behavior, right, and yet where people still feel free in some meaningful way - they're not feeling like they're going to be punished by the state if they don't do something - it's like punished by the market via homelessness or something. But the market is this invisible thing I can't put an agent on so it feels like free. And so if you want to affect people's behavior and still have them feel free capital ends up being a way to do that, but I think affecting their attention is even deeper because if I can affect their attention I can both affect what they want and what they believe and what they feel and we statistically know this very clearly - Facebook has done studies that based on changing the feed it can change beliefs, emotional dispositions, etc. And so I think there's a way that the harvest and directing of attention is even a more powerful system than capitalism - it is effective in capitalism to generate capital but I think it also generates influence beyond what capital can do and so do we want to have some groups utilizing that type of tech to direct other people's attention - if so - towards what? Towards what metrics of what a good civilization and good human life would be - what's the oversight process? What is... **LEX:** ... **DANIEL:** Okay, so maybe the corporation has coordination on its goals that all of its customers or users together don't have so there's some asymmetry where it's asymmetry of its goals but maybe I could actually help all of the customers to coordinate - almost like a labor union or whatever - by informing and educating them adequately about the effects & the externalities on them - this is not toxic waste going into the ocean of the atmosphere - it's their minds, their beings, their families, their relationships, such that they will in group change their behavior and I think... One way of saying what you're saying I think is that you think that you can rescue [Homo economicus](https://en.wikipedia.org/wiki/Homo_economicus) from the rational actor that will pursue all the goods and services and choose the best one at the best price - the kind of Rand/Von Mises/Hayek - that you can rescue that from [Dan Ariely](https://en.wikipedia.org/wiki/Dan_Ariely) and [behavioral econ](https://en.wikipedia.org/wiki/Behavioral_economics) that says that's actually not how people make choices - they make it based on status hacking largely whether it's good for them or not in the long term and the large asymmetric corporation can run propaganda and narrative warfare that hits people's status buttons and their limic hijacks and their lots of other things in ways that they can't even perceive that are happening. They're not paying attention to that - the site is employing psychologists and split testing and whatever else. So you're saying I think we can recover homoeconomicus? **LEX:** ... the education of negative externalities can become viral in this world. **DANIEL:** So interestingly I actually agree with you... **LEX:** Got em!... Tech can do some good... **DANIEL:** What you're talking about is the application of tech - here broadcast tech - where you can speak to a lot of people, and that's not going to be strong enough because the different people need spoken to differently which means it has to be different voices to get amplified to those audiences - more like Facebook's tech - but nonetheless we'll start with broadcast tech. **LEX:**... **DANIEL:** So let's come back to the fundamental thing - the fundamental thing is: we want to kind of order at various scales from the conflicting parts of our self actually having more harmony than they might have, to family, extended family, local, all the way up to global - we want emergent order where our choices have more alignment, right, we want that to be emergent rather than imposed or rather than we want fundamentally different things or make totally different sense of the world where warfare of some kind becomes the only solution. Emergent order requires us in our choice making requires us being able to have related sense making and related meaning making processes. Can we apply digital technologies and exponential tech in general to try to increase the capacity to do that - where the technology called a town hall - the social tech that we'd all get together and talk - obviously is very scale limited and it's also oriented to geography rather than networks of aligned interest. Can we build new better versions of those types of things? And going back to the idea that a democracy or participatory governance depends upon comprehensive education in the science of government, which includes being able to understand things like asymmetric information warfare on the side of governments, and how the people can organize adequately - can you utilize some of the technologies now to be able to support increased comprehensive education of the people and maybe comprehensive informedness - so both fixing the decay in both education and the [fourth estate](https://en.wikipedia.org/wiki/Fourth_Estate) that have happened so that people can start self-organizing to then influence the corporations, the nation states to do different things and or build new ones themselves? Yeah, fundamentally that's the thing that has to happen. The exponential tech gives us a novel problem landscape that the world never had - the the nuke gave us a novel problem landscape and so that required the whole [Bretton Woods](https://en.wikipedia.org/wiki/Bretton_Woods_system) world. The exponential tech gives us a novel problem landscape - our existing problem solving processes aren't doing a good job - we have had more countries get nukes, we haven't done nuclear de-proliferation, we haven't achieved any of the UN sustainable development goals, we haven't kept any of the new categories of tech from making arms races - so our global coordination is not adequate to the problem landscape. So we need fundamentally better problem solving processes - a market or a state as a problem solving process - we need better ones that can do the speed and scale of the current issues. Right now speed is one of the other big things - it's that by the time we regulated [DDT](https://en.wikipedia.org/wiki/DDT) out of existence or cigarettes not for people under 18 - they'd already killed so many people and we let the market do the thing, but as Elon has made the point that won't work for AI - by the time we recognize afterwards that we have an autopoietic AI that's a problem you won't be able to reverse it - that there's a number of things that when you're dealing with tech that is either self-replicating and disintermediates humans to keep going - doesn't need humans to keep going - or you have tech that just has exponentially fast effects - your regulation has to come early - it can't come after the effects have happened, the negative effects have happened because the negative effects could be too big too quickly. So we basically need new problem solving processes that do better at being able to internalize externality, solve the problems on the right time scale and the right geographic scale, and those new processes to not be imposed have to emerge from people wanting them and being able to participate in their development, which is what I would call kind of a new cultural Enlightenment or Renaissance that has to happen, where people start understanding the new power that exponential tech offers, the way that it is actually damaging current governance structures that we care about, and creating an x-risk landscape, but could also be redirected towards more [protopic](https://metamoderna.org/whats-the-difference-between-utopia-eutopia-and-protopia/) purposes and then saying: how do we rebuild new social institutions, what are adequate social institutions where we can do participatory governance at scale in time, and how can the people actually participate to build those things. The solution that I see working requires a process like that." - [Daniel Schmachtenberger](https://youtu.be/hGRNUw559SE?t=13865)

> "So I would say that our global coordination on all of the most critical issues is inadequate to the timeline and consequentiality of the issues - like that seems very very clear. And as exponential tech is advancing, the total number of catastrophic risks and the total probability of each is increasing, and the capacities that we're utilizing to address them are not increasing accordingly. So there is a gap that we need to be focused on which is what you guys are focused on, which is this kind of global governance topic - we have global issues - not just local issues. Everybody's scared of global governance - the frame - the term global governance - or at least global government - for a good reason, which is: we have a good long history of reasons to not trust consolidation of power with no checks and balances. So nobody wants this kind of massive unchecked global government and at the same time you have to have governance at the scale that cause and effect is occurring. And if we're having... if nobody can fix climate change on their own - in terms of nation states - and yet they're all affected by it and they can't fix overfishing, they can't fix nitrogen run, off dead zones and oceans, and etc. there have to be global coordination solutions - otherwise multi-polar traps ruin everything, right, a multipolar trap is some kind of race to the bottom - arms race is an example as we've already mentioned, tragedy of the commons is another example, but the key to both of them is where the agent focused on their own short-term well-being does something that advances their short-term interest, but then makes everybody else have to do the same thing, and where everyone doing it creates the maximally bad long-term situation. And so if we try to create some treaty around not overfishing a particular region of the ocean and anybody violates it - then if anyone else doesn't violate the treaty if they can't figure out enforcement then you're just a sucker for holding to the treaty, right, because all those fish are going to get killed anyways, the ocean's going to get messed up, it's just going to feed another population that's going to grow and have more people to engage in economics and armies... And how do you do enforcement on a nation that has nukes or a nation that has some critical aspect of infrastructure, or you know - the globalized supply chain. And so enforcement becomes tricky, so then you get these types of things: tragedy of the commons, an arms race, multi-polar traps - so you have to figure out how do we solve those coordination issues globally because we have global issues that can't just keep getting pushed down the road. And yet we want to figure out a solution to do it that isn't a kind of global government that becomes its own catastrophic risk of under the name of some problem that is scary enough we agree to some totalitarian power structure. And that's the thing you mentioned about order and chaos is that we can see that the thing we call civilization is a way of having some order, some coordination between lots of people, so that they can do specialization and division of labor, creating a richer world for everybody and then coordinate all that, they can coordinate their activity for not just those kind of productive purposes but also protection purposes. So the thing that we call civilization is how we coordinate behavior of lots of people and that's actually a pretty hard thing to do when you think about people that want different stuff and believe different stuff and aren't necessarily connected to or bonded to each other - like how do you get them to not just do the immediate advantageous thing to them for people that are fundamentally strangers to them. So typically a civilization will try to create order through some kind of imposition - some forced religion, forced patriotism, law, whatever it is - and it can err in the side of in order to have everybody participate with that order becoming increasingly tyrannical, increasingly dictatorial. If it doesn't do that people end up orienting towards tribalism naturally and fragmenting kind of towards each other and you end up getting the thing failing in the direction of chaos. The only other answer is how do you get order without it being imposed - how do you get emergent order - and this was the kind of idea of democracies and republics and open societies is: maybe we could actually get emergent order if we - and it was based on the idea of a culture that invested in the people enough that the people didn't just believe different things and want different things and be willing to defect into war, you had to actually develop a people that could all come to understand the world similarly, can everybody understand the philosophy of science well enough that they can all come to understand base objective reality that they share similarly, can they all have something like [hegelian dialectic](https://en.wikipedia.org/wiki/Dialectic#Hegelian_dialectic) capacities where they can notice not just their own values but other people's values and recognize that only solutions that meet everybody's values will end up working, can they understand things like multi-polar traps well enough to understand that a short-term win of my political party just means that whatever technique we utilize that was effective gets reverse engineered the other side wins in the next four years and undoes everything that we did for four years and we we get nowhere and then dictatorships do much better than us and the society fails, can people understand those things enough that they don't orient towards the short-termism kinds of things. So this is why the modern democracies emerged out of modernity, emerged out of a philosophic system that said we can come to understand the world and understand each other well enough that we can actually have emergent coordination. Obviously the world has gotten much more complex during that time and the cultural value of that kind of education has eroded." - [Daniel Schmachtenberger](https://youtu.be/U0YJ0C81n4s?t=870)

> "You can almost think of what the state in a liberal democracy is as like a labor union for the people, and as a whole, like a labor union, how do you unify all the people to have something that is big enough to represent their collective interests, so that the large corporations and the major wealth holders within capitalism don't just rule everything like feudalism, which is the thing we were trying to replace before? Because it's very clear that if we have a trade system and it's mediated by an abstract system for doing accounting - like currency - that pretty soon you'll have a power law distribution of wealth and a few people will own most of the wealth - some people are better at it and then getting better at it gives you more capacity to keep getting better at it and there's compounding interest which is an exponential return on owning capital, there's compounding interest on debt, and you know, does that thing... Right, and we can see the data of that in [Piketty's book](https://en.wikipedia.org/wiki/Capital_in_the_Twenty-First_Century), but it's also just kind of a natural thing to look at. So the idea was since power law distributions are going to happen, that most people are going to have really no power, how do you not have that be oppression? Well let's have the people all be able to collectively vote where at least the majority of what they care about gets encoded as law, so their values are the basis of the jurisprudence of the law, so then rule of law can get enforced by representatives of, for, and by the people, that are going to be bequeathed with a monopoly of violence so they can actually do enforcement to be able to protect the people in the commons against perverse incentive, while letting the market do all the good things that it does, but most of rule of law is actually binding the perverse incentives of markets. Okay, so if that only works where the state can check the predatory aspects of markets, if the people are checking the state that it is truly of, for, and by the people, there's transparency, everybody's actively engaged - as soon as that stops happening, then the government is just run by people, those people are economic actors they're in there for whatever short period of time and they will be liked about the same whether they do corporate interests or not, because nobody's really going to know, and so of course you end up getting regulatory capture where the market captures the regulatory apparatus and you get crony capitalism and that kind of institutional decay. And as the founding fathers in the U.S. said and anyone who paid attention: as soon as a couple generations pass and the people forget what it means to fight a revolutionary war and be under oppression, they won't keep investing and being educated enough and actively being engaged in government because they'd rather [keep up with the Joneses](https://en.wikipedia.org/wiki/Keeping_up_with_the_Joneses) or party or like some other thing. And so how do you keep the intergenerational transfer of not just the knowledge, but the civic virtues necessary to uphold a democracy, which is not a trivial thing? And especially as time goes on and the complexity of the world increases, understanding the issues well enough to really play a role in them and to be able to oversight them and police them gets harder and harder and so there has to be more and more investment into doing that. So we can see that the people stopped investing and checking the state, the state stopped checking the market, market captured the state, all the innovation got outsourced, and so what we can see today, so we see in that world war two example that the state really pioneered the advancement of all these areas of tech to increase the integrity of the state. There is a jump in technology that is currently happening that is more significant than the world war II jump in technology and the center of it is AI and computation with AI being the very center, right, it's computation, digital tech, but then the application of AI and digital tech to physical tech as well, so the application of that to biotech and crispr kind of stuff, and to robotics and robotic automation, and the other key areas of computer science from the evolution of the computational basis, quantum computing, photo computing, DNA computing, whatever, and again the application of that to the material sciences, nanotech, etc. So we're undergoing this huge jump in technology right now that is something like two orders of magnitude more significant than the previous world war II jump was in terms of the total amount of verticality of power and the speed at which it's developing and the number of verticals simultaneously. And the way I see it is that tech will confer so much power that only those who are guiding it will have much of a say in the future, and right now I only see two types of groups really guiding it meaningfully: some authoritarian nation states are, where the nation state is taking seriously the development of the tech and the nation state is investing a very big R&D budget and how to actually increase the integrity of their nation state and it's a good thing for them to do, aligned with whatever their system and their ideologies are, and obviously China is a prime example here. Where the application... the government is investing in the development of engineers and in the application of all of those areas of tech to the nature of government itself, and that's everything from their IOT system to their [Sesame credit system](https://en.wikipedia.org/wiki/Zhima_Credit) to the transistor development and lithography to the [Belt and Road Initiative](https://en.wikipedia.org/wiki/Belt_and_Road_Initiative) and getting something like 94 percent of the world's rare earth metals in there that are needed for computational substrate in their supply chain to on and on, right, to the creation of their own Internet that doesn't have the same problems for their country that the U.S. Internet has. So authoritarian nation states are using the exponential tech to become exponentially more effective authoritarian nation states, and the only other kind of org are companies, Western mostly companies, and those companies are supported by a military and capital and infrastructure of the nation state but they are not serving the interests of the nation state other than GDP and jobs and some very short-term kind of stuff. And they're becoming exponentially more powerful companies, but you know, Facebook and Google have more users than China and the U.S. combined have people, right, so these are humongous kinds of things of which there is no precedent for a corporation in history. [Ayn Rand](https://en.wikipedia.org/wiki/Ayn_Rand) never imagined things like this when she was thinking about the symmetry of supply and demand and she didn't think of things like [Metcalfe dynamics](https://en.wikipedia.org/wiki/Metcalfe%27s_law) that end up leading to natural monopolies and anti-trust law didn't think of that, right, so you end up having Amazon being bigger than all other online stores combined and Google being bigger than all other search engines combined and Facebook being bigger for time on site than all the other social networks, so you get a natural power law distribution not based on government crony capitalism - based simply on the nature of network dynamics, that once you reach a certain escape velocity your a natural monopoly will start to emerge based on the value of the thing being associated with the second power of the number of users. And so the interesting thing is you see these corporations that are becoming more powerful than nation states in many ways because of the development and direction of the exponential technologies and as that happens they are less able to be regulated by the countries while still benefiting from the infrastructure of the countries and simultaneously eroding the integrity of the country - we can see the way that the time on site optimization ad model of Facebook and Google and Youtube have eroded American democracies and in specific and Western democracies by doing the time on site optimization appeals to people's cognitive biases and tribalism and limbic hijacks and those types of things. We can see that the kind of consolidation of market function like Amazon, that Amazon's growth during covid matched pretty closely the closure of all small businesses that aren't going to reopen - well the American dream without small businesses isn't the thing, right, it's not a thing in the same way, and we see the technological automation of so many jobs impending and not the replacement in the current way that it's trending of a similar American dream kind of sovereignty, so there's kind of a a billionaire to centibillionaire class that runs whatever the one big dog on the top of the power law distribution that defines a vertical is and an increasingly less upwardly mobile in terms of real capacity to play those games under class. And obviously some kind of middle class that is serving the very upper class in that context. So what I see is that is the movement to a new kind of feudalism, right, a tech feudalism, and that it's even interesting some of those companies - you know - we see this with Tesla, we see with the other ones - some of those companies are getting subsidies - government subsidies - that means they're collecting taxpayer money, to utilize taxpayer money to do the thing they're doing, but the taxpayers didn't vote on them doing that, they were not elected representatives, they cannot be unelected and there is no traditional jurisprudence for the guidance of the thing that they're doing - that's something much more like a king than a president, which is why I say kind of an emergent tech feudalism. So what I see is there's one strange attractor which is tech feudalism, there's another strange attractor which is kind of authoritarian nation states, and anything like an open society where there's participatory governance and jurisprudence that is grounded in the will of the people - there is no system that is based on those ideals that is innovating in exponential tech to make better versions of that social tech - that is the number one imperative of our time in my opinion, and either we figure that thing out or those are the only attractors. And the third attractor is that the exponential tech just causes x-risk and we're fucked, right, so you have x-risk, feudalism and authoritarianism, as the current dominant attractors in the presence of exponential tech, or there's not 17 sustainable development goals that really matter because we can't achieve any of them without better coordination - there's figuring out coordination that it becomes the central goal of the world, figuring out a kind of coordination that is emergent order that is neither chaos nor oppression, that is able to utilize the exponential technologies and also to bind and direct them so that they do not either directly or through externality create x-risk and that they don't erode... that they don't create authoritarian systems or kind of feudal systems that erode civil liberties in the process. So we need to have a kind of global innovation zeitgeist of how develop and apply all the areas of exponential technology to building new social tech that can guide, bind, and direct the exponential tech, prevent x-risk, and do it in a way that is commensurate with what our underlying kind of deepest values for participatory and empowered governance and civics are." - [Daniel Schmachtenberger](https://youtu.be/U0YJ0C81n4s?t=1501)

> "A lot of our issues are just increases in the severity of the same underlying type of game theoretic dynamics, and so we can say they are continuous with them in type, but there are places where a change of magnitude becomes a change in kind, right, like as soon as the magnitude gets beyond human information processing capability it's now a change of kind, as soon as we move from a war that's winnable to a war that's not winnable even though they're both the logic of war it's a change of magnitude that becomes a change in kind, right, so there's a lot of places where even the things that are continuous with the past become discontinuous past certain thresholds - meaning that the same types of solutions - the whole class of solutions - doesn't apply anymore. Now that doesn't mean that we throw out everything that we've learned - it means that we have to make sure that we're applying everything that we've learned that is effective, that we aren't making the mistake of not paying attention to the total amount of human thinking and ingenuity that's happened so far, and that the new innovation that we do is commensurate with the smart parts of it, but it happens all the time that we're exploring a search space and there's a couple branches and in the immediate term this branch has more incentive, and so we explore this branch and then we just forget about this one and we just keep exploring and then we hit a cul-de-sac at a certain point, but we have reasons why there's momentum to keep - you know - some combination of [sunk cost fallacies](https://en.wikipedia.org/wiki/Sunk_cost#Fallacy_effect) with the actual belief that this is the only path - this earlier choice - and it wouldn't go all the way back there to the not even knowing the other branches that were cleaved that we didn't pay attention to, to like perverse institutional incentives of standard models where it's hard to get a research grant to do anything outside of that thing or to get your professor who believes in that thing to change their opinion on it or whatever it is. So there are a bunch of places where we actually have to go back and say: okay, there was an incentive to make faster and faster, smaller and smaller computer chips and there was enough money around that there were whole other directions in computational substrate that we didn't take that for reasons of manufacturing resilience and a bunch of other things might actually be meaningful and interesting - this is starting to be a real conversation in theoretical physics with string theory and like maybe we actually need to rewind and try a fundamentally different approach. I think there are places in governance where like we've just accepted, we've just kind of accepted capitalism in the West is the only reasonable answer combined with some kind of open-ish government state, and if you think anything else you didn't study the history of Mao and Stalin and [Pol Pot](https://en.wikipedia.org/wiki/Pol_Pot) and whatever because everything else ends up becoming that kind of dreadful slaughter - like that's kind of the dominant narrative where it's worse than going against Christianity or it's similar to going against Christianity in the dark ages, right, there's almost a religious tone to it. It's like: well we could come up with better shit that isn't any of those things, like there's nothing new under the sun - blockchain's new, like the ability to have an uncorruptable ledger where you can have a provenance of data that you can't fuck up - that makes it where you can have a history that can't be corrupted or changed by the winners afterwards - that's kind of new, that's a big deal - makes it to where you can have a system of justice where you can't actually fuck up the data, right, it means that you can have a system of accounting where let's say the government spending was on a blockchain that was transparently oversighted - there wouldn't be missing money anymore. Right now there's all these places where the total amount of money going in and the receipts coming out don't add up and there's missing money - it's like well, that couldn't be. And so it's like does that make something new possible? Yeah, totally it makes something new possible. You look at the way the AI can make new sounds, it can do error correction of sound where there is an error or make new sounds or make new faces by doing an average composite of all faces that look similar-ish, right - you say: well could huge numbers of people express their sentiments about something and have the AI actually come up with something that is like a weighted average of all of those as a form of proposition creation, and then could we use distributed methods of proposition advancement that didn't exist when we had to meet in a town hall and ride a horse from that town hall to the other ones and we haven't innovated the structure of government since we had to ride horses? Like why do we think that this particular thing is the best thing? Well because the other things - the last time we had that conversation seemed dreadful - at least that was the winning narrative. But totally new things that are not just those previous things are possible, and so what I would say is someone should not assume that the moment we say maybe there's a problem with capitalism that we're instantly going to turn into Stalinism, but to say let's make sure we study that history well enough to know what was wrong with those ideas we don't do that - yes - but let's also do the critique of the system and not just end with the critique but take it as a design criteria to say what would a better system look like, and have we got all the design criteria? Do we have the critiques of the communist system and the socialist system and the capitalist system simultaneously and then can we take all those as design criteria and work on a fundamentally better design that might not look like any of those isms that utilizes new technology which means new possibilities that didn't exist before with new forcing functions that didn't exist before?" - [Daniel Schmachtenberger](https://youtu.be/U0YJ0C81n4s?t=2558)

> "They haven't even tried hard enough to have that doubt mean anything - it's just an emotional default. That was the other question you asked is: are we hitting the limits of cognitive complexity? That is such a like shit answer if you haven't actually applied the full limits of human cognitive complexity and seen that we were failing. So we're not even trying, like, China's trying and they're doing amazing, right, like... in the U.S. we have no high-speed trains - none, none - in the time that they've existed China's been exporting them all around the fucking world in that same amount of time. But a system that doesn't have term limits and that doesn't have a two-party system where you just use all the energy wasted as heat fighting each other and then whatever you do for four years the other people undo for four years and nobody invests in anything with longer than four year timelines because it won't get them re-elected - that system is just stupid - that's going to fail to a system that can do long-term planning. So if we say: okay, let's imagine just hanging out in the 30s and saying we got to figure out how to split an atom - no, not just split an atom, we're going to figure out how to split an atom and deliver that as a warhead with on a rocket to some other place with some decent precision - in fact we're going to go beyond that - we're going to use uranium to fission something and split it to then drive nucleons into a fusion - it would be easy to say well there's no fucking way, like, we don't have the cognitive complexity to be able to split atoms - we don't even know what an atom is. But the Manhattan project was a very serious investment in cognitive complexity and and we got everybody there, right, like we got all the best thinkers in the world there, we put the budget on - are we doing that? Like are we even fucking... we got Von Neumann, we got Turing, we got time, and we got - you know - Oppenheimer - we got all those folks in Bletchley Park and in Los Alamos and like - where is the equivalent of that thing outside of very narrow areas of military - which is why we have a dope military, like, we have an awesome military, but that's innovation in military - it's not innovation in the social technology of governance itself. We actually have to not just innovate our military, but innovate the social technology of governance for a participatory governance system, and this is why we come back to the... there's this quote that I always forget so I paraphrase of George Washington's that said something to the effect that the number one aim of the federal government has to be the comprehensive education of every citizen in the science of government, and science of government was the term of art. And I think it's so profound that he did not say the number one aim of the federal government is to protect its borders, and he did not say the aim of the federal government is to protect rule of law, because you can do rule of law effectively with a police state, and you can protect the boundaries fine with a military dictatorship, but they won't be democracies - if it's going to be a democracy, then democratically the people will probably decide to protect their borders and to engage rule of law, but if the number one goal is anything other than the comprehensive education of all citizens and the education was considered both a cognitive education and a moral education - the way they described it which is the kind of civic virtues that people are willing to give something for the larger system that they also receive benefit from and they're actively participatory engaged. So that's the thing we need to be innovating in right now - not just innovating in military while turning it into a some kind of autocratic or kleptocratic system, but how do we apply the new digital and other exponential technologies to be able to both direct the exponential technologies well so that they don't cause existential risk and in a way that is aligned with the actual values that we care about as a people. And so then the core question comes: what is a successful civilization? Well it's one that doesn't fail, but that's not the only criteria - it's one that doesn't fail and it maximizes the possible quality of life for everybody in perpetuity and then we have to find what does quality of life mean, right, so there's like core existential questions of what is a meaningful human life to be able to design a civilization that is optimizing for that, which is culture, right, which is why we have to have innovation in culture, which is why I talk about that there's a cultural renaissance - a cultural enlightenment - that is necessary right now as the basis of the creation of these new institutions that can solve the x-risk problems, because our current problem-solving mechanisms can't solve them, which is why they're not being solved. We have to develop new institutions that are capable of solving these types of problems - these types of complexity - but if those new institutions are created by a few people that get it and impose them on force then it's some kind of autocracy. So they have to be created by people who want them and are willing to participate with them and capable of participating - that is the cultural enlightenment that has to be the basis of it... And of course there's a recursive process of some people engaging in that to then build systems that in turn engage more people in it - so you get a virtuous cycle between cultural evolution and social evolution employing physical technologies, binding physical technologies, and advancing them for the right purposes." - [Daniel Schmachtenberger](https://youtu.be/U0YJ0C81n4s?t=2928)

> "How do we solve global multi-polar trap issues is not solved anywhere and that's the most central thing we have to figure out. How do we create digital open societies - you can say that it's kind that there are some places that are trying to pioneer like Taiwan and Estonia and that's true, but those are very far from have really got worked out solutions that are adequate to all the other places and scale. So I think we have to acknowledge that many of the most critical solutions don't exist at all and need to become the primary focus of innovation and then where they do start to develop we have to say: what type of governance and incentive landscape would be necessary to get them everywhere they need to be in time and who would have to be participating to make that happen and what kind of oversight and enforcement would be necessary to really make it happen. You know in the U.S. the government making deals with native americans and then not keeping them whenever it's inconvenient - almost all the time - it's not just about did you say when you developed a new technology that will get it to the world - it's is there a method of enforcement that will actually ensure that that occurs and that it occurs within time - that becomes critical." - [Daniel Schmachtenberger](https://youtu.be/U0YJ0C81n4s?t=3475)

> "Yeah it's apologism. So if I win a war and we kill a bunch of people that we call terrorists or infidels or some bad thing that makes them not human but what it means is we blew up a lot of civilians and a lot of women and kids and whatever it was, but we got more land and resources and whatever it was out of doing that thing - survival the fittest is a nice narrative to say that's how nature works and that's the way that it should be and it's actually the prey animals... it's actually the predators that keep the prey animals from eating themselves into extinction and that drive them to evolve by eating the slow ones so that the good genes kind of inbreed and - you know - most people are like prey animals so the some more predatory humans that cull the herd and that kind of drive them who are otherwise kind of lazy eaters - like that whole ideology is apologism for whoever is winning at an extremely damaging rivalrous kind of system. Naive techno capital optimism is one of the best examples of apologism of this kind where: like if you have a theory that criticizes capitalism - nobody who's winning at capitalism who has the money is going to upregulate it, and if you are criticizing tech nobody that was winning at tech is going to say yes I like your idea of why I suck and I'm going to upregulate that. So you realize that for narratives to catch on - somebody has to upregulate them and there's cost associated in doing that and there has to be a motive associated with that cost. It's not just like the ideas that are the most true and the most beneficial proliferate - the ideas that have the most agentic basis to drive them through the society are a lot of the ones that proliferate." - [Daniel Schmachtenberger](https://youtu.be/U0YJ0C81n4s?t=3591)

> "So do humans need to ensure - as the metaphors of nature go - that where we have competition that it's symmetrical and that it's constrained and that the micro competition really does lead to macro symbiosis? We need to ensure that? This is true. Is the competition between Facebook for your attention and you for your attention symmetrical? No, of course not. Well you say well there's a competition... the competition between supply and demand is symmetrical because there's an equal number of dollars flowing from demand to supply - bullshit! Right, the demand side is not coordinated - the supply side's coordinated, and so even though there's a total symmetry in aggregate, there's not a symmetry of coordinated capacity because it isn't Google against all Google users as a Google user labor union that is also applying similar exponential technologies to buying this thing - it's Google against one person in terms of the person didn't think that they were about to spend the next three hours on Youtube and now they do which is better for their advertising model - not necessarily for your life. And so then you can have supply side driving manufactured demand - well now there's not real... the market ideology is broken now - that's not a... market ideology was that there was a thing called demand that was foundational, that people wanted real shit that would improve the quality of their life and that created an environmental niche for supply, and the rational actors would buy the product or service amongst all of them at the best price that would drive innovation - well the moment supply started to get much bigger than demand because of coordination it realized that it could manufacture supply and the humans weren't all that rational - all the [behavioral economics](https://en.wikipedia.org/wiki/Behavioral_economics) - and now the entire logic of markets is broken, right, like market theory is broken with manufactured demand and radical asymmetries on the supply side. Okay, that's important to know, and so if you go back to the nature example where there's competitive forces: do they need to have symmetries in order for the competition to lead to symbiosis as a whole and metastability of the ecosystem? Yes. If you bring something in that is not symbiotic with the rest of it - you get an invasive species - it can destroy a whole ecosystem. Right, so we should study biology where we're not trying to compare ourselves to apex predators or slime molds or whatever - we could just study general principles of things like cooperative dynamics and competitive dynamics and meta stability - we can kind of get a sense of that: what is needed for meta stability and then say how does that apply in the human world, but it will be different - it'll be very different. The rest of the animal world is not forecasting the future and making game theoretic decisions based on forecasts of the future. So this is why like complexity theory where we model us as termites is silly, like, we don't behave like termites. So it's not that it's useless, but it's profoundly inadequate as a set of metaphors. So we have to recognize: are humans part of nature? Of course. Is there a distinction between humans and the rest of nature that is fundamental in type? Maybe it was just a change of quantity of neurological complexity that crossed a threshold it became a change of kind, but it is a change of kind, and so we will have to have fundamentally different metaphors for thinking about that, which is why it makes sense to just think about the problem space and make sure that you understand the problem space well and that your solutions are aligned with the problem space." - [Daniel Schmachtenberger](https://youtu.be/U0YJ0C81n4s?t=4024)

> "To be civilized is kind of a domestication program for wild humans to be able to operate together at larger than tribal scale. And for hundreds of thousands of years, we never got tribes bigger than about 150 people. They stayed at very small scales, where everybody knew everybody, so that the sacrifices you made for others were non-anonymous people. They were people that you knew really well, and that you wouldn't do that at much larger sizes. And so, then the much larger thing, the thing we call civilization, can also be thought of as a domestication program. And the main things you have to domesticate out of people that make them not work other well have to do with sex and violence. And so, this is also where most of the psychological shadow comes, and it's why the intersection of sex and violence is the deepest part of most people's psychological shadow. They're kind of put into the same areas. But if you think about what institutional monogamy occurring with that context, one of the things that it was designed, or a few of the things it's designed to do, if you couldn't have sex until getting married, and then you weren't allowed to divorce, and that was actually held, and of course, no system will be perfectly held, but like just the idea, then in order to get laid, a guy had to get a girl's parents, and preacher, and community to decide that he was an acceptable husband and father. And that, and the binding of his ability to get laid to his ability to be a good father long-term meant that there was an incentive for him to actually be a good guy long-term, which meant him being a good guy for civilization and him being a good guy as a father were bound to his need to get laid, right? And that there was a vetting beyond her, who might have already got oxytocin to not be, you know, assessing him well, 'cause of the crush that the father, and the mother, and the whatever would also be helping to assess, to grant the right to do the thing. And then in the wedding ceremony, does anyone object? If he had been an asshole to other people, and they got to bring that up, so he has to be an asshole to nobody, otherwise, he's never gonna be laid. Then this would also be even where the slut-shaming came, which is such a terrible thing in our modern context, but I was coming to understand where a possible evolutionary relevance of it was that if any women would start to have sex with guys outside of the marriage context, which would mean that assholes could get laid, it creates an evolutionary niche for assholes to actually be able to make it, and then those guys figure out how to get more women to do that thing, and so, the idea was almost like herd immunity. The idea was a collectivist idea. You actually have to close the niche for assholes comprehensively. If you want a civilization to go well, guys are going to do what they need to do to get laid. So if you bind the opportunity to get laid to being a good citizen with multiple people vetting it, that's a good system. It's actually interesting, right? Like most people, myself included, who kind of grew up in a more post-sexual revolution, liberated idea, thought of that as just oppressive nonsense. And then I'm like, "Oh, that's actually interesting." So then the idea was that with birth control, you kind of have a sexual revolution. It seems like it's liberating for women in particular, because you decouple sex and reproduction for the first time. Where historically you could never really decouple sex and reproduction well, which is also why that was gonna inexorably affect her biology more than his, because he could possibly get laid, have a genetic benefit to do so, and have no consequence, and she could not have no consequence. It'd be a life or death possible thing for her, right? And so, of course she'll have higher criteria and more bonding biologically oriented, which makes perfect sense that it should be that way. But then she's able to kind of let that go and be a liberated modern person because of the birth control pill, but her evolutionary biology hasn't changed. Again, just like I can't eat all of the chocolate cake that I want and not get fat just cause I want to, right? The biology is the way that it is. I don't get to just separate the reward circuit. And so, then the idea that after that there was more of an evolutionary niche where assholes could get well-laid as a result of that, and that that actually has a culture-damaging property. So if you wanna go the convention of marriage, if you wanna not drop to pre-conventional developmentally meaning more selfish than the convention, but go to truly post-conventional, the post-conventional has to be, okay, well, how do the individuals have more freedom than the institution of marriage to make that choice while still paying attention and not creating niches for bad behavior to be able to propagate?" - [Daniel Schmachtenberger](https://youtu.be/_7aIgHoydP8?t=764)

> "The conservative, or traditional intuition is the idea that if there's a social system that made it through the trials of evolutionary history, and there's lots of them that failed, it probably has a lot of embedded wisdom that isn't obvious. It probably made it through for a reason. So go back to the old, keep the old thing, whether it's the Founding Fathers, or Christianity, or whatever the thing is, right, that you're trying to conserve, that there might be reasons why it worked that we don't even understand well, but that it was tested, and you know, tried and true, and so the conservation of that. The progressive intuition is we're facing novel situations that we never faced, and that the things that worked in the past couldn't possibly work for that, and innovation is needed. These are obviously both true, and need to be in [dialectic](https://en.wikipedia.org/wiki/Dialectic#Hegelian_dialectic). So the idea that either of those would be adequate is nonsense, 'cause if the new thing you're doing doesn't factor that most of the environment is still the same and the things that worked might work for reasons you don't know, and you throw the traditional thing out too fast, then realize it was doing things you didn't realize, and you just fucked up. Right, so the progressive often doesn't pay enough attention to the traditional impulse, and vice versa." - [Daniel Schmachtenberger](https://youtu.be/_7aIgHoydP8?t=1109)

> "Capitalism doesn't mean one thing. For some people, they think about that as any system primarily based on private property ownership, which would've included feudalism, and a different version, whatever. And obviously, Adam Smith capitalism and Milton Friedman capitalism are not the same kinds of structures, so with and without a central bank, with and without AI high-speed trading of complex financial instruments. They're totally different structures. I would say all versions of it are inadequate for a long-term viable system, but so are all versions of communism, socialism, and other economic systems as we've proposed them, so- - [Zubin] Perfect. - [Daniel] There's a lot to learn from all of them. There's a lot about theory of markets that's important, but the long-term system, like what isn't, what do we have to think about in terms of economics for making it through all of the catastrophic risks the world faces? And if it's not obvious, briefly, what the catastrophic risks are, you have all the environmental risks that are the result of the cumulative effects of industrialization and globalization. And so, dead zones in oceans, overfishing, biodiversity law, species extinction, topsoil erosion, climate change, blah, blah, blah, all of those things, peak nitrogen, phosphorous, whatever, all of those are the result of being able to extract resources from the world much faster than they can replenish themselves, and turn them into waste much faster than the earth can process them, i.e. a linear materials economy running on a finite planet that is bound to a monetary system that has a need for exponential growth to keep up with interest. And so, the exponential growth of the monetary system forces an exponential growth of depletion on one side and pollution on the other side. You get all the planetary boundary issues. So that's one set of things, and obviously, there's an economic driver associated with all of that, right? We have to change economics to be able to make sure that the social sphere and technosphere are compatible with the biosphere, right? Now, the social sphere-technosphere combo is debasing the biosphere they depend on. - [Zubin] And you can probably point at the root of that being the primary economic drivers now are one-marshmallow drivers that do not necessarily promote two-marshmallow, delayed, longer term thinking when it comes to those planetary boundaries. So in other words, if I don't go out and fish the oceans, another country will, if I, like sort of tragedy of the commons, like if I don't mine that particular ore, some other company will come, and knock the top of that mountain off, and pollute the rivers, and so on. And it's all in the service of the particular economic model, that is, you're trying to generate revenue, and those things are rewarded in the current system. - [Daniel] Yeah, and you know, the economic system creates a discount rate on future value, one, 'cause you can't predict it fully, but two, the current value gives me the ability to invest that capital, and make compounding interest, or other kinds of financial services investments with it. It also gives me increased optionality in a changing environment. And so, not knowing what the environment will hold, and wanting to do the best I can, I want the most choice tokens, right? And the dollar is a choice token. It's the ability to, with very high optionality and high liquidity, do whatever would be adaptive, whereas if I have a bunch of farmland, and the thing that I want in the moment isn't farmland, selling it is gonna be, take a while. If I have a bunch of mining rights, or I have a bunch of timber, or whatever it is, and especially if I have a bunch of trees that aren't yet timber, and then I decide that I want to turn them into capital for some purpose, there's a long lag time. So there's a game theory optimization towards more optionality, which means that the thing that has no real value, right, the dollar is purely representational value, but with maximum liquidity and optionality. I don't want the things with real value. I want to convert things with real value into the things with the only fictitious value, but that maximizes my optionality. And that's very much a short-term interest multiplied by a competitive collective action problem that is just where each agent making the choice that is good for them in the short-term is, creates a collective making maximally bad choices for the whole for the long-term. - [Zubin] And that in itself, and this idea that cash is king for that reason, the idea that those long-term choices are the potential civilization-level risks that we face, whether it's environmental, whether it's technological, whether it's national defense, whether it's nuclear war, all the things that you talk about. And I think, so going back to the capitalism is a one-marshmallow sort of optimizer, how does that then relate to where we are technologically, say, with one civilization-level threat, which is big tech, social media attention hijack? - [Daniel] Yeah, I mean, it's like something that anyone one would learn in the beginning of their business career that every business wants to optimize the lifetime revenue of a customer. And addiction is a really good way to optimize lifetime revenue of a customer, right? - [Zubin] Every hustler on the street knows this. - [Daniel] And so, I want, like the best business will apply to the most number of people, and have the most need for continuous purchases. And so, it's like, it's hard to beat fast food, right? It's hard to, like we can start when they're young. We can make it apply to almost everybody, and have it be a daily point of purchase for forever. And that's why McDonald's became very big, and Nestle, and you know, whatever, and Coca-Cola, and all those. But even that is actually dwarfed by social media, because obviously, a kid can start with an iPad before they can talk. - [Zubin] Yeah. - [Daniel] And start getting conditioned to hypernormal stimuli and customized environments to them. So we can start very young. The most time someone gets a Coke is still less than they check their phone, right? And so, the total number of points of contact, and it's optimizing for hypernormal stimuli across lots of vectors, right? It's getting your- - [Zubin] News- - [Daniel] Media outrage. It's helping, you know, sex appeal, food that you're interested in, stuff like, and- - [Zubin] Social credit. - [Daniel] And it's personalized to you with AI optimization. - [Zubin] Right. - [Daniel] And so, your newsfeed is like if I got to test every different version of salt, fat, sugar, artificial flavor combinations that maximize addictiveness to you, and Hostess could do that for each person, that's what social media is for the newsfeed." - [Daniel Schmachtenberger](https://youtu.be/_7aIgHoydP8?t=1880)

> "We live in a reality where most of the stuff that feels most consequential that we believe we have no first-person sensing of. - [Zubin] Right. - [Daniel] We are getting it mediated through a 2D screen, through other people's thinking, and other institutions, and you know, those types of things. That's significant, right? It's significant to people's ability to have collective intelligence systems work. There's a book, I think it was called "The Politics of the Invisible" that was looking at regulation issues after Chernobyl, where, you know, should farmers be allowed to grow food here and sell it that the countries had to deal with downwind of where Chernobyl was given that the uranium was invisible. And for the first time ever, not the first time ever, but like for the first time it became really obvious that there was totally invisible stuff that was totally consequential. So the farmers and the layperson had to trust those who had the ability with the Geiger counters, and whatever, to tell us stuff that only the priestly class that understood how to do that could do. - [Zubin] Oh. - [Daniel] Because now, we're engineering in the invisible in a really fundamental way. - [Zubin] Which we're not designed to deal with as humans- - [Daniel] We don't have the ability to all check and balance and go through the same epistemic process. So unless you happen to have the Geiger counters, and the knowledge of nuclear physics, and et cetera, and then the biophysics to say, well, how much increased radiation of what type is gonna create how much mutation to then be able to weigh against the difficulty of the farmers not losing their jobs, and those types of things. - [Zubin] Yeah. - [Daniel] And so, having created a very scientifically advanced society also means that then you need a lot of scientific insight to weigh in on the policy things. But that also means now people have to just trust a priestly class. And, or they all have to be adequately educated, and have access to all of those tools, and that, like adequately educated about virology, and nuclear physics, and epidemiology, and climate, and et cetera- - [Zubin] Not possible. - [Daniel] So you start to reach information limits. So then you have to say, "Well, fuck it, "we need institutions that are trustworthy "that can do that." Well, how do you get trust? How do you get everybody to be able to trust institutions? Even if you had an institution emerge that everyone trusted, 'cause it had some transparent way of being able to show real good epistemic process, and lack of vested interest, and rigor, and checks and balances on power, and it became a kind of legitimate authority, there's so much power to being a legitimate authority, to being able to be the arbiter of what is real that everyone who wants to win at the game of power will have a maximum incentive to try to corrupt that thing. - [Zubin] Hmm. - [Daniel] And so, then who wins? The scientists, and mathematicians, and philosophers focused on the thing, or the best players at the game of power, who are funding the thing, who have a maximum incentive to start moving it in one particular direction? So how do you maintain legitimate authority and have it not get captured? It's a real tricky thing." - [Daniel Schmachtenberger](https://youtu.be/_7aIgHoydP8?t=2584)

> "Democracy, like modern democracies, the US, and other kind of modern European democracies, emerged out out of kind of European Enlightenment, cultural enlightenment, and this is why the founders in the US said, "This system only works "with a comprehensively educated citizenry." And George Washington said, "It's the primary aim of the federal government to ensure "the comprehensive education in the science of government "of every single citizen," science of government meaning everything you would need to understand to know how to do collective choice-making well. So the difficulties of game theory and vested interest, economics, history, all those things, comprehensive education of every citizen in science of government is the number one goal of the federal government, because if the number one goal is rule of law, you can do it with a police state. If the number one goal is to protect the boundaries, you can do it with a military dictatorship. If you have the number one goal of being anything other than the comprehensive education of every single citizen, it won't be a democracy, 'cause democracy's very fragile, and requires that kind of thing, and it requires not only that everyone can make sense of third-person reality together, apply the philosophy of science, and kind of natural philosophy, but that they can make sense of each other's positions and value systems well, which is the good faith discourse, the empathy, the Hegelian dialectic. Can I really argue your position well? Without that, democracy has no chance. And so, when people have made their fellow countrymen the primary enemy, they are actually, in the short-term, they think they're trying to win a battle about COVID, or climate change, or systemic racism, or whatever the thing is. What they're actually doing is waging a war against democratic process writ large, where as you're making your primary countrymen the primary enemy, where all of the energy within that system goes to infighting, and then you elect more polarized representatives, who create more gridlock, authoritarian countries are just gonna do better geopolitically across every way. And then you're actually, what you're really fighting for is the authoritarian process to have more global influence over the 21st century. - [Zubin] Yeah. We're fighting for China, basically. - [Daniel] So really, the democratic process requires an epistemic commons, shared sense-making, and shared meaning-making to inform shared choice-making. Democracy is a shared choice-making process. But that means that we have to have some process to talk about what is- - [Zubin] Right, sense-making, right. - [Daniel] And some process to talk about what do we want, and I have to be able to understand the thing that you want and understand that just fucking you with the thing, you don't stop being a political actor, and then you're gonna act even harder next time. We're just gonna escalate arms race. - [Zubin] Yeah. - [Daniel] So how do we make compromises that address what everybody wants? - [Zubin] Yeah. - [Daniel] And so, the bad faith argumentation destroys the social contract, and the epistemic commons, destroys democracy. Good faith argumentation is not sufficient, but is necessary. And so, the steel man is the beginning of a good faith argument." - [Daniel Schmachtenberger](https://youtu.be/_7aIgHoydP8?t=2986)

> "One kind of model of the development people go through in terms of game theory, like their own intuition of game theory, you could call naive, cynical, post-cynical as a developmental process in the direction of increased capacity to do citizenry. Naive is where you assume good intent on other people's parts as a kind of default. You assume that what people are saying is generally what they believe, and that other people's interior experience is probably a lot like yours, and that where fucked up things are happening is probably mostly because of mistakes, and things like that. And if you interact with the world, and particularly systems of power enough, that will become destroyed in you, right? And then the naivete will crash upon the rocks of reality, and then you'll move into a cynical place, where you realize how much ladder-climbing, how much of virtue is virtue signaling, how much of communication as a whole is strategic, where someone is saying something for the effect they want it to have, not just for what they maximally believe, how much of the epistemic commons is the result of everyone's agentic desire to make other people believe stuff, rather than just what is true, all those types of things, right- - [Zubin] And by the way- - [Daniel] Get cynical. - [Zubin] And when you say epistemic commons, you're talking about the where, how we even get information by epistemic, yeah. - [Daniel] Yeah. We could call it the knowledge commons, which is just the available information that we can all look at. - [Zubin] Yeah. - [Daniel] But it's not just the knowledge, because the methodology that produced it, right, the epistemic process, is gonna be key to whether or not I believe it, how I factor it, all those types of things, and then what do I do with that? There's an epistemic process of how do I factor that data to actually come up with forecasts, and conclusions. And so, the data is not that interesting by itself. The entire epistemic commons, how do we collectively make sense of the world together? - [Zubin] Got it, got it, so you had the naive, then you had the cynical. - [Daniel] Yeah, now, in cynical, so you read Machiavelli, and you get a good description of the cynical, and that that type of court dynamic is actually playing out. And typically around any center of power, there's something like court dynamics. Around any very wealthy person, you watch in their social circle, and there's something like court dynamics. - [Zubin] Yes, we've all seen it. We see it at CDC, we see it at FDA, we see it every big institution. - [Daniel] And so, then you end up getting situations, where whoever is in the position of most power will get a distortion bubble of the type of feedback they get because people want something from them, so there are certain types of disagreements that won't happen. So then you'll get the propagation of their own biases, and other people confirming it, and all kind of nonsense like that, right? - [Zubin] The Steve Jobs reality distortion field type of deal. Actually, that's- - [Daniel] There's different kinds of reality distortion. This is one kind of vested interest reality distortion, and if you want an introduction to how to think cynically, "The 48 Laws of Power" is probably the best you can get. - [Zubin] "48 Laws of Power," who's that by? - [Daniel] Robert Greene. - [Zubin] Got it, okay. - [Daniel] And he's taking Machiavelli, but also Sun Tzu, and von Clausewitz, and most of the kind of strategic thinkers, and giving a summary of how does the game of power work. - [Zubin] Yeah. - [Daniel] And... And you know you're in the cynical if you say something like, "If you don't know who the sucker in the room is, it's you." - [Zubin] Yeah. - [Daniel] Right? Because you assume that the game of power is happening everywhere, there is some suckers, they're getting taken advantage of, et cetera. - [Zubin] Yeah. - [Daniel] I think the key is that there is such a thing as post-cynical, and the cynical would say, "The only thing that is not cynical is naive," because typically, things don't even have an awareness of a developmental stage that is beyond them- - [Zubin] That's right- - [Daniel] So that's where you get mistakes- - [Zubin] Blindness, yeah. - [Daniel] So the-post-cynical says it is possible to authentically care about something more than just self-interest in a way that you're actually willing to make real sacrifice for, and that they're are other people who also can, and that authentic relationships of trust can be formed. - [Zubin] Hmm. - [Daniel] So I couldn't be post-cynical if I didn't believe that there were other people that could be post-cynical. Right, 'cause I have to believe I can have- - [Zubin] They need to be there. - [Daniel] Of trust. - [Zubin] If everybody else is cynical, you can't, there's no trust. If everybody else is naive, there's no, you can't do it. - [Daniel] If they're just naive- - [Zubin] Yeah. - [Daniel] I can't trust 'em that much, because on accident, they'll get played by the cynical people, and even though they're trying to be loyal, the whole thing will still get fucked up- - [Zubin] It'll fall apart- - [Daniel] I have to know that the other people have an immunity to that process, that they're aware of it, but they are also not bound to it. This is in the world, but not of it, right? - [Zubin] Ah. - [Daniel] And so, to be post-cynical, you have to know that other people can be post-cynical, and then you have to be able to know how, what is a legitimate basis of trust, and how do I know that? How do I sense that? And so, what I would say is post-cynical good faith communication is necessary for something like the continuation of anything that's at all democratic, or republic. Anything that has participatory governance and is not just the people being ruled requires the people being able to develop that. So that has to become the center of the values of a culture that then develops that in people and checks it and reinforces it. - [Zubin] So does a post-cynical, this is fascinating. Does a post-cynical standpoint require the sort of transcending and including the naive and the cynical standpoint? - [Daniel] Of course. - [Zubin] So you have to be able to understand and inhabit the naive and the cynical to develop a post-cynical. - [Daniel] In the same way that a metamodern, or an integral, or a post-postmodern system actually has to understand postmodernist critiques on modernity well, and then also understand modernity well, right? You have to understand the philosophy of science- - [Zubin] Yeah. - [Daniel] And the Hegelian dialectic. You have to understand the postmodern critique of why there is no objective fact. - [Zubin] Right. - [Daniel] And why there is no objective absolute perspective, and claiming it's probably some type of imperialism, or power game in that you can't separate game of power from the propagation of ideas. - [Zubin] Yeah. - [Daniel] And then not just leave it there, 'cause that's an untenable place to leave it, and say how do we take that critique as a refinement, 'cause that's a deconstruction process. How do we take that deconstruction as a refinement to a constructive process, which means everybody can get on the same page with something other than the game of power, 'cause if all there is is the game of power, and all truth claims have no basis other than claimant power, then what you're actually doing is exalting power as the only possible thing, and that thing actually self-terminates, right? A situation where everyone is just playing the game of power, where that means that the epistemic commons and the social contract break, democracy breaks, you can't sense-make climate change well enough to do any solution with it that half the population doesn't resist, or COVID, or AI, or anything. And so, you have to come to a way of being able to make sense of the world, address values, and cooperate beyond just the game of power, which you know, kind of the metamodern thing. So the same with the post-cynical, right? The post-cynical understands why the cynical is there, and has to be resilient to that. So let's go ahead, and see where, say, a left, or woke perspective would say good faith just means you're a naive sucker, because let's say we're talking to a Native American about the history of the US keeping its agreements with Native Americans. And they're like, "Okay, well, good faith communication "just continues to privilege the current power system, "because it just says let's all be polite, and civil, "and whatever, and not address the fact "that the power system came the way it was "by some people totally fucking other people, "and there's no real push for them to change it, "and the victors rarely just give that up, "and every time we made the agreement, "then they fuckin' violated the agreement." And the black community could say the same thing. If you go and look at the history of like, oh, Emancipation Proclamation, but then fuckin' Jim Crow, and peonage, and you're like okay. So at some point, oh, I see, your argument about being good faith is just gaslighting. You're not gonna be in good faith. You're gonna pretend. You're gonna ask us to be in good faith, and then just fuck us- - [Zubin] And you're gonna screw us. - [Daniel] Yeah. - [Zubin] Oh, you see this play out on social media all the time- - [Daniel] In which case cynicism then seems like the only informed thing. - [Zubin] Right. - [Daniel] And so, you have to have some process to be able to say how do I show up to a good faith process and really sense if the other side is, and ensure they are, and orient towards that simultaneously, 'cause otherwise, we get defect-defect in the prisoner's dilemma. How do we get something to ensure against defect-defect and be able to have cooperate-cooperate, because everybody rationally doing defect-defect leads to catastrophe for everybody." - [Daniel Schmachtenberger](https://youtu.be/_7aIgHoydP8?t=3318)

> "In an environment that incentivizes you to lie, and to not trust people, and to even weaponize trust by creating fake trust in people, so you can then, you know, take advantage of them, whatever, if that's adaptive, right, you're actually being environmentally trained to be that way." - [Daniel Schmachtenberger](https://youtu.be/_7aIgHoydP8?t=4193)

> "So it's the idea that you can have something that is disruptive to the ideal homeodynamics of the system, but subclinical. It's not yet causing the acute pathology, but it's contributing to a causal cascade with a lot of other things that can have an effect. So that's examples of that physiologically. The same is true psychologically. So before someone has diagnosable, you know, serious depressive disorder, they can be much more depressive than would be an optimal state for someone, and we can call it kind of subclinical. Before they have generalized anxiety disorder diagnosably, they can have a lot more background anxiety then is necessary for the human experience. And the same is true for OCD, the same is true for complex PTSD, right? Complex PTSD, where you have kind of an excessive trigger response, sympathetic response to some kind of trigger, but instead of an acute PTSD, where that's on one event, it was a complex PTSD, meaning something that occurred many times. I would say it's arguable that people have complex PTSD on civilization, right? Like they have this kind of continued trauma associated with lots of things that creates an increased sympathetic response to lots of things. That is a pretty common phenomena, right?" - [Daniel Schmachtenberger](https://youtu.be/_7aIgHoydP8?t=4537)

> "So I think there is some kind of under-reporting, under-assessing types of issues that are part of it. And so, when we look at what percentage of the population has narcissistic personality disorder, whatever, that might be wrong, right? Those assessments might be wrong for any number of reasons. There's reasons to hide that signal if you can. - [Zubin] Yeah. - [Daniel] But I would say that the percentage of narcissistic personality disorder, or antisocial personality disorder in the general population is probably much higher than it ever was in an indigenous tribe, in which case I would say it was probably much, much closer to zero, because it would have always been found out, and be non-adaptive. - [Zubin] Yeah. - [Daniel] And I would say it's gonna be much higher as you climb up the stack of power and you have to actually win at lots of power games to get up there. And so, you know, there are some stats, I don't know if they're any good, but it's like, you know, 5% in the general population and 30% in the C-suite of Fortune 500s, and probably something like 90% in the C-suite of top financial services companies, and- - [Zubin] Yeah. - [Daniel] So- - [Zubin] It's adaptive in those locations, yeah. - [Daniel] It is selected for, incentivized, conditioned. - [Zubin] Yeah. - [Daniel] Et cetera. - [Zubin] All the above. - [Daniel] Which then also means that people with those conditions also have a disproportionate amount of power and influence institutionally. - [Zubin] Which that feeds back on a population level, because the institutions are a big part of our socio-technological environment. - [Daniel] So do I think that, you know, narcissistic traits are much higher than is native to the human condition under different developmental environments, and particularly tribal? Like tribal environment, you're just not gonna get away with lying very well- - [Zubin] Yeah. - [Daniel] 'Cause there's too much surveillance. You're not gonna get away with hurting people in a small environment, where everybody knows what's happening with everybody. You're not gonna be able to hide the effects of things, right? The increased transparency. But as soon as the system gets large enough that you can hide the effects, then you start having an evolutionary niche for those kinds of parasitic and predatory behaviors." - [Daniel Schmachtenberger](https://youtu.be/_7aIgHoydP8?t=4684)

> "Typically, in biological situations, it's not simple as one cause, right? It's a lot of things that collectively can reach a threshold and you have nexus causation. - [Zubin] That's right. - [Daniel] So are there genes that predispose certain kinds of things, but there's a lot of other attenuating factors and whatever? Totally. - [Zubin] Yeah. - [Daniel] That's what I think with regard, I think that the anxiety, the depression, the narcissism, the short attention spans, I think those are all conditionable, and I think they're conditionable where, you know, I like to look at positive deviance culturally, like where a whole culture for some period of time had one, or two standard deviations more of some desirable trait. So I like to look at Jains for nonviolence, or Buddhists, or Quakers, and be able to see can you have a whole population, which means all the genetic mutation within that population, and all the kind of variance, but where the population as a whole its median violence is a standard deviation better than everybody else's? - [Zubin] So there's a group dynamic- - [Daniel] Which means that culture, right, actually was able to, with factoring genetics, whatever, attenuate that a lot, and the same as across very different environments, do Jews usually educate their kids better than a lot of other cultures do, and reach higher level of education? It's very clear there's a cultural effect that does that thing, right? And so, then you start to think about could you have something that had Buddhist nonviolence and Jewish education and whatever types of processes in terms of could you have a culture that was developing the, you know, a different set of traits in people that made a different set of civilization possibilities associated with a increased post-cynical possibility? Now, of course, we're also looking at the fact that the technology is developing people itself. As we were saying, just simply the, simply the infinite scroll personalized to me type thing is going to have effects on attention span. It's gonna have effects, and having an effect on attention span also means it's gonna make me more one marshmallow everywhere, including offline. - [Zubin] Mmm-hmm. - [Daniel] Because I don't have delayed gratification built-in. And- - [Zubin] We see that now- - [Daniel] It means democracy will end, because democracy requires a long enough attention span, a long enough working memory that I can hear someone's perspective, hear multiple perspectives, hold them all in working memory, and try I to find a proposition that would meet many of their goals, right? Like if I really wanna be able to do collective intelligence well, it requires that, which is why, you know, Marshall McLuhan showed that not only did the printing press occur as, and the written word being accessible to everybody, everybody could get a newspaper, so you didn't need a specialized knowledge class that had access, and everyone could get textbooks and read, not only was the printing press a prerequisite for democracy, but the written word as the primary type of media was probably required for democracy to work, because it required people to think well enough that they could communicate in writing in long form in a way that could then translate to legal code, right, to really think through things formally, and that they were reading, which meant increased attention span of non-dopaminergic stuff, which also meant enough working memory to hear multiple perspectives, to be able to find something that might work, come up with a good proposition." - [Daniel Schmachtenberger](https://youtu.be/_7aIgHoydP8?t=4866)

> "What we have is we have a massive scale, right, maybe trillion dollar, maybe multi-billion person, massive scale population personal data, AI-optimized behavior mod system with no checks and balances on the power of it. (Zubin laughs) That's not like a company the way Adam Smith thought of companies. - [Zubin] Right. - [Daniel] And when you take that if it has an ad model, where the more time people are spending on site, and the more engaged, the better the ad revenue's gonna do, and it has a fiduciary response way to maximize value to the shareholders, so it has to keep optimizing that thing, the AI's gonna optimize for engagement, and the one-marshmallow sticky shit is just more engaging, right? Because otherwise, I don't plan my day, and say, "I wanna spend seven hours upset scrolling Facebook." I say, "Fuck, I don't wanna spend any time on Facebook. "I'm just gonna check it real quick," and then I get stuck, because something that was hypernormal enough brought me into a rabbit hole that obscured my prefrontal assessment of the amount of time I don't wanna spend on Facebook, right? - [Zubin] You got hijacked. - [Daniel] I got hijacked. - [Zubin] Yeah. - [Daniel] And so, it does not have the incentive to keep me intentional. It has the incentive to capture my intention, right? And so, if you have something that does that, it's going to increase all limbic process, so outrage, and addiction, and et cetera, which also includes polarization, and tribal identities, and certainty, and sanctimony, right? It's gonna increase all those things. So it'll double down on bias, rather than undo bias. It'll double down on tribal in-group kind of stuff, and shorten the attention span, so you couldn't even listen long enough to hear a counter perspective. And it wouldn't be dopaminergic enough to maintain the attention span. So that can't not polarize the population. And so, China was smart to be like, "No, fuck it, we're not gonna let that thing emerge. "It'll ruin our nation." And so, so if you polarize the population with increased certainty, outrage, everybody thinks their thing is an existential risk, if Trump gets elected, it's the end of America, if Trump doesn't get elected, it's the end of America, whatever, right, then they, the people will select more polarized representatives. The more polarized representatives in Congress and Senate like that can't cooperate with each other at all, so everything gets gridlocked. Everybody filibusters each other, and whatever. An increased gridlock system can get slower and slower, and more and more expensive capacity to regulate tech that is moving faster and faster. And if the regulatory system has slower feedback loops than the thing it's trying to regulate, it will just lose the ability to regulate it. And so, a tech that polarizes the population, and polarizes the representative class, that creates gridlock, that decreases the capacity of governance, will make that governmental system lose to another system that doesn't have those problems going on that doesn't have all of its energy going to infighting, that doesn't have gridlock in its decision-making process, and- - [Zubin] Has a longer term outlook, too. - [Daniel] It has a longer term outlook, because you don't think that in four years everything you did will get undone. - [Zubin] Yeah. - [Daniel] And so, in the same way that the printing press kind of ended feudalism and started to make modern democracy possible, this tech is kind of ending democracy as we know it, and orienting towards authoritarianism, unless we start to redesign it in a fundamentally different way." - [Daniel Schmachtenberger](https://youtu.be/_7aIgHoydP8?t=5486)

> "So let's say we built a Facebook-like thing that had lots of different types of content that were being personalized to the individual, but that didn't have a business model that required ads to do it, so it had a different basis of optimization, wasn't trying to maximize time on site, or engagement in that way. Let's say that the thing it was trying to maximize was your Lectical Score. - [Zubin] Hmm. - [Daniel] And so, it was looking at where you were typing in responses, and your general engagement, and it was wanting to see that your ability to, and your disposition to seek and steel man more perspectives, and have more nuanced perspectives, more ability to orient towards empiricism where it was relevant, et cetera, that those were the things it was optimizing for, and it was curating content to you both based on what would be outside of what you were already exposed to, but also in the zone of proximal development that you could grasp it. And again, empirically upregulating in that way, that would produce really different results, right? You could be growing attention span, rather than decreasing it. You could be growing multi-perspective, multi-perspectival kind of capacity through the nature of what that AI pointed at your brain is optimizing for." - [Daniel Schmachtenberger](https://youtu.be/_7aIgHoydP8?t=6597)

> "The thing that is measurable will have externalities. Even a weighted algorithm of N measurable things will have stuff that's really important that's not included in it that if you're optimizing for you'll end up having the externality. So you can optimize, but you want a process that what you're optimizing for is itself being continuously iterated. - [Zubin] A recursive process with the optimization parameters. - [Daniel] Where the externalities of what's being harmed by the optimization are continuously being internalized. But that means you also need a governance system that can do that, which means you can't be bound to something like fiduciary responsibility for profit maximization." - [Daniel Schmachtenberger](https://youtu.be/_7aIgHoydP8?t=6796)

> "How do you internalize externality, and make, and close perverse incentive niches is one of the fundamental things humanity has us to get better at, right? Like we have to fundamentally change our socioeconomic systems to do perverse incentive minimizing much better than they do." - [Daniel Schmachtenberger](https://youtu.be/_7aIgHoydP8?t=6921)

> "But Bohm was looking at the orientation of a mind that mostly thinks in words, of Western mind, you know, in particular, to break reality into parts, and make sure that our word, the symbol that would correspond with the ground there corresponded with the things that it was supposed to, and not the other things, so try to draw rigorous boundaries to, you know, divide everything up, led to us fundamentally relating to everything as parts first. And so, then you get stuff that doesn't make sense. Like you bring parts together, and there's some new property that none of the parts have, and you have to call it emergence, and it seems kind of wacky, but it was only because that property was there from the beginning and you took it into parts- - [Zubin] Parts- - [Daniel] And- - [Zubin] Oh, fascinating! So you call it emergence because you started with the parts, and you built it up, whereas it was a whole to begin with, and ah, so what was missing, you're calling emergence. - [Daniel] Exactly. - [Zubin] Ah, fascinating. (Zubin laughs) - [Daniel] And so, whether you have one country trying to benefit itself at the expense of another country, or all of the countries trying to grow their GDP at the expense of the ecosystem, or a proposition that is benefiting something, but harming something else, and polarizing the population, or a particular metric you're trying to optimize for in healthcare that causes iatrogenic cascades to damaging something else, or whatever, the highly interconnected world where the solution, or what you're optimizing for, is made a narrow subset of everything. The thing that you're doing is still interacting with complexity. So whatever it's affecting outside of what you're intending to affect will be negative externalities. Some people will care about those. They'll respond to those. You'll keep driving conflict, driving externality. With exponential population and exponential tech, that thing self-terminates. So how do we, we can't do exponential externality. So you have to do a better job of not doing externality, which means that the goal is not to optimize for GDP. It's something broader than GDP. It's not just GDP per capita. Okay, we need to add a Gini coefficient. Yeah, but that doesn't include personal happiness, whatever, so we need to add a national happiness index. Yeah, but that doesn't include environmental stuff, so we have to add a CO2 thing, but that doesn't include nitrogen, so- - [Zubin] Parts, parts, parts. - [Daniel] You keep adding, and yet there will always be stuff in some finite set of metrics you're optimizing for that matter that are outside of that set. - [Zubin] Yeah. - [Daniel] So how do you actually relate to the whole, and say the thing we're trying to optimize for is not definable, right? That's what I would say the first verse of the "Tao Te Ching" was about, right? The Tao that is speakable is not the eternal Tao, and that's what I would say the no false idols thing was about, that as soon as you say, "The thing we wanna optimize for is X," it's not really it, right? That's not. The thing you wanna optimize for is the nature of the sacred. You try and define it, you're gonna fuck it up. - [Zubin] Yeah. - [Daniel] But you can sense it progressively better. - [Zubin] Yes. - [Daniel] And you can do a lot of defining around it. But if you think your definition is it, that's a false idol- - [Zubin] I see. - [Daniel] And so, how do we, (Zubin laughs) how do we not have metrics that create optimization systems that then bind us, right, where now the board wants to hold the CEO to quarterly profit metrics to be able to get the money back to the shareholders who invested, so we create a law for the fiduciary responsibility for profit maximization. And now, even if you see there's an externality, you can't do anything about it, because you're already bound to the metrics you're optimizing. - [Zubin] Yeah. - [Daniel] So whatever set of metrics that we're optimizing for, we have to be able to pay attention to things that are outside of those metrics that matter, and be able to progressively internalize that, which means we have to create governance structures that can orient around the ability to do that. - [Zubin] Okay. - [Daniel] Which also means we have to create minds that are oriented to do that, and know that other minds will notice shit that you don't. This is where authentic diversity matters. Other minds will notice shit that you don't, and there's no way to notice all the things they do, which is why you have to be in dialogue." - [Daniel Schmachtenberger](https://youtu.be/_7aIgHoydP8?t=7726)

> "One way that you get over the data singularity of that there's more data than anyone can pay attention to is people don't actually need to make, they don't need all the data to make a choice. They need the meaning, which is like a second, or third derivative on the data, which can I have the AI process a fuckton of data to be able to parse where there's incorrect stuff, where there's high confidence stuff, and put it into the form that is decision informing, and then what is relevant for decision informing is stuff that people can actually keep up with?" - [Daniel Schmachtenberger](https://youtu.be/_7aIgHoydP8?t=8861)

> "Satellite imagery of the earth is a pretty amazing technology. There's a friend of ours who runs a company called [Planet Labs](https://en.wikipedia.org/wiki/Planet_Labs) and they image the entire surface of the Earth every day - 30 terabytes of compressed data - but they're increasing the spectral and temporal resolution of that and spatial resolution sets that it'll be pretty much real time human level video capture of the surface of the Earth in about three years. Which is amazing and one of the things it means is the ability to see where logging is happening and where mining is happening and where dumping is happening and where illegal phishing is happening and even to be able to see in a dead zone in the ocean, the effluent how much of it came from which source, how much came from which port, and all those types of things - the ability to see all that, use machine learning to process it, means that there's a whole bunch of international law that we've never even bothered to create because it'd be no way to know if it was being violated or enforce it. Now we'd have the ability to create international law that says: no, actually you don't have plausible deniability anymore - we know exactly how much of the trash or the nitrogen affluent came from there because we can see the whole thing. It also has the ability to do spectral analysis that can see an invasive species entering an area or soil microbes in an area to be able to actually support the environment when critical issues are starting to happen. But this is itself very concerning, because probably many of you even as I'm describing this are like: wow, that's really hopeful for the environment - to be able to have that level of transparency - that could create law so we could support the environment, but who gets to have access to video level data of the entire surface of the Earth all of the time? That sounds like pretty massive surveillance capability, which it is. So that can prevent certain catastrophes but can totally create dystopias depending upon how it's managed. So how do we create the governance of that information such that it doesn't get used for nefarious purposes and that people get to know what it's being used for? This is this is not trivial, right, because it's easy to deploy the technology to solve those problems - it's actually quite hard to create the governance to ensure that it's used properly." - [Daniel Schmachtenberger](https://youtu.be/6aKI2C61jVE?t=3054)

> "There's a cost to a whole ecosystem: into the people, into the future generations that'll be affected by the pollution, but I don't pay the cost, and because I'm not paying the cost I get to have the profit margins that I have. If I had to pay the cost, which mean I had to employ a technology that currently exists to clean all that up and whatever that costs, my business might be radically not profitable. So then maybe we'll try and create a law to make it to where I can't do that pollution. But I'm not doing the pollution as a person - I have some corporation that has some liability limiting functions of any of the people within the corporation, so the corporation is breaking the law, and you can't put a corporation in jail - so there's a fine. But if the fine is less expensive than processing the waste would be then it's just a cost of doing business. And then the corporation will employ lobbyists to go change the law because laws are going to be created by lobbyists, that are paid for by somebody, and they're going to be created by politicians who have a campaign budget that is controlled by somebody. So basically economics has perverse incentives, we try to create law to bind it, but economics is deeper in the stack of power than law is. So you end up getting this legal system that is supposed to bind the perverse economic incentive that mostly ends up legislating and in the benefit of it. And this is a fundamental problem with the liberal democracy idea." - [Daniel Schmachtenberger](https://youtu.be/_b4qKv1Ctv8?t=3177)

> "We don't even have to deal with protesters with tear gas or beanbags or whatever mostly, because mostly addiction and student debt and information overwhelm and those things deal with the people adequately. So they don't actually understand enough or care enough or have the capacity to organize very meaningfully." - [Daniel Schmachtenberger](https://youtu.be/_b4qKv1Ctv8?t=3787)

> "We keep searching for our own blind spot so that we can do business there, right, and so what it is that we can't measure very often becomes a place to do business because almost everything produces negative externalities. and so it has to be disguised." - [Eric Weinstein](https://youtu.be/_b4qKv1Ctv8?t=3352)

> "The market is a collective intelligence that is eventually self terminating in the same way that a cancer is. Right, the cancer cells are self-replicating and they're growing faster than normal cells but they end up killing the host which kills themselves. And so the reason I'm bringing this up in terms of collective sense making is: those who do the will of capitalism, like, those who do the will of the [paperclip maximizer](https://en.wikipedia.org/wiki/Instrumental_convergence#Paperclip_maximizer), [Moloch](https://slatestarcodex.com/2014/07/30/meditations-on-moloch/), Sauron, or whatever kind of analogy we want to use here - those who do well at the game of power get more power. And then they use that legislative power, media power, capital power... to modify the systems in ways that help them more. Right, those who oppose the system of power also oppose those who are doing well at it, so even though the system is inanimate - the people who are doing well at it are animate, so then they take those people out - which is... we see how Martin Luther King and Gandhi and Jesus and etc. died - people who actually opposed the system of power. And so you end up having a system that is selecting for or is conferring more power to those who are good at getting more power, which ends up meaning who are selecting for conferring power to sociopathy." - [Daniel Schmachtenberger](https://youtu.be/_b4qKv1Ctv8?t=4203)

> "All of these interesting people are simply humans and you can destroy any human reputationally. And so the cheapest thing to do is not to kill anybody, but just as somebody starts to accumulate mindshare - the [gated institutional narrative](https://theportal.wiki/wiki/Gated_Institutional_Narrative_(GIN)) goes into hyperdrive and it just starts pumping out fear, uncertainty, and doubt, which is the... you know [FUD](https://en.wikipedia.org/wiki/Fear,_uncertainty,_and_doubt) is the major tool for destroying an individual's ability to communicate reality." - [Eric Weinstein](https://youtu.be/_b4qKv1Ctv8?t=4600)

> "So their definition of something that translated to schizophrenia: the first symptom was 'had negative feelings about the state' and the second symptoms might take a while to show up. And so what I think happens is that the dominant system ends up eating psychology and saying that the psychology that supports the dominant system is healthy psychology and anything that is dissenting to it is not healthy. It ends up eating spirituality and virtue and ethics and academia and whatever to basically say: the behaviors that support the system are good, so the thinking that supports those behaviors is good, and anything that's dissenting is bad. And like it's so easy to see it in the Crusades or in jihadism or even in Victorian time period - it's just very hard for us to see it about ourselves now. But I think that's actually like one of these fundamental things in terms of you're saying like why don't we have group sense-making is because you have us you have a self-perpetuating system that includes the self perpetuation of the memes that support the system." - [Daniel Schmachtenberger](https://youtu.be/_b4qKv1Ctv8?t=5255)

> "When we come back to the difference between personal incentive and collective incentive you say why aren't we more successful? Obviously it's like: okay, so what is the incentive for someone to agree with us that for the most part expressing these things would make them do less well at politics and their job and maybe even their social club and maybe even be part of the in-group that they're part of whether it's the left or the right or the whatever it is because then they would be saying things that there's almost no in-group that they would be aligned with or very very small? And so you still end up having that there's more selective pressure for the individuals to continue to be part of institutions even an institutional thoughts also doesn't make sense." - [Daniel Schmachtenberger](https://youtu.be/_b4qKv1Ctv8?t=5460)
^^ maybe not a good enough quote...

> "If we ask a question like even what's actually causing coral die-off: how much of it is temperature versus pH versus nitrogen messing up the phosphorous cycle versus trophic cascades - how long do we have before the coral die-off? What are the consequences of that? You know, like, really important questions. Or what are the actual... What really happened in North Korea - like why there was such a change just recently, and what are the actual tactical nuclear capabilities that they have or how much leakage actually occurred at Fukushima or like any of these things - nobody fuckign knows. And you'll hear different narratives and you'll hear kind of equally compelling disagreeable narratives on those and almost no one has the time or the will or the epistemic capacity to really figure that out. So one point is that sense making is actually hard: you have a situation in which a lot of these things are complex enough and there's so much disinformation that when people try to actually figure it out they just get an information overwhelm and then it's very hard for them to continue. So when you're saying like obviously stupid - well there aren't... there's a lot of places where people can hold a train of thought that seems cogent enough even if it's in direct opposition with another cogent train of thought and like just the plausible deniability that it might be one of the true ones since nobody can really sense make seems to be enough. And so this is one of the really tricky things is: in a world where if I have the incentive to disinform at various different levels and then I have exponential information tech so I can do exponential disinformation - now this is... when I say that the system is inanimate I.. abd I give this example: everybody who's seen Tristan Harris's stuff will know this - but if we think about disinformation via the nature... **ERIC:** Tristan Harris is a mutual colleague - he heads a movement called time well-spent and he's trying to show you that your attention has been effectively weaponized against you where the big tech platforms are figuring out how to keep your eyeballs on their system to your detriment. **DANIEL:** Center for humane technology - you can see his stuff, but like I think a lot of people know that news stations as for-profit companies have to make money and they make money by monetizing attention and basically they sell advertising and the advertisers pay more the more people who are watching for more total minutes. So the incentive of the news station is to make stuff that is both inflaming and scary and entertaining and whatever will engage people to spend a lot of time watching in, and to not say things it would not be to the advantage of the advertisers that can afford to pay for them, right, so they have an incentive to not share really complex nuanced things that will have most people click off..." - [Daniel Schmachtenberger](https://youtu.be/_b4qKv1Ctv8?t=5590)

> "I don't believe that this is all being driven by profit - I believe that there is some force that we don't understand that keeps the [gated institutional narrative](https://theportal.wiki/wiki/Gated_Institutional_Narrative_(GIN)) gated. **DANIEL:** Yes, I think profit is one part of it - that's why I say we have to think of profit as one aspect of kind of power or rivalrous dynamic more largely, because it's... I think government or academia or religious or cultural groups or profit can all influence the nature of narrative and information. **ERIC:** I think there's an economy of shame and terror. I believe that the real reason that this works the way it does is we have not even gotten to a very basic point where it is considered acceptable to say: I want immigration restricted. Now I point this out because I think it is very funny: most people who want immigration restricted enjoy food from other cultures, they have friends who come from other places, they enjoy travel - there's nothing xenophobic about them - in general there is xenophilic, and the idea that you can be both xenophilic, fascinated, and interested in the world's cultures, and want immigration to your country restricted, and that this is the generic position that the average person holds this position - is a story that appears nowhere. So nobody has an idea that xenophilic restrictionists might be a plurality or a majority in the country, because there is a rule that says: anyone who calls for a restriction of immigration must be tarred as a xenophobe, and I think it's time to double dog dare the people who are keeping this level of discipline. Say: why is it it impossible to be a xenophilic restriction. What I think is is that the economy of shame is such that whoever acts first to make this point is in such danger for their livelihood, their reputation, that they are going to be tarred and feathered and why one of the things that I'm trying to show people is that you can make these points. Now I can't do this on CNN, but I can do this on pirate radio. This is basically audio [samizdat](https://en.wikipedia.org/wiki/Samizdat) - to take the Russian underground mimeograph movement as a template. We can say things here, but there's only a matter of time before this starts to become problematic to the institutional structure, and it responds by debiting my account. Oh, well that that's that alt-right guy, you know, he seems disgruntled or you know - he seems gloomy and out of touch, and then the fear uncertainty and doubt campaign starts and that's what is actually keeping everybody in line. It's not that there isn't money to be made - there's tons of money to be made - what's happened is that it's been too easy to pick off the initial adopters. **DANIEL:** I agree, and I'm curious what your explanation of how that phenomena emerged. **ERIC:** So let's really get into it. We did have a dissension suppression unit inside of the FBI which was called [COINTELPRO](https://en.wikipedia.org/wiki/COINTELPRO). And it tried to induce Martin Luther King jr. to suicide through a letter from Sullivan who was I think number one or number two - maybe under Hoover - this thing lived inside of the FBI, it probably tried to tell John Lennon that he was traitorous, it tried to humiliate Jean Seberg who is a Black Panther supporter by planting false information inside of mainstream media - Newsweek in the Los Angeles Times, it tried to get la cosa nostra to kill Dick Gregory - the famous comedian and black civil rights leader. So we did have a dirty tricks unit inside of the United States that needs to be known broadly, which was pretty thoroughly investigated in the mid-1970s and once we saw that we were engaged in his dirty tricks against our own people we were kind of shocked and flipped out, and the economy wasn't in great shape, and then Ronald Reagan came riding in and I think he pardoned Mark Felt who had been the head of COINTELPRO after Hoover, but he was also deep throat, and so you had this very strange situation that we got this reboot during the Reagan years where we went back to some sort of more traditional more patriotic imagined version of our country, and my belief is that in part when Bill Clinton decided that he couldn't take yet another loss to the Republican Party and was gonna start experimenting with republicanism inside of the Democratic Party - by that point we had two parties that more or less were two flavors of the same thing. I refer to that collective as the looting party: in the looting party - the neoliberals, the neoconservatives - sort of intergenerational warfare within the country, in the US, and my take on it is that the common ideology is that profit had to be found abroad and so you had to loosen the bonds to your fellow citizens and that's where all of this kind of 'the market always knows best, we need to offshore and downsize and securitize' and what I've called the new gimmick economy. So that right now we're waking up from the new gimmick economy and having never lived in anything really authentic unless we're quite old. So my belief is that during that period of time there was very swift retribution for anyone who dissented - famously a prominent trade theorist who was talking about the benefits of trade restrictions for infant industries let's say apparently got a call from one of the people high up in the field say: 'oh, you seem to be a very bright young man - it would be a shame if anything happened to your career' and so this kind of idea suppression is the hallmark - well it is what I think these two generations - the baby boomers and the Silent Generation - may become best known for in the future, that this was a period in which new corrective ideas had to be suppressed because of the fragility of the system. We saw the fragility breakout in 2008, we saw have vulnerable we were in 2001, and we see that the whole sense making apparatus is breaking down from the Trump election. So these have been the three moments when the gated institutional narrative has broken because it just got overwhelmed by events. But other than that, the key was making sure that people like you, or like me, or like [Peter](https://en.wikipedia.org/wiki/Peter_Thiel), are not mainstream. The cost of listening to us has to be driven to astronomical levels so we have to look wild-eyed, we have to, you know... they can't call me uneducated if I have a Harvard PhD which is one of the funny parts of the system, but the idea is that you have to say: 'well, you know, maybe he used to be smart but he's gone fringe' so the social cost... **DANIEL:** It's amazing how effective such small amounts of that can be. **ERIC:** Well it's also just funny, I mean, it just... There's so many hours of audio of us and I was just astounded, for example, with the number of people who would try to portray let's say my [brother (Bret Weinstein)](https://en.wikipedia.org/wiki/Bret_Weinstein) as right-wing - I mean from my perspective: can you imagine making that decision that a guy as far left as Brett and you're gonna spend your credibility pretending that he's like allied with the Nazis? I just... It doesn't even make sense to me because it's simply to me a way to incinerate your credibility. And yet the way the system works is you incinerate people's viability. It's economic warfare - that if your reputation is damaged you can't be trusted, you know, and that's how this enforcement is working. So you ask me the question how does it work to keep this in line - it's to trivially easy to destroy individuals. And my question has always been: is there a program which I have tentatively called 'no living heroes' - I don't know if you've heard this riff before. [Charles Lindbergh](https://en.wikipedia.org/wiki/Charles_Lindbergh) who was not a great human being almost kept the U.S. out of World War two - he said why is this why is this America's problem? And if you think about it, he had self-minted credibility in that he got into a plane and he flew it over an ocean solo and became a hero, and that level of visibility allowed him to compete with the state. Okay, I think that there was a program after Lindbergh that said: individuals should not be able to amass sufficient mindshare to affect the course of government policy. And this is a question in my mind: is there a program that got started that said we're gonna wait and see if anything starts to bubble up that seems to have integrity, it seems that mindshare, it seems to be opposed to our policies, and if and when we find such a thing - it has to be redirected, co-opted, destroyed reputationally, or made ineffectual. And the phrase that I really appreciated that was used about Jean Seberg who was - you know - one of Hollywood's great leading ladies at the time, was we have to cheapen her image. This is the federal government talking about cheapening the image of a Hollywood star because she was interested in radical black politics." - [Eric Weinstein](https://youtu.be/_b4qKv1Ctv8?t=5830)

> "Imagine if we could create a situation where there was no incentive for disinformation. I'll talk about in a moment how I think we could do that. And not just no incentive for disinformation but also no incentive for information withholding. And something pretty unique about humans is how good we are at being able to add intention to signal - lie - but all the subtle versions, right, which is most of the signal that is coming to me is just bouncing off of stuff and reflecting and doesn't have that much disinformation in it, and obviously animals have camouflage and strategies like that, but every time we're communicating we are usually communicating towards some intention that we have and so I want you to think certain things were you thinking those things I think will advantage me, but then to the extent that you take what I'm saying as adequately informing you - like accurately informing you about reality - or not be, right, like there's a discrepancy between why I'm communicating to you and what would be maximum benefit to you. So... and even if we're not doing spin and [Russell conjugation](https://en.wikipedia.org/wiki/Emotive_conjugation) disinformation - even if it's just IP & trade secrets and information withholding - this lowers our coordination capacity to do interesting things tremendously. And then there's so much coordination cost that goes into the competition. So let's imagine... and I think we can say: up to a tribal scale people could do - I'm not saying they always did it, I don't wanna be romantic - people could do a better job of accurate information sharing, because there was less incentive to disinform each other inside of a tribe because it would probably get found out and we actually depended on each other pretty significantly. But the Dunbar limit seems to be a pretty hard limit on that kind of information sharing. **ERIC:** So do you mean this supposed Dunbar number that is the limit of our ancestral mind or group to track the number of interactions we have, so maybe I can keep track of 200 or 300 people, but not much more? **DANIEL:** Yeah, whether it's a hundred and fifty or 50 or 200 or whatever it is - and you know, I think we've attributed this to different things - why tribes never got beyond a certain scale within a certain kind of organization and if they would start to they would cleave, and then if they were going to get larger they had to have a different kind of organization. I think how... one thing that we commonly think about is that kind of a limit of care and tracking, right, up to that number, up to 150 people or whatever, I can actually know everybody pretty well, they can all know me, and if I were to hurt anybody I'm hurting the people that I've known for my whole life. So something like universal interest of that group or almost like a communalist idea makes sense if there's no anonymous people and there's no very far spaces where I can externalize harm - I basically can't externalize harm in the social commons when I know everybody. I also probably can't lie and have that be advantageous. I think there's another thing which is there's a communication protocol that anyone who has information about something within that setting can inform a choice where that information would be relevant that the tribe would be making, because they can actually communicate with everybody fairly easily. And if there's a really big choice to make everybody can sit around a tribal circle and actually be able to say something about it, and as you get larger you just can't do that. And I think there's a strong cleaving basis for not wanting to be part of a group that would make decisions that I'll be subjected to that I don't get any say in. Unless it's really important to do that, like, we're gonna have... there's a situation where tribal warfare is starting to occur more often, and so having a larger group is really important or you know something like that, in which case the bonding energy exceeds the cleaving energy. But let's say that we could actually have a situation where we had incentive to share - to not disinform - and to share accurate information with each other and it could scale beyond a dunbar size - so now we have something where we don't have fractal disinformation inside of a company, we don't have people competing for cancer cures that aren't sharing information with each other. I think that system would outcompete all the systems that we've had in terms of innovation and in terms of resource utilization, resource per capita utilization so much that if we could do such a thing it'd become the new attractive basin to which civilizations would want to flow. And I think the limit of Dunbar dynamics were communication protocols. And I think we do have technological capacity - and I mean both social technologies and physical technologies to develop systems - and so like this is kind of at the heart of it: to develop systems where there was more incentive to share honest information - and obviously this is an example of anti-rivalrous where I had my well being and your wellbeing and wellbeing of the commons more tightly coupled to each other. That's the first part of it. **ERIC:** Okay, so try to figure out how to get very large-scale human collectives to behave like small scale human collectives. **DANIEL:** Well, yeah... If I think about two groups of people... **ERIC:** That sounds to me like TripAdvisor where I travel to some country I've never been to and I'm never going back again and there's some sort of reputational cost that a hotel would have had if it had gamed their guests so it becomes a bad idea to game your guests because you have a fractional relationship with the world in some sense, where somebody has left a review that says: 'be careful they try to upsell you on the Wi-Fi and it's a scam and here's how to look out for it' and suddenly you have got a problem if you're a dishonest actor because there is this sort of reputational game that is technologically enabled. **DANIEL:** So I think this is why people like blockchain as the idea of an uncorruptible ledger is that dinformation and information withholding that wouldn't be really beneficial to the public and any kind of bad acting does less well with good accounting systems. I have to be able to kind of corrupt the accounting in some way to be able to have it be advantageous. And so can we make systems that make the accounting much better is part of it, but it's not the whole basis, because then of course you still have incentive to figure out how to game the game - whatever it is - as long as we still have separate interests. And the separate interest which is that any in group can advantage itself at the expense of an out group or any individual can advantage itself at the expense of other individuals which is grounded all the way down to like a private balance sheet - I do think is an inexorable basis of rivalry, and I do think that rivalry in a world of exponential tech does self-terminate. And given that I don't think we can stop the progress of tech I do think we have to create fundamentally anti-rivalrous systems and I don't think you can do that with capitalism, or that private property ownership is the primary basis to how we get access to things. I don't think you can do it with communism or socialism or any of the other systems we've had, but I don't think that if we look at how the coordination system of cells or organs inside of a body works - I don't think it's capitalist or communist - I think there's a much more complex way of sharing information and provisioning resources within the system." - [Daniel Schmachtenberger](https://youtu.be/_b4qKv1Ctv8?t=6688)

> "I look at some outliers on both sides of the bell curve of various dimensions of the human condition and let's say we take Buddhism for instance. We have something like three millennia of 10,000,000 fluxing give or take people who mostly don't hurt bugs - across different bioregions and across different languages - and that's really significant when we think about the inexorability of violence in humans. And then we look at say the [Janjaweed](https://en.wikipedia.org/wiki/Janjaweed) or some group of child soldiers where by the time someone's a teenager they've all hacked people apart with machetes. I think that the human condition can do both of those. Human nature can be conditioned to do both of those. But then I see that we have a system where in general as soon as a tribe figured out... as soon as a couple tribes were competing for resources it was generally easier to move than it was to war. Until we had moved everywhere, in which case it started making sense to war and then as soon as any tribe militarized as every other tribe has to militarize or they lose by default and the game of power has begun and in earnest in that way - the human on human game. And I think we've seen that the peaceful cultures largely got killed by the warring cultures and the warring cultures learn from each other how to be more successful at it and so the thing that we have now is something that has emerged through iterations on power dynamics and it's conditioning everyone within it and then we do all of our social studies within that and say this is human nature." - [Daniel Schmachtenberger](https://youtu.be/_b4qKv1Ctv8?t=8207)

> "I see the possibility for a steady-state population that is within the carrying capacity of a closed-loop materials economy, but that is fueled by renewable energy - so you basically have a finite amount of atoms, so you circle the atoms, you don't have a finite amount of energy because you're getting more energy every day but you have a finite amount per day and so you have to be able to cycle the atoms within the energy bandwidths, and you're cycling it from one bit pattern into another bit pattern, right, like from one form into another form, and the forms are stored as a bits. So you have atoms, energy, and bits, and you don't really have a limited number of the bits that you can have. And so we can have an economy where it's getting continuously better but not by getting bigger, but by getting better - we continuously make more and more interesting things with the same fnudamental stuff." - [Daniel Schmachtenberger](https://youtu.be/_b4qKv1Ctv8?t=8464)

> "It's important to say: obviously if I have a situation where valuation is at least largely proportional to scarcity, then I have a basis to continue to manufacture artificial scarcity, and if something becomes abundant enough it loses value - then of course abundance and markets don't go together." - [Daniel Schmachtenberger](https://youtu.be/_b4qKv1Ctv8?t=8837)

> "There are so few people who are attempting to think rigorously about what we actually are and what we must become if we are to have a long term future." - [Eric Weinstein](https://youtu.be/_b4qKv1Ctv8?t=8975)

> "Every branch of the decision tree has gotten hyper weird, and anybody who's not looking at the fact that there is no non-weird branch of the decision tree is missing the story of who we are and what time it is in human history. So I think to not explore the weird, to not dream about what might be is the least responsible, least adult thing we can do. If we don't dream and we don't explore the weird we're doomed." - [Eric Weinstein](https://youtu.be/_b4qKv1Ctv8?t=9056)

> "I think we get something like a certain level of empathy up to the Dunbar number just through mere neuron type effects, through the fact that I know these people, they know me, we've lived together, if they're hurting I am gonna see it because they aren't somewhere far away. And similarly I'm less likely to pollute in an area I'm in then through an industrial supply chain that pollutes somewhere that I'm not. So just a proximity where the cause and effect has a feedback loop as we start to get to much larger scales where I'm having a cause and there's an effect but I don't get a feedback loop on it - the broken open feedback loop is a problem. So I think the Buddhists were able to train abstract empathy - not just empathy for the people who I see hurting, but empathy for all sentient beings throughout time and space, right, feeling their connectedness with them, that the nature of the [vows of the Bodhisattva](https://en.wikipedia.org/wiki/Bodhisattva_vow), and they're not the only one, right, this is... different religions have tried to do this, but it's an example of a group succeeding at it, where they were able to have a sense of positive coupling: of my well-being in the well-being of another rather than inverse coupling: they get ahead and it's decreasing my ability to get ahead. What the other side of the Dunbar number was not just who we care about, but also our ability to coordinate, and I don't think they were able to figure out coordination mechanisms that are adequately effective at scale. I think if we do both of those things we can make a fundamentally different kind of civilization. And rivalry mostly comes down to today: private balance sheets, which is I can get ahead economically and that money equals optionality for most of the things that I want. And I can get ahead economically independent of you getting ahead and even at the expense of you getting ahead or the expense of the Commons. Right, and so my near-term incentive can oftentimes be a long-term disadvantage to others of the whole so now this basis of where my well-being and the well-being of others or the Commons - the Delta between those - is the basis for rivalry. But then dealing with that rivalry keeps increasing coordination costs, keeps - you know - creating disinformation systems where we can't coordinate effectively. So how we deal with the balance sheet part - there's a few things: right now for me to have access to stuff I have to mostly - with a few exceptions - possess the stuff, right, so possession and access are coupled. And if I possess something - I don't have to be using it - I'm just reserving the optionality to use it: the drill that sits in my garage that I might not have used in a couple years but at least it's convenient that when I want it it's there. Right, but me possessing something means that I have access to it and means you don't have access to it, and so with a finite amount of stuff: the more stuff you possess - the less stuff I have access to - rivalrous basis. But we all know library type examples, or shopping carts, where if I have enough shopping carts of the grocery store for peak demand time I don't have to bring my own shopping cart which would be a pain in the ass and would require 10,000 shopping carts per grocery store rather than 300 - everybody bringing them. So what matters is you having access to the shopping cart doesn't decrease my access, and we start to see a potential for this: if we think about something like an Uber and then we think about self-driving Uber that then has a blockchain that disintermediates it being a central company, and being a commonwealth resource where you having access to it doesn't decrease my access - so we're not rivalrous anymore. But then we take the next step and say: if you having access to transportation then also allows you to go to the maker studio that you have access, to the science studio, to the educational places, to the art studios where you then have more access to be creative, but the things that you create you aren't creating for you to get more money and get ahead because you already have access to all the things that you want and you don't differentiate yourself by getting stuff - you differentiate yourself by the things that you offer because you already have access to stuff, so there's a fundamentally different motive structure - then you having access to more resources creates a richer Commons that I have access to. So now we go from rivalrous not just to non-rivalrous, which is uncoupled, but anti-rivalrous - meaning you getting ahead necessarily equals me getting ahead. And so when we look at getting out of the Malthusian type dynamics, part of it is that we can actually get out of the population dynamics, part of it is that we can actually get a closed-loop materials economy with renewable energy that can continue to upcycle, and part of it is that we can utilize our resources much more effectively and much less-rivalrously where we start decoupling access from possession - that'll start easily in some areas & be harder in other areas, but we start with in the areas that it happens, and so we start getting more and more of a situation where I want you to have access to more things because as you're more creative than I get access to more things that are the results of your creativity. So this is an example of removing some of the basis of rivalry associated with balance sheets. I can go to sex underneath that now if you want me to. **ERIC:** You should go where is most natural to take the conversation. I will just try to follow... and the problem is if you go to sex directly from where you are - you are describing the value let's say of prostitution, which is that people do not have to make a commitment to a sexual partner, many people can have the same sexual partner, you start to get into all of these very funny areas where status, for example, is a very weird commodity: do I want you to have more status because somehow that will give me more status, do I stop caring about status if there is exactly one parcel of land which has unequivocally the best view - is that something that I want you to have rather than me having it? **DANIEL:** Yeah, so let's talk about status for a moment. If I'm comparing you and me in terms of who has more dollars or who's taller or who can run faster or some... I can compare us on the same metric. And if status is number of followers on Twitter, then whatever - Kim Kardashian's most interesting human being that's ever lived. And so I think we know that reductionist metrics on status are also gamified and inappropriate. But if we say like [M.C. Escher](https://en.wikipedia.org/wiki/M._C._Escher) or dolly, like, what was more brilliant art? I think it's a meaningless question because they both offered something completely novel to the world and something meaningful and beautiful that neither of the other ones offered or could offer, and I can't compare them because I can't metricize them. And the reduction of... that's the thing: I can't reduce totally unique things to a fungible metric. So one of the problems I think is actually fungibility and metric reduction. And so if you have status associated with unique things that you offer to the world: awesome, I'm not competing with you writ large for more status - I'm going to... people are gonna have a relationship to me for the things that I offer and those are really the people that I want to have a relationship with me, and if you're offering things to the world that people have a relationship to you for and I see that the world is getting better as a result of what you're offering and I have access to more... a better world as a result of it - I'm totally stoked on that. **ERIC:** This is where it starts to feel not real to me. Okay but let's go through the show. **DANIEL:** So here's why it sounds not real. I think... so do we have a slowing in technological progress? Yes. And - you know - less so in some areas than in other areas. But do we still have exponentially growing technology in terms of both cumulative amount associated with number of people in globalization and in terms of just technologies that are still continue to grow? Yes, of course we do. So is it 50 years or hundred years we don't know. But I really like... I have to think of this in a kind of a mythopoetic frame - that's how it occurs to me - as technology is empowering our choices and we are getting something like the power of gods, you have to have something like the love and the wisdom of gods to wield that or you self-destruct. And so when I think about the rapture story or the Mayan calendar or any of those stories in a metaphoric sense as just like: let's say you and I were in the Bronze Age and we had just seen a larger war than had ever happened because there were some new better weapons and they could shoot further distance, and there were deserts where there didn't used to be deserts because we had got new better axes and saws and had been able to cut down more trees, and we just thought about it and we said: we're still developing better weapons, and were developing better economic extraction tools, were using our power in ways that are constructive in a narrow sentence and destructive in a larger sense, but everybody is doing that - this doesn't get to happen forever. So this phase is defined by increasing power on all sides, used in destructive ways, constructive narrowly, but destructive broadly - that phase comes to an end. And there's something like a hard fork where if we keep doing anything similar to that - it'll come to an end cumulatively - whether existential or catastrophic - more likely catastrophic, right, not full everything end, but a lot. And to be able to have that much power and not use it in ways that destroy the system requires being actually good stewards of power. So then the whole question for me becomes: how do we make a social system, like, what is the the Bodhisattva engineering, how do we make a social system that is conditioning not just individual humans, but also collectives to do good choice making - Omni-positive kind of choice making. Well I have to have a sensemaking system that can factor things like externalities ahead of time better and that doesn't have things like multipolar traps where if anybody is doing the fucked up thing that everybody has to do it. And so I can start to think about what architectures such a system would have to have to be able to do sensemaking as to what externalities would be and be able to internalize them, and where then I can actually confer resources to those right choicemaking, and that we're developing humans, so again, think about the the education associated with some religions bringing about less violence, the education associated with some cultures bringing about higher average cognitive capacity, and being able to bring those together - as much as I know this sounds like hippie and silly - I don't actually see anything other than a radical increase in our good stewardship of power that makes it. **ERIC:** I love the idea that you think that there might be something here, but let me come back at with my - and again I'm not trying to be negative: I had an experience at some point... **DANIEL:** Your answer requires a warp drive! So we both recognize the inexorability of this thing and then are saying: okay, so what is the fundamental thing and something... **ERIC:** I'm not making fun of you because what you're saying is insane - what I'm saying is insane, and the people who are saying the most common supposedly adult things are the craziest of us all. So I at least accept the idea that we have to be here and I want you on that branch, and I want other people on other branches because we need to fan out and start exploring or at least start to care. But I guess what this makes me think of: it was a particular moment in my life where one of my closest friends brought his father to dinner, and his father was a guy who was legendary in the film industry, and one of the things he taught his son was never let the other guy get the first punch in and I thought Wow! First strike - you're teaching your child to strike first. Nobody had ever suggested anything remotely like that in all of my upbringing - I never heard anything like this. And I instantly recognized it for what it was: somebody was going to parasitize whatever I had been taught and say: well great, Eric's been taught self-restraint, Eric's been taught to turn the other cheek, to make sure that you de-escalate conflict, and goodie-goodie - more for me - your multipolar trap. Okay. **DANIEL:** There's a way out of it. **ERIC:** Tell me - I'm dying to hear it. **DANIEL:** So do we retrofit the system? No, impossible, foundational axioms are all the wrong axioms. Can we make a situation in which we can raise children quite differently? Yes. Go to see kids who grew up in an Amazonian tribe or - you know - some very different conditioning environment you'll see very different types of human behavior. Can we change already set adults? Much harder - not impossible, but harder. So could we find adults that would be the most likely to be fast adopters of a new system like this and capable - so both kind of at the cutting edge of their capacity to have abstract wide empathy and bind that to their action, and - you know - deeply considerate about actual cause-and-effect dynamics, factor complexity, and work with other people well. Can we find the ones that are closest there and then train them up additionally in some systems that are developed for how to do a different process of collaboration that doesn't lead to... One way of talking about it is that when we go to command and control hierarchy systems to get beyond the Dunbar number we get diminishing returns on collective intelligence as a function of the number of people, which creates an incentive to defect against that system - even internal defection - and so then we get a problem. If we could get collective intelligence scaling linearly we get something radically different. So we get just the number of people that are needed to be able to do something like that, trained to do that, and we build a civilization - a full-stack ground-up civilization - because obviously I'm talking about not private balance sheets, and private property is the dominant system, I'm also going to talk about not democracy because the nature of voting is inherently polarizing to populations - because we make propositions where both voting for it and voting against it suck for somebody for something because they're based on theory of trade-offs where we didn't even tried to figure out what a good proposition for everybody would be in the first place. So better systems of sense-making, in choice making, which we could get to, and so let's say you have a full stack civilization of people who are capable and oriented to implement it, and you have not only much higher quality of life for the people who are there, but innovative capacity to solve certain problems the world can't currently solve well because of no disinformation in the system and better coordination. Well then that system can export solutions that other places in the world that would normally have an enmity relationship with it actually need that they can't solve for themselves. So it can create a dependence relationship rather than an enmity relationship. And then they're like: well why the fuck are you figuring out these pieces of tech and we aren't - we're like: well we figured out a better social system and if you want it you're welcome to use it - we were open sourcing the technology, here's how here's how it works. But given that the technology as a social technology is a social technology of how people share information and share resources and coordinate differently - it can't be weaponized because it is kind of the solvent of weaponization itself, and so any other group using it is just now that kind of social architecture starting to spore or to scale. And so yeah, I think you get out of the multipolar trap by... You don't have to win at the game of power against some external force to avoid losing at the game of power. So far, if people didn't focus on militarizing they lost to whoever militarized, and if they didn't lose to whoever militarizes is because they militarized which means their culture became a culture that supports the ideas of militarization, right, but if I focus on being able to have whoever would militarize against me be able to offer them things that are particularly valuable that are novel to a collective intelligence that can do better innovation - you get out of a multipolar trap that way." - [Daniel Schmachtenberger](https://youtu.be/_b4qKv1Ctv8?t=9123)

> "Let's go protopian not utopian, let's go that there are some... **ERIC:** Say what you mean by protoian? **DANIEL:** Moving in the right direction. Let's say that there are some things that are harder to make adequately abundant than other things, but there's a lot of low-hanging fruit that we can start moving, and as we do it we will discover there's good reason to think that there is a basis to do that in more areas. So in a system where when something is more scarce it is worth more, then if I'm on the supply side of that I have an incentive to manufacture artificial scarcity. And to definitely prevent abundance that would debase the value of the thing that I have. In a world where we remove the association of value and scarcity, then where there are actual scarcities the goal is to engineer the scarcity out of the system. And so if we're talking about limited amount of Oceanfront then this is where we say: well can we do seasteading and create a lot of Oceanfront that is really awesome - where there is actually more to... just like more people are shopping at the store then we need more shopping carts. And so part of the answer is how do we actually increase the abundance, but not an exponential abundance, because we're talking about also steady-state population and using and a lot of shared resources, and it's that coupled with psychologically healthy or more mature people that relate to these things differently - both of those are necessary and neither would be sufficient on their own." - [Daniel Schmachtenberger](https://youtu.be/_b4qKv1Ctv8?t=10550)

> "So it is both how we develop that socially which I don't think will happen uniformly - I think will happen in pockets that become strange attractors that other groups want to then implement once seen, because they're so clearly better at both quality of life and innovation. And how long that takes to develop widely is a while - like this is a multi generation thing. I think that that would not be sufficient on its own, but it's necessary. Better sense making systems where we can actually solve problems without causing worse problems which we're not historically good at is also necessary. And this is both some evolution in our epistemics and our actual processes of collective sense making and collective coordination - so yes, I see level ups in both of those possible." - [Daniel Schmachtenberger](https://youtu.be/_b4qKv1Ctv8?t=10688)

> "Let's try to take some of the stupid fun out of discussing sexuality by talking about it for what it is: a central system that has to be discussed because it is the engine of human behavior." - [Eric Weinstein](https://youtu.be/_b4qKv1Ctv8?t=10827)

> "And it really matters for when we think about resource scarcity, because the resources that people need to deal with the first part - the survival part - are not that much actually, but the resources that people need to deal with the mating part is more than the other guy historically, which is why the guy with the 150-foot yacht might feel bad when the 200-foot yacht pulls up. **ERIC:** And let's say this is closed if... You're not an evolutionary theorist and I'm not, but we could do our best. There is a version of evolutionary theory which states that there needs to be crisis - there needs to be a function for showing that you are better in order to keep individuals max - you know - sort of on that razor's edge of performance, and that mating opportunities means that there's always a crisis - there's never enough abundance because somebody with 13 homes is more desirable than somebody with 9 homes if you're just trying to figure out if there were a crisis who would do better. **DANIEL:** Right, so we have to overcome that because that drives a Malthusian situation of no amount of resource ever bring sufficiency about, and drives a fundamental rivalry which is why you said we have to address it. So what I'm... My take on this as I explored it my process with myself has been asking ok, as soon as I saw that the dynamics of this world that seemed intuitive and natural to most of us as we kind of grew up in and were conditioned by it were self-terminating, and I said any of the things that we think of as normal I'm willing to question deeply. And so how do I think - could I imagine a high-tech civilization that doesn't implode, could I imagine a kind of enlightened planet what would life be like there - all the different things: conflict, emotion, resources, and sexuality is obviously one of the big questions. And I think the book [Sex at Dawn](https://en.wikipedia.org/wiki/Sex_at_Dawn) obviously gets plenty of things wrong - it's trying to make a strong antithesis to the standard evolutionary history of Homo sapiens thesis, but I think there are some key parts to it. When they look at the moss wah people or the Canela people or people that did not have... that had a stable society that was not primarily pair-bonded but had multi-male multi-female dynamics - it's not to say that's how humans mostly were - that doesn't matter - it's to say that it's a possibility. If it's within the possibility set - same Buddhism I'm not saying that's how people mostly have been. **ERIC:** It doesn't have to win - just needs to establish proof of concept and then we can try to scale it up from there. **DANIEL:** It's a positive deviant analysis for proof of concept to then say can we make that actual... is that a viable model for a new center and is that a possible thing to make. And the fact that it didn't make it through evolution so far, like, evolution has a blind quality to it, right, where it'll make an adaptation that makes sense in the moment determined by something like warfare, that is actually not that good long term or is even self-terminating long term. So the argument if it would have been a good system it would have made it - well, the thing that has made it is continuing to up ratchet rivalrous capacity and that itself is gonna self-terminate. **ERIC:** Like metaclass hacking that somehow we've hacked ourselves to a positions where we can keep surviving and so one version says that we can never escape the evolutionary imperatives, the other says we have always escaped whatever our last problem was and so we should be expected that even if there's only the sliver of hope we should exploit it to the fullest. **DANIEL:** Yeah, and so generally this situation happens that we have a near-term incentive to pursue some advantage but where the disadvantage of that thing might happen over a much longer term. and that's like one of the fundamental problems, right, the externality might show up over hundreds or thousands of years but the benefit occurs over this year so I have to do it. So we have to get over that actually, if we're affecting the world in such fundamental ways over the long term we have to actually be factoring that into our decision making now. That's one of the minimum requirements of a GameB if it's going to exist, which also means of a viable civilization at all." - [Daniel Schmachtenberger](https://youtu.be/_b4qKv1Ctv8?t=10900)

> "I think when we really start to think about this clearly we recognize that this direction is self-terminating - the need to get stuff from the world, that when I die it ends with me, that there is actually only a kind of self-transcendence and permanence in the way that I touch the world which does ripple ongoingly. But there's also this thing where - again - I feel almost a little bit shy talking about it even even more than the sex topic in some ways because I'm proposing that there is something like spiritual growth that is actually necessary for civilization to make it, and so people affirming that they are these kind of - to themselves - needy things that need stuff from the world, that need other people's validation and attention and etc. and living life that way where the more of it they get what they're still getting as a self - the affirmation of that sense of self, as opposed to coming from a place of wholeness. And the desire and actual love for the beauty of life and the desire to have their life be meaningful to life - that my life ends but life of the capital L doesn't end, and that life starts to be central to my awareness more than my life is, and my life becomes meaningful in it's coupling to life - this answers the sex question, it also answers all the other questions but I don't think... **ERIC:** There is a there to break through to and the problem that we're having conceiving of it in your mind - now again, I don't think this gets us out of all the issues that I've raised - but I think it's the first point at which I start to see there's something really different about your perspective, so just as a slow learner... **DANIEL:** If we take the kind of [Girardian](https://en.wikipedia.org/wiki/Ren%C3%A9_Girard) idea of all [desire is mimetic](https://en.wikipedia.org/wiki/Mimetic_theory) - and I'm oversimplifying it, but just meaning I want what other people have - and then that inexorably causes conflict and then the conflict will inexorably cause violence. I think there is statistical truth to all three of those steps but not inexorable truth to any of them. I don't only want things that other people have... you know - or that I learned from other people - there are things that are just intrinsically fascinating to me or there are wanting for other people that is not wanting for myself anything in particular - just actually caring about, wanting for other people - there are innate creative impulses." - [Daniel Schmachtenberger](https://youtu.be/_b4qKv1Ctv8?t=11960)

> "I think dominant paradigms co-opted psychology to define healthy psychology as supportive of the paradigm, so what I'm about to say in terms of what I think healthy psychology is is not the current definition of healthy psychology - it is one that would be fit to an actually viable civilization. I think psychologically healthy humans are emotionally coupled to each other, so when you're happy - I'm happy, I'm stoked for you - if you're hurting I feel that, I feel compassion and empathy. I think the worst psychology is the inversion of sadism where I feel joy at your pain rather than joy at your joy and pain at your pain. **ERIC:** I think it's a French expression: it's not sufficient that one succeed in life - one's friends must also fail. **DANIEL:** Yeah, so that is a perfect statement of what is most wrong with the world, right, that is the heart of the worst part of GameA. But I think jealousy is one step away from sadism because if sadism 'is I feel joy at your pain', jealousy is 'I feel pain at your joy or your success', or envy, right, and I don't think that is a psychologically healthy place for people. I think it is a... largely we condition this because we watch movies where we celebrate when the bad guy gets it and we condition the fuck out of we celebrate when the bad guy gets it and we celebrate when our team wins and the other team loses, so we can collectively decouple our empathy from other human beings arbitrarily, so that we can then feel good in a war supporting - you know - when that type of thing occurs. And we get conditioned that second place is the first loser, and all those types of things. But this is conditioning again, and conditioning of a highly neuro plastic species, so I think our intuitions are all bad if we haven't spent time really questioning these things and then also looking at cultural outliers, because I don't think any of this is inexorable - is it ubiquitous? Yes. Is it inexorable? No. But I think what is ubiquitous is psychopathology. **ERIC:** Well Daniel, I think what I've gotten from our conversation is that you've got a lot of examples that are at the proof-of-concept level of things that are under exploited, you've got an observation that we're far off the efficient frontier, that there's one giant overlooked opportunity which is that we are so radically [k-selected](https://en.wikipedia.org/wiki/R/K_selection_theory) that our developmental period from age zero to thirteen could be used for something radically different, which I think is the biggest hope in your whole complex of ideas, together with the idea that there are realms beyond somatic pleasure that most of us spend our entire lives not knowing what it's like to break through the status and wealth and security games, and effectively we have no idea what the top of Maslow's hierarchy when fully realized is, and that it might be possible to at least begin the game to buy us some time to try to figure out what we would do at scale. Now I still don't see any world in which we can defeat all these multipolar traps, but I think what you're really saying to me - again, always correct me if I'm wrong - is that we could potentially change what winning feels like and that when we do that, then these [prisoner's dilemmas](https://en.wikipedia.org/wiki/Prisoner%27s_dilemma) don't look right any longer, because I no longer want to be the one who defected while you cooperated so that I get off scot-free and you wind up with a 20 year jail term. **DANIEL:** And we have to remove the context of the [prisoner's dilemma](https://en.wikipedia.org/wiki/Prisoner%27s_dilemma) as our model for the world, right, like actually change the nature of the context and because that is a fundamentally inexorably rival risk dynamic." - [Daniel Schmachtenberger](https://youtu.be/_b4qKv1Ctv8?t=12320)

> "So if I have a system like a corporation where my playing by the rules fully gets me ahead less than me defecting on the system internally and doing corporate politics or a back-end deal or whatever it is, then I have the incentive to defect on the system and it doesn't have the collective intelligence to notice it, right, because there's a diminishing return on the collective intelligence of the system as a function of more scale. If I could make a system - and I will claim that we can and there are architectures that can achieve it - we could make a system where the collective intelligence scaled with the number of people, then I would always have more incentive to participate with it than to defect. And if I did defect because I had a head injury - the system would have the intelligence to be able to notice that and deal with it. Now this is the place where I'm saying: the Dunbar number was both care and sense making. It was a limit on both - you know - our values generation and our sense making to inform choice making. So if we want better systems of governance i.e. better systems of choice making we need to get both collective values generation and collective sense making down. The conditioning gives us ways to start to work with things like very different value systems, but I can't have a very different value system while still incentivizing - meaning a value equation economically where the whale is worth a lot dead and nothing alive, and it doesn't have adequate sense making to even inform what good choice making for everyone so we can participate with the system is. So that'll have to take more time." - [Daniel Schmachtenberger](https://youtu.be/_b4qKv1Ctv8?t=12583)



> "Human cognition is in volume the largest input of raw material into society." - [Bryan Johnson](https://youtu.be/1YbcB6b4A2U?t=3518)




> "We spent most of the 20th century figuring out how to strip mine the physical resources of the planet. Now with these digital tools, we're spending most of the 21st century figuring out how to strip mine the cognitive resources of the planet. If we understand that that's the basic arc of what's been happening, then we can get enough distance to imagine a different way that this could go. If you get too involved in the tiny thing, it's like, "Well, this person got banned off of Twitter and that person got pulled back on, and now I'm going to go fight about that." No, no, no. At the higher level, we got multiple companies that are doing cognitive strip mining, that are basically... The sanctity of your thought processes is now intruded with ads and misinformation and on finite resources, which is, how many coherent thoughts can a person have in a lifetime? It's not infinite, because it takes a certain amount of time for neurons to go fire. The signals in your neurons, at their fastest pace, only move 90 feet per second. There's a actual, physical limit to how quickly one can think and how many actual, skilled, coherent thoughts they can have in a lifetime. We're ruining that resource right now." - [Tom Chi](https://youtu.be/AjGOGfzAvyc?t=7459)

> "Any civilization that is net negative to nature, even a little bit, let's say a civilization is only 0.1% net negative to nature per year. It still has a thousand years, and that's its death date, because nature runs out. When you take away 0.1% per year, in a thousand years, you got nothing left. Literally, the goal construction is also something that obviously must be true, at some point in human history, otherwise we will not survive. Every civilization that has the opposite goal construction, where it's even a little bit net negative, we'll have a death date on civilization." - [Tom Chi](https://youtu.be/AjGOGfzAvyc?t=7949)

> "I can break your regulation in three months, it takes you seven years to do it. Like, you, there's a, there's a concept I call rates not states, right? People always bemoan the state of the world. But they forget that the world is the way that it is because of the rates at which things happen. The reason that we haven't just gotten on top of regulatory for all the damaging things in our environment, including in the food system, you know, like, you know, endocrine disrupting, flame retardants in our clothes, and just on and on. Is because the regulatory thing is like a seven year push five, seven, 10 year. And then the work around molecularly is like a three to four month push. So like rates are more important than states rates will define what the states will become, or they define why the states are the way that they are." - [Tom Chi](https://youtu.be/P-5YBAYcE3g?t=2147)





> "The most difficult thing is to take the burden of evolutionary thinking and the theory of natural and sexual selection and to realize that that is your tool kit and from that tool kit you must build something that doesn't look like evolution has always looked before, because we're now on too crowded of a planet and the toys we've been able to produce from science are too powerful. I think Brett has called this wisely the hard problem - the really hard problem in evolutionary theory - which is: you can't continue to dance with the one that brought you, because evolution gets you here and it almost certainly will end in a self-extinguishing event. If you keep playing the evolutionary game and there is no thought - and this is, you know, I think that this is... Brett is the best person carrying this forward - there is no proof that there is a way to use evolutionary building blocks to avoid the evolutionary fate of having - you know - unlock the [twin nuclei of cell and atom](https://theportal.wiki/wiki/Twin_Nuclei_Problem) - they're just too powerful as tools." - [Eric Weinstein](https://youtu.be/MmXq97do-tQ?t=1925)

> "I never heard anyone say: 'I'm not going to allow my child to have life-saving surgery until we get somebody who's not elitists' - like give me the best effing surgeon you can possibly find. So what we can't have is we can't have our current Elite ruining the concept of elite - the elite looting party? The elite termites that are eating through the infrastructure? Every time I hear the word... I mean my simplest phrase is: 'our Elite are not' period. That is what's true - we need to re-establish the concept of elitism." - [Eric Weinstein](https://youtu.be/zDTdm5ZS7gI?t=4012)

> "Are there equations? Are there new mathematics? Is there new form of analysis that can actually deal with an interacting nonlinear system in which we are both being influenced by media and we are influencing media in return? And now when you have a really complicated feedback loop like that, can you say anything about whether or not the market will tend towards a positive or a negative social outcome? That is, is the market going to efficiently get us to a better place? Or is it going to efficiently get us to a place that we don’t want to be at all? These are the sorts of questions that have been traditionally punted by the academics.
>
> And so I think you may not even understand just how profound a question you’ve asked. We’ve been at this for a very long time. And it’s stunning to us the way in which the economics profession pretends to be incurious about this, there’s a paper by two particular authors, both of whom have received the prize that is frequently referred to as the Nobel Prize in Economics. And although it technically is not, and these authors are Gary Becker, and George Stigler, and they wrote a paper called [De Gustibus Non Est Disputandum](https://www.uvm.edu/~jfarley/EEseminar/readings/StiglerBeckerAER.pdf) (meaning "In matters of taste, there can be no disputes"`), and they argued that tastes should be treated as the same for all men, and do not vary over time, comparing them to the Rocky Mountains. The reason that paper is so bizarre is that the field is terrified of your question. What happens when you ask that question is that the field may in fact collapse and it required two people at the very highest levels of the economics profession to effectively put a tourniquet on the bleeding that you can expect to stem from asking that question, because they didn’t have the mathematics or the sophistication to be able to handle it. And furthermore, it may very well lead to a check on the power of economists, if that question does not have a positive answer. Maybe markets, in fact, lead us right up to the gates of hell.
>
> So what the economics profession did was that they put in a very artificial claim, which is that you don’t need to worry about that because tastes cannot, in fact, be altered. This is positively academic nonsense of the worst kind. You’ll find this paper in the late 1970s, and I have an excellent authority from a member of the economics profession affiliated with the Chicago department, in which both of these gentlemen worked, that, in fact, they did not see economics as a free field so much as as a bulwark against totalitarian Soviet-style communism, given when they were writing. Now, if that’s true, it means that we came up with an artificial position in order to make the claim that capitalism was superior to communism. Communism then was defeated, but modern economists don’t necessarily even know that some of these claims were inflated, specifically as a political Bulwark rather than as an intellectual contribution." - [Eric Weinstein](https://theportal.group/38-mass-media-markets-and-human-malware-a-portal-qa/#:~:text=Are%20there%20equations,an%20intellectual%20contribution.)

> "If a particular leader is referred to as a president, a strong man or a dictator, you’re being told a great deal about the editorial viewpoint at that particular media origin." - [Eric Weinstein](https://theportal.group/38-mass-media-markets-and-human-malware-a-portal-qa/#:~:text=if%20a%20particular%20leader%20is%20referred%20to%20as%20a%20president%2C%20a%20strong%20man%20or%20a%20dictator%2C%20you%E2%80%99re%20being%20told%20a%20great%20deal%20about%20the%20editorial%20viewpoint%20at%20that%20particular%20media%20origin.)

> "I think that, in general, without national projects that we feel great about, it’s very tough to say, “Well, what are you getting out of your country?” If it has a high tax rate, particularly a high marginal tax rate, what does that—what is that buying you? And, here’s a question, did the rich really understand why they might want a high marginal tax rate? I think that’s a very weird question for most rich people. Obviously, they would say, I don’t want a high marginal tax rate and they, individually, should not. But what if they were told, let’s say, you know, we don’t know how to prevent violence. And if we do a good job of a reasonable, although somewhat high marginal tax rates on top earners, we can probably avoid the revolution that may, in fact, threaten your ability not only to earn, but to be unmolested by civil unrest in the future. It’s a very upsetting thing for people to think about, who have 10 or 11 figures worth of wealth. However, it may be that a highly unequal society is not a stable society. So I’m not really sure whether we’ve ever had deep conversations about the essential violence that may be embedded within human organization, and what the very powerful and very wealthy need to fear about becoming ever more unequal, because, in fact, I have no doubt that would have been very hard to have a conversation with Marie Antoinette and King Louie, about their long term interests. I don’t think their long term interests were served in a world in which they were viewed as presiding over an incredibly unequal state. And I don’t know how to begin the conversation with the wealthiest families that what they think may be in their best interest with respect to wealth conservation, they might, in fact, be far better served by making sure that the society on which their success rests is a stable one. So these are fascinating and interesting questions. I don’t know whether that fully answers that but I would say that you want to minimize the violence that might be necessary in the system between your two possible alternatives, and you should also try to get the very wealthy on board and get them to understand exactly why they don’t want to become too wealthy. And why that should best be shared. And if you want to see what can happen, take a look at what happened to the Soviet Union. Take a look at what happened to Communist China. Take a look at what happened to any of these societies that experienced a very violent communist revolution." - [Eric Weinstein](https://theportal.group/38-mass-media-markets-and-human-malware-a-portal-qa/#:~:text=I%20think%20that%2C%20in,very%20violent%20communist%20revolution.)

> "Obviously, capitalism and communism both have to die. You need to hybridize it into something which captures the essence of what capitalism did best, which was to provide for freedom, you have to figure out something, short of communism, that provides for people on the basis of being a soul rather than a pair of hands, so that we can’t have your entire value resting on whether or not jobs will continue to exist. As the economy continues to transform, the new economic system has to take much more into account, the issue of public goods and services, because the market will not be able to associate the proper price to the value provided. So you should expect that we were going to have to have hyper capitalism because people will have to be allowed to sort of invent in an unfettered environment because it’s gotten very difficult. And the individuals on whom we depend are really outliers. They’re determined by very fat tails, power laws, kurtosis, various things that people don’t think about. So when you have an Elon Musk, for example, you probably need to give him a wide berth in order to create as much value as possible, but then you probably need hyper socialism to go with hyper capitalism. And the idea there is that our traditional claim in a capitalist economy is simply through our labor. And, in fact, we have two claims we have one claim as a soul and one claim as a set of hands or a brain, which is what do we what do we provide and what do we need?" - [Eric Weinstein](https://theportal.group/38-mass-media-markets-and-human-malware-a-portal-qa/#:~:text=obviously%2C%20capitalism%20and,do%20we%20need%3F)

> "Every modern economics department represents a fusion of two separate traditions, a bullshit tradition that attempts to rationalize power and an analytic tradition that attempts to understand the world as we have it." - [Eric Weinstein](https://theportal.group/38-mass-media-markets-and-human-malware-a-portal-qa/#:~:text=every%20modern%20economics%20department%20represents%20a%20fusion%20of%20two%20separate%20traditions%2C%20a%20bullshit%20tradition%20that%20attempts%20to%20rationalize%20power%20and%20an%20analytic%20tradition%20that%20attempts%20to%20understand%20the%20world%20as%20we%20as%20we%20have%20it.)

> "With respect to capitalism. I’m a huge fan of what capitalism did. And what I’m concerned about is that people don’t realize that capitalism has a different future than it has a past. It was absolutely the most powerful idea in the 19th and 20th centuries, because it created so much wealth, it lifted so many people out of poverty, but it has various problems. It doesn’t incorporate all of the negative externalities. So for example, the price of a gallon of petrol or gasoline almost certainly doesn’t include all of the costs of belching the waste product into the atmosphere or the despoiling of the environment that was needed to go after that oil.
>
> You have all sorts of situations where it doesn’t deal well with public goods and services. And those are things that are increasingly created by technology from what were private goods and services. I’ve talked about that elsewhere. So capitalism may have been tied to a particular place and time, and people get emotionally invested because they think that it’s always going to function the way that it did function. I’ve called this problem the problem of anthropic capitalism, that is, that capitalism was tied to a particular time and place in history, and it’s now time to move on to the next thing.
>
> And I’ve talked a bunch about the idea of what happens when you graduate from high school, but you keep hanging around year after year, you know fewer and fewer of the people and it becomes more inappropriate that you aren’t moving on with your life. In part, I think that that’s what we have, we have a failure to launch our post capitalist society. So you’re watching capitalism come unraveled. And as I’ve said before, we thought that capitalism and communism were in fact rivals, but I’ve likened them to Thelma and Louise, in the final scene from that film. It doesn’t really matter who hits the ground first, but both capitalism and communism are intrinsically unsustainable. And the fact is, we don’t know what that leaves us with except to invent the future. That’s what Adam Smith had to do. That’s what we did with Bitcoin and crypto. We have to invent the future. And so I don’t know why our economists and our best thinkers aren’t realizing that they’re probably looking at a system on its last legs. We’re going to have to take what worked from capitalism that continues to work, and we’re going to have to fuse it to what we now know about markets and the human condition. It’s a very tall order, and it’s scary, but I don’t understand why we think that the answers are going to be in the past, and not things that we’re going to have to invent for ourselves in the future if we want to have a long term perspective on our own viability." - [Eric Weinstein](https://theportal.group/38-mass-media-markets-and-human-malware-a-portal-qa/#:~:text=With%20respect%20to%20capitalism,on%20our%20own%20viability.)

> "In a democracy, any shared group beliefs in nonsense, and particularly self-serving nonsense, will still beat an incoherent haystack of noise that nevertheless contains the missing needles of truth." - [Eric Weinstein](https://theportal.group/30-the-awakening/#:~:text=in%20a%20democracy%2C%20any%20shared%20group%20beliefs%20in%20nonsense%2C%20and%20particularly%20self%2Dserving%20nonsense%2C%20will%20still%20beat%20an%20incoherent%20haystack%20of%20noise%20that%20nevertheless%20contains%20the%20missing%20needles%20of%20truth.)

> "Because the most aggressive such nonsense has become structural through what must be admitted to be an unexpectedly successful pattern of perseveration over more than four decades, our senior leadership class can be relied upon to engage in magical thinking on just about everything in the world of policy." - [Eric Weinstein](https://theportal.group/30-the-awakening/#:~:text=Because%20the%20most,world%20of%20policy.)

> "A particular form of our five word law, when applied to news media, would be “the headline generates the story”, or “the headline is the story”. Once this has been discovered, we see that increasingly, the purpose of the article in our era is not to inform, but to minimally support the desired headline for wide dissemination." - [Eric Weinstein](https://theportal.group/optics/#:~:text=A%20particular%20form,for%20wide%20dissemination.)

> "There is not only a market for your attention, but one for your inattention as well. Your smartphone may well put all the world’s information at your fingertips as is so often remarked upon, but unlike the fabled Library of Alexandria, it puts all the world’s disinformation, misinformation, noise, and distraction as well. And what our CEOs and technologists have learned is that your emotions are responsive to optics and not substance when there are cat and GoPro videos to be watched." - [Eric Weinstein](https://theportal.group/optics/#:~:text=There%20is%20not,to%20be%20watched.)

> "Right now the main institutions of our society have abdicated their role for public spirited adjudication of what is true based on expertise. And so what you're seeing is people coming to hate experts in coming to hate institutions, because they're realizing that these institutions lie to them at a level that they've never considered unless they were Alex Jones fans to begin with. And so what you're having is you're having a large number of people waking up to the idea that: yeah, there really are organizations and working groups that determine what you hear from a multiplicity of venues - it's the same message relentlessly." - [Eric Weinstein](https://youtu.be/LJxBnSyH0T4?t=2511)

> "Nobody knows what's true. And - you know - if you ask me well Eric how are you dealing with this - I would say I'm failing - I'm just flat out failing, as are all of you - I'm just more honest about it. Some of you have an idea that you've got one lens, which is: fix the money - fix the world - Bitcoin - that's the answer. Yeah, Bitcoin - rock on. But no - that's not the answer. Or somebody else says: you know, I really think that we just need to be open and tolerant and realize it's a big world and we just have to give people their due. Well that doesn't work either - you can't just let everything run riot. Or: we have to go back to our institutions - with these people at the helm - are you kidding? We have to abandon our institutions - wait, what are you saying? We're going to abandon our institutions? Do you know what that looks like? Nobody has an answer." - [Eric Weinstein](https://youtu.be/LJxBnSyH0T4?t=2620)

> "I think Sam is discounting the idea that once people wake up to the concept that they were living in an orchestrated [Truman Show](https://en.wikipedia.org/wiki/The_Truman_Show) that they did not understand - they're not going to have the idea of like: oh sure the vaccines were a little bit more dangerous than claimed, and maybe a little bit less effective, and maybe we knew a little bit more about the lab leak. No way - you spat directly in my face and told me not only that it was raining but that I was a crazy person for thinking that you spat directly in my face and you piled up how many Nobel laureates to defend the idea that any inquiry into the origin of this virus was racism? It's like: you're dead to me." - [Eric Weinstein](https://youtu.be/LJxBnSyH0T4?t=2786)

> "You want a culture in which everyone is allowed to burn the flag and it doesn't even occur to you that that's something you would want to do - that's culture. You've got to load the the inhibiting factor on culture. And people say well that's what cancellation is about. Well but if you misuse the concept of shunning - let's call it by something older than cancellation - if you shun people for good questions, if you shun people for speaking truthfully and decently as if they had done something horrible - then you lose the ability to control bad behavior through social norms. And one of the things that I've now come to understand is: we are either going to restore a culture which shuns only when shunning is really the correct course of action, or we are going to have rules that prohibit what you can and cannot say. And I am absolute in that we should not have rules. We've got to put this on culture and we've got to get a culture in which in general you are very careful about the negative things that you say." - [Eric Weinstein](https://youtu.be/LJxBnSyH0T4?t=11179)

> "When your idea about what a just society is: well let's vindictively punish successful people, let's pretend that male and female have no difference or all the difference according to some set of rules on alternate tuesdays, let's decide that we can redefine what a recession is or the Consumer Price Index, let's decide that we don't need masks - yes we do - no we don't - yes we do, because of the science, science, science - can somebody get rid of these people? We need to be in a society that makes some semblance of sense." - [Eric Weinstein](https://youtu.be/LJxBnSyH0T4?t=11362)

> "Many of the voices that we've been listening to because they got jobs in our organs - whether it was the New Yorker, or the Washington Post, or a professorship at Duke - we have to stop listening to these people wholesale. We have to stop being tolerant of the intolerant. If you come from a position that is sufficiently extreme and your whole point is to try to use and weaponize democracy, to weaponize free speech, to weaponize good faith, to weaponize what it means to hold a debate - you need to not really have a voice at the table because we don't have a solution." - [Eric Weinstein](https://youtu.be/LJxBnSyH0T4?t=11455)

> "The internet needs its own version of a religion - it doesn't have to be a god, but it has to be something that has the word mustn't in its vocabulary." - [Eric Weinstein](https://youtu.be/nz7cheVQ15w?t=797)

> "If your scientists can't tell you to go fuck yourself they're not going to be scientists." - [Eric Weinstein](https://youtu.be/nz7cheVQ15w?t=3711)

> "The great sin with money is not really understood. There's nothing wrong with luxury and there's nothing wrong with wanting status. The great crime when it comes to personal wealth is using money to generate your status." - [Eric Weinstein](https://youtu.be/nz7cheVQ15w?t=3741)

> "I want to see you showing off - I just don't want to see you showing off what you've bought." - [Eric Weinstein](https://youtu.be/nz7cheVQ15w?t=3801)



> "Davos man - it was my current rubber stamp for GameA and its highest manifestation - believes that they can beat down the people, make them reach the 17 united nations sustainable development goals by making them, right, guess what davos man: that ain't gonna work because the problem is GameA has defined their status for them as status through possessions and positional goods. If you just take away their status and their positional goods, their human well-being goes down - they're going to revolt and the result is going to be a right-wing tyrannical dictatorship - a populist right-wing dictatorship. Take that to the bank davos man! The GameB finesse there is: yes, we are well aware that Europeans need to cut their consumption of energy and stuff by 65 percent at least, and Americans by 80 percent, but if we move to GameB as we do this our human well-being can actually increase, because we're not defining human well-being as status through possessions driven by a short-term money on money return loop, but rather building and rebuilding actual human life the way we've lived for hundreds of thousands of years - what I've come to call the meso scale. And the big mistake that modernism made about 100 years ago was moving away from the extended family and the face-to-face community and having the services that were formerly provided by those two instead be provided by the market and the government - two faceless and cold institutions which have their own inherent logic and run away in a classic bureaucratic fashion. And if we can return to a place where humans well-being is designed and operated at the humane scale we can cut back our consumption of stuff massively and have our human well-being go up, and this is to, you know... out-compete them, they come the GameA-ers come to a proto-b on an Airbnb getaway weekend and they say: damn isn't this a better way to live than the rat race where I may be making... have fancier cars and bigger houses, but that's not what life's all about. And so I've now come pretty strongly to the view that the davos man strategy of beating people into submission to fight climate change ain't gonna work - just think of the modest increase in diesel prices in France that produced the yellow jacket movement and that was - you know - yay much of what davos man has to do by his top down beating. The only way we're going to make it to the other side is to redefine how we live such that our actual in the body human well-being is upregulated at the same time our consumption of stuff goes down." - [Jim Rutt](https://youtu.be/byau1SegVqw?t=3144)






> "When you say casually "I don't know what I'm seeing" - you don't mean that there are no words in your head to describe it, you mean you literally can't make sense of what you're seeing. So sense making goes beyond words - it goes to like things like pattern recognition, it goes to a literal gut feeling of confusion or clarity, and so on. These are very basic human experiences and the scaling of these basic human experiences is what helps you produce a dynamic coherence to society. So a society that has sense making does not need to just you know follow the leader's gut feeling - it in fact has something of a shared correctly constructed gut feeling versus one that is to a significant extent very chaotic, oppositional, no premise is followed up by a conclusion, no incorrect premise is ever disproven, you say A on monday - B on tuesday, A is more viral, the virality is rewarded - not the correctness. That's the problem. If you wish to have a somewhat free society the sense making has to be participatory, which means that different levels of society can correct each other, different centers of society can correct each other, and they're even able to find this like commonality of speech and so on. Then there's the question of meaning - how do we evaluate things, do we find meaning in them or do we not find meaning in them, what is motivating us even? The sense of enemy often comes with not just a loss of sense making - there are many people in fact who have fairly coherent world views, they even share these worldviews with others but they're fundamentally depressed, and one of the reasons they're often fundamentally depressed is because of the question "So what?" - you said how it is, tell me how it should be. Or rather "I know how it is but I don't know how it should be". And then finally there's the question of choice making and how are decisions between different possible futures made - again both for individuals and society as a whole. The sort of simple solution is that you have a single center that tries to make decisions. The other alternative is sort of anarchy - there are no real decisions made anywhere, and the ideal coherence is that society builds these decisions together through something like a discourse, something like a deliberative process, where deliberative doesn't just merely mean voting - it goes much beyond voting - it is the shared building of the model of the world and the "what about it" & "so what do we do about it" and finally the details of the implementation." - [Samo Burja](https://youtu.be/bHCg8bhtbqs?t=1530)

> "The example you used was actually of implementing a system of carbon accounting. Tell me: is there any agency in the federal government today that you would trust to implement that system? Is there any organ of the United Nations? Is there even a non-profit organization and is there any hope that such a system could be rationally discussed, optimized, taking into account the considerations of the common citizen, of all relevant groups of society? I think the problem is that to set up a system of carbon accounting you actually first need a system of epistemic accounting - you need the epistemic commons once more to function and the epistemic commons have to function updated to the digital world." - [Samo Burja](https://youtu.be/bHCg8bhtbqs?t=2056)

> "It's one thing to say read a paper on what a North Korean EMP strike might do to America's power grid, it's quite another to evaluate whether the nonprofit that produced that report - are they just producing reports that suggest we should go to war with North Korea? You can't trust just the white paper - you actually have to see what sort of selection effect is at play and if you see - you know - this kind of conflict of interest you have to be careful for subterfuge. The proof might still check out but if a sketchy person is handing you the proof you might want to put extra scrutiny into it." - [Samo Burja](https://youtu.be/bHCg8bhtbqs?t=2417)

> "There's no hope for a tiny country like Estonia to compete with Russia on the dimensions Russia picks, or a tiny island like Taiwan competing with the Chinese mainland on you know whatever dimensions the Chinese mainland picks - they can always build more jet fighters, they can always build more aircraft carriers, they just have 100 times more people - what are you going to do? You have to pursue the asymmetric advantages and because these are both relatively new nations the asymmetric advantages meant integrating digital infrastructure into government, but also integrating digitally native people, staff, talent into government and opening yourself to public discourse as a method of sense-making. You lean into the strength of an open society rather than imitate the strengths of a closed society because if you try to beat China being a close society - well you know it's it's not going to really work out for you especially if China's 100 times larger." - [Samo Burja](https://youtu.be/bHCg8bhtbqs?t=3123)

> "What we did on economics is we took the tiniest slice of human behavior - self-interest - and then we wrapped it with abstract mathematics in the late 1800s. Big chunks of our economic theory has been there ever since. This theory of the self-interested individual wrapped in mathematics is built from the sanctity of the person and personhood and it's kind of all set up to guarantee market equilibrium. It's also over the course of the last hundred+ years a theory that has largely been walled off from other disciplines while growing in influence and in stature and Academia, infecting public policy, business administration, infecting the other social sciences, and even in more recent years affecting the Natural Sciences. When its assumptions are challenged, or when the theory of the rational actor - the self-interested individual - doesn't hold up against other theories or other disciplines, or when the scientific method gets in the way, economists have this very convenient line "it's just a model", or they often quote George Box - the statistician - "All models are wrong, some are useful". I would add one little piece to that: "All models are wrong, some are useful" - I agree - "Useful for whom?" - and that's the big question that we need to ask today." - [Jon David Erickson](https://youtu.be/EC11UQD9q3w?t=369)

> "I don't think our moral compass for the future is very well-developed as human beings because we haven't needed it to get to where we are now. We've needed to worry about the future over the next few days so that we can eat the next few years so that we can raise our kids and maybe we care about our grandchildren. But beyond that, we really just don't deeply care by nature. And that I think is the fundamental problem." - [Sandra Faber](https://youtu.be/04jg5--t8RQ?t=2418)

> "Very deep in human values is the worship of low entropy. Now, what do I mean by low entropy? Entropy is a very elusive question. It's a concept that's hard to explain. But to try to make it as simple as possible, low entropy happens when you develop structure and organization in something. So, I'm looking in my office here, I'm looking around and the air is uniform density everywhere. The molecules have spread out uniformly. That's what entropy wants to do. It wants to increase, it wants to get smooth, it wants to lose its structure, its differentiation. Things basically want to smooth out and lose their organization. An example, drop a teacup. It started by being highly organized with all of its atoms in a particular way. And by the way, it took work to do that. That didn't happen randomly. Somebody had to make that happen or some artificial process. We drop it and the atoms go all over the place and get disorganized and the structure is lost. So that's an increase in entropy. I think human beings intuitively understand that making something out of nothing, getting structure where there was none before is miraculous. And I think that's what we worship and we grieve when that is lost." - [Sandra Faber](https://youtu.be/04jg5--t8RQ?t=2717)

> "I think we need a new religion. I think the religious impulse is very important in human beings and should be put in better service to solve these problems that you and I are talking about today. So I think we have this basic urge to serve a higher purpose. And if we could inculcate people from the very beginning to understand how wonderful Earth is and that our role as human beings, we do have a mission to protect the planet. And at the same time, continue its wonderful story of constantly evolving new and more wondrous things." - [Sandra Faber](https://youtu.be/04jg5--t8RQ?t=2973)

> "One of the things that astronomers are good at is math, and one of the things you learn about in physics is exponential growth... So if everybody could understand exponential growth intuitively, that would be a big step forward to reorienting ourselves to understanding planetary problems." - [Sandra Faber](https://youtu.be/04jg5--t8RQ?t=3602)

> "The other would be I would like to give people the gift, which I feel has been given to me, to have the big picture, to have this understanding of how it all began, how it's evolved, and how we fit in, culminating, and here's the key point, culminating in an understanding of human nature because I think we make a mystery out of human nature. We should be teaching young people where they came from and why they are the way they are and how things are going to work out for them in the future. We just make it a mystery. I would like to change that and make our situation clear." - [Sandra Faber](https://youtu.be/04jg5--t8RQ?t=4848)




> "There are chemical addictions, there are behavioral addictions there. We have both. So, anything that stimulates the nucleus accumbens, anything that stimulates the reward center in the extreme is addictive. So we have chemicals like heroin, cocaine, nicotine, alcohol, sugar. We also have behaviors. We have shopping, gambling, internet gaming, social media, pornography. All of these stimulate the same reward center in the brain. Every one of those has an "aholic" after it. Shopaholics, chocoholic, sexaholic, alcoholic, you pick it. The point is, we have a reward system and it is under fire every day, by not just the food industry, but by virtually any corporate entity, because that's how they get you to buy." - [Robert Lustig](https://youtu.be/onVqjZOYlQs?t=1736)

> "Teach the children. You can do this. This can be done. We are doing this now. Now, there is a problem. It's called time. We have a clock. We have a drop-dead clock. We have a 1.5 centigrade temperature increase on climate beyond which there's the point of no return, and we have to meet it. And, that's the problem. We have to speed this education up. And we're going to have to educate the naysayers too, because we got to fix this problem fast. And that's hard." - [Robert Lustig](https://youtu.be/onVqjZOYlQs?t=4943)

> "Patents were a very important invention in the market, but it's a relatively new invention. It's a bit more than 100 years old and it came from the insight that you can actually speed up technological development if you encourage people to publish their findings, and their inventions. In exchange for making the facts public and putting it in public domain, and allowing other people to build on your ideas instead of keeping them secret, you would be granted a monopoly of use for 10 or 20 years, or something that would be reasonable for you to have the incentive of putting it in a public domain and innovating, but that concept has morphed. Today, of course, when we talk copyrights and patents, we have completely deviated from the idea of having things quickly put in the public domain for reuse and for innovations. For example, when Mickey Mouse was about to celebrate 50 years and fall into the public domain, Disney lobbied to the government to extend copyrights from 50 years to 75 years, and got that. Now, there's even talk now when Mickey Mouse is about to turn 75, that we should extend copyrights into 150 years. Of course, this is just a matter of economic transfer. A market would clear very differently if you had copyrights and patents that would be 10 years, or maximum 20 years, which is really the economic lifetime. If I'm running a corporation and I'm doing an investment calculation, anything today beyond 10 years, definitely beyond 20 years, is discounted to absolutely zero. That does not affect my business decision at all, so it doesn't make any sense to really have any copyrights or patents longer than 20 years. That's just one example of how we have these constitutive rules of the market, that are really the rules that makes the market start working. Then we can have regulations and regulative rules, but we have constitutive rules like what can you own, what can you patent, can you patent human genes? Can you own radio frequencies? Then, the next question is, who can own? That I, as a private individual, can own something, absolutely. But then we have this very strange social innovation like the corporation, that is also not very much more than 100 years old, and are completely dominating the market today. By changing the rules, what can be owned, for how long, for what use, and who can own things, then you can change the constitutive rules of the market, and it could clear completely different." - [Tomas Björkman](https://youtu.be/TJa_6AHjLw0?t=3167)

> "There's no government in the world actually helping you not die. In fact, most of them are enablers of a death economy. They actively allow companies to help you die faster." - [Bryan Johnson](https://youtu.be/PXkhhHPUud4?t=3758)

> "If I could wave a wand, I would have everyone be able to, for just a moment, move beyond the polarization and the partisanship and all the real and imagined differences we have and the voices on both the left and that are exploiting them. And remember that we have two things in common. The first one is we share a common mortality. We're all going to be born, we're all going to die. That's the reality of our existence. And between those two events, we all walk a path, a very individual path, but it goes to the same destination. And I believe in my heart and from my experience, that all of us in our own way want the same things as we walk that path of life. We want to find meaning and purpose and satisfaction. We want to be valued. We want to add value, and we want to all believe that we have an equal opportunity to succeed, to reach our dreams, no guarantee of equal outcomes, but an equitable opportunity to try. If we can remember that, if we can remember those common attributes of being a human being, I don't think there's anything we can't do." - [John Kitzhaber](https://youtu.be/Z4cjl77rj78?t=2807)






> "Pretty much any definition of wisdom that anybody offers usually has restraint as an embedded concept. Wisdom involves what not to do, where you could have personal advantage, where you could have some near term advantage, but it's actually not the right thing to do." - [Daniel Schmachtenberger](https://youtu.be/tmusbHBKW84?t=1109)

> "The, the cancer is not just another cell having its own individual freedom to express itself in a slightly different way, and it should be allowed to have its own individual expression. The other cells, like, there's a difference between the liver cells and the blood cells and the kidney cells and the, they're all different, but they all have a shared genome and they're all working as parts of this larger whole, and they're constrained by that, and that's okay, because they would also die. Like, a kidney outside of a body is not that interesting. It doesn't sustain itself. So all of the cells are constrained by being a part of a body to serve the good of the body. So they get to have individual expression, but they also have interconnectedness and with that an obligation. The cancer cell, it's like, nah, fuck the obligation. I'm going to do my thing and I'm going to actually consume resources faster and replicate faster. And if it does that and metastasizes that idea, right? Then the rest, the rest of the body, the immune system has to kill that thing, or that thing will kill the rest of the system, including itself, including itself, right? And that's the thing is that the cancer cell is having amazing progress at consumption and replication. It's betterment for its own goals. Yes, it's, it's succeeding at its goals. And then the, there are the most number of copies of itself right before it kills the host and kills itself." - [Daniel Schmachtenberger](https://youtu.be/tmusbHBKW84?t=2259)

> "We are the descendants, unavoidably, of the people that scaled empire with all of the ecological harm, warfare, genocide, et cetera. We are genetically and mimetically and culturally the descendants of those processes." - [Daniel Schmachtenberger](https://youtu.be/tmusbHBKW84?t=2424)

> "The first question with progress is progress for whom? And then, then we would say progress of what, across what metrics across what way of assessing what is valuable. And progress that is progress for some that is totally bad for others, but also bad for others that that some depends upon is a very narrow definition of progress. And even like the cancer cell that will eventually kill its own host, it's a definition that is not actually long term even viable for the interest of where the progress seems to have been true." - [Daniel Schmachtenberger](https://youtu.be/tmusbHBKW84?t=2794)

> "We have lots of different global catastrophic risks just in the domain of ecology we're facing, right? We could really mess the biosphere up just because of PFAS, just because of pesticides, just because of mining waste, just because of biodiversity loss, just because of damage to oceans and dead zones and coral. Like we have lots of different, from the extraction side and the pollution side, catastrophic risks that are the result of our success at progress." - [Daniel Schmachtenberger](https://youtu.be/tmusbHBKW84?t=2853)

> "There are lots of times where we actually know the harm something is going to cause, whoever it is, industry, whatever, ahead of time, and do it anyways, cover it up. That's a known thing. There are other times where we just don't try very hard to do an analysis of externalities, because if we put money and resource into looking at, is this going to harm things, and the other competitor doesn't, they're going to get first mover advantage. They're going to later be able to say, we couldn't have possibly known. I, the money that I put into seeing those harms might just tell me not to do the project. And now how do I get a return on that money that I put in? And if it does show me a safer way to do the project, it's probably so much later and with less margins than the other thing. And so at minimum, there's a kind of negligence of if we do due diligence, we do this box checking plausible deniability version, because we know we're going to be able to privatize the gains and socialize the losses." - [Daniel Schmachtenberger](https://youtu.be/tmusbHBKW84?t=3336)

> "A corporation does not, a corporation is a, you can think of it as a cybernetic entity. Right. The, the operating agreements, the legal agreements of what it is, plus its whole operational machinery does not depend on any particular person because you have an org chart. And if you lose this assembly line worker or this chief marketing officer, you replace them with a kind of market equivalent all the way up to a CEO. And so the. Entity is controlled by the cybernetic entity kind of controls itself aligned with these legal operating agreements, not controlled by anybody in particular and recognized as a corporate person. So it protects the directors from legal responsibility of what that corporate person does, even though, of course, it couldn't do it without running on the people. And then you have a fiduciary responsibility to maximize profit, which is a measure of extraction. And so. And of course, that corporate person doesn't have empathy. It cannot. It's not a it's not a sentient thing, right? It is a cybernetic thing, but it's not a sentient thing. So it doesn't have empathy. It does have planning, i. e. Machiavellianism. It does have my own growth should continue forever. And I should be the market dominator. That's narcissism. And so, yes, it is an obligate sociopath. And it is actually legally required to maximize It's, you know, shareholder return on profit by the directors of the organization. So the idea that you cannot possibly anticipate externalities is not true, but it's a useful idea of those who are going to benefit by causing externalities. And the people who benefit by causing externalities because they're privatizing all of the gains to write the narrative in the same way the history was written by the winners of war previously, like it costs a lot of money to affect the narrative of the world. You see this in political campaigns, you see it in marketing campaigns, but if if an idea is spreading, who is writing all that stuff and who's up regulating it and who's paying for the commercials and who's getting the data to do the personalized micro targeted ads and who's, so the ideas that spread are not just spreading through a kind of natural selection of the goodness of the idea, they are getting oftentimes amplified by the media. Interests that want those ideas to spread. Duh, right? We know this. This is how political campaigns work. This is how advertising works. This is how propaganda works. This is how, you know, on and on. This is how religion works, right? There's a lot of money that goes into proselytizing and getting the ideas to spread. So there are a lot of ideas that are marketing and or apologism for the dominant class in terms of power. So the dominant narrative is usually apologism for the dominant power system. In the same way that, like, when we talk about externalities, when Facebook was in its early phases, there were people like, you know, Jared Lanier famously was saying this very publicly, but there were people coming from the McLuhan school and You know, coming from various, coming from the Mumford School who were saying, Hey, look, this technology where you're monetizing people's attention and you're going to race to effectively monetize their attention. And unlike where TV commercials did that, but it was the same for everybody, you now get to have them interact with it to gain personalized info to split test how sticky you monetize their attention. A lot of the things that are going to engage their attention more are going to be limbic hijacks. They're going to be things that make the person scared or horny or distracted or, or in group, out group identity or whatever it is. And this is going to be really bad for society. It's not that no one was saying that then. It was being said, it was being ignored. It was not being studied and researched and pursued because, and then later they get to say, we couldn't have possibly known it was going to polarize society and break democracy and decrease everyone's attention spans. So. The, we couldn't have possibly known as a bullshit story. If you think about does, am I saying that you can anticipate everything? Of course not. But am I saying you can do a million times better than we even attempt to do now? Yes, of course. So in the process of developing a new technology, say, could we proceduralize thinking through the total set of effects, not just the intended set of effects and the market benefits of those, but thinking through if this technology really takes off, And goes to its full scale. What is the pressure of that on all the supply chains to make it? And what is the environmental effects of that? What are the, you know, geopolitical and et cetera effects? What if people use it, is it conferring some power? If so, what other thing is it obsoleting? How will that change power dynamics, et cetera? You just kind of think it through. Now we have a process That we've developed called yellow teaming. Red teaming is, you know, now become pretty famous, which is you're wanting to do something. You want it to succeed. Red teaming is a process you can do to see how it might fail, how somebody could beat it or how it might fail. Yellow teaming is if it succeeds, where might it mess other things up? So could we yellow team? Well, yes, you're not going to predict everything, but you predict a lot of the things, and then you keep watching, and when you notice other things, you procedurally internalize them. Now, in the same way all this was the buildup to the billionaire question, the long buildup, the people in a multipolar trap who are at the front of the race, could stop the multipolar trap, but they don't want to because they believe they can win. So they use the multipolar trap as a story of their own lack of power to do anything else as plausible deniability. The littler guy cannot necessarily stop the multipolar trap, but someone who's at the leading edge of an arms race, if they wanted to apply the same energy and same sophistication to agreements to pursue, because of course, there's a situation that if my country becomes more secure relative to other countries, which means develops better weapons, It automatically makes everyone else less secure. So now they have to do the same thing. And it just means that you have an arms race of increasing weapons forever and increasing budgets going to it forever, which is great for defense contractors. It's actually great for GDP and it's bad for everything else. Now, if we could just say how let's make an agreement to all spend less on weapons, we can be proportionally less. Right. Proportionally less such that relative security changes. Well, of course people say, well, we can't possibly do that. We couldn't get China. We couldn't get Russia. There's no way to enforce it, etc. And we're saying that right now with regard to AI. Well, even if we wanted to stop this thing from advancing that has That accelerates every global catastrophic risk. We couldn't possibly because there's so many places racing and we couldn't stop China and blah, blah, blah. Therefore, the only possible answer is to win the multipolar trap because losing at it is too bad. If you look at the resources we invest in figuring out AI, if we invested those same resources and actually creating healthy diplomacy where we were not assholes to our international Neighbors and really tried to create global coordination to bind the multipolar trap we could. And so the billionaire that says, well, I don't know how to solve the problems of the world, like I'm too small, right in the, it's a hundred trillion dollar economy. I'm almost nothing. I'm this little. Guy, I couldn't solve the problems of the world, therefore me continuing to just pick up all the game theory tokens I can under a world of increasing uncertainty. The optionality of that is what's best for me and my family. Look at how much time you spent figuring out. How to gather all those optionality tokens, understanding markets, understanding how to do lobbying, understanding your industry, understanding financial markets, et cetera. And look at how much time you spent trying to say, if I applied all of that same energy, time, thoughtfulness, resource to solving some of the great problems, could I, you have not put enough time to say that you couldn't possibly, it's just not in your interest." - [Daniel Schmachtenberger](https://youtu.be/tmusbHBKW84?t=3691)

> "The system that emerged in the context of power competition selects for people who are oriented to power competitions and other people who are complicit with it. Those are the two things it selects for." - [Daniel Schmachtenberger](https://youtu.be/tmusbHBKW84?t=4702)

> "I'm being conditioned by the environment I'm in in terms of my language, my worldview, my technological capabilities, desires, identities, all those things. So, so the civilization is conditioning the minds. which means patterns of perception, identity, value, and behavior of the people. And those minds are, in turn, creating more of the types of things that they were conditioned to. And so there is a feedback loop between the individuals influencing the whole, the whole influencing the individuals, and there is a particular thing that is getting upregulated." - [Daniel Schmachtenberger](https://youtu.be/tmusbHBKW84?t=4750)

> "The people at the top of the power law distribution explain the shape of civilization much more than everybody does, and those people don't come from the center of the bell curve of almost any psychological trait." - [Daniel Schmachtenberger](https://youtu.be/tmusbHBKW84?t=5155)

> "So it is this recursion. Now, the people who are in those top positions are not only changing the system to be better for them. They also are obviously invested in that success. So anyone else who would be very successfully doing something that would mess that strategy up, they have a maximum incentive to make sure don't succeed." - [Daniel Schmachtenberger](https://youtu.be/tmusbHBKW84?t=5348)

> "Very famously in the Nuremberg trials of Nazis after World War II, when the Nazis were being tried for the war crimes, and they were all asked, did you believe that everything you were doing was good? About 90 percent of the Nazis said, Only at first. At first, we were, you know, we had been in terrible poverty in the Weimar Republic. Our kids couldn't eat and, you know, etc. The Jews had all this wealth. And, you know, we, we believed that we were getting supported to be able to, you know, do well for our people and whatever. But as time went on, like, no, we did not feel good about putting kids in gas chambers. And we didn't feel good about seeing them starving. Like we felt really bad about it. Like 90 percent of the Nazis said, no, I did not feel good about it. And then when they were asked, did you try to stop it? They all said no. And then they quoted the same German phrase that translates to officer's orders. I didn't have a choice. And Yet, of course, if 90 percent of them had all said that simultaneously, which is a coordination failure here on their part, there would have been no holocaust. But anyone on their own is like, if I try to defect, I'll get thrown in the gas chamber, too. So it's best for me and my family to just go along with it. It's kind of a gruesome microcosm of what we face on so many levels today. Yes. And so the Ash conformity studies and the Milgram studies were so important. And I think actually under represent how deep those principles are, right? The, the idea that when the authority was telling the person, the scientific authority, Hey, you're in a study, do this thing. And we're doing electroshock therapy, whatever, that the person following authority would shock the other guy to death. Because of, I don't have a choice, the authority is telling me. Or in the other one, in the Ash ones, that if 10 people in the room were all saying this line is longer than that line, the person would defect on their own understanding to go along with that. These are very powerful insights. " - [Daniel Schmachtenberger](https://youtu.be/tmusbHBKW84?t=5736)

> "I want real progress. I think it's a, it's a very important thing to see that we can grow and that we can add our life energy. to the world in a meaningful way. And this is why really thinking about what would constitute actual progress, that the world is better as a result of us having done this. Better, the world, not my tiny world, not better in this metric, but the world long term. Thinking seven generations ahead." - [Daniel Schmachtenberger](https://youtu.be/tmusbHBKW84?t=6124)

> "The idea of [Ubuntu](https://en.wikipedia.org/wiki/Ubuntu_philosophy), I am because we are, It was this foundational concept of human beings before the thing we call civilization, right? I Am Because We Are was, like, just at the most prosaic level, nature did not select for individual sapiens. It only selected for groups of sapiens. Individual sapiens in evolutionary environments were all dead. And so what's best for me that fucks the tribe is not a concept. That's not a thing, right? What is best for the tribe that I can't exist without of? I am because we are, I would not exist. I'd be dead without all of us. That's like the basic insight. So I am, because we are obviously just starts with, I couldn't survive without us. But then it's also deeper, which is I think in words that I didn't invent. that all these other people invented. And, but my own most intimate thing, my thoughts with myself are in a language that I didn't make. I am, my, my thoughts were made by other people, right? The, the, the language of my thoughts, my understanding of the world was transmitted to me largely by other people. The tools that I use, the things that I benefit from, the, all of that, that I am, almost all the things I think of as I am, because we are, right? Because of things that were created. And it goes deeper, because the we was never, never just meant our tribe. It also meant nature. the extension to all our relationships, and all our relationships was all life, and life didn't just mean biological, which is why they were animistic. Those cultures were all animistic. The spirit of the sun, the spirit of the river, the spirit of everything, because it was a very clear understanding. What would I be without the tribe? I'd be dead. What would I be without the sun? I would have never existed. What would I be without the galactic center around which the sun orbits? I wouldn't exist. What would I be without the gravitational field? What would I be without the soil microbes? What would I be without plants? What would I be without all of that? I wouldn't be. So, I, that is not the emergent property of we, isn't even a thing. It's not even thinking." - [Daniel Schmachtenberger](https://youtu.be/tmusbHBKW84?t=6699)

> "So to steward that much goal achieving power, we must meet it with what are good goals. What is actually progress? What is worth maintaining? What is worth for sure protecting and maintaining? What do what should be reversed that already harmed things where the actual progress would come from reversing Some of the stuff, not just making more new stuff." - [Daniel Schmachtenberger](https://youtu.be/tmusbHBKW84?t=7544)

> "So there's this quote from General Smedley Butler. And he called war is a racket. It's very famous. I'll read just the beginning. It's long and people can go check it out. And, you know, I'm assuming people know what a racket is. Racket is like a classic example is a protection racket where a gang will come Rough up a store. So the store thinks that they need protection and the police aren't protecting them. And then other members of that same gang come offer them security services for sale. And so they are protecting them from themselves for a fee. So they are basically manufacturing the demand and then offering the supply. The amount, if you, if you look at How much of our modern market and market government system meets the criteria of creating a problem that's a result of some part of market or technology that some other part of market and technology will come to solve, that will then simultaneously create new problems. The whole thing being a racket is actually a very But with that definition of a racket, what he says here is war is a racket. It always has been. It is possibly the oldest, easily the most profitable, surely the most vicious. It is the only one international in scope. That's not true anymore. He wrote this in like 18. 81. Oh no, 19 something. It's the only one which in which the profits are reckoned in dollars and the losses are in lives. Racket is best described, I believe, as something that is not what it seems to the majority of the people. Only a small inside group knows what it's really about. It's conducted for the benefit of the very few at the expense of the very many. Out of war, a few people always make huge fortunes." - [Daniel Schmachtenberger](https://youtu.be/tmusbHBKW84?t=7621)

> "So there's a lot of perverse asymmetries like that, like those who pay more attention to the risks of a technology up front won't win the technological race and first mover advantage is those who pretend that it isn't there or cover it up and make narratives about how positive it is and scale it rapidly. Ultimately, we have to overcome all of those perverse asymmetries." - [Daniel Schmachtenberger](https://youtu.be/tmusbHBKW84?t=9493)

> "We can expand our capacity for wisdom as much as we expanded for intelligence. We can expand the scope of our considerations of what a good goal is as much as we expand our goal achieving. What I'm saying is we must. Now you're asking, is there a cultural thing that has to happen? Yes, obviously our culture, as we already said, is being an Shaped by our tools and by our social systems. So our, our superstructure, our culture, our value systems, our social structures, our economies and governance systems and institutions, and our infrastructure, our tool set are all co influencing each other. All three of them are confluence co influencing each other. So obviously we can't, as you, as you saw when you were in India, you change your environment and something that no amount of moralizing yourself to do would ever work. It was automatic in a different environment. And so can we achieve cultural change by just moralizing people that they should culturally change while they're still in the environment that is predisposing the culture that is here? No, that's not going to work that well. At the same time, where is the intervention point is some people who already recognize that that's not a culture they value enough. They recognize the fail of it. They meditate on meaningfulness enough that they actually stop willing to be complicit with it. And not just to remove themselves, which is a step, which some people do, but to say, how do I dedicate my life energy to changing those dynamics, which should then entail a study of change efforts that were well motivated and failed. And or made worse problem so as to not repeat that to try to understand why that happens to understand what change that would change all that could actually would require and what it would be like now, of course, to really change culture at scale, we have to change the two Technology and what it predisposes, right? We have to change the social systems. As long as you have an economic system where putting the externalities are externalized and cost, then I can't empathize and take, want to take responsibility for all the harm that I'm causing if I'm competing against someone who's not internalizing those costs, like economically, you can't, that you're economically incentivizing sociopathy. Through the cost externality. So of course that has to change. And of course as that changes, that makes possible a different value set. And the same way that like the algorithm on Facebook could upregulate for different things, it could upregulate for exposing people to different worldviews and different ideas and paying attention to only upregulating the ideas that drive common unity rather than, you know, division. So those are places where culture's affected by technology and social system. But how does it start? It has to start with a culture first recognition of the I am because we are. The version of progress that is good for I, that is not for we is actually not real progress. I, I remove myself from that thing. I won't participate in the lie of it. And I will dedicate myself to wanting to understand. What is, what actually be good for the whole and make sure my life energy is in service to that and then progressively that I am participating in things that have more agency to be able to affect that?" - [Daniel Schmachtenberger](https://youtu.be/tmusbHBKW84?t=9580)

> "We did talk about restraint. And then we talked about if someone wants to do the thing that is more like a cancer cell or more like cause tribal warfare, they're not going to be the ones to restrain themselves from doing it. Other people will have to. That is something like law. Right. That is something like imposition. And so then we are right to consider how those systems have went in the past. And because using force to curtail someone's liberty has its own problems, even if what they're wanting to do with their liberty has problems. And that's already in, in the zeitgeist right now. A lot of people are worried that climate change is such a thing that will cause people to eat bugs and not own anything and all kinds of authoritarian rules. Yeah, and I think if the people who were talking about the eating bugs are the solution and not owning anything were themselves not major capital owners who were not applying those things to themselves, people might feel a little better about it. But like, The dude that is a hunter gatherer and he eats a lot of crickets and grubs. And if he says like, bugs are good, like nobody's freaked out about that. They're freaked out about a situation of radical wealth inequality and class warfare and the class warfare telling more stories of justifying radical inequality as the, you know, as a solution while they have the largest carbon footprints themselves. So like understandable, right? So the thing that I want to say is. The, you, you introduced me to her Vanessa Andrade, who you had on the show, who I had a conversation with and thought she was amazing and really respect it's in her book. She said that her the chief of her tribe, the, his definition of colonialism, she probably said that on your show, but I'll bring it up is that colonialism was not about taking other people's land, fundamentally, or about abuse of land or abuse of people or anything, that those were epiphenomena, that the core of it was believing there are separable things. And you can say even deeper than that is being conditioned to perceive the world as a bunch of separable things. Which is what Bohm said was the underlying cause of all the problems, which is what Krishnamurti said was the cause of all the problems, which is what Einstein said. So if I believe there's a bunch of separable things and I'm separate from other things, then I can optimize some things at the expense of other things. And then I can actually rationalize that everything is trade offs and that's how it is and etc. And, you know, then reify social Darwinism and nonsense like that. So the root One could say that the root of the issues is if people want things that inevitably cause harm to others. That's the root of the problems. Either because they know it causes harm and they want it anyway, so it's some kind of, you know, rivalry or sociopathy or something like that. Or because they don't know it causes harm and it's from, you know, ignorance and externality. They just want what they want and they're not thinking about what all the cause and effect would be. Because if you then say, great, let's let the, let's let people pursue what they want. And what they pursue getting causes harm and then also creates propagating patterns where to protect themselves against the harm that other people have to do similar competitive things and blah, blah, blah. And you have a world defined by arms races. But if the other answer is don't let the people pursue what they want, use some kind of enlightened law that says that's bad and prevent it by force, the oppression is inherently also bad. And the asymmetry of. force tends to lead to an increasing corruption of the power stack. And so neither of those are good. So as long as humans believe that they are separate from everything else, as long as they perceive the world separately, you were mentioning language earlier. And I think similarly, Vanessa was telling you that English has like 70 percent of the words are nouns and most indigenous languages, very small percentage of the words are nouns. You look at Whitehead as one of the kind of great philosophers of 20th century. And the reason he came to process philosophy is he's like, there's no things like the things that we think of as things are processes of interaction of other things, right? A tree is not a static noun. It's the doing trillions of metabolic functions every second. It's interacting. biophysically, with the sun and the air, it's interacting biochemically, it's interacting biologically, doing gene transfer with the fungus on its roots and the soil microbes, like the tree is in a live process. It's a verb. It's lots of verbs. And the idea that it's a noun just makes us think very poorly, makes us very bad thinkers. And the fact that we're thinking in nouns all the time and built into our language is making us bad thinkers at scale that we don't even realize because we don't know what it's like to have a language that doesn't see the world as a bunch of nouns that are all separate." - [Daniel Schmachtenberger](https://youtu.be/tmusbHBKW84?t=9834)

> "Currently, The rates of growth of the things that are moving in the authentic progress direction versus the narrow progress harm externalizing direction are not adequate. Right. And like I said, many of the things and everybody that is contributing to the meta crisis thinks that they are contributing to real progress. Right. I'm, I'm providing a product or service that the market wants, which means there's demand for it, which means it's increasing. It's solving some problem for someone that makes their life better. And I'm employing the tools of science and technology, which is this awesome system that allows us to understand the world in a unified way and improve things. And like, that's, that's The story. So it's like the, and that's why people can come out in such defensive fossil fuels of look at all the things they give us. And you know, and of the market and, and they do, and they give all of these externalities. And while that has benefited some and sucked for others, it also benefits some dimensions of self and sucks for the dimensions of self, even for those most being benefited. And it is in the process of self terminating where it will be a benefit to nobody. No one. In which case, the, damn, I really don't want to be complicit with that thing. Damn, I really don't want to just, what's best for me and my family is continue to have optionality tokens. And damn, I don't want to try to make things better where I end up making them worse because I am coming from the same type of mind that engages in rivalry and cause, does a movement in a way that creates counter movements and that optimizes for one thing in a way that ends up causing harm elsewhere. So I want. That the activism, the protection impulse in me reconnects to the source of reality deeply enough that I know how to participate, that I'm guided in how to participate in a way that is actually meaningful. So I would actually like to see a slightly slower movement into action, a deeper movement into withdrawal, and a deeper understanding of the history of well intended failed actions more rigorously, it's very painful, and a deeper being with the emotions about the whole thing and really taking it all in and noticing how much of our desire to make it better is still ego, is still um, An avoidance mechanism for not wanting to feel it is still a problem solving mode that is reductionistic that will end up contributing to it and like letting that stuff settle to get to a place where one can engage in how to shift the system dynamics of the world in a way that are actually what's needed." - [Daniel Schmachtenberger](https://youtu.be/tmusbHBKW84?t=11570)

> "If you really care about climate change, you're probably pretty depressed. And the hope doesn't look that good. And any kind of hope. So it's like, why is the Jesus is going to come save us all narrative compelling for some people? Why is the maybe the UAPs that we're seeing are benevolent aliens and they'll save us all compelling? AI is another version of that. Like we're, There's no good sign that the answer is going to come from us. We seem pretty intractably fucked. Maybe something radically smarter than us can solve all the stuff, which is, of course, kind of like a regress to a childhood psyche, still wanting a parent who's going to kind of figure it out. So AI does a very believable job of that currently for some people." - [Daniel Schmachtenberger](https://youtu.be/1NFuddEAi5s?t=1059)

> "It is one of the nonsense things countries will do is kind of export their madness elsewhere and pretend that their country metrics are awesome. And so, but that is like, that's just statistical warfare. Like, it's just, goofy, right? and, We've talked about this before, but like you can't say the Gini coefficient is good. We don't have many people in extreme poverty, but we import shit from countries that are made by slave labor and not include that in your Gini coefficient when your supply, your country doesn't make the stuff it needs to survive. And so Gini coefficient only is a real thing if you do partial attribution analysis globally of your entire supply chain that you depend upon." - [Daniel Schmachtenberger](https://youtu.be/1NFuddEAi5s?t=3381)

> "Which is the first scientific paper on climate change was published in 1938. Climate change has had so much attention from so many significant scientists, powerful thinkers, obviously, like a vice president of the United States of America, like most powerful country in the world took it on as his main jam after being elected Vice President, and got everybody's attention on it. International agreements have been made. The United Nations Environmental Program was made over 50 years ago to get all the countries of the world to work together on global commons issues. And like, there are trillions of dollars in climate funding. That are allocated. There are, you know, intergovernmental organizations that just work on this. There's support from NASA and NOAA and super powerful technological orgs, and yet, pretty much every single year fossil fuels has gone up. Like, and the couple little dips have nothing to do with environmentalism. Right? Like the couple of dips have do it. They're recessions. recessions. COVID for a second. And it's like, okay, so, that's enlightening. So in a way we can say, if we just looked at the curve of like solar panel go up, we say, look, we're succeeding. But if you look at fossil fuel use go up, you're like, 100 percent of all the activity that has been done has not even slowed fossil fuel use. It's been reduced. It hasn't even made the curve inflected down, right? And it has to obviously stop it and then reverse total energy needs and, you know, stuff like that. So why this is helpful is to say, okay, we're actually not on track. let's not like take bullshit narratives that somebody sells to inspire people that we're not on track and the totality of the approaches we've employed so far will never get on track. They're not converging. What would it take? One of the things it would take is as long as I can invest a dollar and get more than a dollar back. Or invest a jewel of energy and get more than a jewel of energy back, there is an incentive to do so, right? Anytime there's a return on investment of something that has, adaptive advantage to have, you're, there's an incentive to do it. So, If we make renewable energy, it's like, great, there's more energy. We need energy for everything. Energy corresponds so very closely to dollars. We want more dollars. That doesn't mean we stop using the coal energy and the natural gas and the oil and everything else. It just means more energy. We use all of it. and now actually we have more energy to advance the AIs to learn how to oil exploit faster. And so if we had something instead that was like. Every time a new megawatt of renewable was created, a megawatt of hydrocarbon had to be shut down and there was international agreements to ensure that they were not created again, right? Like something like that, which is a legal binding of the Jevons Paradox associated with the transformation from more toxic to less toxic industries and or movements and efficiency, you get a, you know, increase in efficiency somewhere and you have a legal binding that says that those gains don't get reinvested into more total use, but actually keep the overall domain at the same size and just use less stuff. **NATE:** But that wouldn't work unless we changed our cultural objectives. Cause if we still wanted to maintain this 19 terawatt global metabolism, we could not physically swap those out because it wouldn't work. So we could only swap them out if there was some, you know, agreement to use less and maybe different aspirations. **DANIEL:** So notice what we just did. We were talking about trying to deal with climate change just through tech, more efficient tech, renewable energy. Realized, nope, you actually, and that's infrastructure. And we said, no, you have to go up to social structure. You have to actually change the economic incentives and law. And then you went up to superstructure and said, actually, you have to change the culture of what is it people value that is the basis of what could get codified into law. Yes, it takes superstructure, social structure and infrastructure altogether. And the idea that there is a technological solution that does not also require legal bindings, changes in economics and changes in culture and values, like, no, the technology plays a role, but it only plays a meaningful role as a part of that integrated suite of things." - [Daniel Schmachtenberger](https://youtu.be/1NFuddEAi5s?t=3458)

> "So if we take a look at fusion, the big fusion companies have given dates by which they would have a viable plant and the dates keep getting pushed back. To what? right now, 2030, but who knows what the next pushback will be. Right. And so, if you got the first viable one by then, which there's no reason to have a high confidence in, how long it would take to scale them to replace the existing energy, is a very long time. And yet, the timelines we're looking at crossing irreversible tipping points on planetary boundaries is less time than that. So the timeline on planetary boundaries creates a constraint where it's like, okay, well, if we get that thing, awesome, but that does not solve any of the timely stuff we need to do. And if on the race to get that thing, we're actually using up the environment faster, then that's, that is misguided. And I would say there's a very similar argument for We might not make it here. We're messing this biosphere up. And by the way, eventually the sun's going to take this place out. We have to become an interplanetary species. So let's really focus on the space tech to become an interplanetary species. We're not close. We're not that close. Like, realistically, humans and microgravity not a thing, right? Like that's not going to go well, which is why the actual pursuit of people being able to live in microgravity situations, the exobiology of it is human consciousness uploaded to AI systems that can do fine with it, assuming we get there, or genetically engineered humans that can do microgravity, like this all, who knows? But O'Neill cylinders, where you can actually get one gravity? We're not close. We're not close to putting a lot of the people there. So the idea that, like, maybe our stand isn't here, we can make our stand in space because of the issues here. Nonsense. Like, and if we mess this place up more to say, let's take as many of the resources as we can to get to outer space. No, we have to actually get it right here first. And if we get it right here, then maybe we can export that beyond the planet." - [Daniel Schmachtenberger](https://youtu.be/1NFuddEAi5s?t=3849)

> "What that says is it's not like we pay most of the cost and we externalize a little bit. no, the default nature of the economy is that the only cost we pay for is the cost. We absolutely have to like what we actually have to pay the people and the tech to extract. The thing is, the only cost we pay 100 percent of the rest of the costs are externalized. And so sometimes it's like, and PFOS is not actually a very big industry. It serves big industries, but it was like 30 or 40 billion a year. And yet it would take 16 trillion a year to clean up the mess of it. And you're like, Oh, this is not like it externalizes a little bit of its costs. This is like it's orders of magnitude upside down if you actually had to pay the costs. Right? So in that market dynamic, AI applied to the materials economy means that with the Incentive to continue to externalize all the things that you can means just accelerating everything we have. And everything that we have is more pollution per year and more species extinction per year and more unrenewable resource per year already passing planetary tipping points. And this is just more market efficiency on all of the market dynamics that did that just accelerates it." - [Daniel Schmachtenberger](https://youtu.be/1NFuddEAi5s?t=4224)

> "So the question wasn't, did we do a thing that like moved awareness for a moment? It's, are there more forces moving awareness in one direction ongoingly relative to the other one?" - [Daniel Schmachtenberger](https://youtu.be/1NFuddEAi5s?t=5395)

> "So the precautionary principle says, and is really the right principle to apply here. If there is really significant uncertainty and radical consequentiality in that space and irreversibility of the consequences, then the burden of proof goes on proving safety. And that has to happen first to really get the approval to move forward with the thing. That's not the world. That would be a completely different approach to regulation, tech design, et cetera. But I would, I will say, if we do not get that, I don't think we make it." - [Daniel Schmachtenberger](https://youtu.be/1NFuddEAi5s?t=5571)

> "How much money goes into arms races? A lot. How much goes into really trying to figure out how to bind arms races? Almost none." - [Daniel Schmachtenberger](https://youtu.be/1NFuddEAi5s?t=5768)

> "The need for belonging and the need for security and the need for esteem are all getting hijacked. Getting turned into political warfare in a way that is useful for political parties and people who want to sell their wares and whatever else it is. But those are all the one-marshmallow reward circuits of like, wait, did I actually read all of the literature on climate change in-depth or on vaccines or on whatever it is and really come to sense about this on my own or did I get a sense of certainty really prematurely and really kind of handed to me? Daniel Schmachtenberger: Similarly, when you're saying what are the skills underneath it, I think the skill of... The quality of earnestness in our desire to understand the reality we live in and the earnestness associated with a pure desire for clear understanding as well as a desire to be effective. And the recognition that, if my map is wrong, I'm not going to navigate well, especially if I am falsely certain. And then the willingness to sit in uncertainty for a lot longer. The willingness to not be part of an in-group that is certain. The willingness to let go of the moral righteous superiority and to sit in the uncertainty of that so that I can, without bias, actually come to make progressively better sense of the world. And then to still never get certain because there's always more stuff that I don't even know that I don't know that's going to continue to- Nate Hagens: But isn't that a really high bar? To reject certainty and sit with uncertainty and sit outside of your in-group? Isn't that a rare human that can do that? Daniel Schmachtenberger: Statistically rare in the current environment? Yes. Requiring genetics everybody doesn't have? No. Now, we could say that's not possible for everybody, in which case we should say democracy is no longer relevant. We should get rid of democracy because having a bunch of people that are falsely certain, and angrily righteous about it, trying to do some system of open governance is obviously not going to work well, in which case we should find a small number of people and make them the new nobility. That's the Chinese answer, right? In the current environment. There are other groups that are working on that. If you want an open society where everyone gets to participate in choice-making, then everybody has to do a good job of sense-making. To do a good job of sense-making and meaning-making. What is really meaningful here and what is really going on here? If you want anything like a democratic or open society, the minimum required investment is authentic, deep informed-ness about the nature of the issues, which also requires adequate educated-ness to be capable of that." - [Daniel Schmachtenberger](https://youtu.be/kTFqnPEyweE?t=1300)

> "Can you fix the environment without understanding industry and infrastructure and economics and human political theory? It's all deeply connected. When you decompose it and you try to solve the problems in isolation, you end up just moving the problem somewhere else. And so the need for... Of course, no one person can understand everything, but they can seek to understand in a way that has more cognizance of the depth of interconnectedness. That's the only way to be able to do something like any degree of specialization that is not itself part of the problem." - [Daniel Schmachtenberger](https://youtu.be/kTFqnPEyweE?t=1636)

> "If you would have somebody on your team put in the show notes the conversations between David Bohm and Krishnamurti, the link to that... Some of the most beautiful things ever recorded on video that I watched and influenced me growing up. They were in this very deep inquiry about what is the fundamental nature of the problems in the world and what is the fundamental nature of human conflict and poor human choices. They both shared really insightful frames on it. Krishnamurti's was... He said the highest stage of intelligence is to observe without evaluation, meaning we actually don't see the world. We see the world through the very limited lens through which we meaning-make it. If you can see the world, if you can sense more deeply, then you can do better sense making. But I can't sense-make stuff I didn't even take in and I'm not going to take it in if I'm pushing it through filters too quickly. So, that's very relevant, but I'm actually going to emphasize the one Bohm shared here. Bohm said the fundamental cause of all the problems in the world, environmental war all the way down to family conflict, is what he called a fragmented consciousness. He talked about wholeness and the implicate order. Because remember. He studied with Einstein. Einstein said it's an optical delusion of consciousness to believe there are separate things. There is, in reality, one thing we call universe. It's such a deep thing to think about what Einstein was saying because it's like, I think of myself as a separate human a lot of times, but what am I without the Sun? I don't exist at all. What am I without the electromagnetic field? I don't exist. What am I without the higgs boson? I don't exist. What am I without plants or algae or the biosphere or the ozone layer. Me as a separate thing is actually a misnomer. It doesn't even exist. It's what Einstein called a delusion of consciousness to believe that there are parts that... Just because there's distinction, we think they're separable. And they're not separable. Then, of course, in that delusion, we can try to optimize for a part at the expense of something else, either on purpose or without knowing it, and we cause a lot of problems. If you do it without knowing it, we call it mistake theory and externalities. If you do it intentionally, we call it conflict theory. War, oppression, whatever. So, David Bohm said the underlying cause of all the problems is not perceiving from wholeness first. And it's so true that the generator function of the generator function, the deepest thing, starts there. Which is, if you think about it in terms of I can try to benefit myself in the moment at the expense of my future self, that's the one-marshmallow activities. But that's the connection to my temporally momentary self and not to the wholeness of myself across time. And so the addictive hit in the moment that messes up my future life is a theory of trade offs based on not actually seeing the wholeness of myself across time. Daniel Schmachtenberger: I can try to benefit one part of myself at the expense of another part, which is all of our internal conflicts, or myself relative to someone else, advantaging myself relative to them is traditional conflict, or I try to advantage somebody else at my own expense, martyring and co-dependence, which ends up creating resentment and passive aggressiveness and problems, or my in-group relative to an in-group or my species relative to the biosphere. When you recognize the interconnectedness, you see that all of those are short-term pump and dumps. And that, if you see the interconnectivity of the whole thing, none of those parts can authentically and enduringly be optimized independent of all the other ones. We can get into how we do this systems framing, and we should, but I hold, in terms of the deepest way to look at it, is that particular pattern of perception and identity." - [Daniel Schmachtenberger](https://youtu.be/kTFqnPEyweE?t=2085)

> "It's said by many Vedic philosophers that the Bhagavad Gita, the great kind of scripture, one of them, of Hinduism, chapter two, verse 48 is fundamental. Established in yoga. Perform action. Yoga means union with all that is, "yogastha kuru karmani" is the quote. And it says, "Established in yoga, or union with all that is, from the place where you recognize that your existence doesn't exist without everything else and from the place where you cognitively but also experientially get that, where there's an intimacy with all life, and act from there. Spontaneous right action emerges from that place." When, in the Bible, it says, "Seek ye first the kingdom and all these things shall be added on to you," the place at which everything is sons and daughters of the same reality, the place at which there is a sense of the sacredness of all life in the union with it, then right action starts to be informed from there. I do think it is a different orientation from which sense-making and meaning-making happen differently and inform choice-making differently." - [Daniel Schmachtenberger](https://youtu.be/kTFqnPEyweE?t=2385)

> "And so I would love if the people who are really concerned about the world issues would recognize that they end up having the same premature certainty biases that the optimists have on the other side. That the Trump supporters and anti-Trumpers have. And that it's a lack of a certain kind of cognitive, emotional, spiritual maturity needed to just keep sitting with the uncertainty of maybe it's all catastrophic, but maybe it isn't. And if maybe it isn't, maybe there's shit you really should do and maybe you don't know what the right thing to do is. That's actually harder than just saying, wow, it's all fucked. I'm just going to be one of the mature people who accepts it. It's harder to be like, I actually don't know. And so I'm obligated to work on it as best I can in the presence of still not knowing." - [Daniel Schmachtenberger](https://youtu.be/kTFqnPEyweE?t=3575)

> "He was saying there's a kind of pre-tragic optimism that people will have, where they have ideals that have not yet been shattered on the reality of the world. We call it naivete. And then there's the encountering the tragedy of the world and having the ideals shatter and there's a cynicism that can emerge there. Daniel Schmachtenberger: And then there is a post-tragic place that is committed to being in service to the sacredness of life whether you can succeed or not. It's still the right way to... It's still the right hill to die on. That doesn't even need the certainty of success to have it be the right sacred thing to be living that way. And then that also realizes that there is a false certainty of the tragic place. Just like there was a false certainty of the naive place. And that the universe is much bigger than both of those false certainties. And so then it says, cognizant of all the tragedy and cognizant of all the reason to be cynical and holding that, we're still going to look for solutions and still also operate with the sacredness of life at the center. I think that's the task. Daniel Schmachtenberger: It's so interesting because you and I both know we could solve all of these things, make an economic system that doesn't have an embedded growth obligation and closed-loop materials economy powered by regenerative energy and overcome war and bind AI and biotech, and then a solar flare just takes us all out in a way that we can't control for shit. And so there is something about just sitting also with the fragility and the impermanence of the whole thing that we just have to hold. When people think about how thin the crust of the Earth is, it's like a ball of lava with a little bitty boat of a thin crust and a tiny, thin atmosphere in a bunch of vacuum outer space right next to a sun that can do solar flares. You're like, we're here at all. We're here at all. That's amazing. Who knows for how long it will be? How do we both serve the continuation of life and be with the profundity and beauty of it in its fragility at the same time?" - [Daniel Schmachtenberger](https://youtu.be/kTFqnPEyweE?t=3986)

> " Some of the primary frames that people are related to in from the larger systems that have developed is they're seen as consumers or customers in the market and they are seen as voters, if they're in the US or another democratic country, for the state. They're going to buy a product or not buy a product. They're going to vote yes or no on a proposition or vote for this candidate or that. It's an extremely constrained set of choices that doesn't require them being creative or them understanding well. It's a supply side forcing, it's an institutional forcing, of the choice to be very constrained. So, of course, people have been conditioned that way for so long that they don't even realize that they're just being conditioned that way and that it's not really deep or authentic choice. And so, of course, if we're trying to get people to vote for us rather than the other guy or buy our product because our company is going to solve the industry's problem or whatever it is, we don't have to get them to make sense well. In fact, we actually just want to give them quick certainty and outrage to both join our side and get other people to join our side. We'll do the sense-making for you. Neither you or I are trying to do that. We're not saying go vote for a specific party or a specific proposition or go purchase a thing. We're saying there is a deeper way of being able to make sense of how what seems like a lot of different issues in the world are interconnected, where understanding that gives us a different possibility space with which to think about how to forward. So, it's not oriented to immediate political action in the same way. That doesn't mean that it's not oriented to action, but in a different way. In a deeper way. But it is also much more two-marshmallow. It requires a lot more of the people. And so a couple things I want to say in terms of where we go next time when we're sharing cognitive models about what about the relationship between our infrastructure and our social structures and our cultures and worldview or superstructure and the biosphere and the nature of the exponential curves and technology... What about those things causes which kinds of problems and what would necessary and sufficient design criteria of a better economic system or a better supply chain or a better culture, educational system, or legal system look like? We have to figure that stuff out. Everything that we've talked about today that we didn't intend to talk about is from where we approach figuring those things out. Where it's not against the bad guys. It is for the thriving of life. It's not premature certainty of either the naive possibility or the cynical impossibility, but something that has been through both of those and holds a deeper humility about how much is in the unknown unknowns set, including possible solutions. It's a place that doesn't think that we get real security on a little planet with a thin biosphere floating next to a sun that does coronal mass ejections. We just don't get that thing. There is a different emotional way of relating, where the driver of all of it is the prima facie, the inherent sacredness of life that happens when you chill the fuck out over all the other agendas and disconnects and are just present with it. Those are the places where, if you come from there, the sense-making and the activity is differently motivated and differently informed. Now, understanding the models is still really important. This is heart, will, mind all working together. It's pretty easy to see that any two of those three don't work. You get mind and heart and no will and you get really smart, caring academics who feel broken and hopeless at the impossibility of the world. You get heart and will without deep mental frames and you get activists who are willing to go put their life at risk to chain themselves to a boat or whatever, but they don't know how to think through strategy at the scope of what has to change. You put will and mind together but without heart where there's narrow value systems and you get the kind of sociopathic rule that currently runs the world. That knows how to be highly strategic, knows how to be highly agentic, but to serve some narrow interest at the expense of somebody else. It takes all three of those together. And so what we're going to be talking about next time is some of the strategic frames or the theoretical frames that inform better strategy. And not a specific strategy, but a kind of meta-strategy. Meaning in whatever domain one happens to be working in as the situation changes. That's where the theoretical frameworks come in. I think it was Bertrand Russell... I don't remember... Who said something to the effect of, if the only value of knowledge was its immediate, clear utility, then mechanics would be the only thing really worth studying. The reason one studies philosophy is not so much what you immediately do with it but what it can do to you. What it can do to you in the way that you relate to all information and all situations from a deeper place. So, some of the philosophic inquiry that we go into is not that someone now knows, okay, now I know how to fix climate change or the American democracy or Facebook. It's, now, I'm perceiving the world with more nuance and more complexity and from a different place, whereby maybe the local PTA issue that I'm about to deal with, I'll have new insights on. All the things still needed tending. All the local things need tending. There will be some people who are listening who are institutional... who work at major institutions, who are oriented to how do we change the financial system and legal system and regulate tech. Most of the people won't be working in those domains, but that doesn't mean that it's irrelevant to understand the world we live in better. There's a relevance to have a better understanding of the world even if you don't know what to do with it exactly because it can help you perceive differently the situations that you're in and where you can do something with it. So, when we get into these frameworks next time, it's not to give certainty about catastrophe. It's to understand the principles that are driving it well enough that you can see applications of them in all kinds of domains, think about those domains better, and start to get a sense of what adequate solutions at scale might entail." - [Daniel Schmachtenberger](https://youtu.be/kTFqnPEyweE?t=4202)

> "There is this generalized [Jevons paradox](https://en.wikipedia.org/wiki/Jevons_paradox) that when anything that is relevant for the market as a whole gets cheaper the market as a whole grows and so you have that kind of boomerang on efficiency not just on energy but kind of writ large and that's an important part of understanding maximum power principle." - [Daniel Schmachtenberger](https://youtu.be/Nkv5mpBA8o4?t=6244)

> "Let's take cigarettes or mothers against drunkdriving and seat belts or HFCs CFCs in ozone, we could give plenty of examples, but it'strue that we have not... that we don't have a history where we've never solved anythingthat matters, ecologically or socially. There are some times where people out of concernfor the commons have went against some profit stream and actually won a thing, but theyare different in kind than what we're facing now and I want to point out where they'redifferent in kind. Nate Hagens:And different in scale, but go on. Daniel Schmachtenberger:They're different in scale and different in kind in a way that's connected. So if we look at cigarettes, and four outof five doctors choose camel cigarettes, we obviously haven't gotten rid of cigarettes,but we've made it to where you have to be 18 to buy them and they have to have a surgeongeneral's warning that this will kill you before you use it and we've definitely decreaseda total number of people that use cigarettes and they can't use them in the buildings andstuff. That took a lot of work. A lot of people died of lung cancer and secondhandlung cancer first, et cetera for a vested interest profit stream that knew it was wrongfrom well before it was regulated. But the sale of tobacco, as big a deal asit was, was not at... it was not the engine of creation for the economy as a whole. It was one sector of the economy, it was oneproduct. When we're talking about climate change, asyou focus on, there are no industries that don't need energy. There is no such thing as even the possibilityof any good or service that doesn't need energy. So when we're trying to deal with somethingthat is the byproduct of using energy itself, it is connected to the machine of creationrather than one little area, in the same way that it's like HFCs and CFCs, not every singleindustry was based on aerosol propellants. And so you were able to change that withouthaving to change macroeconomics. You really only had to change an industryand so you could get enough force to do it. When you're trying to change something thatis at the heart of macroeconomics itself, the vested interests that are against it iseverything. And it's not only that every industry andthus every single business requires it, it's that also every nation states geopoliticalposition requires it. So literally power itself is bound to it. So the entire machinery of power will resistanything that would decrease its relative power capacity. And this is why from backing out of the KyotoTreaty to whatever the whole history of the thing, why has it been so hard is becauseif any... so there the market can get us to organize based on incentive, but if incentiveisn't adequate and we actually have to use a anti incentive, we have to use a deterrent,the market doesn't really do deterrents well. So you have a state that does that, whichis you make it illegal and someone will get arrested if they break the law or their businesswill stop being able to operate. So this multipolar trap that we talk aboutwhere there is some near term incentive where if any agent does that, they win in the shortterm and it creates a race for everybody to do that, we've figured out how to solve multipolartraps inside of a nation state by rule of law and monopoly of force and enforcement. So we can say, "No, we're not going to cutdown all the trees, we're going to have a national park, we're going to keep trees inthe national park and no logger is allowed to cut there." And what that means is a monopoly of violencewill forcibly stop you if you're cutting there and take you to jail to protect the rule oflaw. And so inside of a nation state, we're ableto prevent most multipolar traps, but we do not have international governance to dealwith global ones. And so then we end up getting the variousnation states competing with each other and this is both... this is why there is a desirefor something like global governance is because the global oceans or the global atmosphereor the global biodiversity or global commons that we depend upon can't have a situationwhere each country, if they make the right choice, gets disadvantaged so that nobodymakes the right choice. The reason we don't want a one world governmentis because how do you have something that has that much power that doesn't become corruptand how do you ensure that there are checks and balances on it? So we do need something like effective global  governance, which does not have to be a government, it can be a decentralized process, but thatstill allows us to solve the multipolar traps. Nate Hagens:I'll push back a little bit on that because even within countries, the pressure to continueeconomic growth even understanding, and deeply caring about some of the negative impactsof decisions, these countries are powerless to do it. Look at Germany right now, they're importingtrain loads of coal and they're taking down old growth forests for trees. This has nothing to do with the global situation,they are compelled to get energy to keep their industries going. Of course it's a externally imposed emergencything because of Ukraine and Russia, but there's lots of examples like this that to keep themouths fed, we make populist... Well look at Brazil, that's not a global thing. They continue to tear down the rainforestto grow more soybeans for beef and that's an economic decision within the country ofBrazil. But go on. Daniel Schmachtenberger:Of course it's a global thing, is if any country does not grow its GDP relative to other countriesthat are, it's overall geopolitical position is going to decrease. And so a country does not have total sovereigntyand last time you and I were together with Samo, he was asking the question of how manycountries are there actually in terms of entities that can make real strategic decisions, andhe's like- Nate Hagens:And there's not 195, there's like 10 or something like that he said Daniel Schmachtenberger:One hypothesis is only countries that have nukes, the other hypothesis is only countriesthat have nukes and or some critical control of an aspect of the global supply chain thateverybody needs, but basically has some play on power that is fundamental and everybodyelse is to some degree a vassal nation. It's an interesting conversation. But you're right, it's not like a countryhas total sovereignty within it because it also has to do with external pressures andin a global media world it has to do with internal pressures. And so the external pressures do force everybodyto keep up with growth, it's kind of the nation state keeping up with the Joneses in the mostkind of destructive way. But the point is, if you have rule of lawand a monopoly of violence, you can bind a multipolar trap. It doesn't necessarily mean you will, it doesn'tnecessarily mean they'll be very politically feasible, which is why there are no nationsthat have done that for oil because they just couldn't. They couldn't because there is no way thatthey would maintain economic viability within the overall global system that exists. So what we were mentioning is no country isgoing to take the lead on properly pricing oil and say, "We're going to price oil atthe actual cost that it would take us to produce it renewably in terms of how we manufacturethose hydrocarbons and how we process the externalities," and the price is 10 or a thousanddollars a barrel, depending upon how you price it, but it's... I mean a gallon, but it's a fuck ton up fromwhere it currently is, they would be so radically disadvantaged GDP-wise relative to every othercountry in their ability to build militaries or keep up with trade or whatever. And particularly, the leading nations aren'tgoing to do that. So the US isn't going to do it if China doesn't,China's not going to do it if the West doesn't. And as a result, you have this situation whereany nation has an anti-incentive to lead." - [Daniel Schmachtenberger](https://youtu.be/tQkQrc3Ant4?t=1200)

^^ from 20:00 till 28:40

> "That's another way of stating the multipolartrap, which is that this system where the cost is externalized to the environment andthe commons does seem to short term benefit us and whether us means corporation, countryor person. And even though the aggregate effect of thatsystem does self terminate for everybody. And so we do have to voluntarily at a minimumadequate scale, create a new system that doesn't self terminate orwe get the plausible deniability of saying we couldn't have done anything else whilebeing chained to and part of a system that is on a self termination path, which is whyunderstanding what the alternatives look like is key." - [Daniel Schmachtenberger](https://youtu.be/tQkQrc3Ant4?t=2490)

> "Humans don't exist without the rest of natureso we have to be stewards for it. But what is different about us allows us todestroy all of nature in a way that nothing else in nature can. Therefore, we have to be stewards or we don'tcontinue to exist." - [Daniel Schmachtenberger](https://youtu.be/tQkQrc3Ant4?t=2705)

> "The Gini coefficient in my country mightbe really nice, but the Gini coefficient in the supply chain that my life depends uponis probably not very nice. And so again, this is where we have globaldependency, global effects. So you have to have global governance otherwiseeverybody just does, "not in my backyard" and sends the messed up stuff to countriesthat don't really have much of a choice and then has plausible deniability on their ownmetrics. But it's like that's not real." - [Daniel Schmachtenberger](https://youtu.be/tQkQrc3Ant4?t=4521)

> "And I want to say just because it's such an easy knee-jerk reaction to have that whenI say global governance, what I mean is global government that this is some new world order,one world government agenda for top down total control in the debasement of good nationalismand checks and balances on power and blah blah blah. No of course I don't want that. No thinking person wants that unless theyassume they're the one who runs the thing, in which case they probably do. And that's important because... but this isthe trade off we have to deal with. Nate Hagens:I think there's a good... there's a reasonable percentage of the environmental movement that  wants that, some sort of environmental authoritarianism... Daniel Schmachtenberger:Unfortunately they probably have over focused on the environment and under focused on othercritical aspects of what makes the world not suck or suck to that they're not realizinghow dystopic a system that has no checks and balances on power would be. Humans don't have a good track record   at stewardingpower well. Noblesse Oblige. The obligation of the nobility class to benoble does not have a good statistical track record, right? That power is abused pretty universally hasa better track record. And so we talk about the third attractor wherethere's currently two attractor states for the future, meaning states that are most likelybased on the kind of general dynamics we're on. There's an attractor state of increasing catastrophes  and there's an attractor state of increasing dystopias. The catastrophes largely result from not havingmore coordinated governance. And so everybody, all the countries racingto grow their GDP to grow their military presence and things like that, equals passing planetaryboundaries and the destruction of the environment and that leads to cascading catastrophes oflots of types. Climate change leads to extreme weather events,leads to human migration, leads to resource wars, leads to large scale wars, leads tobreakdown of infrastructure and supply chain, leads to more resource wars, blah blah blah. Right? So that's the catastrophe model and there'sa million different ways that can go. To avoid that model, you have to be able toprevent those bad things from happening. You have to prevent people in the age of cheaperand cheaper gene synthesis capabilities, from building pandemic weapons in their basementsin the next few years. You have to prevent all the countries fromracing forward on using up all the resources as fast as they can in competition with eachother. You have to prevent them from military escalationand whatever. In order to do that you have to have somepowerful control systems because incentives alone won't do it. You will need deterrents and we can do someproofs of why incentives alone don't do it. Well if you create powerful enough controlsystems to check all the exponential tech and to check all of the externalities, howdoes that not become dystopic? How do you have checks and balances on something  that has that much assymetry of power on everything else? So one attractor is increasing catastrophes,the other is that the answer to the increasing catastrophes is control mechanisms with nochecks and balances that become top down dystopic forces. And even if we say, "No, no, no, they won'tbe because we will make sure that there is some good process of jurisprudence bound tothe collective will of the people somehow and transparency and checks and balances,"If you make a system that's centralized, even if the initial governance of it is good, isn'tit capturable by negative forces eventually? So how do you make a system that has thatmuch power that is not capturable or corruptible? That's the other big question. So the third attractor we're looking for isable to prevent all the catastrophes and have the coordination system that does that notbe corruptible or capturable and that is threading the eye of a needle. And I don't think it is impossible and it'salso not easy." - [Daniel Schmachtenberger](https://youtu.be/tQkQrc3Ant4?t=4568)

^^ from 01:16:08 till 01:20:27

> "We talked before about Marvin Harris's model, that a civilization can be modeledin terms of its infrastructure, its social structure and its super structure. Its infrastructure is the physical toolingthat it mediates meeting its physical needs with, its social structure is the collectiveagreement field law, basically, law governance and its super structure is its shared valuesthat are hopefully the basis of its law and its coordination, what it's coordinating inservice to. So it might be its religion, its clan identity,it's national identity, whatever. So we can say that from early on humans, whatwas being selected for was groups of humans with their infrastructure, social structureand super structure.... And so what was selected for was the groupof humans, their coordination mechanisms, which included their social structure andtheir super structure and their tech stack. And then groups of humans relative to eachother were in inter tribal coordination. They would trade but also conflict. They would war, which drove them to up-regulaterelative to each other. But all of them were up-regulating relativeto nature on vastly faster time scales, meaning able to convert more of nature into humanuseful stuff. And so given our capacity, so the first thingI want to say is you can't think about sapiens without thinking about the group of sapiens. It's coordination mechanisms and it's tooling. Like implicit in us is all of that. Because we were not selected for based onwhat's in our genome, it's our genome plus the extension of that. That was actually what was selected for. So when you think about sapiens, you actually  have to think about the tech stack, the coordination, you have to think about all of that as a thingthat's being selected for. We have the ability to destroy whole ecosystemsin a way that no other animal can. We have the ability now to genetically engineernew creatures. We have the ability to... it's so easy tosee that we are not apex predators. When you think about a polar bear on a rampage,how much destruction it could do versus what's the video of the Tsar bomb when we detonateda large nuclear weapon, it's like we just are not apex predators. We're a totally different creature. Because we have the capacity to ruin the biosphereupon which we depend, we have the necessity to steward it. But no other animal has to consciously stewardall of the ecosystem because they don't have the capacity to destroy it. The ecosystem as a whole stewards itself becauseof the relative symmetries of power of everything with everything because we broke those relativesymmetries of power and we have so much power relative to everything else. Either we use that power in service of everythingor in service of our own short term interests, we debase our long term existence. That's the new super structure that we haveto get. I am because we are, and the we extends tonot just our in group but all people. Because otherwise our in group is in an arms  race with others that eventually is too destructive for anybody to make it through. But I am because we are, where the we meanseverything that we depend upon, which means all the other inhabitants of the biospherethat make it bio-inhabitable for us. So what I'm saying is actually really simplebecause our adaptive capacity has surpassed the process by which evolution usually createsadaptive capacity, our motive also has to transcend normal evolutionary motive." - [Daniel Schmachtenberger](https://youtu.be/tQkQrc3Ant4?t=5030)

^^ from 01:23:50 till 01:28:30

> "Popular support absolutely does put real pressureon economic and political lever pullers. So do you need a popular zeitgeist to change? Yes. Do you need people in key decision makingto change their understanding? Also yes. Those inter-inform each other. Both. And it's... what we're talking about is definitelya cultural enlightenment of a particular type, a cultural enlightenment, meaning distributively,everyone coming to understand the nature of the world they live in differently and better,more clearly in a way that leads to different types of coordination and where the defaultis, if I don't they're going to, therefore I have to. If that remains the default, we don't makeit for very long as a species or at least we have enough catastrophe that whoever makesit through makes it through on a biosphere nobody wants to be on. And so we have to get off of the, if I don'tthey're going to, so I have to, which means we have to get the capacity for coordinationthat does not maximize short term self-interest. But that is absolutely aligned with both longerterm self-interest and a different definition of self-interest. Because as you were mentioning before, theculture that did the plow might have been less happy overall, and we're not saying itwas, we're just saying might have been less happy or fulfilled than an animistic one. But that wasn't what mattered. The definition of best self-interest gametheoretically and the definition of best self interest in any other meaningful way are notthe same. And that's another really critical thing whenwe talk about profit and what's fundamentally wrong with it. We enjoy breathing, we value breathing a lot. We don't pay for breathing because we alljust have access to an atmosphere. If I cut some trees down, is there less CO2sequestered and less oxygen produced? So a worse atmosphere, yes, but so marginallyso that it affects my breathing, seemingly none at all. But I immediately get the value of that lumber. And so for me it makes total sense to cutdown these trees, get the immediate benefit, and still get the benefit of the atmosphere. Does everybody running that calculus threatenthe atmosphere as a whole? Yes, but unless we all agree to do something  different, I don't want to be relatively disadvantaged and I notice the advantage of the trees morethan I notice the disadvantage of the decreased atmosphere. So none of us pay for the atmosphere eventhough every other thing that we value isn't worth shit if we lose our atmosphere. And so if something is abundant, we don'tbother putting it in the accounting system at all. Therefore we end up damaging and debasingit. We all want to watch the sunset and the sunriseand to hear birds chirp, but we don't have to pay for that. And so what we end up putting our money intois not things that we value, but the subset of things that we value that we can extractthat we wouldn't have access to without the money and that we can extract and exchangefor other type of game theoretical things. So this is, it's not just that we get thevalue calculus wrong of we're not pricing in the real cost of the environmental externalities  of the thing and what it would cost to produce a thing. It's also that what we put dollars into andwhat we value don't equal each other because there's a lot of things we value that we don'thave to put dollars into. And if I did put some of my dollars into protecting  those things, then I'm not maximizing my return on agency. Because someone else who just takes thosethings for granted and puts all their dollars into making more dollars ends up winning ina war. And so what that means is what seems mostgame theoretically beneficial and what actually optimizes for real value aren't the same thing. Game theoretical value and real value havea major delta. So the thing that we're saying we have todo does not equal a decrease in quality of life. It does equal a decrease in immediate gametheoretic capacity relative to someone else, but could be not only more sustainable longterm, but higher quality of life for everybody simultaneously. So long as we get off of that coordinationfailure calculus." - [Daniel Schmachtenberger](https://youtu.be/tQkQrc3Ant4?t=5423)

^^ from 1:30:23 till 01:35:01

> "And so right now we can see that with, whatsome people call, the third industrial revolution computation, there's been this radical growthand information processing and a lot of new types of services and value and change inthe manufacturer of goods that come from that. And a lot of people have this hope that theinformation processing gives us the ability to produce more value per unit of energy andper unit of physical goods. And therefore, we can keep growing GDP withoutputting all of that as demand on the environment because we can just do it through growingthe value of software. And I think you and I- Nate Hagens:Which will require materials and atoms. Daniel Schmachtenberger:... You and I would both say yes and no. Yes, software might have less energy and materialdemand per dollar worth of output, but that's not an exponential curve, it's another S-curve. Where eventually, you have a limit on humanattention and it doesn't matter how many movies there are or how much new software there is,you get diminishing return on the value of the digital stuff limited to human attentionseconds. And then when what you're competing for, isas you do more in the domain of software, you're either applying software to human attentionor you're applying it to the materials' economy, because what else is there? So if you're applying it to the materials'economy, the innovation and software equals more efficiency at extracting atoms and energy,extracting, converting whatever. Or it equals   human attention seconds for engagement,whether it's Netflix or Facebook or TikTok or whatever. And if you do that, then the competition againstgroups doing that is a competition for human attention, which ends up being, as our friendTristan Harris and so many others point out, a pretty bad race to the bottom of the brainstem for making maximally limbic hijacking stuff. And so it's not like the software proliferationjust solves all the problems. The software creates a whole new set of attentionhijacking, belief hijacking capabilities which are problematic, that can drive polarization,addiction, low attention spans, all those things. Or it's simply adding efficiencies to thematerials economy, where if you don't have some law or deterrents that limit the upperboundary, you have Jevon's paradox that, when you increase the efficiency you just end upusing more total stuff because more new markets open up. And so what we can say, is that sustainedcompetitive advantage of a nation or whatever is not their energy or their atoms or theirinformation processing, it's the binding of all three of those together and their coordinationof the humans within that. And that those are fundamentally all tightlycoupled to each other. And that from a purely incentive standpoint,there will always be an incentive to pursue whatever the maximum area of return is, butto still pursue things that have any return on at all, which ends up meaning you extracteverything. And that doesn't work long term viabilitywise so we do end up having to get something that is not just incentives but deterrents. The only reason you can have a national parkis because the incentive for logging is stopped by a deterrent called the rule of law thatsays, we're not going to cut these trees down. And yet the problem is, if we're trying toprevent dead zones in oceans from where no one country's putting all of the nitrogenthere, it's coming from lots of areas or putting all of the trash or forever chemicals or whateverit is. And in order to stop someone else from doingit and it's another country, you actually have to have war, not just law because youdon't have monopoly of violence.How do you solve those types of things? This is where we realized that the globalissues that we face, the global market, we have a global market, we don't have nationalmarkets, we have a global market and it's important to say that, of course, we havenational markets but not really because the laptop that we're both speaking on requiredglobal supply chain. So without global trade we actually can'tmake anything. And so we have global markets but we don'thave global governance.The incentive alone system is fundamentally incompatiblewith the biosphere, it will continue to extract and externalize. And so you have to have some system of deterrents. No, we're not allowed to do that at a globalsystem. How do we create that and how do we createthat is both enforceable and non dystopic? I think that's some of the tee up of wherewe go next." - [Daniel Schmachtenberger](https://youtu.be/tQkQrc3Ant4?t=6007)

^^ from 1:40:07 till 1:45:08

> "All of the various domains are interacting with each other, so global finance is interactingwith the environment, is interacting with tech, is interacting with regulation. And so you can't look at them in isolationand say, do we get the catastrophe in this one first or in this one first? When we talk about planetary boundaries withclimate change, before we hit the planetary boundary of runaway climate change from albedoeffect or whatever it is that would mean we can never fix it, or before we hit the pointof venus-ification, well before then, we will hit the point at which extreme weather eventsstart causing human migration that will cause- Nate Hagens:That's already locked in, we've already passed that point. Daniel Schmachtenberger:... On small scale, so far, Syria was relatively small population and Australia was low populationdensity. But as soon as you have Australia scale thingsin high population density areas, then you start getting world changing effects fromthat. And so that's a place where we've alreadypassed a planetary tipping point, not in terms of the habitability of the planet biospherewise, but the habitability of some areas for short periods of time that are enough to causemigrations of people that cause resource pressures that cause wars, that cause supply chain issues. There's a lot of very near term things thatcan start to cause breakdown of the world systems that meet people's needs that happenat the interface of a lot of these areas, not just one of them going catastrophic onits own." - [Daniel Schmachtenberger](https://youtu.be/tQkQrc3Ant4?t=6359)

^^ from 01:45:59 till 01:47:49

> "Most people are much more aware of the partsof the world system that they look at than the other parts and so they're able to seesomething that looks like a win within that domain without factoring how much that canactually be a loss in other domains. And this is the problem of siloing and hyperspecialization in a radically interconnected world. And I would argue that one of the deepestgenerator functions of all of the issues that we face is that our primary processes forsolving problems externalize problems somewhere else. Because we define the problem too narrowlyand then we look for a solution to that narrowly defined problem that interacts with complexsystems where the externalities go somewhere else and then either someone notices those  externalities says, no way, and you get polarization or nobody notices it happens and you actuallyget the externality." - [Daniel Schmachtenberger](https://youtu.be/tQkQrc3Ant4?t=6664)

> "What it takes to actually politicallyactuate or make something happen is a different set of skills than what it takes to figureout what the right thing that should happen is. And so the people who have the capabilityto navigate the status hierarchies and prestige hierarchies and influence and whatever itis to make sure it happens given those positions, they're supposed to, of course, be advisedby groups of specialists, but they're also advised by vested interest groups that wantparticular things to go through and that has all the problems that it does. If we don't take the current system of governance,any aspect of it as a given, that we will have representatives at the level of statesthat are called congressmen and senators and that we'll vote on propositions made by specialinterest groups. And we just said if we were going to rebuildgovernance from scratch using all the 21st century technologies and factoring the typesof problems that we have, the speed at which they occur, the complexity, how would we doit? We would do it in a way that doesn't looklike how any nation state in the world runs today." - [Daniel Schmachtenberger](https://youtu.be/tQkQrc3Ant4?t=6836)

> "If we were going to rethink it all from scratch,we might not have nation states at all. We might have networks of city states becausethat makes more sense. Or we might have, how would we redo it fromscratch? Factoring not just did all of our issues involveglobal supply chain so there have to be global dynamics involved. Factoring that, if regulation moves slowerthan the speed of tech, then it's not going to be able to regulate the thing that is movingmuch faster than it. So if tech is moving on compounding curveswith exponential tech, how do we make a system of regulation that can keep up with that? Now that we're in a new era where open publishinghad always been good for science, but open publishing of the pandemic viral gene sequencesthat are found through gain of function equals increasing everybody's ability to make decentralized  catastrophe weapons, in the age of gene synthesizers, we have to rethink info sharing. There's a lot of places where it's like, theproblem space of the world and the affordances of the new tech mean that we have to rethinklong term governance from scratch." - [Daniel Schmachtenberger](https://youtu.be/tQkQrc3Ant4?t=7094)

> "What do we have to change in culture in ourcollective values and what the definition of the good life and what's meaningful is? What do we have to change in our governanceand coordination systems? And what do we have to change in our fundamental  technology, governance, coordination and economics? What do we have to change in our fundamentaltechnologies and how do those affect each other? And what are necessary activities in eachthat lead to necessary and sufficient collectively?" - [Daniel Schmachtenberger](https://youtu.be/tQkQrc3Ant4?t=7179)

> "I would say that in the next phase, we don'tstop having a evolutionary imperative or a growth imperative, but it moves dimensionand it requires increasing the dimensionality of our reason for being, of our calculus. That the increase of the quality of life personally,  interpersonally, transpersonally, the sacredness is actually the domain in which growth startsto happen. And that there is a way to coordinate towardsthat, that actually isn't outcompeted by the existing violence domination, extraction profitstack. And that can both remove the pathologicalcompetition mindset from itself while not being outcompeted by it." - [Daniel Schmachtenberger](https://youtu.be/tQkQrc3Ant4?t=7429)





https://civilizationemerging.com/media/darkhorse-podcast-with-daniel-schmachtenberger-bret-weinstein/
^^ transcript for "DarkHorse Podcast with Daniel Schmachtenberger & Bret Weinstein":
https://youtu.be/YPJug0s2u4w

> "I think temporal myopia and the collective action, collective coordination problem is a good way to describe all of the problems we face, or one of the generator functions of all the problems we face: that you have a bunch of game-theoretic situations where each agent within their own agency, pursuing the choice that makes most rational sense to them, pursues local optimums where the collective body of that drives global minimums. But if anyone tries to orient towards the longer-term global maximum, they just lose in the short term. That’s an arms race, that’s a tragedy of the commons. And so how do we reorient the game theory outside of those multi-polar traps, I would say is one of our underlying questions. That when the biggest harm we could cause was mediated by stone tools or bronze tools or iron tools or even industrial tools, we didn’t have to cause it immediately because the extent of harm was limited in scope. When it is mediated by fully globalized exponential tech running up against planetary boundaries with many different kinds of catastrophe weapons held by many different agents, we actually have to solve the problem." - [Daniel Schmachtenberger](https://youtu.be/YPJug0s2u4w?t=761)

> "Now we need to get that number of people who actually have taken some sovereignty over their fitness and wellbeing in the presence of the cheaper reward circuit, we need to get that number up to everybody because right now obviously overweight is one of the main causes of death in the developed world. But we have to then apply that to the even more pernicious, hyper-normal stimuli because salt, fat, sugar are hyper-normal stimuli in the gustatory system. We have to apply that to the sentry system that’s coming in through things like social media and that means less social media, less entertainment, more study. And it doesn’t have as fast a reward circuit, it just doesn’t. But it has a much better longer-term reward circuit where your baseline goes up. And this is where enough mindfulness and enough discipline have to come in because otherwise the orientation of the system is that it’s more profitable for corporations for me to be addicted because you maximize lifetime value of a customer through addiction. And it’s an asymmetric war because they’re a billion or trillion dollar company and I’m me. So how do I win in that asymmetric war where it’s in their profit incentive whether it’s McDonald’s or Facebook or Fox for me to be maximally addicted? I have to recognize holy fuck, I actually have no sovereignty—even if I claim to live in a democracy—against these autocracies who want to control and manipulate my behavior in a way that is net negative for me holistically while having the plausible deniability that I’m choosing it because they’re coercing my choice. So I have to get afraid of that enough that I mount a rebellion, a revolutionary war in myself against those who want to drive my hyper-normal stimulus reward circuit. So the whole, “how can everybody become more immune to the shitty reward circuits and notice them and become immune to them, and how can they become more oriented to the healthy reward circuits”, that’s another way of talking about what we have to do writ large." - [Daniel Schmachtenberger](https://youtu.be/YPJug0s2u4w?t=2629)

> "We have to rigorously close the evolutionary niches for human parasitic behavior, humans parasitizing other humans. And the first part of that is a kind of forced transparency that if someone were to engage in that, it has to be known. And now the question is that all the versions of that we’ve explored at scale look like dreadful surveillance states, so how do you make something that doesn’t look like a dreadful surveillance state that also doesn’t leave evolutionary niches for parasitic behavior that ends up rewarding and incenting sociopathy?" - [Daniel Schmachtenberger](https://youtu.be/YPJug0s2u4w?t=3403)

> "Manufactured demand kills classical market theory—which is the idea of why a market is like evolution, it’s like some evolutionary process—is that the demand is based on real people wanting things that will actually enhance the quality of their life. And so that creates an evolutionary niche for people to provide supply and then the rational actor will purchase the good or service at the best price and at the best value. But of course, as soon as we get to a situation where, and you look at Dan Ariely and all the behavioral economics saying the rat homo economicus, the rational actor, doesn’t exist. We end up making choices based on status that’s conferred with a brand based on the compellingness of the marketing, based on all kinds of things that are not the best product or service at the best price. But you also get that I want stuff that will not increase the quality of my life. I desperately want shit because the demand was manufactured into me, so it’s not an emergent authentic demand that represents collective intelligence. It’s a supply side saying I want to get them to want more of my shit, and I actually have the power to do that using applied psychology. And as soon as you get to split testing and the ability to AI split test a gazillion things, we’re talking about radically scientifically optimized psychological manipulation for the supply side to create artificial demand and then be able to fulfill it. And most of that ends up being of the type that is actually bad for the quality of the life of the people but you have the plausible deniability “they’re choosing it, hey I don’t want to be patriarchal and control what they’re doing. The people are choosing it, I’m just offering the source of supply that they’re wanting.” Bullshit. That’s like offering crack to kids and then when they come back for more of it saying hey..." - [Daniel Schmachtenberger](https://youtu.be/YPJug0s2u4w?t=3698)

> "One of the points that I was making in that context was this inherent asymmetry around unionization, and that the problem is unions have gotten a bad rap because of the tight association cognitively that we have with labor unions. We think of unions and labor unions as synonymous but union is actually a category. It’s potentially a very large category and effectively, management always has the benefit of it. The question is will workers have a symmetrical entity, that’s the labor case, but you can make the same case with respect to banking. Credit unions don’t work, they’re very bank-like, but if they were structured in such a way to actually unionize people who utilize the bank it could be highly effective. It could be a complete replacement for the insurance industry which doesn’t even make sense in a market context. But as a risk pool you could do a very effective job. So anyway, yes, the question is how do you scale up the collective force and especially how do you do it in light of the fact that the entities that are already effectively unionized see it coming and they disrupt it with all of their very powerful tools." - [Bret Weinstein](https://youtu.be/YPJug0s2u4w?t=3832)

> "So a way of thinking about what the architectural idea of a liberal democracy is and why the founders of this country set it up not as a pure laissez-faire market but as a state that had regulatory power and the market together, the idea is that a market will provision lots of goods and services better than a centralized government will. So let’s leave the market to do the kind of provisioning of resources and innovation that it does well, but the market will also do a couple really bad things. It will lead to increasing asymmetries of wealth inexorably. This is what Piketty’s data showed, but it’s just obvious having more money increases your capacity to have access to financial services and you make interest on debt and on compounding interest on wealth. And so you end up getting a power law distribution of wealth. So then a few people in just the market dynamic would be able to have way outsized control over everyone else against everyone else’s interests. And the market creates opportunities for things that are really bad. We all know that we want there to be a thing called crime where even though there’s a market incentive for child sex trafficking and whatever else, we say no we’re going to create some rule of law that binds that thing and not just have market drive it. So the idea is that we create a state that we actually give a monopoly of violence to, so it has even more power at the bottom of the stack of what power is than the top of the economic power law distribution. So the wealthiest people and the wealthiest corporations will still be bound by this rule of law. And the rule of law is an encoding of the collective ethics of the people. The ethics are the basis of jurisprudence, and there is some kind of democratic process of getting to say, what is it that we consider the good life and important that we want enshrined in rule of law? We give that a monopoly of violence, and really then the goal of the state is to bind the predatory aspects of market incentive while leaving the market to do the things that it does well. But pretty much every law is where someone has an incentive to do something, which is a market-type dynamic, that is bad for the whole enough that we make a law to bind it. Ok, so the purpose of a state is to bind the predatory aspects of a market. That only works as long as the people bind the state. And the people bind the state if you have a government of, for, and by the people of an educated populace who had a quality of education that were capable of understanding all the issues upon which we are governing and making law, and a Fourth Estate where the news that they are getting is of adequate quality and unbiased enough that they’re informed about what’s currently happening. If you think about that, that’s what a republic would require, and you realize that both public education and the Fourth Estate have eroded so badly for so long, it’s not that we’re close to losing our democracy, it’s dead. We don’t have a republic, we have a permanent political class and a permanent economic lobbying class, and the people who aren’t really actively engaged in government in any way at all, beyond maybe jury duty now and again if they can’t get out of it. And if the people to be engaged in government in any meaningful way had to tell the DOE what they think should be done about grid security and energy policy, or tell the DOD what should be done about nuclear first strike policy or tell the Fed and Treasury what they think about interest rates, they have no fucking idea how to have a governance of, for and by the people. They don’t have that education, they don’t have the media basis. So if the people can’t check the state, then the state will end up getting captured by the market, and so you’ll end up having the head of the FDA be someone who ran a big drug or a big Ag company and the head of the DOD being somebody who ran Lockheed or some military-industrial complex manufacturer, you’ll have just lobbying, just straightforward lobbying gets paid for by somebody. Who’s it get paid for? Those who have the money to pay for lots of lobbyists. And so then you end up getting a crony capitalist structure which is worse than just an evil market because now it has the regulatory apparatus of rule of law and monopoly of violence backing up the market-type dynamics. So then we say, well ok what do we do here? And we see that civilizations fail towards either oppression or chaos, those are the two fail states. They fail towards oppression if trying to create some coherence happens through a top-down forcing function. They fail towards chaos if not having enough top-down forcing function, everybody kind of believes whatever they want but they have no unifying basis for belief and so then they will end up going into—they’ll balkanize, they’ll tribalize, and then the tribal groups will fight against each other. Either we keep failing towards chaos, which we can see is happening in the west and in the U.S. in particular right now, and then China, which is happy to do the oppression thing—and oppression beats chaos in war because it has more ability to execute effectively, which is why China has built high speed trains all around the world when we haven’t built a single one in our country. So either we lose to China in the 21st century and oppression runs the 21st century, or we beat China at being China, meaning beat it at oppression or it’s like fuck, those are both failure modes. What is there other than oppression or chaos is order that is emergent, not imposed, which requires a culture of people who can all make sense of the world on their own and communicate effectively to have shared sensemaking as a basis for shared choicemaking. The idea of an open society is that some huge number of people can all make choices together, a huge number of people who see the world differently and are anonymous to each other, not a tribe. That was an enlightenment-era idea born out of the idea that we could all make sense of the world together, born out of the philosophy of science and the Hegelian dialectic, that we could make sense of base reality and that we could make sense of each other’s perspective, dialectic, find the synthesis and then be able to have that be the basis of governance. So what I think is, this is not an adequate long-term structure because we can talk about why tech has made nation-state democracies obsolete and it’s just not obvious yet, but it has. But as an intermediate structure, the reboot of the thing that was intended has to start at the level of the people, at culture, and that collective sensemaking and collective good faith dialogue, because without that you can’t bind state, without that you can’t bind market incentive." - [Daniel Schmachtenberger](https://youtu.be/YPJug0s2u4w?t=3946)

> "This is related to the thing we said about as the market as a whole gets bigger, then the individual consumer stays an individual consumer but the supply side, the company gets much larger. As that happens, the asymmetry of the war between them, of the game theory between them, gets larger and so manufactured demand becomes a more intense thing. Well the same thing is true in terms of the market capacity to influence the government, and the market-government complex’s capacity to keep the population from getting in the way of the extraction. And so there’s a heap of mechanisms that happen, and there’s not like five guys at the top who are coordinating all of this, it’s a shared attractor or incentive landscape that orients it. Yeah, and where there are people conspiring it’s because there’s shared incentive and capacity to do so. So the conspiracy is itself an emergent property of the incentive dynamics, which then in turn doubles down on the types of incentive dynamics that make things like that succeed. So, ok let’s take a couple examples. If people haven’t read it, they should all read at least the Wikipedia page on public choice theory, a school of libertarian thought that critiques why representative democracy will always break down, that the founders of the U.S. basically said this, which is—all right, we’ll come back to symmetry for a moment. At the time that we were creating the structure of a liberal democracy, the size of choices and the speed of them was smaller and slower such that the town hall was a real thing. And when the town hall is a real thing, the coupling between the representative and the people is way higher because the people are actually picking representatives in real time that are really representing their interest and they get to have a say in it. There was a statement by one of the founders of the country that voting is the death of democracy, because the idea is we should just be able to have a conversation that is good enough that we come up with a solution and everyone’s like that’s a good idea. If we can’t then we vote, but that means that some big percentage, close to half the population, feels unhappy with the thing that happened. And so it’s a sublimated type of warfare, it’s a sublimation of violence but that leads to a polarization of the population. And so the goal is not voting. Voting is the last step of when we couldn’t just succeed at a better conversation in speccing out what is the problem? what are the adjacent problems? what are the design constraints of a good solution? can we come up with a solution that meets everybody’s design constraints as best as possible?" - [Daniel Schmachtenberger](https://youtu.be/YPJug0s2u4w?t=4544)

> "Wait, there’s a symmetry here between the conversation that we had about the market incenting people who focus on the opportunity and not the risks such that it actually suppresses those who look at the risk. Once you say, “hey there’s always going to be somebody talking about a risk that isn’t going to happen, we’ll innovate our way out”, and that becomes the story, now you have plausible deniability to always do that. Once you say “there’s no way to get everybody on the same page, we can’t do that, it’d be too slow”, now I don’t even have any basis to try. And so I don’t ever even try to say what is it that everyone cares about relative to this so I even know what a good solution would look like to craft a proposal. No, we’re going to vote on the proposition having never done any sensemaking about what a good proposition would be. And that’s just mind-blowingly stupid. And so then who’s going to craft the proposition? A lawyer. A lawyer’s paid for by who? Some special interest group. So most of the time what happens is you have some situation where one thing that matters to some people has a proposition put forward that benefits it simply in the short term but it externalizes a harm to something that matters to other people. But ultimately all of it matters to everybody, just differentially weighted. And the “how do we put all those things together”, so ok we’re going to do something that’s going to benefit the economy but harm the environment. Well, everybody cares about the economy and everybody cares about the environment, but if I put forward a proposition that says in order to solve climate change we have to agree to these carbon emission controls that China won’t agree to and therefore China will run the world in the 21st century and we all have to learn Mandarin or be like the Uyghur or something. Ok well now I have bunch of people who, because they hate the solution space because it harms something else they care about, don’t believe in climate change. It has nothing to do with not believing in climate change, you’re not caring about the environment, it’s that they care about that other risk so much as well. But if I said ok well let’s look at— **Bret**: It’s a negotiation tactic, is what you’re saying. That at the point that you want X prioritized over Y, you’ll descend into a state in which you’ll make any argument that results in that happening, including “Y doesn’t exist.” **Daniel**: Exactly, because I’m so motivated by this other thing and the solution has a theory of tradeoffs built in that is not necessary. Sometimes the theory of tradeoff is necessary but oftentimes a synergistic satisfier could be found but we didn’t try. In the same way that a way to move forward with the opportunity without the risk could have happened, we could have found a better way to do the tech that internalized that externality. We just need to try a little bit more, but there isn’t the incentive to do it. So let’s say we said no we don’t care about climate change by itself, we care about the climate and we care about the economy and we care about energy independence and we care about geopolitics. And we’re going to look at the adjacent things where making a choice in one of the areas necessarily affects the other area. And we’re going to bring those design constraints together and we say what is the best choice that affects these things together? Then we could start to think about a proposition intelligently. We don’t do this in medicine either. We make a medicine to solve a very narrow definition of one molecular target of a disease that externalizes side effects in other areas without addressing upstream what was actually causing the disease. And then the side effects of that med end up being another med and then old people die on twenty meds, of iatrogenic disease. So in complex systems you can’t separate the problems that way, you have to think about the whole complex thing better. And so one part of fixing democracy that we have to think about is we have to define the problem spaces better, more complexly. And we have to be able to actually have a process for coming up with propositions that are not stupid and intrinsically polarizing, because almost no proposition ever voted on gets 90% of the vote, it gets 51 fucking percent of the vote which means half of the people think it’s terrible. And so what that means is you care about the environment, I care about the economy on proposition A. Well you petition to get the thing to go through because you care about the owls there but I think that you’re making my kids poor. You’re my fucking enemy now and I’ll fight against you. Now all the energy goes into internal friction and fighting against each other, and any other country that’s willing to be autocratic and force all their people onto one side will just win. And we will increasingly polarize against each other over something where we could have found a more unifying solution." - [Daniel Schmachtenberger](https://youtu.be/YPJug0s2u4w?t=4781)

> "I’m not saying that we get out of having constraints, I’m saying we can do design by constraints much better than we currently do. And so I’m saying that there’s a lot of things that we take as inexorable tradeoffs that aren’t." - [Daniel Schmachtenberger](https://youtu.be/YPJug0s2u4w?t=5114)

> "So when I say I’m looking for synergistic satisfiers, the idea that I have X amount of input and that input has to be divided between these various types of output and it’s linear, is nonsense. I can have X amount of input and have something where the total amount of output has increased synergy based on the intelligence of the design. The question of how do we design in a way that is optimizing synergy between all the things that matter becomes the central question." - [Daniel Schmachtenberger](https://youtu.be/YPJug0s2u4w?t=5479)

> "Markets are excellent at figuring out how to do things, and they are atrocious at telling us what to do. In other words, they will find every defect in human character and figure out how to exploit it if you allow them to do that, but when you have a problem that you really want solved—how can we make a phone that doesn’t require me to be plugged into the wall, allows me to get a message across a distance to report an emergency, whatever—markets do a better job than we could otherwise do of figuring out what the best solution is. And so in some sense the question is, how can we structure the incentives around the market so that markets only solve problems that we want them to solve but they can be free to solve them well? And what I think I realized in this conversation here is that in some sense the role of the citizenry in a democracy is to discuss the values that we want government to deploy incentives around. In other words, the people, by deciding what their priorities are, what their concerns are, which problems are top of the list to be solved and which ones could take a backseat, that that’s the proper thing that we are to be discussing. That the role of government freed from corruption would be to figure out what incentives will result in the best return on our investment, structuring the incentives of the market, and then the market can be freed to solve the narrowest problems on that list. And I think we fail at every level here, but from the point of view of what we’re actually shooting for, I would say it’s somewhere in that neighborhood: that division of labor between the citizens, the apparatus of governance, and the market." - [Bret Weinstein](https://youtu.be/YPJug0s2u4w?t=5830)

> "Venture capital is not going to put up the amount of money that a nation-state can, for the amount of time that’s necessary. And when you look at the very largest jumps in innovative capacity, a lot of them happen by nation-state funding, not market funding, and then a market emerging in association with kind of government contracting. And so if we look at why the Nazis were so technologically farther ahead than everyone else going into World War II with the Enigma Machine and the beginning of computing, with the V2 rocket, it was not a market dynamic. It was a state dynamic where they invested in science and technology development for a long time, which is why this tiny little country with limited industrial supply capacity had more technological advancement than the Soviets or the U.S. and it was our ability to steal their shit and rip it off and then be bigger than them that was a big part of how we were able to succeed in the war effort. And so that’s a clear example that computers were developed by a state, not the market." - [Daniel Schmachtenberger](https://youtu.be/YPJug0s2u4w?t=6018)

> "Now I think that it’s true that something more like a market will explore more edge cases that are not known whats, and come up with interesting things, whereas the centralized thing can do a better job sometimes of existing whats that require very high coordination. Because if you look at the Manhattan Project, the scale of the budget and the scale of coordination, no company has that, and a bunch of companies competing for intellectual property and whatever wouldn’t have worked, right? One of the reasons I bring this up is because there’s a whole bunch, you mentioned fusion, whether it’s fusion or whether it’s thorium or whether it’s closer to room temperature superconduction or any of the things it could possibly generate, whether it’s 65% efficient, photovoltaic through nanotech—there’s a bunch of things where we kind of know the science that could lead to the breakthrough but the level of investment just isn’t there. And I think there’s a heap of examples like this where the percentage of the national budget that used to go to R&D has went down a lot, and it shouldn’t. And the Apollo Project was kind of the last thing of its type. And then the government starting to shift to government contractors started to be a source of massive bloat, where the government contractors had an incentive to just charge whatever the fuck they wanted. Which is why then Elon could beat Lockheed and Boeing at rockets so much cost-wise because in that situation he didn’t have to do the fundamental innovation on rocketry, he could just outcompete them with market incentive. And then that could create enough money for iterative innovation. I think fundamental innovation of certain scales does require larger coordination than markets make easy." - [Daniel Schmachtenberger](https://youtu.be/YPJug0s2u4w?t=6263)

> "Yes, and we don’t want to give the government that much power because we don’t trust that kind of authority, but that’s because the people aren’t checking the government. Which comes back to the thing that we talked about earlier. And now this becomes one of the central questions of the time. It’s what is the basis of legitimate authority and how do we know, and what is the basis of warranted trust? Because we all know what it means to have trust that isn’t warranted. Everyone who disagrees with us, we think that their trust isn’t warranted. If we’re on the left we think people who trust Trump it’s unwarranted, and they think that the people who trust the FDA or vaccine scientists or the CDC have trust that’s unwarranted. We also know that legitimate authority, the idea of legitimate authority is so powerful to be able to be the arbiters of what is true and what is real, that anyone who is playing the game of power has a maximum incentive, however successful they are, to be able to capture and influence that for their good. We also know that it’s possible to mislead with exclusively true facts that are cherry-picked or framed. So I can cherry-pick facts on one side or the other side of a Gaussian distribution and tell any story I want that will make it through a fact checker. So fact checking is valuable but not even close to sufficient. So I can lie through something like The Atlantic as well as I can lie through something like Breitbart through different mechanisms for different populations... And so I can do a safety analysis on a drug, and I’m not looking at every metric that matters. I’m looking at some subset of the metrics and it might be that it’s safe on those metrics but all cause mortality increases, life expectancy decreases. But I only did the safety study for two years, so I wouldn’t notice that. So I can say, no, methodologically this was perfect and sound. It just also doesn’t matter because I wasn’t measuring the right things. **Bret**: Right, and so this also basically what you have just said means that the replication crisis can be understood as a mechanism for generating data which can be cherry-picked to reach any conclusion you want about the effects of this intervention or that intervention, because effectively what you have is the ability to choose between experiments where sampling error will result in both outcomes being evident somewhere. **Daniel**: This is another one of those, is it conflict theory or mistake theory things, is I can intentionally manipulate an outcome that looks methodologically sound and then say, oh we just didn’t know those factors. I’m not saying whether that’s happening or not, it certainly can happen. Ok so now we get back to, how do you have a legitimate authority that has the power of being the arbiter of what is true and real and all the power that’s associated and have it not get captured by the power interests, is a very very important question. How in the name of the Bible and Christendom and Jesus saying let he who has no sins cast the first stone, did we do the Inquisition? Like weird mental gymnastics by which the authority of that thing was able to be used for the power purposes of the time. And so now when you start to have increasing polarization between the left and the right, and historically more academics being left-leaning and the social sciences being so complex that you can cherry-pick whatever the fuck you want and do methodologically sound and yet still misrepresentative stuff, then you say is that actually a trustworthy source? And then we say, well ok do we want a bunch of wacky theories going out over Facebook and Twitter and whatever, or do we want to censor it? Well if we want to censor it, who is the arbiter of truth that we trust? If we don’t censor it, we’re appealing to the worst aspects of everyone and making them all worse in all directions. Those both suck so bad, and that’s the oppression or chaos. And the only answer out of the oppression or chaos is the comprehensive education of everyone in the capacity to understand at least three things. They have to increase their first person, second person, and third person epistemics. Their third person epistemics is the easiest, philosophy of science, formal logic, their ability to actually make sense of base reality through appropriate methodology and find appropriate confidence margin. Second person is my ability to make sense of your perspective. Can I steel man where you’re coming from? Can I inhabit your position well? And if I’m not oriented to do that, then I’m not going to find the synthesis of a dialectic. I’m going to be arguing for one side of partiality, harming something that will actually harm the thing I care about in the long run. And then first person, can I notice my own biases and my own susceptibilities and my own group identity issues and whatever well enough that those aren’t the things that run me? When I look at the ancient Greek enlightenment, first person was the Stoic tradition, the second person was the Socratic tradition, the third person was the Aristotelian tradition. There’s a mirror of all those in modernity. We need a new cultural enlightenment now where everyone values good sensemaking about themselves, about others, about base reality. And good quality dialogue with other people that are also sensemaking to emerge to a collective consciousness and collective intelligence that is more than our individual intelligence. And so that we have some basis of something that isn’t chaos but that also isn’t oppression because it’s emergent more than imposed. So it’s cultural enlightenment or bust as far as I’m concerned." - [Daniel Schmachtenberger](https://youtu.be/YPJug0s2u4w?t=6402)

> "Science can do a good job of what is, but not what ought, which means applied science, i.e. technology, i.e. markets, can do a good job with changing is, but not in the direction of ought. And so that is ethics, which is to be the basis of jurisprudence and law, that’s exactly why you bring those things together. And it’s because is is measurable, third person, measurable and verifiable, repeatable. It’s objective, right. Whereas ought is not measurable in a—you can do something like Sam Harris does in Moral Landscape and say it relates to measureable things, but it doesn’t relate to a finite number of measurable things. There is a Gödel proof that whatever finite number, there are some other things that we end up finding later that are also relevant to the thing that weren’t part of the model that we were looking at. And so the thing that is worth optimizing for, you talked about that the blue and the fast would be part of the same thing. The thing that is worth optimizing for is not measurable. It includes measurables, but it is not limited to a finite set of measurables that you can run optimization theory and have an AI optimize everything for us." - [Daniel Schmachtenberger](https://youtu.be/YPJug0s2u4w?t=7076)

> "So the first verse of the Tao Te Ching is the Tao that is speakable is not the eternal Tao. The optimization function that is optimizable with a narrow AI is not the thing to optimize for, is a corollary statement. And the Jewish commandment about no false idols is that the model of reality is never reality, so take the model as this is useful, it’s not an absolute truth. The moment I take it as it’s an absolute truth, I become some weird fundamentalist who stops learning, who stops being open to new input. And in optimizing the model where the model is different than reality I can harm reality and then defend the model. So I always want to hold the model with this is the best we currently have and in the future we’ll see that it’s wrong. And we want to see that it’s wrong, we don’t want to defend it against its own evolution. And so what we’re optimizing for can’t be fully explicated, and that’s what wisdom is. Wisdom is the difference between the optimization function and the right choice." - [Daniel Schmachtenberger](https://youtu.be/YPJug0s2u4w?t=7213)

> "We don’t want a one-world government run by any of the people we currently have, and we also don’t want separate nations where any of them that defect lead everybody into a race to the bottom, so that means that they have to have rule of law over each other because they affect common spaces. So how do you have rule of law over each other without it being one-world government and then capture? Oppression or chaos at various scales, and the only answer is the comprehensive education and enlightenment of the people that can check those systems. Now obviously the founding of this country was fraught with all the problems we know of now in particular, and it was still a step forward in terms of a movement towards the possibility of some freedoms from the feudalism it came from. And so I find the study of the theoretical foundation of it meaningful to what we’re doing right now. And famously there’s this quote from George Washington where he says something to the effect of, I’m going to paraphrase it, the comprehensive education of every single citizen in the science of government should be the main aim of the federal government. And I think it is fascinating. So science of government was his term of art, and science of government meant everything that you would need to have a government of, for, and by the people. Which is the history, the social philosophy, the game theory and political science and economics as well as the science to understand the infrastructural tech stack and whatever, the Hegelian dialectic, the enlightenment ideas of the time. But the number one goal of the federal government is not rule of law, and it’s not currency creation, and it’s not protection of its borders, because if it’s any of those things it will become an oppressive tyranny soon. It has to be the comprehensive education of the people if it is to be a government of, for, and by the people. Now this is the interesting thing, now I remember where I wanted to go. Comprehensive education of the people is something that makes more symmetry of power possible. Increasing people’s information access and processing is a symmetry-increasing function. So everyone who has a vested interest in the increasing asymmetries has an interest in decreasing people’s comprehensive education in the science of government. And so now let’s look at the education changes that happened following World War II in the U.S. There’s a story that I buy that the U.S. started focusing on STEM education—science, technology, engineering, math—super heavily partly because it was an existential risk because look what happened with the STEM that the Germans did and now we know that a lot of the German scientists that we didn’t get in Operation Paperclip the Russians got in Sputnik and so it’s an existential risk to not dominate the tech space. So we need to really double down on STEM and we need all the smartest guys, we need to find every von Neumann and Turing and Feynman there is, so the smarter you are the more we want to push you into STEM so you can be an effective part of the system. That’s part of the story, but also the thing that Washington said, the education, the science of government—we start cutting civics radically and I think it was because social philosophers of the time like Marx were actually problematic to the dominant system. And I’m not saying that Marx got the right ideas, I’m saying the idea of ok we have a system where let’s have the only people who really think about social philosophy be the children of elites who go to private schools who learn the classics, and otherwise let’s have people not fuck the system up as a whole but be very useful to the system by becoming good at STEM. I think this is a way of being able to simultaneously advance education and retard the kind of education that would be necessary to have a self-governing system." - [Daniel Schmachtenberger](https://youtu.be/YPJug0s2u4w?t=7426)

> "Ok now I remember why I used the analogy of the body. What I’m going to say here is wrong, so let’s just take it as a loose metaphor. Let’s take in the body that the closest thing to top-down organization is the neuro-endocrine system. But that there’s a bunch of bottom-up that is at the level of genetics and epigenetics and cellular dynamics and whatever, and that there is a relationship between the bottom-up and top-down dynamics. Well obviously I can take a cell out of a body and put it in a dish and it has its own internal homeodynamic processes. It’s dealing with entropy on its own, they don’t need a top-down neuro-endocrine signal for how they do that. So let’s say we tried to make a perfect top-down neuro-endocrine system and the cells had no cellular immune systems or redox signaling homeodynamics or anything else. You would die so quickly. There is no way to have a healthy body at the level of the organization of all the cells if the cells are all unhealthy. And that’s the comprehensive education of the individual thing we’re talking about. Can you make a healthy system of government as a system, can you just get the cybernetics right, that is separate than that which develops all of the individuals and the relationships between them? And the answer is definitely not." - [Daniel Schmachtenberger](https://youtu.be/YPJug0s2u4w?t=7979)

> "Let’s take the classic dialectic that relates to right and left, that’s not the only one, of individual and collective for a moment. And say ok, fundamentally the right is more libertarian, individual, pull yourself up by your bootstraps, we want to have advantage conferred to those that are actually doing—they’re conferring their own advantage, and doing well. And then the left model, the more socialist model is, yeah but people who are born into wealthy areas statistically do better than people who are born into shitty areas in terms of crime and education and access to early healthcare and nutrition and all those things. And you can’t libertarian-ly pull yourself up by your bootstraps as an infant or a fetus and so let’s make a system that tends to that well. But then the right would say, but we don’t want something like a welfare state that makes shitty people that just meets their needs for them and orients them to lay on the couch all day and do TV and crack. Ok, I think it’s mind-bogglingly silly that we take these as if they are in a fundamental theory of tradeoffs as opposed to a recursive relationship that can be on a virtuous cycle. What we want to optimize for is the virtuous cycle between the individuals and the society. Do we want to create social systems that take care of individuals but make shittier people? No. Do we want to create social systems that condition people that have more effectiveness and sovereignty and economy? Yes. And do we want to condition ones that in turn add to the quality of society? Yes. So we don’t want to make dumb social systems. A social system that is more welfare-like is much dumber than a social system that provides much better healthcare and education and orientation towards opportunity for advancement rather than opportunity towards addiction cul-de-sacs. And so we already have some people, all the listeners of your show I think, we already have some people who are trying to educate themselves independent of not having a government that is doing that. And this is why I say it has to start at culture before state or market. It has to boot in that direction. So those people can start to work together to say how do we influence the state, and two, start to then influence better education for more people, better media and news for more people. And how do we influence it to affect market dynamics where the market dynamics are more bound to the society wellbeing as a whole rather than extractive?" - [Daniel Schmachtenberger](https://youtu.be/YPJug0s2u4w?t=8124)

> "Now, there’s something also that you just said that’s interesting is, ok so George Washington’s quote, comprehensive education of every citizen in science of government, well how can you afford that when most of them are going to be laborers? Because them having a strong background in history and in political science and social science and infrastructural tech stack, does that help them be better farmers? Not really, it helps them be better citizens in government but not better farmers. And so how do we afford to pay for all of that additional education and how do they maintain that knowledge when they’re just engaged in a labor-type dynamic? And so this is why the children of the elite who are actually going to become lobbyists and senators and whatever go to that private school and get that education. Well now we have this AI and robotic technological unemployment issue coming up, and it’s definitely coming up. Well, the things that it will be obsoleting first are the things that take the least unique human capabilities, because those are the easiest to automate, so labor-type things. So either this is an apocalypse that just increases wealth inequality and everybody’s homeless and fucked or on the absolute minimum amount of basic income so the elites can keep running the robots as serfs rather than the people as serfs. And just hook the people up to Oculus with a basic income so they don’t get in the way. Or this actually makes possible a much higher education of everyone so they can be engaged in higher-level types of activities." - [Daniel Schmachtenberger](https://youtu.be/YPJug0s2u4w?t=8351)

> "Let’s say we look at a particular group and we can predict how they’re going to respond to something we’re going to say with quite high accuracy. So we can take a particular woke SJW group and if we have a conversation of a certain type, we can predict that they’ll say oh that thing you’re calling dialectic is giving platform to racists when you should be canceling them, therefore you’re racist by association, or whatever. You can take a QAnon group and predict that they are going to say that because we talk to someone that was four steps away from Epstein in a network that we are probably part of the deep state cabal of pedophiles or whatever it is. And to the degree that people have responses that can be predicted better than a GPT-3 algorithm, they can’t really be considered a general intelligence. They are just a memetic propagator, they are taking in memes, rejecting the ones that don’t fit with the meme complex, taking in the ones that do fit, and then propagating them. And I think if people think about that, they should feel badly about not being someone who’s actually thinking on their own and being a highly predictable memetic propagator. And be like, I would like to have thoughts that are not more predictable than a GPT-3 algorithm, I would like to know what my own thoughts about this are. And in order to know what my own thoughts about it are, can I even understand and inhabit how other people think all the things that they think? So that’s one thing, because it’s not only going through the filters like Facebook, it’s going through the filters of the fact that people have these memetic complexes that keep them from thinking. And so the cultural value of trying to understand other people so that we can compromise, because politics is a way to sublimate warfare. And if you don’t understand each other and compromise you get war, and the people who are saying yes let’s bring on the war, they’re just fucking dumb. They just don’t understand what war is actually like, they haven’t been in it." - [Daniel Schmachtenberger](https://youtu.be/YPJug0s2u4w?t=8670)

> "We don’t live in an authoritarian state, but we live in a state in which thought is policed as if we did. Not perfectly, but enough that one who wishes to escape from the accepted, the sanitized narrative has to be ready for what happens next. And that’s something that is, it’s very hard to generate that. In other words it’s a developmental process that causes you to learn how to navigate that space so somebody who just simply recognizes I don’t want to be an automaton and I’m going to start thinking for myself, if their next move is to start thinking for themselves and speaking openly about it, what comes back next is something for which we don’t have a good response." - [Bret Weinstein](https://youtu.be/YPJug0s2u4w?t=8926)

> "Earlier you said, when you were defining at the beginning of our conversation what you meant by independent thinker is someone who wants to go wherever the facts and information that are well-verifiable actually lead them. I would say that there’s something like the spirit of science, which is a reverence and respect for reality, where I want to know what is real and be with what’s real more than I want to hold a particular belief no matter how cherished or whatever ingroup I’m a part of. And the uncomfort of not belonging with the ingroup—if I want to belong with anything I actually want to have a belonging with reality first. And a belonging with my own integrity. And then with those who also share that. And that the other belongings that I give up, I don’t stop caring about those people. I care about them still, but I don’t necessarily care about their opinion of me enough that I’m willing to distort my own relationship with reality." - [Daniel Schmachtenberger](https://youtu.be/YPJug0s2u4w?t=8977)

> "The thing about the flat Earth is that the hypothesis is formally falsifiable. And the alternative hypothesis is formally verifiable with the best methods that we have, with the highest confidence we can have. And now one thing I would still say is interesting is, I know many people who refer to flat-earthers as the moniker of maximum stupidity who cannot do the Copernican proof. So they take as an article of faith that the Earth is round, but they actually don’t know how to derive it, have never tried, and so then they also move to taking as an article of faith similar things that don’t have the same basis. So does someone even understand what falsifiable and verifiable mean? Does someone have a basis for calibrating their confidence margin? Because if I start to talk about the moon landing, or then I go a little bit further and talk about long-term autoimmune effects or epigenetic drift or whatever that come from a vaccine schedule of 72 vaccines together, is the standard narrative verifiable? Is the alternate narrative falsifiable in the way flat Earth is? No. So the fact that we put flat Earth and anti-vax in the same category is an intellectually dishonest bad thing to do. But the fact is that most people don’t even know how to do verify or falsify. And so with the lab hypothesis, when you come to 90% I’m guessing you have a process for that. What I would say is, I haven’t studied it enough to put a percentage because I don’t have enough Bayesian priors to actually come up with a mathematical number. What I would say is I consider the idea of it coming from a lab in some kind of dual purpose gain of function research to be very plausible, and I have seen nothing that falsifies that. And the few attempts that I saw early to falsify it were theoretically invalid to me. Now to be able to go from plausible to a probability number I would need to apply different epistemic tools than I have already applied." - [Daniel Schmachtenberger](https://youtu.be/YPJug0s2u4w?t=9302)

> "So, I think this is actually one of the most interesting applications of blockchain or decentralized ledger technology is this idea of an open science platform. So imagine every time someone did a measurement, the fundamental measurement, it had to be entered into a blockchain, and then the other places that independently did it was entered into a blockchain so it was uncorruptible. And then the axioms and the kind of logical propositions get entered in, and then the logical processes of whether I’m using an inductive or deductive or abductive process gets put in. And then we get to kind of look at the progression of knowledge. Then at any point that we come to realize that a previous thing in there was wrong, some data was misentered or a hypothesis is proved wrong, now we can come back to that point and look at everything downstream from it and re-analyze it. Of course you still have the oracle problem of the entry in the first place. So if I’m doing motivated science and I get some answers I don’t like and I can hide them and not enter them, then that’ll happen. So you still have to have then the proper entry into the system, but this addresses something with the integrity of science and also the integrity of government. Government spending and the capture of market forces of the regulators rather than the regulators being able to regulate the market, is we only know when the fucked up thing happens if we can see it. Which means that everyone who wants to do something asymmetric or predatory has a maximum incentive for non-transparency. So certain kinds of uncorruptibility and transparency are very interesting in what they can do towards that." - [Daniel Schmachtenberger](https://youtu.be/YPJug0s2u4w?t=10093)

> "It’s easy to look at the nature of the problems and just assume that we are fucked and usually to tie that to some conversation about human nature. And to say ok well we were able to figure out technology that was extraordinarily powerful, to speak mytho-poetically, the power of gods. The nuke was clearly the power of gods. And then lots of tech since then. We can genetically engineer new species, gain of function, whatever. Without the love and wisdom of gods, that goes in a self-terminate direction. Is it within the capacity of our nature to move towards the love and wisdom of gods to bind that power, or are we inexorably inadequate vessels for the amount of power we have? So then I do a positive deviant analysis to look at what are the best stories of human nature to see if they converge in the right direction. And then also where there are conditioning factors that we take for granted because they’ve become ubiquitous and think that they’re nature? So if we go back to the Bible for a moment and we look at Jews, and we look at was there a population of people that were able to educate all of their people at a higher level than most other people around them for a pretty long time in lots of different circumstances? Yes. You look at the Buddhists. Were there a population of people that across millennia and different environments were able to make everybody peaceful enough to not hurt bugs? Yes. Across all the genetic variants and across all of the economic factors and the whatever else, do we have examples of very high level of cognitive development and very high level of ethical development of different populations based on cultures? We do. And then we say oh well but look at how well the founding fathers’ ideas failed here. Well the comprehensive education of everyone is not in the interests of the elite that have the most power as we’ve mentioned, and so making it seem like that that’s an impossible thing is actually really good to support the idea that there should be some kind of nobility or aristocracy or something like that. There should be elites who control because they’re more qualified. I would say that we have not in modern times ever tried to educate our population in a way that could lead to self-governance because there was no incentive to do so. Or those who had the most capacity had incentive to do something else even when they said they were doing that. So do I think that it’s possible? Do I think that we have examples historically of people who developed themselves cognitively and ethically enough that if we did those together, Buddhist-Jews, however we want to talk about it, do I think that’s possible within human nature and basically untried? Yes." - [Daniel Schmachtenberger](https://youtu.be/YPJug0s2u4w?t=11120)



> "**Daniel**: It sounds like the key thing that you shared in there is the increase in sharing and transparency, and thus collaboration, and thus collective intelligence and collective capacity, where the current incentive structure incentivizes owning and hoarding IP and making sure nobody else uses the things that you discovered, because you're going to make your money on patents, and not sharing what you're learning until it's published, because the whole thing is published. Really what you're talking about is the ability to change the information ecology, the incentives that change the information ecology from ones that incentivize hoarding information and making it hard for other people to use — they have to pay for a license — and even disinforming, to one that maximizes informing, sharing, and collaboration. **Jordan G**: Yeah, and I think there's actually two key pieces to that. The first we've talked about a little bit, which is the ability to keep records, or as our friend, Michael Vassar, talks about it, the ability to actually deliver justice, which he defines as making sure that the loops are closed, the value created needs to be value returned, and that externalities need to be returned to the creators of externalities, all right? If you have injustice, if you have bad records in a system, if you don't have the ability to determine who created how much value and who created how much externality and thereby return it, then you get a system that drifts quite rapidly, and where a lot of strategies are about stealing credit and avoiding responsibility. That's one piece for this, and one piece is just radically increasing the quality of the records that are being kept, and therefore closing more and more loops, which is to say creating more and more justice. Then the other side of the equation actually has to go to stuff like- **Daniel**: As soon as you say "more justice," you also mean more incentive to actually do the right things rather than the wrong things. **Jordan G**: Yeah, and intrinsically, just very simply. It's not that people have to become more pro bono. It's just that the good things they do will be noticed and rewarded, and the bad things they do will be noticed and punished, done. It's pretty simple. That's straightforward. As long as you can provide a framework where people have clean boundaries, and good choices are awarded and bad choices are punished, they will begin to move in that direction, and they'll begin to move in that direction en masse. The other has to do with the notion of the theory of the firm- **Daniel**: Before you go to- **Jordan G**: Oh, go ahead. **Daniel**: Theory of the firm- You and I have had the benefit of having Michael Vassar spend a lot of time explaining this model to us. I think a lot of people think that markets do what you just said, that we live within capitalism, capitalism's based on market theory, and that markets are supposed to reward the things that are good and not reward the things that are bad, and therefore you get a natural evolutionary dynamics of good stuff, and it's kind of how evolution itself works. **Jordan G**: Sure. **Daniel**: Why is that not true? Let's just assume that someone's listening to this, thinking that markets already do that. Why is that not currently the case? **Jordan G**: Well, I think a big part of it has to do with this notion that gold hath no smell, meaning that, again, person A shows up in the market with 10 apples, and person B shows up in the market with five apples. The fact that person A stole those apples from person B is simply that the market may have no capacity to proceed at all. In fact, we don't even think about that as a market transaction. That's called justice. What we say is, "Okay, well person B then needs to find some way to sue or otherwise rebalance the underlying infrastructure," so what we think about then is that the market is consisting of a whole bunch of little circles that are communicating with each other through transactions, and it doesn't actually have any information outside of that information flow. It has an inability to perceive all the different ways that somebody might actually falsify the stuff that the market actually needs to be able to make good choices, meaning that if you think about the game, like they start off with "do the right thing," and it slides all the way down. If everybody who's playing the market game is self-enforcing to do the right thing — social norms really, really work, and anybody who plays in anything but the most virtuous way is selected, again, through their normative channel, then the markets will actually tend to do a pretty good job. Well, there's more to it than that. I mean, there's a whole bunch of other stuff to think about, but that's one that we can focus on right here. Since markets actually have very little ability to perceive that kind of a thing that they outsource that to other areas, social norms, laws, et cetera, that's the channel you gain. All right, you gain that channel, and so you show up as a really great market player. You're a bank. You've got a giant fucking building with marble columns and actually completely covered in marble and have trusted people wearing fancy suits, that all signal certain things that the market can perceive, but the gap between signal and the thing being signified is something the market has effectively no capacity to perceive at all, and that, then, becomes the game. When you move more and more and more power and choice making into the market, you end up basically creating a niche for gaming what the market can't perceive and simulating what the market perceives as being a good answer. Then you're on that slide, right? Do what is most profitable, highest money for money return. The market sees that as positive signal, and you're riding the sleigh down the hill. **Daniel**: Is there more on that? **Jordan G**: Damn sure, I mean there's lots more. Do you want to keep exploring that space? **Daniel**: No, I think it's good. I think it's important for ... I think most people today have some sense of how much greenwashing and various forms of we are saying we're doing a good thing as part of the marketing budget more than the actual product budget of really doing a good thing proliferates, and I don't think most people think the amount of money that's been made in derivatives as a market corresponds to real goods and services that benefit the lives of most people. **Jordan G**: Right. Let me just ... We can actually say this extremely simply. If people who are in control of the money supply printed all the money and gave it to themselves, the market would have absolutely no idea and no way of responding to that fact, right? It's like the brain and heroin. By itself, the way the brain responds to simulated neurotransmitters, it has a really hard time being able to tell the difference internally. The only way you can respond to the notion of mass counterfeiting of money is through a completely different channel, not known as the market. Now, of course, you could try to invent ways to simulate that. Okay, well, all right, fine, what we'll do is we'll create agencies that we're calling anti-counterfeit agencies that we will pay to enforce this. We thought, okay, cool. Now, what we're doing is we're trying to create market mechanisms to instantiate other kinds of social functions, and that's a second order solution. We should be very mindful that it's second order, not first order. It actually requires us to be thinking about this different modality and then using market mechanisms to do it. What we end up in, then, is a regression. **Daniel**: Then, of course, you have the scenario where the lobbyists that are making the laws are getting paid for by somebody, and that means they're getting paid for by the groups that have enough money to pay for them, that then work on creating legislation in their own interest, and the campaign budgets for the politicians, and the et cetera, et cetera. **Jordan G**: Right, and this again gets back to that notion of justice, injustice, and record keeping, that if you actually happen to have ... Well, there's a limit to this, but if you happen to have something that was just really, really good recordkeeping, and you have really high quality ability to measure who's doing what to whom, what are the various interests, and everything else, then the ability for, particularly, a decentralized system to make good choices, a marketing system, is relatively high. The less high quality of recordkeeping, the less high quality or ability to perceive reality and have a history, a real history of what's going on, the less effective those kinds of mechanisms are going to be. Then, of course, there's the actual limit, which is- **Daniel**: That's where blockchain is actually valuable. **Jordan G**: That's where and why blockchain is a very interesting solution. The other piece is just the limits of understanding that, past a certain amount of information velocity, you just get lost in the fire hose, no matter how accurate your records are. Let's assume there's a 100% chance that, with an adequate amount of investigation, you'd be able to know that I had just cheated you, but that so much craziness is going on constantly that I'm also quite able to make a bet that I can cheat you in the likelihood that you're going to be able to traverse the information flow, within the time that it's worth to you and with the attention that you have, to close the loop on me. That bet's going to keep being made. What will end up happening is we'll basically invert it into the defraud equivalent of high speed trading, which may, in fact, just be defraud. It may not be the equivalent. High speed trading may just be fraud, but the point is that I can defraud you so quickly and at such a low cost that you can't actually close the loop, and therefore again I've found another solution to the problem. Let's get back really quickly to the notion of Coase, because I think it's actually quite interesting in the concept of thinking about how this shows up in places like medicine and pharma. Coase, who is an economist at University of Chicago, where things like "markets make good choices" was the theology, was wondering, well, okay, if individual economic actors make good choices, in fact make better choices than centralized entities do, then why the fuck do we have companies? What's going on here? Why do these things show up? Of course, he said, "Oh, the reason for that is because there's another thing going on called transaction costs, and that market transactions have higher transaction costs than the transaction costs that sit inside some kind of pre-associated envelope." If you and I agree that we're going to split the returns on our activities 50/50, so we don't have to make any more negotiations past that first negotiation, now we're a partnership, and we can now both just throw it into making that thing work very quickly. We don't have to rethink about it. We just are very creative at the edge; whereas, if every single time either one of us does something, we're constantly having to renegotiate some kind of transaction, the cost of negotiation, and by the way the cost of monitoring and the cost of interpreting and enforcing, goes through the roof. What ends up happening is the market collapses into a series of firms that are defined by a boundary where, on the inside of the boundary, you've got a whole bunch of agreements that solve the transaction cost problem, and a lot of people to coordinate in a very high velocity, low cost way. Then, those firms then do the market transactions back and forth between each other. Now, that obviously works. It built the 20th century and even earlier, but it runs into boundary condition problems, where, for example, information inside one of these envelopes can't easily translate and connect to the information outside one of these envelopes. For example, let's say you had Apple and Google. Inside Apple there were three engineers who had developed something really interesting and important, and inside Google there were three engineers who developed something really interesting and important. In both cases, the missing piece was the opposite innovation, where if they're able to connect those dots something 100 times more powerful would emerge, but because they're inside those envelopes, not only is there no obvious way to make that connection happen, it's in fact actively inhibited, in fact possibly even illegal for them to cross those boundaries. This is the point. In the blockchain environment, we may be in a circumstance where, through automation of contracts, smart contracts — say, if we're in Ethereum — we can radically reduce transaction costs by maybe a factor of 1000 and, as a consequence, collapse most of the economic utility associated with large-scale and long-enduring firms and therefore get a whole lot more of the surface area, this innovation, exposed to a broader shareable environment and, by the way, also do it in a way that enables, as you said earlier, sharing to make sense, meaning, on the one hand, recordkeeping is better. The innovators themselves are able to have high confidence that their value will actually loop back and connect. On the other hand, you have ways of wiring and incentive structures who could do things like actually consider the commons as a commons and build into code rather than build into, say, norms or law, ways of enforcing the commons against strategies of the commons and things like that." - [Daniel Schmachtenberger & Jordan Hall](https://youtu.be/OUv-ZOM0dOo?t=2540)

> "I don't know if you ever saw it. There was a paper Alfred North Whitehead wrote on the problem of hyperspecialization, that was speaking to this model. It was meaningful to me. He said the kids that seem smart or more talented, we push them into specialization younger, and then we push them further and further into specialization, so by the time they finish their PhD, it is on the most narrow subfield of molecular biology or string theory that only a few other people in the world know, and so none of the people that have a lot of cognitive horsepower are ever looking at the whole, which, if the whole wants to not be disturbed, you would try and make it do that, right? You would make them very sharp gears inside the machine, but not something that was looking at redesigning the machine as a whole. Then, the people who are left to actually look at the whole and what's wrong with it, in externality, are people that didn't do that well in the system as a whole. Now, we're in a world where we have to actually redesign the entire system, the whole game, and that requires a different set of thinking than how to optimize some tiny part of it." - [Daniel Schmachtenberger](https://youtu.be/OUv-ZOM0dOo?t=4537)

> "Okay, so I want to restate and underline something that Jordan just said, for everyone listening, because it's so key. He's talking about the feedback loops here, so wait, is it that demand drives supply or is it that supply drives demand? It's very much both, and it's really critical to get that, of course, originally demand drives supply. More people want something, and supply steps up, but then you have a real source of supply and you want to manufacture. You want to protect the demand, because otherwise your business goes out, and maybe manufacture more demand, and that looks like marketing, and that looks like whatever to create manufactured demand, so supply is driving demand, demand is driving supply, and you can get feedback loops that move in the wrong direction, move in the direction of society, as a whole, getting worse. Similarly, we have dynamics where this very much just addressed one of the core differences between what the rational left-right argument has largely been about. Do individuals create the whole, so you want to optimize for the sovereignty of the individuals, or are the individuals affected by the whole, so you want to make good social systems that make good individuals? It's very much both. You want to make good educational systems, good economic systems, that condition better people. You also want to make more sovereign people that lead to better whole systems. When we start thinking about these feedback loops, and the same is true with if someone is in an economic system that's causing certain kinds of stress and certain kinds of behavior, does that affect their brain and their health? Yes, but if we also are ... does someone's ... What they're doing with their diet and with their physicality that's affecting their brain and health then affect the decisions that they make in the world? Yes, it's very much both, and so mind-brain interface is a classic one, like supply and demand, like individual and collective, and to really get the basins of attraction right, we have to not think about either/or. We have to think about the synergies in the feedback loops." - [Daniel Schmachtenberger](https://youtu.be/OUv-ZOM0dOo?t=6118)




> "Money equals optionality to do lots of things. So money is a decentralized incentive system to incentivize people to figure out how to get better at making it and which means novelty search and optimization do a better job of whatever you already figured out how to do. And obviously you can make money via production but also extraction, you can make money via value adding but also externalization of cost. And so when we're talking about organizing towards these other purposes, towards a fundamentally different mastery, you might still have to figure out how to pay your bills, but it's not what is motivating you. Still, you will need to be in coordination with other people who are similarly motivated to you but have different capacities. Now can we come back to externalities, how to avoid externalities?" - [Daniel Schmachtenberger](https://youtu.be/Kep8Fi_rUUI?t=2081)

> "Externalities, it asks questions like if you're looking at a problem, whether it's healthcare in my town or too many extragenic deaths at my hospital or why there's so much soil erosion in this area or so much government corruption or whatever it is. In the assessment, there are questions that are universally relevant. Where in this system are there perverse incentives? Just see if we can start to map where anyone has a financial incentive or a status incentive or a cover your ass incentive that is not aligned with doing the maximally good thing to the whole and honestly, just by starting to notice that and not in a partisan way, in the bipartisan all directions way, you'll start to be like, "Oh well of course this thing isn't going well because there are these perverse incentives."" - [Daniel Schmachtenberger](https://youtu.be/Kep8Fi_rUUI?t=2241)

> "When David Bohm and Krishnamurti had their dialogues in the eighties on what is the fundamental cause of all of the meta crisis, the way they talked about what is the fundamental cause of human conflict that leads to poor coordination and poor management. And David Bohm said it was fragmented consciousness. The underlying issue is being able to separate us versus them and benefit us at the expense of them. But they're just as smart and they up-regulate stuff and so we just get arms races that make the wars larger and larger in their potential or me versus you. So we get class systems and everybody fucking each other, even within the us, we'll be in us when it comes to this nation versus that nation. But we'll be an us when it comes to our company versus their company. But me versus you when it comes to ladder climbing within the company and office politics or our species versus the other species in the Earth or the right now benefit relative to the long term harm. The ability to separate things that are in truth connected to benefit one part while harming another part, but that ultimately those causal loops come back to harm everything, the cause of all the problems is that, it is a consciousness that doesn't see how it all connects. If you see how it all connects and then you tend to all of it, only then, only that is considerate enough to manage the power of exponential tech... The capability to take this whole totality of experience and then start naming everything and making things separate. Having a semantic interface, being able to have a symbol that I can... that relates to, represents the ground but is not the ground. This is what makes us so powerful is because we can up-regulate one part relative to another part. Our tool making is the ability to take my fist and say I want more of that and make a hammer, right? A stone tool or take my ability to bite something and make a sharp knife. Or it's the ability to say I want more of this part and how do I increase it, but increase it at the expense of what? What is becoming less, where is the cost happening if our technology is not that much and there's not that many of us? So what? So when our technology becomes profound and there's lots of us, then it's a big so what. Then the us versus them can equal a war that kills everybody. And the us versus nature equals planetary boundaries that kills everybody. So the same consciousness that was viable because there were not that many of us and our tech was not that big, but the poor stewardship of tech, the poor stewardship of our power, meaning poor in terms of whatever we're externalizing the harm to, that same mindset does not get to steward exponential power. It self-terminates. So either if we are to not self-terminate, we must have the wisdom to be able to steward exponential power. And it is something like exponentially more wisdom than we have been operating with. And it's not impossible, but it is... And this is where we said culture, political economy, tech. There is some radical cultural shifts that have to occur to instantiate a political economy that is the will of the people. But where the will of the people is not a will that wants to benefit some people at the expense of others and some people in the moment at the expense of our future and people at the expense of nature. If the government that is going to bind the tech and the economics is not an instantiation of the will of the people, it'll be oppressive and then it has to justify violence to oppress the people and then it'll become corrupt and whatever. So the government has to be an expression of the will of the people. But if it's a will of the people who want what harms each other, that also doesn't work. So you have to basically do the culture work to have people recognize that which they're fundamentally interconnected with to then be able to have that expressed in a system of law that binds the economics that can bind, guide and direct the tech, which is where the physical power is, to be viable... On externalities it's important to say, so how do you think through externalities better to avoid them? So we were saying think through the upstream stuff because if you don't solve some of the upstream causes of the problem, it's very likely they will be displayed somewhere else. Think about the downstream stuff of whatever you're going to do so that you aren't going to cause problems as something else that matters. Example. I'm wanting to bring food to people in an area where there's food insecurity. Is my strategy going to increase the power of warlords to be able to capture huge surpluses of food and increase harm, that type of political incivility in the area? Is it going to create increased dependency on other countries that are going to actually erode the culture of the people feeling like they have any agency? Is it going to use agricultural methods that actually kill more pollinators and more top soil and cause more dead zones in oceans? And those are not the core problem I was trying to solve. I was trying to solve food insecurity, but I don't want to make warlords worse. I don't want to erode the will of the people, feeling they have no agency and I don't want to ruin the environment. So I have to say, how do I think about this problem and how do I think about the connected problems well enough? Because can I bring sustainable agriculture, permaculture type things that don't hurt the soil, actually make the soil better and grow it rather than not, that are inherently decentralizing, rather than centralizing so they don't cause the warlord thing, that increase the agency of the people? It just means we have to deepen the understanding of the problem space enough to notice which solutions will be viable. **Nate Hagens**: You're really talking about embedding systems, thinking systems, ecology in a central role in our governance systems... But we have no incentive to be systems thinkers in our culture right now unless you're a hedge fund or a teacher. **Daniel Schmachtenberger**: Well, two things, not all motivation is extrinsic. Incentive is an extrinsic motivator where someone else is getting you to do something and where I'm doing it because of what I get out of it, not because of my intrinsic motivation to the thing itself. So if I am trying to run a civilization where there's a lot of labor to do and nobody really wants to do all the labor and so we have to incent them to do the labor because otherwise we have to beat them to do the labor. So we can end slavery by having a wage slavery or something like that. But people aren't doing the thing 'cause they want to do it, they're doing the thing 'cause they want the money for some other purpose. Intrinsic motive is also a thing. So people's value systems, the culture work is, I do certain things not because I'm going to get anything financially from it or necessarily even status from it, but because I just intrinsically care about the thing. So one is, we're talking, I think most of the people listening are spending hours listening to this thing and they're not getting paid to listen to this. And some of them might be taking this to their job as a consultant because they sound smarter and they get paid. But probably mostly not, probably they're investing time doing this because they just authentically care independent of incentive. I think the future is defined much less by extrinsic motivators and much more by intrinsic motivators. This doesn't mean there won't be any extrinsic ones. So of course we have to design our incentives and our deterrents better. We have to solve for perverse incentives and like that. But that's not the whole of the story. It shouldn't even be most of the story. And then there is also an incentive to care about these things, which is non-extinction is a good incentive just even from a personal extrinsic point of view. If I don't work to affect the world's trajectory and if I don't work to help other people to affect the world's trajectory, it might preclude anything that I care about. So I would say there is not an incentive in the formal monetary systemic sense for a lot of people, but that does not mean that there's not both intrinsic and extrinsic reasons if you pay attention. Okay. So we were saying upstream, downstream things, externalities, we were saying the solution is generally oriented to produce a first order effect on a small number of defined variables. But we have to think through the second, third, fourth order effects on a large number of variables that we don't know. How do we do that? The first part is I want people to endeavor to do it completely while knowing they never can. Your best externality analysis will still miss shit, that there's no way you could have thought of. But I want you to try to think of everything as best you can and then knowing that you didn't think of everything, I want you to have some kind of broad listening and watching after you do it to see what might be being affected that you wouldn't have even expected. And did we expect when smartphones came out that they would have the effect on dinner tables or human attention in relationships or porn addiction or people's ability to study or... we didn't expect those things, we might have anticipated some. So anticipate all the things you can, but also maybe even in the visual human focal length, the focusing on 2D things that affect focal length so much of the time and the effect of losing our navigation and orientation and what other things that does neuro-psychologically. So what I would say is you have to do the best job of anticipating externalities you can, while recognizing there will be ones you didn't anticipate. So you want some very broad diffused listening to say, after we started this thing, what new things started to occur that might have been connected? **Nate Hagens**: Are you kind of talking about the precautionary principle? **Daniel Schmachtenberger**: Totally. But I'm talking about specifically how to think about applying it. Right? And so we're talking about a wholistic principle and a precautionary principle, but we're trying to formalize it as a way that people can think about applying this thing. So first, how do you think through the externalities on second, third, fourth order effects? By talking to more people with different perspectives about the thing. That's the first really key part. This is where diversity of perspective and pluralism is really a real thing. If I'm thinking, okay, I'm going to solve this issue, or I'm going to protect this area of the Amazon from being harmed by this combination of law regarding mining rights and regarding agriculture rights and etc. Okay, cool, sounds good. Go to the indigenous people about the solution and they'll be like, "No, no, no. There's some other groups that did things like that. And here's what happens. They just hire mercenaries that do this thing, or it gets worse for this reason or whatever". And you're like, "Oh, fuck. I didn't know that". And go talk to the legal scholars and they're like, "Oh, there's no way to implement this in law because of such and such". And go talk to the economists who are like, "Law is written by lobbyists and they have more money to keep writing law than you do. You're going to lose this one". And go talk to the environmental scientists and they'll be like, "Actually, you're protecting the wrong part of the forest. There's not even high biodiversity here relative to this area." And so there's a lot of people who will know stuff that you don't know and they will be able to see where some of the externalities will occur, including people that are on the opposite political side of the thing. Whoever would fight against it, there's something that they care about that is real. Even if they're wrong about some stuff, they're not wrong about 100% of everything. So finding out why do they not like it and say, "How can I factor that in, so one, I can not cause the problems for them and as a result, decrease their enmity and maybe get them as allies rather than fighting the thing". You'll become both more successful and it'll be a better solution. So the way to think through externalities better is when you come up with a possible solution, talk to lots of people about what might be wrong with it. So red team it, but then don't give up, say them, okay, how would you make it better to still serve the thing I'm wanting to serve, but to improve the thing that you're seeing? And so you use it as a proposition or design refinement process. And so that's the first part. And then the second part is once you implement it, try to implement it in experimental ways. You have some safe to fail probes. You don't implement the largest thing possible. Okay, I think we figured out that this version of AI or this genetically modified organism is safe. Let's just fucking take it everywhere. Maybe our safety experiments were not totally complete. Let's do contained experiments. So the first thing is think through it well, right? Which you can't do on your own. The next part is run some experiments and try to, if you missed stuff that will show up in the experiment, try to do it in a contained way and then as you implement it at scale, there will still be stuff that you missed. So have a broad listening and ensure that when you find where something is being harmed and you need to change the strategy, it doesn't mean you stop - it means you update it, that you maintain the governance capacity to do so, that you haven't turned it over to where now that it's initiated, the fiduciary responsibility to shareholders means you can never change that thing or whatever. Ensure that the governance structure is such that when we learn new stuff, the underlying thing can be changed. ... I think this is the thing that I would arguably like to start with at some, but if someone doesn't have the meta crisis frame, it's not obvious that the way we try to solve problems is the cause of the other problems and is a major part of the generator function of the meta crisis. And so once you've understood that, then you can be like, okay, so a part of how we solve it is by a much more holistic set of frames in how we go about doing things. And now I don't think this is impossibly hard to teach or train. I think this should be being trained in K through 12 education at various levels of development. I think that people who are learning anything from design science to becoming technologists to being lawyers or studying political economy should be thinking and being trained in these things and thinking through the specifics in their domains. Okay, now the next part is I want to identify two types of externalities, physical externalities and psychosocial externalities. A physical externality is where we do something to benefit. We do something that has a physical effect to benefit something, but part of the supply chain of that thing happening causes some physical harm somewhere. So we want water repellent coats and water repellent umbrellas and everything like that. And we want industrial surfactants. So we make fluorinated surfactants to be able to do that. But then they go into the water supply and they're forever chemicals and they never break down and they're carcinogens and endocrine disruptors and neurotoxins. So that's where we want an herbicide to make agriculture more effective, but it messes up the soil bacteria and human health and whatever. Those are classic examples of physical externalities. Obviously CO2 and climate change is a physical externality. No one is intending to cause climate change, they just want to generate energy. So everybody knows physical externalities. They didn't use to, but Rachel Carlson and friend got people thinking about that, now I think everybody is at least somewhat aware, but that the supply chains that make anything happen have lots of effects. That's physical externalities. There are also psychosocial... **Nate Hagens**: Just a point on that is the physical benefits we get in terms of profits or services aren't on equal footing with the negative externalities that Rachel Carson warned about and others, because those things happen in the future and we're a biological species. So emotionally and culturally they have very little weight in our brains. So that's why this stuff has happened because our capitalist exponential system has back loaded some of those costs that are second, third order effects from our decisions and our products. **Daniel Schmachtenberger**: Great. I'd actually like to explain a few reasons why it happens. So one is a lot of the harms will occur in the future, but the benefits occur now. And so there is a perverse orientation to now. It's also that whoever does the thing that provides more advantage now, probably wins, having more power to influence the overall system and those who don't do the thing that will cause the future harm, also don't get the power and then don't influence the whole system. So there's a perverse incentive, not just a psychological bias. There's also a game theoretical perverse incentive to do that thing. It's also true that as we were mentioning earlier, making a tech that produces a certain benefit is epistemologically easier than preventing all of the harms from doing so because creating a first order effect on a small number of metrics is just epistemically easier than considering end order effects on a very large number of undefined metrics. So there is also something epistemically about it. And then the other thing is that many of the problems only occur through very large scale cumulative action, but the individual action produces my benefit. If I cut this tree down, I get money from the lumber, but I have just as much air to breathe. It's everybody cutting it down that messes up the atmosphere. But me not cutting this tree down doesn't make any seeming difference to the atmosphere, but it does make a difference to my balance sheet. So each person, the risk reward ratio orients them to do the thing because the harm is more collective and the benefit is more personal. You have to factor all of those asymmetries. And then one version of this that I want to point out for people is that there's obviously many narratives that tech will make everything better. AI will solve all of our problems, and healthcare is going to become awesome with genetic engineering and immuno-oncology and all those things. And nano tech is going to make environmentally friendly everything. Manufacturing and capitalism makes things better. There's obviously many narratives like the environment is fucked and was only positive for a few and the result of colonialism and et cetera. There's partial truth to both of these and there's obviously risks associated with AI that some people are aware of and benefits or of any tech, but there is a perverse incentive that's worth paying attention to that those who focus on the opportunity more than the risk, will get ahead more than those that focus on avoiding the risk more than their own advancement of the opportunity. **Nate Hagens**: Even in our hunter-gatherer days, that was probably true. **Daniel Schmachtenberger**: And well even more now because the hunter, if he did something too risky, he might have died. Now I socialize the losses of the risk. I can declare a bankruptcy. I'm not going to go to jail, limited liability corporation is just going to take a bit of a loss, whatever. So I get to privatize the gains and socialize the losses. We can do an oil spill, it's not going to hurt me as the executive, but I am going to make money when I exploit more oil. And so the ability to privatize gain, socialized losses, the ability to cause some new tech, Facebook, social media destroying democracy and the social contract and the epistemic commons, and yet no accountability for that thing, but just a fuck ton profit, I can always say afterwards, oh, there's no way we could have known. But nobody tried to do the external calculus that I'm mentioning or to the degree that anyone did they said, "Shut up, we don't want to hear that". And the focus was, it's going to be amazing. It's going to connect the world, it's going to whatever the narrative of you're being too negative, let's focus on the opportunity. Whoever runs that narrative will get wealthier and be able to up regulate the narrative and show the success and highlighting the thing. **Nate Hagens**: Well, you've just described why I am poor and still teaching, but go on. **Daniel Schmachtenberger**: So as we move forward toward the tech now where one, we can't keep externalizing cost to the commons because we're too close to planetary boundaries and the world is too fragile. And two, the new tech is way too fucking powerful. The speed at which everyone got smartphones compared to the speed at which everyone got railroad or the plow, right? It was like thousands of years for the whole world to get the plow. A hundred years for a railroad, less than 10 years on the phone. It's like the speed and scope of impact. And then you start to think about genetically modified or synthetic biology and AI. We can't keep externalizing exponential - We can't keep externalizing harm with exponential tech. So we have to get much more fucking careful on the risk reward side and get less reward seeking and willing to externalize risk as a whole society. If we're going to make it, we actually have to get much more conscious of that. **Nate Hagens**: And the default in 47 years is one human is worth a quadrillion dollars, everyone else is serfs and it's a dead planet. **Daniel Schmachtenberger**: Yeah, that's one of the futures that we're not that interested in. **Nate Hagens**: Okay, where are we? I interrupted you a couple times. Are you on track? You had another part of the externalities that I kicked you off. **Daniel Schmachtenberger**: Yes. Psychosocial externalities. So there are physical externalities and the physical externalities we're clear on, they produce a physical harm on the environment or human health. The psychosocial externality, and they're not always perfectly preventable sometimes that you have to manage them. Like I'm on a laptop right now. One of the externalities of the convenience to being able to carry this computer as opposed to a desktop is that it's going to mess my neck up. And almost everybody today has neck issues because they look down too much and we're not supposed to look down physiologically, evolutionarily that much. So at home, set your monitor up and you get the proper C-curvature in the cervical vertebrae. I might not be able to have the benefit of portability and not have that, but I can at least say, all right, well don't be lazy and stay on the laptop when I get home. Really do get a raised monitor, so the physical externalities don't only look like effects on the environment. They also look like the ergonomic effects and the behavioral effects and lots and lots of things. **Nate Hagens**: A tiny, tiny observation. I knew everything you just said, but the social mirror neuron cultural evolution, while you were saying that, I straightened up in my chair a little bit subconsciously. So thanks. **Daniel Schmachtenberger**: Funny how that works. So the psychosocial externality is that my technology or my movement or my whatever might also have an effect on people's experience, people's emotions, beliefs, identities, not just individually, which has a psychological effect, but collectively, which has a sociological effect. And I'll give a couple examples. One of the biggest examples is anything that has to do with trying to win the minds and hearts of people, like how do we get people to really care about the climate change, the mask wearing, the vaccine, the whatever the thing is. Typically, we and particularly recently egregiously, we focus on who our intended audiences and how to be able to get a political effect from that intended audience. And we don't focus that much on how the people that will not agree with this respond. And there are many reasons for this. In the US, which has such an outsized media influence on much of the rest of the world, the nature of a bipartisan political situation and not having something like ranked choice voting is such that putting the other candidate down and saying how bad they are and it'll be catastrophic if they get in, is actually a very empirically effective way to get people to vote, or at least it has been. But of course that other side then does the same thing. If one side figured out a really effective communication strategy, the other side makes some innovations, comes back. So one side gets in and they do whatever they do for four years. The other side comes in and then undoes all that for four years. And most of the energy of the whole system just goes to infighting waste heat and no long term continuity. So we have to stop that shit. That is so critical. So one thing for anyone who's developing solutions that involve communication, that involve any public perception is to think about whose my intended audience? Awesome. What do I want them to understand and maybe do, but who is not my intended audience, and who's going to not like this message, and what are they going to do? And am I radicalizing them? Am I polarizing them? Am I making them feel like what they care about is going to be attacked where they're more likely to become terrorists or more likely to whatever. That's an effect. That's an externality of my choice. I might have made a choice that seemed like coalescing these people to do this thing was good, but I actually just up regulated extremism or terrorism or total polarization in a critical audience. **Nate Hagens**: But this gets back to your example though, that if you can get rich or elected from doing that and you have made extremes of your enemies, who cares as long as you win, is the current logic. **Daniel Schmachtenberger**: Yes. And so what I'm saying is if your politician is doing that and you actually care about the world more largely, they have the wrong logic, that's not the thing to support. And if you are working to do a non-profit thing or whatever and there's a media campaign involved, don't do that thing. So of course, the world is where it is because the things we're talking about are not widely practiced, understood, or implemented. There is a huge amount of perverse incentive. But since you cannot actually kick the other half of the world off the planet, and since they aren't just inert pieces of wood, they're smart people with goals and values, they're political actors and if what you say anti resonates with them and they get up regulated to do a bunch of action, so it's true that when you villainize somebody else, you can coalesce a bunch of people against them and you can actually have moral people be willing to celebrate, causing harm to others. That's very effective politically. It also happens to be evil. Calling women witches allowed seemingly moral people to burn them to death and calling somebody terrorists or whatever, it's a very effective... **Nate Hagens**: I don't think we've evolved that much from the burning witches' era. **Daniel Schmachtenberger**: I wish people understood the lynching was not long ago. The lynching as a form of entertainment was not long ago. The burning witches, the concentration camps of World War II, there's still shit like that happening today. So how quickly, when you look at the pictures of women wearing mini skirts in 1968 in Iran, and then the thing that happened in the Ayatollah and then the burkas, when you look at how it, well relatively advanced Liberia was and then the internal war and then child soldiers replacing what had been an economically prosperous area. When you look at Syria recently, when you look at Ukraine, you can have an area that seems peaceful and economically prosperous, progressive and liberal, and it collapses and turns into war, violence, extremism, et cetera. It goes from mini skirts to burkas to whatever. And so those are canaries in a coal mine of something that is possible for anywhere in the world. People should, in recognition of that, not take for granted the stability of where they are and not taken for granted work to protect it. So the making, 'they are anti-vaxxers' is another word for witch or terrorist or, on the other side they're sheeple or they're libtards, or whatever it is. Both sides have their terms to dehumanize. This might be politically expedient. It is definitely moving us towards planetary extinction as a whole. Stop this. If you are doing that thing, you are definitely not part of the long-term solution. You are orienting a short-term, narrow thing at the expense of increasing enmity, polarization, et cetera. So this is a place where the externality is psychosocial. So one thing I want to think about is who cares about this issue, and then who cares about another issue that feels threatened by this? That's in theory of trade-offs. What do they care about? How do I come up with a solution that could get more broad support and less enmity? It's just a more effective strategy also, unless I don't care that the thing I worked real hard for gets undone in four years. But there are no groups of people that feel really good about being villainized and that will just sit comfortably and let the thing that villainize them, continue to succeed. So that's one example of a psychosocial externality, which is where you are trying to create fervency of belief in some population without really paying attention to what you're doing in that process to another part of the population." - [Daniel Schmachtenberger](https://youtu.be/Kep8Fi_rUUI?t=2773)

> "You and I know that the super organism, there's 70 to a 100 trillion dollars that trades hands every day, that pretty much every one of those dollars has some externality associated with it. That's a problem. And there's a exponential embedded growth obligation on it, which means exponential future externalities that are attached to the thing and hitting the fragility points of planetary boundaries. What we're up against is a big thing. And not only are people not educated to think and feel and care and understand holistically like that, but they're continuously engaged in a media environment that will do everything that it can to capture them in a partisan, political, outraged, whatever kind of way. And they will actually use AI split testing to figure out what shit does that the most effectively in terms of what will show up in their newsfeed. So the fact that we are dealing with some big issues here is obvious. The cards are stacked in a rough direction that now what is the thing we need the most of? I think people that are oriented, I think everything we've been talking about today, people who are oriented with a very high touch like I actually care about century and beings and want their life to be good, and I'm not just interested in talking about topics that have power associated. I'm not interested in just virtue signalings, green something because it... make money in a fun that way. Like, it grounds in mirror neurons, it grounds and I know what suffering feels like. I see it there. I want to solve it and I want to prevent it. People who are oriented that way who then also start learning how to be able to think at scale well, which means that it has to implement large numbers of people and technology and things in culture and the political economy and in tech. And that simultaneously think through these frameworks of how do I not jump to certainty in action too quickly, but make sure I actually understand the problem landscape, the many things that are causing it, the things that are downstream, the people who care about something else and how do I come up with not a solution, but a series of solutions that actually addresses this and progressively gets more people on board. People that are capacitated this way is the rate limiting factor right now as far as I can see it. There are people who care but have very poor strategy. The people who understand strategy well are mostly serving very narrow aims. So people who are developed in these skillsets, and this is why I'm excited to be talking about this with you here, this is why we're working on in a training modules and an academy to be able to do this, et cetera. **Nate Hagens**: So in the three by three grid, culture, political economy, tech stack, triage - meaning urgent, near term transition - and long term education/systems thinking is in all nine quadrants, all nine boxes. **Daniel Schmachtenberger**: Yeah. So I'll say something else I said there was one other thing and it relates to this that I was going to say upfront. So one is how do you understand how to think about a solution in a way that will prevent unintended consequences and that will be better set to deal with it and manage. The other thing I said I want to talk about was that people can get fundamentalist about their particular solution, because if you're working on something, you should really care about it, but in really caring about it, you can become overly narrowly focused. So when I was first starting to try to wrap my head around what is upstream from all of these various problems, or what are the underlying causes that everything from nuclear war to environmental degradation to animal rights issues, to class issues, what do these things have in common? What do not a specific solution for one thing, but a solution for civilization doing better, look like, I of course read the work of people and also had the fortune to talk to a lot of people that it's been their life thinking about these things and working on them, and would ask their analysis and I got so many answers that sounded like this. At the end of the day, whenever somebody uses a phrase like that, at the end of the day, or the key is, you can usually expect a reductionist thing to come next. Not always, but sometimes you want to pay attention to that. At the end of the day, really the thing we have to shift is the economy because perverse economic incentive is under the whole thing. There's no way that as long as you have a for-profit, military industrial complex as the largest block of a global economy that you could ever have peace, there's an anti incentive on it as long as there's so much money to be made with mining, et cetera. We have to fix the nature of economic incentive. And I'd be nodding, I'm like, this makes perfect sense. And then somebody else would be, the core of the thing that we have to address is education, because you can have so much change occur in a generation if those children are growing up different. As different as it is learning Chinese as your first language versus learning English, we're so neuroplasty. By the time we're adults, were not that neuroplasty, we're kind of screwed. If you get education right, we want adults who care about the animals and the oceans and can tend to all of these things and can think complexity. If we really get education right, we'll be able to solve everything. It's upstream from all that. And I'm nodding, I'm like, "Oh yeah, this is it". And then somebody else will be like, "No, really, the thing is it's about media because we're continuously being bombarded". And that was before social media, then it was social media. "We're being continuously bombarded and we are ready to go do a Capitol riot or a George Floyd protestor riot or a whatever it is based on the stuff that's coming in. If we could change the media environment of what people were in taking, it would change all of these things". And someone else is like, "No, no. The thing is really at the end of the day, it's about government and law, and how do we get that right. Because the economic incentive wouldn't be that same issue if we could govern it properly. If we could force the internalization of the price of carbon and get carbon pricing properly and get cost of everything proper, all that would be fixed. But we have to do that through law. So how do we fix governance and law? And then somebody else would be like, you can't because law is written by lobbyists that get paid for by somebody and wherever the economic motive is is what's going to pay for that. Which is why you have to think about economics and law together. So the key is political economy, and how do you get that? And on and on, people would say no. Really, the key is actually parenting. What we've really got to do is restore the family because before education, by the time that kid goes to school at five or six, that so much of their identity and psyche and value system is already set. It happens early on. We have to actually change the entire culture to have parenting emphasize raising better kids from the beginning. And what I came to learn is they were all right. Somebody else would be, everything you're saying is so anthropocentric, the key is the fucking environment. Because none of us are anything without the environment. You have to prioritize that. Everything else doesn't matter that much. And what is an economy? We can breathe without money. We can't breathe without air. And so be less anthropocentric and focus on the integrity of the environment because that's upstream from everything. And so what I learned was the answer to all of the problems is all of the solutions. There is not a theory of change, there's an ecology of theories of change. So often when someone says what is the solution, it sounds like someone's saying what species is the forest? I don't know what you're even asking. A forest is lots of species, lots and lots and if it's an old growth forest, it's even more complexly interacting. So what is the solution? There's not a solution. There's lots of things that need to happen. So if anything, I want patterns of how to think about it and I want frameworks for how to think about it. And I don't want people to attach to those frameworks because they'll be useful. But also limiting and to realize the cultural aspects do involve education and media and parenting and religion and lots of other things. And the structure of cities and the political economy aspects involve lots of things and getting past the zelotist and reductionist focus and being able to get how do all these things come together is key to understanding properly. **Nate Hagens**: I love that. I got the systems ecology equivalent of goosebumps as you were unpacking that and that's exactly right. But that's a lot of complexity for most people to hold in their mind because they've worked their whole life on climate and they think climate is the single problem and their identity is attached to it. Their job is attached to it. So to say it's all these things, governance and love and law and pricing and everything that you just mentioned, how does someone shift from where they are now to that more holistic view of our system? Not only to think about it but also to apply it to their work and their lives. I don't know if you want to answer that now, but I'm curious. **Daniel Schmachtenberger**: No, I do, actually. If you are young and you're listening to this and you're thinking about how do I do the most useful thing of my life and do I go to college or not? Or do I go back to college or what kind of work do I do? For most people, here's something I would offer. Figure out - if you are not already independently wealthy, if you are awesome - figure out how to keep your overhead as low as possible and make the money that you need to live in the least number of hours possible. Doing something that isn't terrible. So you buy most of your time back to continue to train yourself on what is actually yours to do. This is what I did with my life and many of the people I know who I really respect did something like this where rather than, okay, I've got the basic bills paid, let's make more money and get more shit. It's like no, no. The more shit is way less interesting than actually the time. I want my time back so that I can keep understanding these things so I can know how to have my life actually be meaningful. And so it's both the learning and the development of capacity. So if you are young still and you're in this interest, figure out how to keep your overhead low. Figure out how to pay your bills in the least amount of hours doing something that isn't terrible and really keep investing in developing how you... And now, if there's already something that you feel very called to do and that feels right, then do it and keep investing in your development in the additional hours both. If we're talking about someone who has kids and a mortgage and a job and whatever, if the job is not clearly making things better in a way that is aligned with your dharma, be willing to change at all. The shortness of your life and the urgency of the situation of the world is such that be willing to do that. If you're mostly in the right direction, you just feel like you wish you could do even more, then continue to do what you do while studying is there a way I could do this with even more insightfulness as you start learning how to think through externalities and system dynamics better. It might take a year or two of study while you're doing this to start to come up with insights, but maybe in a few years you're actually revolutionizing the field that you're in. The other thing I would say is when you say like, hey, it's a lot of complexity. The world situations are complex. Reducing them to be too narrow is at the core of everything wrong. We can optimize some things, harm other things, we have to... And when we can act very powerfully because we can act through six continent supply chains and supercomputers and satellites and AI and steam engines and I mean, oil engines and all of the powerful tools from the industrial revolution on, you just can't do that in an oversimplifying way ongoingly. Where the model of what you're optimizing is not reality is where reality gets harmed. You don't get to do cumulative and exponentially growing harm forever on a finite world. So we do have to actually wrestle with the reality of the world, which means the complexity of it. It is what it is, we don't get a... It just is what it is. And now, not everybody has to begin with. Because we go back to each of those partial narratives, it's just about media, it's just about education, it's just about economics. Well, let's say somebody is wrestling with all this and really thinking how do I make a better educational system? And maybe they have a transitional version and a long-term version. The long-term version might be a radically different system of education that is based on a different system of community development where school is not just a centralized thing, it's how the parents and how the extended family and community are all supported to support the development of children. Maybe that's some long term future of education and maybe it involves AI tutors and shit. Maybe the immediate transitional thing involves are there some curriculums in systemic thinking and whatever that we can start to add to existing curricula and is there a way of getting that through? That both requires me to think through the content, the pedagogy and the political actuation needed to make it happen. Not that many people have to be thinking effectively to get something to happen that will train a lot of people to where there's now a lot more people. In the same way that it didn't take that many people to make Facebook to affect the minds of lots of people. So it wouldn't take that many people to make new media systems that think strategically enough about how would we get Metcalf dynamics and how do we get the people on there, whatever, that could be oriented very differently. And the same with perverse incentive. If some people figured out how to make laws that make particularly bad things for what's their current incentives illegal, whether it's fishing or whatever or create better regenerative economic systems, then everybody else who doesn't understand the whole complexity just has a slightly less perverse incentive system. A lot of the complexities built into a better incentive system, incentive legal system. So not everybody has to get everything to begin with. Some people being able to do that and build things that affect other people at scale and affect the world at scale is how the thing starts. So I don't want anyone who is wrestling with like, okay, I want to understand this well to get overwhelmed when they think about their family members who aren't even interested or whatever and say, if everybody has to understand this, we're screwed. No, everybody does not to begin. And the path by which people are enculturated in time always starts with some people building things that become on-ramps for more people." - [Daniel Schmachtenberger](https://youtu.be/Kep8Fi_rUUI?t=4784)

> "So when I talk about triage, transition and long-term adequate solutions, sufficient solutions, these are horizons of focus. There's lots of management theories that talk about something like this, but I'll tell you how I think about it. Triage basically means that there is some problem and particularly some catastrophic risk that has a non nail likelihood over in the near term. I'm mostly not focused on things like the sun blowing out someday. I'm focused on pretty things within the years to decades timeframe. And there's some problem like that. It does not seem the world has an adequate set of solutions already in place for, so more needs done. And probably needs done fairly quickly through whatever means necessary to avoid that. When I say whatever means necessary, I mean not necessarily total systemic solutions, but more just direct implementation. So if we are looking at something like the risks associated with the speed of growth of synthetic biology and a direction of lots of viral hunting and gain of function research in ligi laboratories with publishing of those gene sequences, that's just super, super, super risky. So things should be done to stop that, that involve mostly some scientific work that says okay, let's not do these things. The benefit is not worth the risk. And instead let's do these things for zoonotic pandemic, spillover prevention and these things regarding information sharing and lab security and whatever. And then there's like legal work to do. Legal work to get a couple of the main countries to do and then maybe the WHO to do something, the G20 to do something that is adequate. That's a triage type thing. That's saying, okay, here's a risk and we don't need to get everybody to buy into something. We basically need to show that the risk opportunity space needs something different done. So there's some scientific work, but this is a convening of a not large number of people. And obviously this is a topic we have both actively worked on along with a number of other people, but this is just one that kind of makes sense. And then there's legislative work within existing legislative apparatus to be able to get that stuff done. We could say a very similar thing of protecting, ensuring that the Amazon doesn't get to the point of the hydrological pump breaking, a planetary boundary thing like that. Okay, well, how would we think about how to do triage there effectively? I'm just going to talk through some principles of how to think about it. Because whether you're working in Ecuador to begin with at the headwaters of the Amazon or Brazil, because it's the largest total amount of the Amazon or any of the other five countries touching it or nine countries that have some involvement in the watersheds, you're going to do different things. But principles, the economic incentive, whether it's from mining, oil extraction or agriculture is going to be an ongoing pressure because those things are going to not only keep being worth money, many of them will keep being worth more money as population demands and et cetera needs that. And those forces can bribe governments and they can put out commercials and campaigns that affect the minds and hearts of people and they can do campaign budgets and they can pay lobbyists. So if the NGOs that are fighting it are just fundamentally less capacitated in all those ways, it's just not going to work. Then you've got to think about, all right, factoring the forces that want to harm the thing, we're wanting to protect it, what forces are large enough to protect it? Just even basic kind of strategic thinking. And how could we get the forces that are large enough to care? And it might not be by appealing to them with some kind of moral or environmental thing. It might be some other thing. So in this case, this is an example you and I have talked about. If the hydrological pump of the Amazon breaks, meaning the water that transpires from all the trees then rains down and keeps it as a rainforest, but also pumps some of the groundwater into the air that becomes rain in North America that is somewhere between a third and a half of the rainfall in North America every year. If the hydrological pump breaks because you've got enough destruction that you stop getting enough rainfall, that you stop getting enough plant growth to keep pumping the thing. You get this, like the climate change albedo effect is a positive runaway thing that happens at a certain point. And whether we're five years from that or 15 years from that, depends upon how fast things are being destroyed and whose model you're looking at. But it's not like forever. There's a timescale there. So then you're like, all right, so half of the rainfall in North America goes away. That is absolutely a national security threat because it's a food security threat, a water security threat. It threatens the food sovereignty and food security. And so the State Department would care about that, not because they necessarily care about the Amazon on its own, but because they care about food security. Now, is the State Department bigger than Amazon Watch and Rainforest watch and whatever NGOs are there that could do more to intervene? Obviously. Now, this is presenting the issue to someone else that has the capacity for a reason that they care about, even if it is not the reason that people caring about the rainforest care about it. And then who would they need to see that modeling? They would probably want to see that Noah and NASA agreed modeling wise. Yes, this much can't be harmed or you'll get that runaway effect to occur. So if some people wanting to work on the Amazon were like, how do I get people at Noah, and NASA to explain the hydrological pump thing in a way that the State Department adds it to its list of things to ensure that it ameliorates? This is just an example of triage strategic thinking. We're not trying to make capitalism as a whole better. We're not trying to make the governments of each of those countries better. We're simply trying to think strategically more effectively about how to do a thing that needs to be done. This is what I would call the triage category. And there are a lot of principles. So I just gave a principle of whatever are the forces array against the thing, make sure that you have competent forces similarly arrayed, but they don't have to care about it for the same reason. They have to care about it for a rationalized reason. That speaks in the language they understand. So who can help translate that? That's one principle. We could do a whole thing on how to do strategic thinking effectively. But triage is largely that. It's largely how do we get different players? How do we get the economic incentives, et cetera to be able to do the things that are needed. And of course we still have to think through the externalities because there might be issues of having the State Department to focus on the Amazon. So we have to think through that. But that's what I would call the triage category. And there is a lot in there. And of course, there's a lot of people already working on frontline approaches for the Amazon. They're just not thinking about what is the total threat landscape to the Amazon? What are the tipping points to not hit and what is a strategically adequate focus? And so that's one triage. We could give a hundred other examples, but I think that is an example category. **Nate Hagens**: So do we want to go horizontal or vertical here? Maybe you could stick with that example and look at transition and long-term briefly, or do you want to break the triage down between culture, political economy and tech stack? **Daniel Schmachtenberger**: Yes. We can do that. Yeah, yeah, yeah. So I'll give a transition example. So having something like a State Department, and I'm giving one example, there's obviously groups other than the State Department that would also care. But in the same way that I said earlier about who are you politically polarizing against you, and how could you get them on your side rather than not, how do you get groups that don't currently care to care either that are larger or where the cumulative effect of how they care stacks functions enough, right? That's just straightforward principle of political thinking. This is not changing the overall economic incentives in those countries or the mindsets of the people or anything. So it's not a systemic effect. That's what I call triage. So transitional would be working with the institutions of those countries. Their Department of the Interior or it's equivalent, their academies and universities that are focused on these things, their government security bodies, their financial bodies. How could we make those smarter? How could we make the logics of them better so they do a better job with these types of things? So an example there could be something like, I learned this kind of thinking from a guy named Nelson Del Rio, Prosperity of the Commons, really smart lawyer who did a lot of the work on making the public-private partnership and then legal structure and then saw how that got weaponized in a different structure. But let's say that we focused on Ecuador because it's the headwaters of the Amazon. So even though it's not the most total square meters, it's the most critical square meters because you messed the headwaters up, obviously the entire basin gets messed up. And we see that... And I might have some of my stats wrongs because I looked at this a couple years ago, so I'm just using this as a random example but Ecuador owed a lot of money to both the World Bank and Chinese Bank, and some of that debt is collateralized with resource access and was not in a position to be able to pay that debt off well. So what happens? Does that threaten resource acquisition near the headwater of the Amazon, that could mess up the Amazon basin? If you start thinking about the relationship between the State Department that might want to prevent the hydrological pump breaking for food security and the World Bank. Obviously, the US and the World Bank are very related institutions. Could the State Department get the World Bank to change its debt structure, debt forgiveness or things like that? Yeah, totally could.Could the World Bank work with the Chinese Bank to get it to do it as well, based on if it was motivated enough, international financial agreements? Yeah, it probably could do that as well. If somebody could negotiate how to set that whole thing up, of the state department's support with the forgiveness of the debt, which is like $32 billion, a lot of debt. Then that would mean a lot to the government of Ecuador and they might not know how to do that on their own. Now the country needs an economic development plan that doesn't involve ruining its rainforest assets. So they probably need an education process to do a lot more skilled labor and they probably need tech. So let's say somebody put together an economic development plan that involved bringing more tech jobs and tech capacity to the area and more education for more skilled labor, so that you could still have economic development without as much environmental exploitation. Let's say that to the degree there were some resources that needed to be extracted or exploited, we helped have that country develop its own national capability to do its mining or extraction, that employed people there as opposed to say a Chinese contractor that was employing Chinese people to do it and that because of that, had much stricter environmental regulation, did a better version of it and held more of the wealth for Ecuador rather than more of it going to a multinational. But they can't do that because they don't have that capacity on their own economically or whatever, but they could be supported to. So again, I'm saying if there is some group that is really caring about the Amazon, they want to do a transitional thing. Could someone say, all right, here's a 10, 20, 30 year economic development plan that involves some of those resources being extracted in a viable way that doesn't ruin the environment and provides jobs and whatever, but also provides a lot of economic development, not in the resource extraction category and gets you both a lot less environmental harm per extraction and more of the money from that extraction. And we will help set that up and open the capital markets, help negotiate the capital markets being able to fund this thing and you'll bond back it so we can make sure that the capital markets can come into it. We'll also help negotiate the release of your debt. But here's the deal, we're going to offer this deal to you as a package that includes excluding the mining rights of all these other companies and the logging and the ranching and like that. So you either get this deal in whole or not, but you can't take this other thing that's happening in this. Why this is unique is because most people who focus on for benefit capitalism. They're like, okay, well I can make money doing this good thing, but it doesn't bind other people from doing the bad thing. If I want to bind other people from doing the bad thing, I either have to create law that doesn't make it illegal or contract law where those who would say, allow the other multinational to come and do the thing, are not going to because there's an exclusive contract. And so if I think about how to use markets more effectively, I don't just want to incentivize some positive thing, I also want to bind the negative thing from not happening. So we all know that politically people bundle shit in ways that are really messed up. There's some clean water act that everybody's going to want with some privatized prison or up fucked up thing that's attached to it in the same thing. You're like, why did those things get together? They don't belong together. But can that same tool be utilized for positive purposes, where you provide an actual healthy economic development plan and a protection plan for that country? You factor which choice makers are going to have to make the choice and what do they need in terms of public opinion and whatever to be able to do the thing and put something together that's a deal they will take, that also is exclusive to the other thing. Now this is helping their entire institutional complex to be better structured, less perverse incentive in the whole thing, long-term development of new economic areas. This would be an example of a transitional strategy where you're helping the overall set of institutions get healthier, longer term. And again, I gave an example here, but we could give an example in a coral reef or in the Congo or in whatever, a gazillion things where you're thinking about principles like that. What things would we want to bundle together to ensure that they all happen together? Which ones would we want to force exclusion of? Who would have to make which choices? What are the incentives that they need, things like that. **Nate Hagens**: And what about long-term? **Daniel Schmachtenberger**: Long-term term is things like, you don't have global capitalism and the global financial system in the same way anymore. Long term is things like real cost valuation on everything, so that the actual market cost of a thing included the cost to make all of the raw ingredients renewably and the environmental cost long term, in which case you just don't have perverse incentive environmentally as a whole. Long-term means education system where everyone is educated in this type of way so that you actually have culture where people are oriented about what is actual value fundamentally differently. So long-term is food systems and manufacturing systems and whatever, that are closed looped, that don't need to keep exploiting new virgin areas forever. **Nate Hagens**: And do these things happen sequentially, triage, transition, long-term or do you start all three of them now on parallel tracks? **Daniel Schmachtenberger**: Not only do they have to all three start now they have to be in conversation and in turn, form each other because what will long-term viable be? If the people who are doing the transition aren't thinking about it, they might be transitioning more sideways than forward. They might be missing critical insights about what will long-term sufficiency look like. And if the people who are thinking about long-term solutions aren't paying attention to the details of the reality on the ground, they might not have enough detail to think about it rightly. They're thinking about it too abstractly. So those are horizons of focus, but that doesn't mean sequential and they do need to be in dialogue. **Nate Hagens**: And then vertically, how do we think about culture, political economy and tech stack infrastructure on the bottom, with respect to what you were just saying? **Daniel Schmachtenberger**: When you think about triage, it's hard to separate them because you're looking at an eminent issue happening in which they're all happening together. And your triage might have to affect cultural things because the mindsets of the populous matter, it might not. Regulation of synthetic bio probably does not need everybody to agree. It probably needs a very small number of people to agree. So how important culture is, or not, depends. Most people don't really have a say in, do we go to nuclear war or not, over a certain thing? What is the point of nuclear escalation? And yet, those who would do it, still have to pay attention to political will to some degree. So I would say that you want to use frameworks like this to think about, am I factoring what the cultural elements are, what the political economy elements, what the tech elements are? But your triage solutions are going to and are going to be focused on just immediate efficacy and they'll all three be very connected. When you're thinking longer term transition, I can think about culture in terms of, there are versions of all the religions that are more compatible with each other and less compatible. There are versions that are more non-violent, forgiveness oriented universalists and other ones that are more fundamentalist religious oriented. Being able to support the more compatible versions of the religions flourishing more than the other ones is a culture play long-term, that I don't have to think about the political economy and the tech to think about that, though they are very, very connected. If I think about a how do I support the proliferation of a particular version? Well if I can help it develop more tech and more financial capacities, it becomes a lot easier for that version to proliferate if it also has more economic power behind it. So I think we did a good job of giving a couple examples of triage. On transition, I'd like to give a different example. So like transition and then the difference between transition and long term. Let's say we're taking the United States government, federal government. Long-term, the underlying structure of representative democracy is just insufficient. The US structure made in 1776, when the world was radically more simple, there is no way to retrofit it adequately. Specifically things like, markets just get advanced new tech and only after it has caused health or environmental problems long enough for long-term studies to be done and watchdog groups to lobby enough and fight against the vested interest lobbying, does regulation happen post facto. And so 80 years after lead gasoline was causing problems, you finally out outlaw it or cigarettes or DDT. You don't get to keep having a post facto regulatory system with problems that cause harm at exponentially faster scale and more speed and live. So a new situation where when new tech emerges, you actually have to go through this externality process that we talked about, to get regulatory okay, for it to move forward. And of course, I'm aware that it's very hard to concentrate that much power and not have it become corrupt and dystopic. So of course, there have to be checks and balances on that power and transparencies and there are really hard issues in there. We can get into that. But there is a need to be able to ensure the not terrible risk of things that have exponentially bigger and faster impacts ahead of time. That's an example of a fundamental change in our existing system of government. Obviously, if we were going to rebuild a new open society civilizational architecture from scratch today, we would do it differently than the retrofits of how we did it starting in the early industrial era. So there are a lot of long-term shifts where we think about how do we implement all of the information technology tools to factor all of the things. Actually we should do one, where we talk about the combinations of liquid democracy and qualified democracy and addressing arrows and possibilities here. I mean, all the things on what the future of a governance stack could look like. But I'll pass on that for a minute and just come back to transition because that was the example I wanted to do. **Nate Hagens**: You said we should do one, what do you mean one podcast or one? **Daniel Schmachtenberger**: I mean, it would be worth talking about that at some point if that was something people had questions on like, what does a governance system that is adequate to the complexity of the issues actually look like? But let me go ahead and give an example of transition that is not yet adequate but a lot better than we currently have. People like Larry Lessig, who constitutional lawyers and focused on these issues have identified a handful of issues that they see as being able to, and I don't mean to misquote him, I spoke with him recently about this and I think this is roughly right. He's focused on, that if we can get the primaries to not be partisan because one of the problems of the primaries being partisan is you get this heavy focus on appeal to your in-group and don't pay any attention to how the outgrowth of the other side is going to focus, and you get much more extreme polarizing things. Similarly, if you can get ranked choice voting rather than just the single vote, then if you highly polarize the other side, you'll do much less well than if you appeal to your support base but also appeal or don't dis-appeal to the other side. So you'll decrease the incentive for polarization with rank choice voting. If you can fix gerrymandering, which is such a just obviously corrupt nonsense thing and it's such a straightforward thing to be able to fix, so districts start to make sense. And if you can fix campaign finance, then in the perversion of the system to focus on party over country to continuously polarize, which will make most of the energy turn into waste heat fighting each other and then four years do something and four years undo it, like the current system with its existing logics, would just be so much smarter if you did a handful of things like that. Now obviously, the only people who wouldn't want that, are the people that benefit from the corruption of the system, which might be things like the people who run the political parties and stuff. So there is some work to do, but that's not triage, that's not going to solve a particular biosecurity risk, it's not going to solve a nuclear risk, it's not going to solve an environmental boundary, but it's going to make something called the US federal government, smarter and less stupid and less corrupt. So all the things that it does will be better, but it's going to do it in a way that works within its own existing system logics, so that's what I would call a transitional solution. Whereas how do we rebuild a digital democracy from scratch, that is a totally different kind of structure, is a long-term solution. So that's an example of thinking about the distinction between triage, which is not systemic, transition, which is systemic, but a change to existing systems, and then the build of fundamentally new systems." - [Daniel Schmachtenberger](https://youtu.be/Kep8Fi_rUUI?t=6288)

> "The answer to all of the problems is all of the solutions." - [Daniel Schmachtenberger](https://youtu.be/Kep8Fi_rUUI?t=5251)



> "" - [Daniel Schmachtenberger]()

> "" - [Daniel Schmachtenberger]()

> "" - [Daniel Schmachtenberger]()

> "" - [Daniel Schmachtenberger]()

> "" - [Daniel Schmachtenberger]()

> "" - [Daniel Schmachtenberger]()

> "" - [Daniel Schmachtenberger]()





