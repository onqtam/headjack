

██████████████████████████████████████████████████████████████████
# SECTION: Cybernetics
██████████████████████████████████████████████████████████████████

> "Cybernetics is the art of steering." - [Paul Pangaro](https://twitter.com/paulpangaro)

> "Science, as well as technology, will in the near and in the farther future increasingly turn from problems of intensity, substance, and energy, to problems of structure, organization, information, and control." - [John von Neumann](https://www.azquotes.com/quote/1337572)

> "All stable processes we shall predict. All unstable processes we shall control." - [John von Neumann](https://www.azquotes.com/quote/878804)

> "Cybernetics: Cybernetics is the science of communication, coordination, and control in natural and artificial systems. It examines how complex biological, mechanical, or social systems process information, maintain stability, steer towards goals and adapt to changes in their environment. Cybernetics treats systems from a new angle. It doesn’t ask, “what does this system consist of?” but “how does it function?” thus examining more or less intelligent forms of goal-directed behavior. Cybernetics aim to understand the principles and mechanisms underlying self-steering systems (such as negative feedback) in various disciplines (biology, psychology, computer science, sociology…) and application domains (artificial intelligence, robotics, engineering, management, etc)." - [Glossary of Concepts, Human Energy](https://www.humanenergy.io/glossary)

> "Cybernetics is the science that studies the abstract principles of organization in complex systems. It is concerned not so much with what systems consist of, but how they function. Cybernetics focuses on how systems use information, models, and control actions to steer towards and maintain their goals, while counteracting various disturbances.
>
> ... Perhaps the most fundamental contribution of cybernetics is its explanation of purposiveness, or goal-directed behavior, an essential characteristic of mind and life, in terms of control and information. Negative feedback control loops which try to achieve and maintain goal states were seen as basic models for the autonomy characteristic of organisms: their behavior, while purposeful, is not strictly determined by either environmental influences or internal dynamical processes. They are in some sense "independent actors" with a "free will".
>
> ... Cyberneticians use high level concepts such as order, organization, complexity, hierarchy, structure, information, and control, investigating how these are manifested in systems of different types. These concepts are relational, in that they allow us to analyze and formally model different abstract properties of systems and their dynamics.
>
> ... While negative feedback is the essential condition for stability, positive feedbacks are responsible for growth, self-organization, and the amplification of weak signals. In complex, hierarchical systems, higher-level negative feedbacks typically constrain the growth of lower-level positive feedbacks.
>
> ... Probably the most important innovation of cybernetics is its explanation of goal-directedness or purpose. An autonomous system, such as an organism, or a person, can be characterized by the fact that it pursues its own goals, resisting obstructions from the environment that would make it deviate from its preferred state of affairs." - [Cybernetics and Second-Order Cybernetics, by Francis Heylighen](http://pespmc1.vub.ac.be/Papers/Cybernetics-EPST.pdf)

## Goal-directedness, Regulation, Control & Feedback

> "Sound strategy starts with having the right goal." - [Michael Porter](https://www.azquotes.com/quote/605346)

> "Regulation (or control): the process by which an agent continually neutralizes deviations from its goals, by effectively counteracting disturbances. Regulation implements negative feedback: deviations in one direction are compensated by reactions that push the state in the opposite direction, so as to reduce their effect. The classic example of regulation is the functioning of a thermostat, which switches on the heating as soon as the temperature moves below its set temperature or goal, and switches off the heating as soon as the temperature moves above the goal temperature." - [Self-organization of complex, intelligent systems: an action ontology for transdisciplinary integration, by Francis Heylighen](http://pespmc1.vub.ac.be/Papers/ECCO-paradigm.pdf)

> "Navigation: the process by which an agent constantly adjusts its course of action so as to dynamically maximize its advance in utility while taking into account the diversions it encounter. This means that the agent should optimally allocate its effort in simultaneously counteracting disturbances (regulation), finding affordances (exploration), and making use of the affordances it has found (exploitation). Navigating means that the agent needs to set out a well-thought out, but flexible course, using a combination of planning (to deal with known disturbances and affordances) and improvisation (to deal with new diversions)." - [Self-organization of complex, intelligent systems: an action ontology for transdisciplinary integration, by Francis Heylighen](http://pespmc1.vub.ac.be/Papers/ECCO-paradigm.pdf)

> "Variety of action: the number of actions that an agent can potentially execute. The larger an agent’s variety of action, the larger the variety of diversions that the agent can deal with, because different types of diversions typically require different types of actions. This is a generalization of Ashby’s well-known “law of requisite variety”. However, while increasing the variety of actions makes the agent potentially more powerful in achieving its goals, it also makes it more difficult for the agent to select the most appropriate action." - [Self-organization of complex, intelligent systems: an action ontology for transdisciplinary integration, by Francis Heylighen](http://pespmc1.vub.ac.be/Papers/ECCO-paradigm.pdf)

> "Cognition: the acquisition, processing, storage, and use of information and knowledge to support intelligent decision-making. This includes perception (the processing and interpretation of incoming information), learning (extracting recurrent regularities from perceptions and storing them into memory in the form of knowledge), and inference (using stored knowledge patterns to anticipate situations as yet not perceived)." - [Self-organization of complex, intelligent systems: an action ontology for transdisciplinary integration, by Francis Heylighen](http://pespmc1.vub.ac.be/Papers/ECCO-paradigm.pdf)

> "Rationality: the hypothetical desire and ability of an agent to always choose the best action. In reality, rationality is restricted or bounded, as an agent never has enough information, knowledge or intelligence to accurately determine the utility of all possible courses of action. Bounded rationality implies that there is always an element of uncertainty or trial-and-error involved in making decisions; no decision can be a priori proven to be the best one." - [Self-organization of complex, intelligent systems: an action ontology for transdisciplinary integration, by Francis Heylighen](http://pespmc1.vub.ac.be/Papers/ECCO-paradigm.pdf)

## Ashby's Law of Requisite Variety

> "Ashby’s law of requisite variety is a cybernetics principle that tells you something about how complex your world model should be. This law—as applied to evolutionary biology—says that to continue to survive, an organism must have a repertoire of states or responses that is (at least) equal to the number of different challenges or problems presented by its environment. In other words, the more options a system has to respond to a given situation, the more effectively it can control that situation." - [Introducing Three of the Teleological Stance's Tools for Self-Optimization and Self-Actualization, by Bobby Azarian](https://roadtoomega.substack.com/p/introducing-three-of-the-teleological#:~:text=Ashby%E2%80%99s%20law%20of,control%20that%20situation.)

> "In colloquial terms Ashby’s Law has come to be understood as a simple proposition: if a system is to be able to deal successfully with the diversity of challenges that its environment produces, then it needs to have a repertoire of responses which is (at least) as nuanced as the problems thrown up by the environment. So a viable system is one that can handle the variability of its environment. Or, as Ashby put it, only variety can absorb variety." - [John Naughton](https://www.edge.org/response-detail/27150)

> "In order to deal properly with the diversity of problems the world throws at you, you need to have a repertoire of responses which are (at least) as nuanced as the problems you face." - [Ashby's Law of Requisite Variety - an alternative description](https://www.businessballs.com/strategy-innovation/ashbys-law-of-requisite-variety/)

To put it another way: systems will become only as complex as their niche requires.

> "This principle has important implications for practical situations: since the variety of perturbations a system can potentially be confronted with is unlimited, we should always try to maximize its internal variety (or diversity), so as to be optimally prepared for any foreseeable or unforeseeable contingency." - [Cybernetics and Second-Order Cybernetics, by Francis Heylighen](http://pespmc1.vub.ac.be/Papers/Cybernetics-EPST.pdf)

## The Good Regulator Theorem (aka the Internal Model Principle) by Ross Ashby

> "Every good regulator must contain a model of the system." - [Good regulator, Wikipedia](https://en.wikipedia.org/wiki/Good_regulator#:~:text=every%20good%20regulator%20must%20contain%20a%20model%20of%20the%20system)

Any system that regulates/controls another system must have a model of that system. This is tightly related to the law of requisite variety - the complexity of the model must be as complex as the challenges of the niche.

> "The good regulator theorem—as applied to evolutionary biology—states that any adaptive system (organism) must model the relevant environmental variables to continue persisting. Relevant variables are any that pertain to the intrinsic thermodynamic challenge of staying far from equilibrium. Energy extraction, threat avoidance, and remaining ordered in the face of environmental disturbances are critical efforts that permit a sentient system to stay in the game of existence, to persist for a little while longer." - [The Romance of Reality: How the Universe Organizes Itself to Create Life, Consciousness, and Cosmic Complexity, by Bobby Azarian](https://www.goodreads.com/en/book/show/59093393)

## Aulin's law of requisite hierarchy

> "A control loop will reduce the variety of perturbations, but it will in general not be able to eliminate all variation. Adding a control loop on top of the original loop may eliminate the residual variety, but if that is not sufficient, another hierarchical level may be needed. The required number of levels therefore depends on the regulatory ability of the individual control loops: the weaker that ability, the more hierarchy is needed. This is Aulin's law of requisite hierarchy. On the other hand, increasing the number of levels has a negative effect on the overall regulatory ability, since the more levels the perception and action signals have to pass through, the more they are likely to suffer from noise, corruption, or delays. Therefore, if possible, it is best to maximize the regulatory ability of a single layer, and thus minimize the number of requisite layers. This principle has important applications for social organizations, which have a tendency to multiply the number of bureaucratic levels. The present trend towards the flattening of hierarchies can be explained by the increasing regulatory abilities of individuals and organizations, due to better education, management and technological support.
>
> Still, when the variety becomes really too great for one regulator, a higher control level must appear to allow further progress. Valentin Turchin has called this process a metasystem transition, and proposed it as a basic unit, or "quantum", of the evolution of cybernetic systems. It is responsible for the increasing functional complexity which characterizes such fundamental developments as the origins of life, multicellular organisms, the nervous system, learning, and human culture." - [Cybernetics and Second-Order Cybernetics, by Francis Heylighen](http://pespmc1.vub.ac.be/Papers/Cybernetics-EPST.pdf)

## Autopoiesis, Learning & Resisting the Second Law of Thermodynamics

> "Autopoiesis: Autopoiesis (“self-production”) refers to a system's ability to produce and maintain its own organization, including its processes, structures and boundaries. This is characteristic of biological organisms. Autopoietic systems have a boundary, such as a skin, bark or cell membrane, that distinguishes them from the environment. The self-regenerating network of processes allows them to function as an autonomous, unified whole, which creates its own components. All living organisms, including humans, are autopoietic systems." - [Glossary of Concepts, Human Energy](https://www.humanenergy.io/glossary)

> "Cybernetic epistemology is in essence constructivist: knowledge cannot be passively absorbed from the environment, it must be actively constructed by the system itself. The environment does not instruct, or "in-form", the system, it merely weeds out models that are inadequate, by killing or punishing the system that uses them. At the most basic level, model-building takes place by variation-and-selection or trial-and-error.
>
> ... Natural selection of organisms is obviously a quite wasteful method to develop knowledge, although it is responsible for most knowledge that living systems have evolved in their genes. Higher organisms have developed a more efficient way to construct models: learning. In learning, different rules compete with each other within the same organism's control structure. Depending on their success in predicting or controlling disturbances, rules are differentially rewarded or reinforced. The ones that receive most reinforcement eventually come to dominate the less successful ones. This can be seen as an application of control at the metalevel, or a metasystem transition, where now the goal is to minimize the perceived difference between prediction and observation, and the actions consist in varying the components of the model." - [Cybernetics and Second-Order Cybernetics, by Francis Heylighen](http://pespmc1.vub.ac.be/Papers/Cybernetics-EPST.pdf)

> "As life adapts to its surroundings, natural selection generates predictive knowledge, and recursive self-organization generates increasingly complex, resilient, and intelligent cybernetic systems." - [Road to Omega: a plan to save the world with science, epistemology, and blockchain technology](https://roadtoomega.substack.com/p/savingtheworldwithscience)

> "Life evolves to maximize empowerment, which means maximizing future possibilities and preserving future freedom of action. In doing so, cybernetic systems carve out a cosmic trajectory that was inaccessible to inanimate forms of matter." - [The Romance of Reality: How the Universe Organizes Itself to Create Life, Consciousness, and Cosmic Complexity, by Bobby Azarian](https://www.goodreads.com/en/book/show/59093393)

> "The Integrated Evolutionary Synthesis starts with what many consider to be the most important law in all of physics, the almighty second law of thermodynamics. The second law can be summarized simply as “Things fall apart.” In other words, systems naturally tend toward decay and disorder. The technical term for disorder is “entropy,” and because the second law says entropy tends to increase, nature is constantly pulling us toward death.
>
> In his 1944 book What is LIfe?, the quantum physicist Erwin Schrodinger explained that a biological system can avoid the tendency toward decay (or keep its internal entropy low) by feeding on “negative entropy” in the environment. Negative entropy was Schrodinger’s name for free energy—which is simply the available energy in the world that can be used to do physical work. Free energy allows an ordered system to stay ordered so that it may continue playing the Game of Life.
>
> As animals, we consume free energy by eating food, which gets turned into mechanical work through the process of metabolism. Similarly, plants absorb free energy from sunlight and convert it into work through the process of photosynthesis. If an organism does not continually absorb energy, it will die and it will undergo entropic decay until the ordered system is no longer intact. When an energy-starved organism succumbs to the effects of the second law, the Game of Life has come to end for that player. If we choose not to play the game—that is, if we do nothing at all—we will soon cease to exist.
>
> This fact makes it easy to see how the natural tendency toward disorder creates an intrinsic goal for all living systems, which turns life into a game of sorts and gives it a purpose. To continue persisting in a world that abides by the second law—to continue playing the Game of Life—we must be able to capture free energy, and we must be able to do so while avoiding threats.
>
> However, navigating one’s environment in a chaotic and constantly changing world is no easy task. It requires that the living system acquire information about the environment, because that information reduces the organism’s uncertainty or ignorance about the relevant variables of the world it is embedded in. We may call the information that reduces an organism’s uncertainty knowledge. Evolutionary adaptation is therefore a learning process, and learning processes can also be seen as a form of adaptation. This was the insight of Karl Popper, and the basis for the influential philosophy known as evolutionary epistemology (which provided a basis for universal Darwinism, proposed by Richard Dawkins and Daniel Dennett).
>
> Based on the same logic, one may also say that to survive an organism must acquire a map or model of its environment. This model is the result of knowledge accumulation, and an agent’s model can be thought of as being comprised of “beliefs” about the world, or what it expects to encounter. This model is a predictive model, which allows the organism to anticipate events in a complex world.
>
> In humans and other animals, this predictive model is encoded in our brains, and it represents what we think of as the “mind.” Our mind consists of many different mental models that allow us to achieve our goals and make sense of a complicated and confusing reality." - [Introducing Three of the Teleological Stance's Tools for Self-Optimization and Self-Actualization, by Bobby Azarian](https://roadtoomega.substack.com/p/introducing-three-of-the-teleological)

> "Self-preservation is the primary and only foundation of virtue." - [Baruch Spinoza](https://www.azquotes.com/quote/500068)

> "Stayin' Alive!" - [Bee Gees](https://en.wikipedia.org/wiki/Stayin%27_Alive)

<!-- 
Second-Order Cybernetics

> "They began with the recognition that all our knowledge of systems is mediated by our simplified representations—or models—of them, which necessarily ignore those aspects of the system which are irrelevant to the purposes for which the model is constructed. Thus the properties of the systems themselves must be distinguished from those of their models, which depend on us as their creators... A second-order cyberneticist working with an organism or social system, on the other hand, recognizes that system as an agent in its own right, interacting with another agent, the observer. As quantum mechanics has taught us, observer and observed cannot be separated, and the result of observations will depend on their interaction. The observer too is a cybernetic system, trying to construct a model of another cybernetic system. To understand this process, we need a "cybernetics of cybernetics", i.e. a "meta" or "second-order" cybernetics." - [Cybernetics and Second-Order Cybernetics, by Francis Heylighen](http://pespmc1.vub.ac.be/Papers/Cybernetics-EPST.pdf)

> "The most logical way to minimize these indeterminacies appears to be the construction of a metamodel, which represents various possible models and their relations with observers and the phenomena they represent. For example, as suggested by Stuart Umpleby, one of the dimensions of a metamodel might be the degree to which an observation affects the phenomenon being observed, with classical, observer-independent observations at one extreme, and quantum observation closer to the other extreme.... Cybernetics as a whole could be defined as an attempt to build a universal metamodel, that would help us to build concrete object models for any specific system or situation." - [Cybernetics and Second-Order Cybernetics, by Francis Heylighen](http://pespmc1.vub.ac.be/Papers/Cybernetics-EPST.pdf)

-->


██████████████████████████████████████████████████████████████████
# SECTION: Inference & the “Free Energy Principle” of predictive processing
<!-- Active Inference, which is based on the “free energy principle” of predictive processing -->
██████████████████████████████████████████████████████████████████

predictive_processing_symbol.jpg

<!-- TODO INTERNET
fighting misinformation with a logical reasoning system
Julia Galef: Think Rationally via Bayes' Rule | Big Think
https://www.youtube.com/watch?v=NEqHML98RgU
A visual guide to Bayesian thinking
https://www.youtube.com/watch?v=BrK7X_XlGB8
https://www.lesswrong.com/posts/x7kL42bnATuaL4hrD/bayesian-reasoning-explained-like-you-re-five
https://www.edge.org/response-detail/27098 -->

## Bayesian Inference

> "Bayesian inference is an algorithm for the accumulation of evidence-based knowledge. This algorithm is now seen to operate over a wide range of evolutionary processes, including natural selection, the evolution of mental models and cultural evolutionary processes, notably including science itself." - [John Campbell](https://youtu.be/_JCaic5Cxms?t=4901)

> "Our aim as scientists is objective truth; more truth, more interesting truth, more intelligible truth. We cannot reasonably aim at certainty. Once we realize that human knowledge is fallible, we realize also that we can never be completely certain that we have not made a mistake." - [Karl Popper](https://www.goodreads.com/quotes/770441-our-aim-as-scientists-is-objective-truth-more-truth-more)

> "[Bayesian epistemology](https://plato.stanford.edu/entries/epistemology-bayesian/) is a unifying approach to determining truth. Absolute truth is never attainable, but we do get closer to understanding objective reality by formulating and testing theories." - [Road to Omega: a plan to save the world with science, epistemology, and blockchain technology](https://roadtoomega.substack.com/p/savingtheworldwithscience)

<!-- > "The logical reasoning system known as Bayesian inference is the only surefire way to acquire valid knowledge about the world." - [Road to Omega: a plan to save the world with science, epistemology, and blockchain technology](https://roadtoomega.substack.com/p/savingtheworldwithscience) -->

> "In recent years, a growing number of influential minds have recognized the societal significance of a statistical reasoning method known as Bayesian reasoning, which is a procedure for updating your theory, model, or belief system in the face of new evidence. What Bayesian reasoning provides in a nutshell is a universal approach to determining truth. Beliefs should not be believed blindly; they should be tested continually. Using this reasoning system is a way to minimize free energy, so it can be seen as an extension of the free energy principle...
>
> All you have to do is 1) consider all possible explanations for something, rather than relying purely on “gut instinct,” 2) rank and rate each theory or belief according to how likely it is to be true based on all the known facts, 3) test each theory/belief by using it to make future predictions, and 4) update how you ranked and rated the likelihood of each being true to reflect what you learned from the testing phase.
>
> If you are living in a “Bayes-optimal” manner, then when some new information you get exposed to discredits your prior beliefs, you should update your model to reflect that reality. For example, if you are a flat-Earther and I take you up in a rocket and let you see that the Earth is round with your own eyes, and you come back down and continue believing the Earth is flat, then you are not being Bayes optimal. You are not updating your model in light of new evidence." - [Introducing Three of the Teleological Stance's Tools for Self-Optimization and Self-Actualization, by Bobby Azarian](https://roadtoomega.substack.com/p/introducing-three-of-the-teleological#:~:text=In%20recent%20years%2C%20a,light%20of%20new%20evidence.)

## Free Energy Principle & Active Inference

> "The free energy principle might be the most all-encompassing idea since the theory of natural selection." - [Wired magazine](https://www.wired.com/story/karl-friston-free-energy-principle-artificial-intelligence/)

> "Inference is actually quite close to a theory of everything – including evolution, consciousness, and life itself." - [Karl Friston](https://aeon.co/essays/consciousness-is-not-a-thing-but-a-process-of-inference)

> "The free energy principle is a theoretical framework suggesting that the brain reduces surprise or uncertainty by making predictions based on internal models and updating them using sensory input. It highlights the brain's objective of aligning its internal model and the external world to enhance prediction accuracy. This principle integrates Bayesian inference with active inference, where actions are guided by predictions and sensory feedback refines them. It has wide-ranging implications for comprehending brain function, perception, and action." - [Wikipedia](https://en.wikipedia.org/wiki/Free_energy_principle#:~:text=The%20free%20energy,and%20action.)

> "The FEP states that living organisms are dynamical systems that are separated from their environment by an interface. We will refer to these living organisms as ‘agents’ for the sake of convenience going forward, since all living organisms sense their environment and act in response to those sensations... Crucially, this interface separates both the environment from the agent and the agent from its surroundings, allowing it to exist as a self-contained and autonomous entity. Agents therefore always necessarily receive sensory information and act through this interface. They never have unmediated access to what is going on in the environment, and as a result always have to guess (or infer) what is the true state of the world based on the information they have access to. According to the FEP, all agents act, as best as they can, to minimize the errors in their guesses about the environment. These errors can be quantified by a metric called ‘free energy,’ and the better an agent can minimize it over time, the better chance the agent has of staying alive and maintaining itself. To understand it intuitively, think of free energy as a measure of surprise or uncertainty.
>
> ... The minimization of free energy is not an end in itself. It is ultimately in service of the maintenance of the agent as an individual separated from its environment. Agents do this by attempting to remain in a state of homeostasis. All living agents have some sense of what that homeostasis for them should be, even if it is only represented implicitly within the structure of the agent itself. In the same way that sensory prediction errors increase free energy, so do deviations from the desired homeostasis of the agent, as the homeostatic set points of an agent itself are another kind of prediction about the world.
>
> ... An interesting aspect of the FEP is that it can often produce behavior which paradoxically doesn’t seem like error minimization, at least in the short-term. Let’s imagine that someone moves to a new neighborhood they are unfamiliar with. They could choose to stay inside their new home, which would indeed allow them to minimize any prediction errors that would arise from the novel environment. On the other hand, they could go outside and explore their new surroundings. Doing the latter will produce many more short-term prediction errors. In the long run though it will allow them to avoid even bigger surprises in the future. It is this dynamic of long-term free energy minimization that can account for various forms of exploration, adventure, and industry which we are motivated to engage in.
>
> ... We humans distinguish ourselves from other living agents by our ability to not only react to the environment but also establish goals and then set out to accomplish them. This might seem to be a challenge for a theory which suggests that all behavior is in the service of entropy minimization, but the FEP accounts for this quite elegantly as well. In this view, when we set a goal for ourselves, we are making a special kind of prediction about the world. This prediction is one that we know goes against the current sensory evidence, thus increasing free energy. Instead of updating our beliefs to account for the world (and in essence give up on the goal), what we do instead is to set out to act in the world in order to ensure that the sensory evidence corresponds to our prediction, and minimize the free energy in the process... We make a prediction about how we would like the world to be, and then act in order to make that prediction come true." - [A Gentle Introduction to the Free Energy Principle](https://awjuliani.medium.com/a-gentle-introduction-to-the-free-energy-principle-03f219853177)

> "What is active inference? It’s a theory that describes how self-organizing biological systems maintain internal order by minimizing uncertainty about the world. Think of living systems as “bubbles of order” actively & dynamically persisting in the face of entropy, the natural tendency to disorder. This is represented by a “Markov blanket” - a statistical formalism for “identity” that partitions internal and external states. Internal order is maintained through exchanges of information between internal states, beliefs in a world model, and external states, the raw environment beyond immediate perception. This intermediation occurs via two “blanket” states: sensory states, the subset of external states that are perceived, and active states that represent actions taken to alter external states and thus sensory states. As the system continuously interacts with its environment, it engages in perception-action loops that iteratively update it’s model of the world... These Markov blankets can be nested hierarchically across spatial scales to provide an ontology for, well, everything. The beauty of this simple formalism is the application of mathematical rigor to identity via the full arsenal of information & energy dynamics." - [Tomer Solomon](https://tomersolomon.substack.com/p/cosmic-bayesian-inference#:~:text=What%20is%20active,information%20%26%20energy%20dynamics.)

> "The purpose of the creation of God is the minimization of free energy." - [Joscha Bach](https://x.com/Plinz/status/1845687311637647842)

<details><summary>Other descriptions saying basically the same</summary><p>

> "The free energy principle is a law of life that emerged from Karl Friston’s “Bayesian brain hypothesis,” but it applies to brainless organisms as well. In fact, it presumably applies to every complex adaptive system in nature, societies included. The free energy principle is a framework for understanding how self-organized systems maintain themselves in a world that abides by the second law. Here we will focus on its applications for humans.
>
> The principle proposes that the brain is an organ that is designed to reduce uncertainty about the world around us and make predictions about future events. This is accomplished by generating internal predictions and comparing them to incoming sensory information. The brain then uses this comparison to update the beliefs of its model. In other words, the free energy principle suggests that the brain is constantly trying to minimize the difference between its internal model and reality. When the brain receives new information that contradicts its predictions, it experiences a state of "free energy" which drives it to update its beliefs and reduce its ignorance. To be clear, this is not thermodynamic free energy, but information-theoretic free energy, a term used in the field of machine learning. Performing this function allows us to make more accurate predictions, and makes us better adapted to nature." - [Introducing Three of the Teleological Stance's Tools for Self-Optimization and Self-Actualization, by Bobby Azarian](https://roadtoomega.substack.com/p/introducing-three-of-the-teleological#:~:text=The%20free%20energy%20principle%20is,us%20better%20adapted%20to%20nature.)

> "... Active Inference: The Free Energy Principle in Mind, Brain, and Behavior (by Thomas Parr, Giovanni Pezzulo, and Karl Friston). They summarize the notion of Active Inference as a goal-directed learning process that continually updates an entity’s world model in response to how well it predicts (infers) future states. Accurate models allow organisms to predict with high probability the state of their environment, whereas inaccurate models will meet with surprise when expectations don’t match reality, occasioning an update to the model. Through this process, the entity learns more and more about its surroundings. They write:
>
> 'Active Inference is a normative framework to characterize Bayes-optimal behavior and cognition in living organisms. Its normative character is evinced in the idea that all facets of behavior and cognition in living organisms follow a unique imperative: minimizing the surprise of their sensory observations. Surprise is to be interpreted in a technical sense: it measures how much an agent’s current sensory observations differ from its preferred sensory observations—that is, those that preserve its integrity (e.g., for a fish, being in the water). Importantly, minimizing surprise is not something that can be done by passively observing the environment: rather, agents must adaptively control their action-perception loops to solicit desired sensory observations. This is the active bit of Active Inference.'
>
> Or, more simply: “Surprise minimization permits living organisms to (temporarily) resist the second law of thermodynamics”.
>
> As a theory of animal cognition, Active Inference extends into the domain of Mind the same sort of dynamics we have been tracking across the lower levels of cosmic complexification. The basic entity–field relationship creates a thermodynamic imperative from the start, setting off a cascade of increasing free energy dissipation, structural organization, and information generation characterizing a universal learning process that grows more sophisticated from Matter to Life to Mind and beyond. At every level, there is meaning owing to the intrinsic desire of entities to extend their existence. So, too, at the level of Cognitive Learning, “Active Inference…is purposive and teleological”, a “normative,” goal-driven process relating entities and environments in a field of value." - [A Universal Learning Process, by Brendan Graham Dempsey](https://www.goodreads.com/book/show/216232048-a-universal-learning-process)

</p></details>

> "The nearest each of us can come to God is by loving the truth." - [R. Buckminster Fuller](https://www.azquotes.com/quote/716546)

> "To understand the actual world as it is, not as we should wish it to be, is the beginning of wisdom." - [Bertrand Russell](https://www.azquotes.com/quote/1081297)

## Anticipation-Control Theory

> "**A neural circuit that succesfully predicted what would happen gets reinforced; one that made a wrong prediction is weakened. In this way every experience of trying to anticipate phenomena leaves its trace in the organization of the brain, making it ever more effective at further anticipation.** This is how we implicitly learn our knowledge. A core tenet of the anticipation-control theory, as emphasized by Hawkins, is that **the brain is organized hierarchically, in different levels of invariance or control, whereby a higher level only becomes active when the lower levels fail to make a good prediction.** It is this hierarchical structure with massive feedback from the higher to the lower levels, allowing us to recognize and learn ever more complex invariances and covariances of patterns, that distinguishes the anticipation-control model from traditional neural network models.
>
> ... The very limited sensory input that an organism has leaves a great amount of uncertainty about the actual state of a complex and changeful world, and about the appropriate actions to take in that situation. **Any mechanism of anticipation or expectation that a priori reduces uncertainty will therefore have a large positive impact on the organism's capability for control, and thus on its fitness.** The essence of cognition is precisely to produce such a mechanism that can complement or fill in incomplete data. **To achieve optimal control, anticipation and perception, or feedforward and feedback, must go hand in hand, the one constantly correcting and extending the other.**" - [Towards an anticipation control theory of mind, by Francis Heylighen](http://pespmc1.vub.ac.be/Papers/AnticipationControl.pdf)


## OODA loop

> "In the end, we self-perceiving, self-inventing, locked-in mirages are little miracles of self-reference." - [Douglas Hofstadter](https://www.goodreads.com/quotes/229730-in-the-end-we-self-perceiving-self-inventing-locked-in-mirages-are-little)

> "I Am a Strange Loop argues that the key to understanding selves and consciousness is the “strange loop”—a special kind of abstract feedback loop inhabiting our brains." - [I Am a Strange Loop](https://www.goodreads.com/book/show/123471.I_Am_a_Strange_Loop#:~:text=I%20Am%20a%20Strange%20Loop%20argues%20that%20the%20key%20to%20understanding%20selves%20and%20consciousness%20is%20the%20%E2%80%9Cstrange%20loop%E2%80%9D%E2%80%94a%20special%20kind%20of%20abstract%20feedback%20loop%20inhabiting%20our%20brains.)

^^ What is our societal (OODA) loop?

we should be thinking in terms of sensory & motor systems

> "We are pragmatists. We don't stick to any ideology. Does it work? Let's try it, and if it does work, fine, let's continue it. If it doesn't work, toss it out, try another one. We are not enamored with any ideology." - [Lee Kuan Yew](https://www.goodreads.com/quotes/10141150-we-are-pragmatists-we-don-t-stick-to-any-ideology-does)

> "I believe that life is a process of continuous change and a constant struggle to make that change one for the better." - [Lee Kuan Yew](https://www.goodreads.com/quotes/7289188-i-believe-that-life-is-a-process-of-continuous-change)

██████████████████████████████████████████████████████████████████
# SECTION: Behavioral Investment Theory
██████████████████████████████████████████████████████████████████

TOK 101 - Behavioral Investment Theory
https://www.youtube.com/watch?v=OHXttFPlqxw

> "Behavior Investment Theory: The “Life-to-Mind” joint point on the Tree of Knowledge System. It is a metatheoretical formulation that frames the evolution of Mind via the positing that the nervous system functions as an investment value system that coordinates animal actions on a cost to benefit ratio on the principles of (1) energy economics; (2) evolution; (3) behavioral genetics; (4) neuro-computational control; (5) learning and environmental feedback; and (6) developmental stage/life history. It bridges evolutionary biology, ethology, cybernetics, complex adaptive systems, traditional cognitive neuroscience, 4E cognitive science, and behavioral science. In combination with the ToK System’s descriptive metaphysics it resolves the mentalist versus behaviorist division via framing animal activity in terms of mental behavior." - [UTOK: The Unified Theory of Knowledge, by Gregg Henriques](https://www.goodreads.com/book/show/219729081-utok)

> "What drove the evolution of the Mind dimension of complexification? UTOK answers this question with Behavioral Investment Theory (BIT), which is the metatheoretical joint point between the dimensions of Life and Mind. BIT bridges B. F. Skinner’s core concept of behavioral selection with the cognitive revolution in a novel way. According to BIT, the brain and nervous system model the animal-environment relationship and then make active inferences about what will occur, and then invest their actions accordingly. These investments yield consequences that impact future investments. The result is a variation, selection, and retention feedback loop that can help explain how learning patterns emerge and evolve in animals...
>
> Although Skinner’s work on operant learning is often taught in terms of rewards and punishers, the fact is that the process of behavioral selection is much more nuanced. Consider, for example, the act of writing. When you write, your pen produces ink on the page. Now consider what happens if the ink runs dry. Do you keep writing? Of course not. The reason is the ink is part of the consequences of your actions that you unconsciously predict and track to determine if you will continue investing in that activity. When the ink runs dry, the investment pattern feedback is interrupted and thus shifts accordingly.
>
> BIT broadly frames the evolution of minded behavior in the animal kingdom in four steps, evolving from 1) reacting to 2) learning to 3) thinking to 4) talking...
>
> BIT gives rise to a cybernetic or control theory model of operant learning that characterizes the behavior patterns of learning animals. There are three essential components in a control system: 1) an input sensor, 2) a reference goal, and 3) an output mechanism. A thermostat connected to an air conditioner is an example of a simple control system. The temperature gauge is the input sensor, the temperature you set the room at is the reference goal, and the output mechanism is the addition of cool air. These basic ingredients allow the air conditioner to maintain a comfortable room temperature.
>
> We can apply this model to how animals behave in a goal-oriented manner. BIT aligns an animal’s perceptions with the inputs, its motivational states are the goals, and emotions are the outputs which function as energizing action tendencies. This is UTOK’s Perception – Motivation => Emotion control theory formulation, or the “P – M => E” equation. It is translated to mean that a perception of an actual state relative to a motivational state leads to an emotional state.
>
> This formulation means that the animal must be able to perceive where they are, which means they need to integrate their sensations into a perceptual whole. Second, they need to have a system that takes an inventory of the kind of things that are good/rewarding or bad/punishing, which connect to the interior state of the animal (i.e., water is good when one’s internal state is registering thirst). The minus sign indicates that the animal is tracking the discrepancy between the actual and the motivated state. Finally, there is an energizing system that moves toward or away from things to regulate the relationship between actual and expected or hoped for state. This results in a feedback loop...
>
> Let’s now imagine an animal that is engaged in foraging and comes to a fork in its path. It must either travel left or right, and the contingencies that will follow are different depending on which way it goes. What is such an animal to do? If the animal has any familiarity with the context, the best thing it could do is run a simulation to model likely outcomes. This brings us to the evolution of thinking animals. Thinking takes place when animals can run simulations on possible paths of future investment that function to select paths that are predicted to yield the highest value.
>
> The logic of BIT helps us to place this in the larger picture. Actions are expensive. The task of the nervous system is to process information and generate models of animal-environment relations that enable the most viable path of investment to be realized. As such, mental evolution can be traced in terms of greater sophistication in mapping possible outcomes across increasingly complex goals and larger spans of time.
>
> The fourth step, talking, took place for humans. The basic idea is that the human capacity for social connection and shared attention and intention was coupled with the capacity to symbolically tag objects, processes, and commands. Then there emerged a syntactical processing structure that shifted the sharing of individual symbols into propositional language. It is here that we move from BIT into Justification Systems Theory." - [UTOK: The Unified Theory of Knowledge, by Gregg Henriques](https://www.goodreads.com/book/show/219729081-utok)

> "**P - M => E formulation**: The control learning theory formulation that arises out of Behavioral Investment Theory and the bridge between operant conditioning and living control systems. It refers to the process by which perceptions are referenced against motivations which in turn activate emotions. This sensory-perceptual-motivational-emotional-motor loop can frame how animals are oriented to salient variables and shift their actions based on consequences. It also provides a conceptual bridge between Mind1 neurocognitive processes with Mind2 subjective conscious experiences." - [UTOK: The Unified Theory of Knowledge, by Gregg Henriques](https://www.goodreads.com/book/show/219729081-utok)

██████████████████████████████████████████████████████████████████
# SECTION: Complexity
██████████████████████████████████████████████████████████████████

> "The greatest challenge today, not just in cell biology and ecology but in all of science, is the accurate and complete description of complex systems." - [Edward O. Wilson](https://www.goodreads.com/quotes/10317579-the-greatest-challenge-today-not-just-in-cell-biology-and)

> "Complexity: The complexity of a system refers to the diversity of its components and the multitude of connections that integrate them into a coherent whole. The more differentiated the components in a system, and the more integrated they are by the connections between them, the more complex the system, and the more difficult it will be to analyze, understand, or predict." - [Glossary of Concepts, Human Energy](https://www.humanenergy.io/glossary)

> "Subsystem/Supersystem: ... To really understand a system, you not only need to analyze it into its subsystems (reductionist approach), but also to see what function it performs within its supersystem (holistic approach)." - [Glossary of Concepts, Human Energy](https://www.humanenergy.io/glossary)

> "Complex adaptive systems: A complex adaptive system consists of many interacting subsystems, called agents, that are relatively loosely coupled. Examples are markets, ant colonies, cities, and the immune system. The agents’ actions are not rigidly fixed, preprogrammed or controlled, but continuously adapt to the actions of the other agents, and to changes in the environment. As a result, the system as a whole adapts and self-organizes, exhibiting emergent phenomena, such as collective intelligence, coordination, and properties of the whole that are lacking in the individual agents." - [Glossary of Concepts, Human Energy](https://www.humanenergy.io/glossary)

> "Law of complexity-consciousness: This is not an actual scientic “law”, but a general trend posited by the scientist/philosopher Teilhard de Chardin. It proposes that as evolution proceeds, both the complexity and the consciousness of the systems it produces increase. Complexity here refers to the diversity of components and the multitude of connections that integrate these components into a coherent whole. Consciousness refers to the fact that the systems become aware of an increasingly wider range of other systems in their surroundings, and become better at making sense of what these other phenomena mean for their own survival." - [Glossary of Concepts, Human Energy](https://www.humanenergy.io/glossary)

██████████████████████████████████████████████████████████████████
# SECTION: Self-organization
██████████████████████████████████████████████████████████████████

> "Emergence: An emergent property is a property of a whole (system) that cannot be deduced from the properties of its parts. For example, a material has properties such as hardness or temperature, which are absent in the atoms out of which the material is composed. Similarly, a car is characterized by emergent properties such as fuel consumption or maximum speed, lacking in its components, such as engine, frame, or wheels. Emergent properties arise from the specific relations or couplings that turn an assembly of parts into a coherent whole. Since there are in general, myriad ways to interconnect parts into a whole, the properties of that whole cannot be predicted just from the properties of the individual parts." - [Glossary of Concepts, Human Energy](https://www.humanenergy.io/glossary)

> "Self-organization: Self-organization is defined as the spontaneous emergence of a global order out of local interactions. It occurs when initially independent elements or agents settle into a coordinated pattern, without any internal 'manager' or external 'designer' telling them how to do this. Think of those thousands of starlings who manage to swirl in a synchronized swarm, without bumping into each other. Each bird follows the same simple rules, continuously adapting to the movements of its neighbors, but without following any leader. Self-organization is sometimes presented as an alternative mechanism of evolution, complementary to natural selection, because it does not require selection by an external environment. However, self-organization is better conceived as mutual alignment or adaptation, where a local component ts into the environment formed by the other components it interacts with." - [Glossary of Concepts, Human Energy](https://www.humanenergy.io/glossary)

> "We need different modes of sociopolitical governance. Complex systems science teaches us that local, bottom-up and distributed coordination are typically the most effective and capable mechanisms for enabling emergent global order in highly complex environments. This is because, in complex systems, there are simply too many differentiated parts for effective top-down mechanisms for coordination to stably function and synergize the whole. Thus any global systems science and serious sociopolitical global development agenda must understand how to maintain a new planetary organization with dynamic and distributed mechanisms that lead to self-organization (as opposed to static and hierarchical historical mechanisms that produce centralized organization)." - [Global Brain Singularity, by Cadell Last](https://cadelllast.files.wordpress.com/2018/11/phd-thesis-articles-pdf.pdf)


> "The flow of energy through a system acts to organize that system." - [Harold Morowitz](https://www.azquotes.com/quote/736471)

> "Self-organization can be defined as the spontaneous creation of a globally coherent pattern out of local interactions. Because of its distributed character, this organization tends to be robust, resisting perturbations." - [The science of self-organization and adaptivity, by Francis Heylighen](http://pespmc1.vub.ac.be/Papers/EOLSS-Self-Organiz.pdf)

> "Although the market is a highly chaotic, non-linear system, it usually reaches an approximate equilibrium in which the many changing and conflicting demands of consumers are all satisfied. The failure of communism has shown that the market is much more effective at organizing the economy than a centrally controlled system. It is as if a mysterious power ensures that goods are produced in the right amounts and distributed to the right places. What Adam Smith, the father of economics, called "the invisible hand" can nowadays simply be called self-organization." - [The science of self-organization and adaptivity, by Francis Heylighen](http://pespmc1.vub.ac.be/Papers/EOLSS-Self-Organiz.pdf)

> "Although centralized control does have some advantages over distributed control (e.g. it allows more autonomy and stronger specialization for the controller), at some level it must itself be based on distributed control. For example, the behavior of our body can be best explained by studying what happens in our brain, since the brain, through the nervous system, controls the movement of our muscles. However, to explain the functioning of our brain, we can no longer rely on some “mind within the mind” that tells the different brain neurons what to do. This is the traditional philosophical problem of the homunculus, the hypothetical “little man” that had to be postulated as the one that makes all the decisions within our mental system. Any explanation for organization that relies on some separate control, plan or blueprint must also explain where that control comes from, otherwise it is not really an explanation. The only way to avoid falling into the trap of an infinite regress (the mind within the mind within the mind within...) is to uncover a mechanism of self- organization at some level.
>
> The brain illustrates this principle nicely. Its organization is distributed over a network of interacting neurons. Although different brain regions are specialized for different tasks, no neuron or group of neurons has overall control. This is shown by the fact that minor brain lesions because of accidents, surgery or tumors normally do not disturb overall functioning, whatever the region that is destroyed." - [The science of self-organization and adaptivity, by Francis Heylighen](http://pespmc1.vub.ac.be/Papers/EOLSS-Self-Organiz.pdf)

> "Self-organizing systems: they are robust or resilient. This means that they are relatively insensitive to perturbations or errors, and have a strong capacity to restore themselves, unlike most human designed systems." - [The science of self-organization and adaptivity, by Francis Heylighen](http://pespmc1.vub.ac.be/Papers/EOLSS-Self-Organiz.pdf)

> "Feedback can have two basic values: positive or negative. Feedback is said to be positive if the recurrent influence reinforces or amplifies the initial change. In other words, if a change takes place in a particular direction, the reaction being fed back takes place in that same direction. Feedback is negative if the reaction is opposite to the initial action, that is, if change is suppressed or counteracted, rather than reinforced. Negative feedback stabilizes the system, by bringing deviations back to their original state. Positive feedback, on the other hand, makes deviations grow in a runaway, explosive manner. It leads to accelerated development, resulting in a radically different configuration." - [The science of self-organization and adaptivity, by Francis Heylighen](http://pespmc1.vub.ac.be/Papers/EOLSS-Self-Organiz.pdf)

> "Cybernetics has shown that adaptation can be modelled as a problem of regulation or control: minimizing deviations from a goal configuration by counteracting perturbations before they become large enough to endanger the essential organization. This means that the system must be able to: 1) produce a sufficient variety of actions to cope with each of the possible perturbations (Ashby’s “law of requisite variety”); 2) select the most adequate counteraction for a given perturbation." - [The science of self-organization and adaptivity, by Francis Heylighen](http://pespmc1.vub.ac.be/Papers/EOLSS-Self-Organiz.pdf)

> "The system needs a fitness criterion for choosing the best action for the given circumstances. The most straightforward method is to let the environment itself determine what is fit: if the action maintains the basic organization, it is, otherwise it is not. This can be dangerous, though, since trying out an inadequate action may lead to the destruction of the system. Therefore, complex systems such as organisms or minds have evolved internal models of the environment. This allows them to try out a potential action “virtually”, in the model, and use the model to decide on its fitness. The model functions as a vicarious selector, which internally selects actions acting for, or in anticipation of, external selection. This “shortcut” makes the selection of actions much more reliable and efficient. It must be noted, though, that these models themselves at some stage must have evolved to fit the real environment; otherwise they cannot offer any reliable guidance." - [The science of self-organization and adaptivity, by Francis Heylighen](http://pespmc1.vub.ac.be/Papers/EOLSS-Self-Organiz.pdf)

> "Self-organization is basically the spontaneous creation of a globally coherent pattern out of the local interactions between initially independent components. This collective order is organized in function of its own maintenance, and thus tends to resist perturbations. This robustness is achieved by distributed, redundant control so that damage can be restored by the remaining, undamaged sections." - [The science of self-organization and adaptivity, by Francis Heylighen](http://pespmc1.vub.ac.be/Papers/EOLSS-Self-Organiz.pdf)

> "Perhaps the most challenging application would be to design a complex socio-economic system that relies on self-organization rather than centralized planning and control. Although our present organizations and societies incorporate many aspects of self-organization, it is clear that they are far from optimal." - [The science of self-organization and adaptivity, by Francis Heylighen](http://pespmc1.vub.ac.be/Papers/EOLSS-Self-Organiz.pdf)


> "Self-organization: the spontaneous emergence or evolution of coordination in a complex adaptive system. Self-organization reduces variety or uncertainty, and thus imposes constraint. The driving force behind self-organization is the co-evolution or mutual adaptation between the different agents in the system: actions and reactions produce a continuously changing configuration of interactions (variation); however, the more synergetic a configuration, the more "satisfied" the agents will be with the situation, and thus the less they will act to produce further changes (selective retention or preference for synergetic configurations); vice versa, the more friction there is, the more the agents will be pressured to intervene and change course in order to increase their utility (elimination of high friction configurations). Thus, self-organization is merely an application of the evolutionary dynamic of variation (because of actions triggering further actions) and natural selection (because of the implicit preference of agents for the more synergetic patterns of action)." - [Self-organization of complex, intelligent systems: an action ontology for transdisciplinary integration, by Francis Heylighen](http://pespmc1.vub.ac.be/Papers/ECCO-paradigm.pdf)

> "Organization: a stabilized network of interactions between agents that functions to ensure the coordination of their actions. This structure specifies the specific roles of and interactions between the system's agents. Its function is to maximize synergy and minimize friction (including transaction costs) in their further interactions. For example, in a human organization the different individuals each have their own responsibilities, and the rules of the organization specify who interacts with whom in what way. This minimizes transaction costs, since it is no longer necessary to search for partners, negotiate with them, or strictly monitor whether they do what they are expected to do. An organization can be imposed from the outside (like in a system engineered by a designer or controlled by a manager), or emerge from self-organization." - [Self-organization of complex, intelligent systems: an action ontology for transdisciplinary integration, by Francis Heylighen](http://pespmc1.vub.ac.be/Papers/ECCO-paradigm.pdf)


> "Hierarchy is now defined as a vertical sequence of layers of accountability, based on different degrees of abstraction." - [The Role of Hierarchy in Self-Organizing Systems](https://www.researchgate.net/publication/254821737_The_Role_of_Hierarchy_in_Self-Organizing_Systems)




██████████████████████████████████████████████████████████████████
# SECTION: Coordination
██████████████████████████████████████████████████████████████████

> "Coordination: the arrangement or mutual alignment of actions so as to maximize synergy and minimize friction in their overall pattern of activity. It implies that any two actions performed simultaneously or subsequently are selected so as to maximally complement and minimally obstruct each other. This requires a minimization of the uncertainty that otherwise would dissipate resources in needless trial-and-error, and therefore the imposition of appropriate constraints or bonds that drive the action in the right direction. There are two types of basic relational constraints between actions: parallel, specifying which actions could or should go on simultaneously, and sequential, specifying which action could or should follow which other action." - [Self-organization of complex, intelligent systems: an action ontology for transdisciplinary integration, by Francis Heylighen](http://pespmc1.vub.ac.be/Papers/ECCO-paradigm.pdf)

> "According to coordination theory, we can distinguish the following fundamental dependencies or connections between actions or processes:
>
> 1) one action can be prerequisite for the next action: the product or output of the first is a necessary condition or input for the second. This determines the sequential organization of the process, or workflow, where activity moves step-by-step through a sequence of tasks (what needs to be done next?).
>
> 2) two actions can require the same condition (input) and/or contribute to the same effect or goal (output), i.e. they are performed in parallel. This determines the allocation of resources (who receives what?) and the division of labor between agents (who is to do what?).
>
> Effective coordination means that the right actions are performed by the right agents at the right time and place." - [Stigmergy as a Generic Mechanism for Coordination: Definition, Varieties and Aspects, by Francis Heylighen](http://pespmc1.vub.ac.be/Papers/Stigmergy-WorkingPaper.pdf)


> "Coordination Theory suggests identifying the dependencies between the tasks the different group members are carrying out and the coordination mechanisms the group use to coordinate their work and then considering alternative mechanisms.
>
> ... In 1994, Malone and Crowston described a new approach to these problems, an approach they called Coordination Theory (CT) (Malone and Crowston, 1994). Their 1994 paper presented examples of similar coordination problems encountered in a variety of disciplines and analyzed them as arising from dependencies. For example, approaches to sharing resources (i.e., ways to manage the dependency created when multiple tasks require the same resources) have been analyzed in economics, organization theory and computer science, among others. Other dependencies identified by Malone and Crowston are producer/consumer dependencies, simultaneity constraints and task/subtask relations.
>
> ... The primary purpose of Malone and Crowston (1994) was to synthesize work done on coordination from a variety of fields... The paper made three key contributions.
>
> First contribution: Definition of coordination
>
> The first contribution of the paper was a concise definition of coordination as “managing dependencies between activities”. Coordination has been a long-standing interest of organizational scholars and more recently of computer scientists, so many definitions for this term had been proposed. Malone and Crowston (1994) and Weigand, van der Poll & de Moor (2003) list several, including:
>
> - Structuring and facilitating transactions between interdependent components (Chandler, 1962)
>
> - The protocols, tasks and decision-making mechanisms designed to achieve concerted actions between interdependent units (Thompson, 1967)
>
> - The integrative devices for interconnecting differentiated sub-units (Lawrence and Lorsch, 1967)
>
> - Composing purposeful actions into larger purposeful wholes (Holt, 1988)
>
> - The integration and harmonious adjustment of individual work efforts towards the accomplishment of a larger goal (Singh and Rein, 1992)
>
> - Establishing attunement between tasks with the purpose of accomplishing that the execution of separate tasks is timely, in the right order and of the right quantity (Reezigt, 1995)
>
> In contrast to the first 3 definitions, drawn from the organization studies literature, Malone and Crowston (1994) conceptualize dependencies as arising between tasks rather than individuals or units. This approach has the advantage of making it easier to model the effects of reassignments of activities to different actors, which is common in process redesign efforts. Compared to the final three definitions, taken from the CSCW literature, the Malone and Crowston (1994) definition focuses attention on cause for a need to coordinate, rather than on the desired outcome of coordination. This focus has advantages again for modelling, as will be discussed below.
>
> Second contribution: Modelling framework
>
> The second contribution of the 1994 paper was to provide a theoretical framework for analyzing coordination in complex processes, thus contributing to user task analysis and modeling. Consistent with the definition proposed above, Malone and Crowston (1994) analyzed group action in terms of actors performing interdependent tasks. These tasks might require or create resources of various types. For example, in the case of software requirements development, actors include the customers and various employees of the software company. Tasks include translating aspects of a customer’s problem into system requirements and checking requirements for consistency against other requirements. Finally, resources include the information about the customer’s problem, existing system functionality and analysts’ time and effort. In this view, actors in organizations face coordination problems arising from dependencies that constrain how tasks can be performed. It should be noted that in developing this framework, Malone and Crowston describe coordination mechanisms as relying on other necessary group functions, such as decision making, communications and development of shared understandings and collective sensemaking (Britton et al., 2000; Crowston and Kammerer, 1998). To develop a complete model of some process would involve modelling all of these aspects: coordination, decision making and communications. In practice, our analyses have tended to focus on the coordination aspects, bracketing the other phenomenon, though clearly groups might face problems in all of these.
>
> Third contribution: Typology of dependencies and coordination mechanisms
>
> TODO continue..." - [Coordination Theory: A Ten-Year Retrospective](https://crowston.syr.edu/sites/crowston.syr.edu/files/CT%20Review%20to%20distribute.pdf)

Crowston, K. A Taxonomy of Organizational Dependencies and Coordination Mechanisms. Massachusetts Institute of Technology, Sloan School of Management, 1994., !!! ALSO Malone? or is their paper a different one?

██████████████████████████████████████████████████████████████████
# SECTION: Enhancing digital coordination
██████████████████████████████████████████████████████████████████

<!-- > "We are concerned with designing systems that allow groups to collaborate over computer networks. We are particularly interested in the question of how to design such systems so they support coherent interactions that enable groups with a shared aim to make progress toward a common goal. It is our experience that such coherent interaction is difficult to achieve in online environments, and thus our work begins with a question: How is it that, in the physical world, we are able to manage our group interactions so gracefully? Our answer is that humans are remarkably skilled at using subtle cues about the presence and activities of others to govern their interactions." - [Social Translucence: Designing Social Infrastructures that Make Collective Activity Visible](https://dl.acm.org/doi/10.1145/505248.505270) -->

> "We are interested in designing digital systems that make perceptually based social cues visible to their users. We believe that such systems—by supporting mutual awareness and accountability—will make it easier for people to carry on coherent discussions; to observe and imitate others’ actions; to engage in peer pressure; to create, notice, and conform to social conventions; and to engage in other forms of collective interaction. We use the phrase “social translucence” as a rubric for our approach to designing such systems... By making social cues visible, and allowing visible traces to accumulate over time, we create a resource that allows people—especially those familiar with the interactive context—to draw inferences about what is happening which can, in turn, shape their collective activity." - [Social Translucence: Designing Social Infrastructures that Make Collective Activity Visible](https://dl.acm.org/doi/10.1145/505248.505270)



██████████████████████████████████████████████████████████████████
# SECTION: Intelligence
██████████████████████████████████████████████████████████████████

> "The measure of intelligence is the ability to change." - [Albert Einstein](https://www.goodreads.com/quotes/85475-the-measure-of-intelligence-is-the-ability-to-change)

> "Intelligence is based on how efficient a species became at doing the things they need to survive." - [Charles Darwin](https://www.goodreads.com/quotes/337972-intelligence-is-based-on-how-efficient-a-species-became-at)

According to cybernetics, intelligence sits on top of feedback loops

██████████████████████████████████████████████████████████████████
# SECTION: Relevance realization
██████████████████████████████████████████████████████████████████

relevance realization: the cognitive process by which you discern and prioritize what is most significant or meaningful in a given context

relevance_realization_symbol.jpg

> "Relevance realization is the name I give to a process which I argue is central to general intelligence. Your general intelligence is your capacity to solve a wide variety of problems in a wide variety of domains. For most of the problems you face the interrelated tasks of selecting what you are to pay attention to, what you are going to remember, and what you are going to do. The problem facing attention is that the amount of information available to you is astronomically vast. You have to ignore most of it, which is a lot of information. You cannot just arbitrarily guess what you should attend to nor can you methodically check all the information for that would take more time than your lifetime. There is a similar problem facing memory. Your long term memory stores a vast amount of knowledge, and the number of ways that information can be combined is astronomically vast. Similarly, all the possible sequences of actions which you could undertake is astronomically vast. Yet, moment by moment you are neither guessing nor methodically checking all the information, all your memory, or all the options for action. You are homing in on the relevant information while remembering the information relevant to your situation and selecting a relevant course of action. What is so impressive is how this is all obvious to you, and it is very often relevant to the context you are in and to the problem at hand. You can rely on the obviousness of your experience and that it is reliably sensitive to context. However, cognitive science has to explain how you generate such obviousness such that it is contextually sensitive to solving your problems. Saying that relevance is obvious or depends on context does not solve the problem because this merely renames the problem of relevance realization as the problem of generating a sense of the relevance of information in a contextually sensitive manner, and how do we do that? To say we learn it by experience is not helpful because to say we learn is to say that we zero in on relevant information in order to solve our problems. This learning cannot be arbitrary association nor can it use exhaustive examination of situations. Learning presupposes relevance realization and therefore cannot explain it. I currently have a paper under review, where my coauthors and I argue that relevance realization is probably convergent with the precision weighting at the core of predictive processing models. This convergence adds significant theoretical plausibility to the proposal that relevance realization is central to intelligence." - [John Vervaeke](https://www.quora.com/What-is-a-summary-of-relevance-realization-according-to-John-Vervaeke)

> "You face a problem - in fact it's a meta problem whenever you're trying to do any problem solving - this is the following problem: the amount of information available to you is combinatorily explosive, it is vast, it is overwhelming. The amount of things you could pay attention to in this room - you could look at that spot right there, or that spot, or the relationship between the spots - you can do that, you're capable of it. When you think about it carefully now: the amount of ways you could look at this room and attend to it is combinatorially explosive. It is vast. The amount of information you have in your long-term memory and the possible combinations - it's huge. You could think of an aardvark, you could think of the Aztec empire, you could think of the beginning of the gold standard, and you could possibly even connect them all together. Think of all the ways you can connect all the things in your long-term memory. All the sequences of actions - I'm going to solve a problem - I'm going to start moving my body around, I can move this finger, then this finger could move these two, I could grab I could lift my hands, like oh I can sing - out of all the possible combinations you somehow zero in on the right thing to do, the right thing to pay attention to, and the right things to be remembering right now. You zero in on the relevant information and you ignore most - overwhelmingly most - of the irrelevant information. You frame your cognition and you pay attention only to what's within that frame and you ignore what's outside of that frame. It sounds paradoxical but this is the case - you're intelligent because of your capacity to ignore so much information." - [John Vervaeke: Democracy and the Relevance Realization of Distributed Cognition](https://youtu.be/8U2caURO-d4?t=730)

problem formulation and intelligently constraining the search space, also insight and problem reformulation

> "Somehow problem solvers reliably (but not perfectly) zero in on the relevant information to be investigated. They do not do this abstractly, but in the way they formulate the problem. How individuals represent the initial state, goal state, operations, and path constraints, is the way in which they attempt to zero in on relevant information. Problem formulation is how problem solvers constrain the search space of a particular problem so that heuristics can effectively apply to it. Problem formulation captures what problem solvers deem relevant to a specific problem, and this formulation helps them to intelligently ignore most of the information in the search space. To intelligently ignore means that problem solvers do not even consider most available information, and they find and focus upon information that turns out to be relevant without comparing it to all the irrelevant information that is available.
>
> ... Consider how we are beset by ill-defined problems all day long such as following and/or joining a conversation successfully, getting and/or telling a joke or telling a story. As such, we frequently have to generate problem formulations in order to both address ill-definedness and to avoid combinatorial explosion. Not only do we have to zero in on relevant information, we often have to generate missing relevant information in order to do so. Problem formulation handles both of these demands and is a primary way in which we do relevance realization within problem solving.
>
> However, sometimes the problem formulation constrains a problem in such a way so that it cannot be solved; the problem formulation itself becomes problematic. In these circumstances, the problem formulations need to be broken up and reformulated. The solver must have an insight: their relevance realization abilities have to be flexibly recursive and self-correcting. They have to realize that they have misformulated the problem and be capable of generating a new relevance profile that then informs a new, more effective formulation.
>
> ... Truly the ability to determine relevance is foundational to our intelligence and would be central to any SmartData system." - [Relevance Realization and the Neurodynamics and Neuroconnectivity of General Intelligence](https://www.researchgate.net/publication/299812171)

RR as self-organizing, self-correcting and self-transforming

> "The processing of relevance realization has to happen as a constraint on all processing both local and global within the brain. Relevance realization has to be internal, sub-semantic, sub-syntactic, and scale invariant in its operations. Finally, it must be completely self-organizing because it has to be a self-correcting and self-transforming process.
>
> ... This is the heart of relevance realization: to be able to usefully ignore information in a contextually sensitive manner so as to enable our actions. Taken together, combinatorial complexity in problem solving, the largely ill-defined nature of most problems and the consideration of consequences serve to indicate the centrality of our relevance realization machinery. Thus, relevance realization is central; it involves the ability to frame our cognition and, most importantly, to do this flexibly, i.e. to be able to reframe. This ability to reframe how we find things relevant is sometimes experienced as the “aha” moment called insight.
>
> ... Relevance realization is always a matter of the selective direction of attention, the appraisal of value, and the rationing and commitment of processing resources. Relevance realization is simultaneously attentional, affective, and motivational. Relevance realization largely concerns how you care about and care for information.
>
> ... Evolutionary processes are constantly redefining from within evolution what it means to be fit. Relevance realization must constantly be redefining from within relevance realization what it means for information to be relevant.
>
> ... Recursive relevance realization is cognition continually redesigning itself to fit the changing world." - [Relevance, Meaning and the Cognitive Science of Wisdom](https://www.researchgate.net/publication/286508333)

> "Relevance is like biological fittedness. It is cognitive fittedness." - [John Vervaeke](https://twitter.com/tomowenmorgan/status/1742174771196866796)

> "General intelligence can be understood as a dynamic developmental evolution of your sensory motor fittedness that is regulated by virtual engines that are ultimately regulated by the logistical normativity of the opponent processing between efficiency and resiliency." - [John Vervaeke](https://youtu.be/gfKcVbNd7Xc?t=3238)

---

One way to think about relevance realization when implementing something like it digitally in terms of mechanisms & algorithms: ranking/sorting/prioritizing - you don't necessarily need to rank/sort all elements (that might take too much time) but you should be able to answer queries of the sort: `"What are the top X elements"` and optionally get the result with weights (quantitative comparison) and not just as simple positional ordering. Comparison/ordering/ranking give us the capacity for non-random choice - they are a necessary prerequisite.

<details><summary>Quotes related to RR</summary><p>

> "In an age of infinite leverage, judgement is the most important skill." - [Naval Ravikant](https://twitter.com/naval/status/998039099427704832)

> "We do not measure a culture by its output of undisguised trivialities but by what it claims as significant." - [Neil Postman](https://www.azquotes.com/quote/456296)

> "Ask yourself at every moment, 'Is this necessary?'" - [Marcus Aurelius](https://www.goodreads.com/quotes/7998994-ask-yourself-at-every-moment-is-this-necessary)

> "The essence of strategy is choosing what not to do." - [Michael Porter](https://www.azquotes.com/quote/234635)

> "Focusing is about saying No." - [Steve Jobs](https://www.goodreads.com/quotes/455912-focusing-is-about-saying-no)

> "The art of being wise is the art of knowing what to overlook." - [David Brooks](https://www.goodreads.com/quotes/7221905-the-art-of-being-wise-is-the-art-of-knowing)

> "To attain knowledge, add things everyday. To attain wisdom, remove things every day." - [Lao Tzu](https://www.goodreads.com/quotes/30297-to-attain-knowledge-add-things-everyday-to-attain-wisdom-remove)

> "Mathematician Richard Hamming used to ask scientists in other fields "What are the most important problems in your field?" partly so he could troll them by asking "Why aren't you working on them?" and partly because getting asked this question is really useful for focusing people's attention on what matters." - [The Hamming Question](https://www.lesswrong.com/posts/P5k3PGzebd5yYrYqd/the-hamming-question#:~:text=Mathematician%20Richard%20Hamming,on%20what%20matters.)

> "To develop the skill of introspection and correct thinking is to learn — in the first place — what you have to disregard. The ineffectiveness of natural thinking comes from being overwhelmed by an infinity of possibilities and facts. In order to go on, you have to know what to leave out; this is the essence of effective thinking." - [Kurt Gödel](https://medium.com/catalyzingcoherence/a-meditation-on-diversity-equality-and-humanity-48008cd197a#:~:text=To%20develop%20the,of%20effective%20thinking.)

> "Things which matter most must never be at the mercy of things which matter least." - [Johann Wolfgang von Goethe](https://www.goodreads.com/quotes/2326-things-which-matter-most-must-never-be-at-the-mercy)

> "Because we retain more of our information now than at any previous point in human history, it takes much more effort to delete or remove unwanted information than to accumulate it. This is the ultimate entropy cost of generating additional information." - [Wikipedia page about James Gleick's book "The Information: A History, a Theory, a Flood"](https://en.wikipedia.org/wiki/The_Information:_A_History,_a_Theory,_a_Flood#:~:text=because%20we%20retain%20more%20of%20our%20information%20now%20than%20at%20any%20previous%20point%20in%20human%20history%2C%20it%20takes%20much%20more%20effort%20to%20delete%20or%20remove%20unwanted%20information%20than%20to%20accumulate%20it.%20This%20is%20the%20ultimate%20entropy%20cost%20of%20generating%20additional%20information)

<!-- > "People think focus means saying yes to the thing you've got to focus on. But that's not what it means at all. It means saying no to the hundred other good ideas that there are. You have to pick carefully. I'm actually as proud of the things we haven't done as the things I have done. Innovation is saying no to 1,000 things." - [Steve Jobs](https://www.goodreads.com/quotes/629613-people-think-focus-means-saying-yes-to-the-thing-you-ve) -->

<!-- > "The first step is just recognizing that *there is a difference* between what's interesting and what's useful/true. I think many of our problems stem from people failing to distinguish between them in the first place. I think it's worth developing an intuitive sense of the "vibe" of truth/insight and the "vibe" of interesting bullshit." - [You Will Find This Interesting, by David Pinsof](https://open.substack.com/pub/everythingisbullshit/p/you-will-find-this-interesting?r=7omg8&utm_campaign=comment-list-share-cta&utm_medium=web&comments=true&commentId=17285575) -->

2 more quotes from John's paper on RR

representation, features, aspects, properties & relevance

> "We never represent all the properties of anything because we are in the finitary predicament. We always only represent a subset of any real world things. This subset of features and how they hang together is an aspect. All representation is aspectual. Yet an aspect is a zeroing in on properties deemed relevant, and a formulation of those properties as highly relevant to each other and to oneself and others. The ability to represent crucially presupposes the ability to realize relevance and therefore cannot serve as a basis of explaining it without circularity." - [Relevance Realization and the Neurodynamics and Neuroconnectivity of General Intelligence](https://www.researchgate.net/publication/299812171)

insight that leads us from illusion (self‐deception) into reality as wisdom

> "McKee and Barber note that it is not just any kind of insight that constitutes wisdom. Rather it is some kind of insight through illusion and into reality. Meeks and Jeste indicate that the insight involved in wisdom also has importantly to do with self‐reflection/self‐understanding. The connection here is that illusion is some form of self‐deception, so seeing through illusion and into reality involves important insight into one’s own cognition and how it might be impeding contact with reality." - [Relevance, Meaning and the Cognitive Science of Wisdom](https://www.researchgate.net/publication/286508333)

</p></details>

good ordering in the complexity of decision-making is basically sortition/ranking aka RR

> "4. COMPLEXITY OF DECISION-MAKING
>
> Let us define the complexity of decision-making or categorization as “the average number of alternatives (categories) that need to be explored before the appropriate one is found”. This seems like a good measure for cognitive effort, amount of trial-and-error, or time spent searching. It is similar to the measure assumed by Simon (1962) in his famous paper on the “Architecture of Complexity” when arguing that hierarchical decomposition enormously decreases the complexity of problem-solving. We will now produce a similar argument for probability ordering.
>
> ... In conclusion, cognitive complexity of choice between a given number of alternatives K will decrease with the goodness of ordering of the alternatives according to probability, and (given ordering) increase with the entropy (homogeneity) of the probability distribution. There are thus two ways to keep complexity small:
>
> 1) Good ordering: this is a factor which depends on the organism's capacity to learn, i.e. to store its experience as to the frequency with which a particular alternative is encountered. It is well-known that past frequency of occurrence, implying likeliness of future occurrence, is a fundamental determinant of learning. For example, associative learning in conditioning experiments or in neural network models assumes that a learned association (if “bird”, then “flies”) becomes stronger the more often it is activated. The “strength” of a connection determines the likeliness that the connection is later activated, and thus the (average) speed with which the alternative represented by that connection is explored.
>
> 2) Low entropy: this is a factor which partly depends on the organism, partly on its environment. In a high entropy environment, where all types of phenomena or situations are about equally likely, cognitive complexity would be maximal, and control through knowledge would be virtually impossible. In a “mixed entropy” environment, where some types of phenomena are equally likely, while others have strongly differentiated probabilities, cognitive complexity could still be kept within bounds by ignoring or filtering out all the high entropy categories. This is not a problem if the eliminated categories correspond to those variables which are irrelevant to the organism's fitness. For example, the Brownian motion of air molecules against one's skin is a largely entropic phenomenon, where it is practically impossible to predict the direction of the next motion given the present one. Yet the pressure exerted by this Brownian motion can be neglected as far as survival is concerned, and thus adequate cognitive modelling, enabling prediction and control, is not necessary." - [Fitness as default: the evolutionary basis for cognitive complexity reduction, by Francis Heylighen](http://pespmc1.vub.ac.be/Papers/FitnessDefault.pdf)

<details><summary>The link between categorization, default reasoning and hierarchies</summary><p>

> "3. CATEGORIZATION AND DEFAULT REASONING
>
> The above analysis argues that a small set of actions may still be sufficient to adapt to an infinitely complex environment. But it does not explain how an infinite variety of phenomena can be adequately mapped onto that small set. Every new phenomenon must somehow be put in the appropriate category, which can then be linked to an action adequate for that class of events. Perceived phenomena will activate simple sensory attributes such as “hot”, “cold”, “red”, “heavy”, “loud”, etc. The function of the cognitive system is to map specific combinations of these attributes onto more abstract categories, which can then be interpreted in terms of required actions. E.g. the combination “hot”, “high”, “light” may elicit the concept “sun”, which may trigger the action “go into the shade”. In order to adequately steer the organism towards its goal of increasing fitness, a maximum number of combinations of attributes must be put into categories denoting possible dangers (e.g. fire, predators, cliffs, rivers, ...) or resources and opportunities (e.g. food, mates, water, shelters, ...). As implied by Ashby's law, the larger the variety of action-triggering categories available to the organism, the larger the control that it can achieve, and thus the better it will succeed in maintaining or improving its fitness, and the more likely that it will win the struggle for life. Evolution thus tends to increase the number of perceivable attributes and categories.
>
> Even when the number of attributes is relatively small, the number of possible combinations will be virtually infinite. However, most of these combinations will not correspond to categories relevant to the system's survival. For example, it may be essential to distinguish a phenomenon with the attributes “moving”, “small”, “striped”, “yellow”, “black” as belonging to the category “wasp”, linked to the action “avoid contact”. On the other hand, combinations like “moving”, “large”, “green”, “purple” will never be encountered, and thus need not be represented by a particular action-triggering category. Finally, a combination like “not moving”, “medium”, “brown” may be very common in the environment (e.g. a piece of wood or a boulder), yet be totally irrelevant for the organism's survival, and thus similarly escape categorization.
>
> A basic mechanism for minimizing the complexity of categorization is default reasoning. Each time a new combination of attributes is encountered, the organism must find the appropriate category in which to fit the perceived phenomenon, in order to further infer appropriate actions. The same combination might fit several categories, or none at al. Rather than systematically test all categories (Is it a bird? Is it a plane? Is it...?), the organism will immediately pick up the “most likely” category, until it encounters evidence that another categorization is needed. It will then try out the “second most likely” category, and so on.
>
> The classical example of default reasoning is the assumption that if something is a bird (earlier categorization or attribute), it can be expected to fly (inferred category). This is probably true in over 99% of the cases. Yet, the existence of ostriches and penguins shows that this is not a universal truth. Violations of the default expectation will be encoded in the cognitive system as exceptions: if it is a bird, then it can fly, except if it is penguin or an ostrich. But the awareness of the “exceptional” situation will trigger new default expectations: if it is an ostrich, then it can run; or, if it is a penguin, then it can swim. Again, there will be exceptions to these rules: if it is an ostrich, and it has a broken leg, it cannot run. But that expectation might in very unusual circumstances again be violated: perhaps an ostrich with a broken leg could still run if it was wearing some kind of artificial support...
>
> The system behind this type of reasoning may be called a default hierarchy (Holland et al., 1986): it consists of different levels of expectations, the most likely one at the top, the less likely below. As ones goes deeper down into the exceptions and exceptions to exceptions, more attributes are added to the necessary conditions, and thus triggering conditions become more specific, and less probable. (After all, it would be quite unlikely to encounter an ostrich wearing a support around its broken leg...)." - [Fitness as default: the evolutionary basis for cognitive complexity reduction, by Francis Heylighen](http://pespmc1.vub.ac.be/Papers/FitnessDefault.pdf)

<!--
not sure this is important enough

> "5. FITNESS AS DEFAULT
>
> Our analysis still implies that at least the variables relevant to survival should have a low entropy. This is not at all obvious, given the 2nd Law of Thermodynamics, which states that thermodynamic entropy tends to spontaneously increase. However, I have argued in an earlier paper (Heylighen, 1992) that increase of thermodynamic entropy can still be accompanied by decrease of statistical entropy (the necessary and sufficient condition for a Markov process to allow decrease of statistical entropy is that its transition matrix not be doubly stochastic (Koopman, 1978)). The present conclusion about cognitive complexity can be interpreted as a further, indirect argument against the common belief that the most “natural” state of the world is one of high entropy. If that were true, knowledge and control could never have developed.
>
> ... What was called “stability” when discussing asymmetric transitions, is perhaps more properly called “fitness”. Fit configurations can be defined as configurations picked out by natural selection. This may happen because they are intrinsically stable, or because they are (re)produced in great quantities. Selection entails a fundamental asymmetry between fit and unfit systems: fit systems are naturally privileged, and are much more likely to be encountered than unfit ones." - [Fitness as default: the evolutionary basis for cognitive complexity reduction, by Francis Heylighen](http://pespmc1.vub.ac.be/Papers/FitnessDefault.pdf)
-->

</p></details>


> "**Recursive Relevance Realization**: A metatheory of neurocognitive processes developed by John Vervaeke that emphasizes how such systems scan for relevant information that enables them to realize both what is the case and what affordances might be created, while recursively modeling the agent arena relation across a multi-level information processing hierarchy." - [UTOK: The Unified Theory of Knowledge, by Gregg Henriques](https://www.goodreads.com/book/show/219729081-utok)


> "Vervaeke’s 3 r’s stand for recursive relevance realization. The idea is that cognitive processes frame situations to identify relevant aspects and this takes place in the context of what the agent is trying to realize in the agent-arena relation. Realize here carries a double meaning; it means realize as in to see and understand, and it means realize as in to make or create, thus creating a tight relationship between perception and action. Finally, recursive refers to the constant modeling and feedback loops that take place vertically (i.e., on the bottom-up to top-down stack) and horizontally (i.e., across different modalities in the sensorimotor looping system)." - [UTOK: The Unified Theory of Knowledge, by Gregg Henriques](https://www.goodreads.com/book/show/219729081-utok)

> "The concept of relevance refers to that which is important and a key feature of neurocognition is determining what is salient and important so that one can model the situation and anticipate what is going to happen... The concept of realization in Vervaeke’s formulation carries the twin dictionary meanings of the word. It means to realize as in to see or grasp and it means to realize as in to make or construct. That is, it is a bridging concept between perception and action. To realize relevance is to see something as relevant that enables you to move closer to your goal." - [John Vervaeke’s Brilliant 4P/3R Metatheory of Cognition, by Gregg Henriques](https://www.psychologytoday.com/us/blog/theory-knowledge/202101/john-vervaeke-s-brilliant-4p3r-metatheory-cognition)



> "Whenever you're solving a problem—you have to solve these two meta problems in order to be adaptive:
>
> • Anticipation: You need to anticipate the world. The farther out you can anticipate the world the more intelligence people will attribute to you. It's way better to avoid the tiger than to fight it.
>
> • Relevance Realization: There's way too much information to pay attention to—and you're intelligent by ignoring most of the information (and zero in on the relevant information). But it’s not a cold calculation—you care about this information rather than that information." - [John Vervaeke](https://x.com/DrJohnVervaeke/status/1924802687607898344)

> "Your brain naturally filters possibilities through what cognitive scientists call "structure of possibility"—a framework that helps you focus on scenarios that are both relevant and probable." - [John Vervaeke](https://x.com/DrJohnVervaeke/status/1880985033319633314)

opportunity overload

> "Whatever the type of action you are considering, the number of possibilities has in practice become endless. This makes it ever more difficult to make a motivated choice among the alternatives. We may call this the problem of opportunity overload." - [Complexity and Information Overload in Society: why increasing efficiency leads to decreasing control, by Francis Heylighen](http://pcp.vub.ac.be/Papers/Info-overload.pdf)

██████████████████████████████████████████████████████████████████
# SECTION: Agency
██████████████████████████████████████████████████████████████████

<!-- > "Feedback Is All You Need" - [Gordon Brander](https://twitter.com/gordonbrander/status/1640521555439386624) -->
<!-- joe biden quote: think about what you think about! -->


EMBED THIS
The Evolution of Agency
https://www.youtube.com/watch?v=gxpbvE8V0Dg
or better this newer version by Kevin Mitchell
The evolution of free will - with Kevin Mitchell
https://www.youtube.com/watch?v=QXwRjb7WF7E
<!-- ^^ the only quibble with this presentation: he says how its impossible to encode all future states of the universe into it at the big bang but they don't need to be encoded in it for it to be deterministic - just like a cellular automata doesn't "contain" every possible unfolding of it in its tiny definition - and yet the system is deterministic and would produce the same pattern if it was ran many times with the same rule -->

> "The minimal definition of agency is a feedback loop." - [Gordon Brander](https://twitter.com/gordonbrander/status/1640781342559313927)

> "When something is both highly integrated and highly differentiated it can do many different things without falling apart. So complexification enhances agency - it gives you your emergent abilities." - [John Vervaeke: Democracy and the Relevance Realization of Distributed Cognition](https://youtu.be/8U2caURO-d4?t=1250)

> "An agent is any being that can detect the consequences of it's behavior and modify that behavior in order to achieve it's goals. Another way of putting it is that an agent is a problem solver. Intelligence is the capacity to be a general problem solver - you can solve a wide variety of problems in a wide variety of domains." - [John Vervaeke: Democracy and the Relevance Realization of Distributed Cognition](https://youtu.be/8U2caURO-d4?t=670)

Program or be Programmed - Douglas Rushoff
https://www.youtube.com/watch?v=imV3pPIUy1k

> "Our enthusiasm for digital technology about which we have little understanding and over which we have little control leads us not toward greater agency, but toward less...We have surrendered the unfolding of a new technological age to a small elite who have seized the capability on offer. But while Renaissance kings maintained their monopoly over the printing press by force, today's elite is depending on little more than our own disinterest." - [Douglas Rushkoff](https://www.goodreads.com/quotes/855874-our-enthusiasm-for-digital-technology-about-which-we-have-little)



