


> "Selfishness beats altruism within groups. Altruistic groups beat selfish groups. Everything else is commentary." - [David Sloan Wilson](https://www.goodreads.com/quotes/950594-selfishness-beats-altruism-within-groups-altruistic-groups-beat-selfish-groups)

██████████████████████████████████████████████████████████████████
# SECTION: Altruism
██████████████████████████████████████████████████████████████████

> "Altruism is not an improbable achievement against the individualizing forces of natural selection; rather, it is an integral part of the social lives of all beings that live with others interdependently—up to a (mathematical) point." - [Michael Tomasello](https://www.goodreads.com/quotes/10710208-altruism-is-not-an-improbable-achievement-against-the-individualizing-forces)

> "Nothing truly valuable can be achieved except by the unselfish cooperation of many individuals." - [Albert Einstein](https://www.goodreads.com/quotes/1170750-nothing-truly-valuable-can-be-achieved-except-by-the-unselfish)

> "The competition between the two forces can be succinctly expressed as follows: Within groups selfish individuals beat altruistic individuals, but groups of altruists beat groups of selfish individuals. Or, risking oversimplification, individual selection promoted sin, while group selection promoted virtue." - [Edward O. Wilson](https://www.goodreads.com/quotes/3233345-the-competition-between-the-two-forces-can-be-succinctly-expressed)

^^ but altruism & group selection are not stable - we need consequence capture & managers
cooperation does not evolve easily


> "It’s bullshit. Indiscriminate altruism, untainted by vanity, reciprocity, or partiality, cannot evolve. It just can’t. I’m sorry. Any altruism that wasn't laser-focused toward our families or our allies, or that wasn’t otherwise shrewdly calculated to increase our status, would be mercilessly selected against by evolution. Darwinian accounting is scrupulous: debts must be repaid, costs must be cut, investments must be recouped." - [Darwin the Cynic, by David Pinsof](https://www.everythingisbullshit.blog/p/darwin-the-cynic#:~:text=it%E2%80%99s%20bullshit.%20Indiscriminate,must%20be%20recouped.)

> "The impartial, unreciprocated, non-status-boosting sacrifice for the greater good—cannot evolve. People really do not like this. They try to wriggle out of it in all sorts of frantic ways." - [Darwin the Cynic, by David Pinsof](https://www.everythingisbullshit.blog/p/darwin-the-cynic#:~:text=the%20impartial%2C%20unreciprocated,of%20frantic%20ways.)

> "You don’t need a desire for moral progress to get moral progress, any more than you need a desire for traffic to get traffic. Here are some of the best, cynically Darwinian explanations I’ve seen for moral progress:
>
> 1. It’s a side-effect of capitalism.
>
> a) If you only sell stuff to members of your tribe, you’re not going to make as much money as someone who sells stuff to everyone. The same thing goes for consumers. If you only buy from your tribe, you’re going to get crappier stuff. Ditto for workers. If you only work for your tribe, you’ll get fewer job offers. And if you reward workers based on tribal loyalty, instead of productivity, you’ll get lower productivity, and less profit. That’s how all these WEIRD ideas about “meritocracy” and “treating people equally” emerged. They were self-interested strategies for buyers, sellers, workers, and employers. But once the capitalist pro-tip of “treating people equally” spread (and got written into the constitution), people started to look like hypocrites for not, you know, treating people equally. Low-status groups used the hypocrisy to rally people to their side in political conflicts.
>
> b) In a market economy, status accrues to those who are most successful in providing desirable goods and services at affordable prices. So when low-status groups enter the labor market in greater numbers, they rise in status. For example, at the turn of the 20th century, women entered the labor market in greater numbers. Why? Because with the rise of automation, there was a decline in manual labor that advantaged humans with greater upper body strength and no uteruses (i.e., men), and a rise in other kinds of service-based labor that women were good at. Women’s status, accordingly, rose. They began to leverage their rising status to advance their self-interest, as humans are wont to do. No, they weren’t seeking moral progress for everyone: the suffragists excluded African Americans from protests and didn’t like the idea of black men voting.
>
> 2. It’s a side-effect of communication technologies (itself a side-effect of capitalism):
>
> a) We didn’t evolve to estimate a group’s formidability based on census statistics; we evolved to estimate it based on how big and well-coordinated they look. To our stone-age brains, a marching minority looks bigger and stronger than it really is, as a percentage of the population. Transportation moves far-flung minorities into the same space to flex their muscles, and television transmits the image to everyone in the nation. When marginalized groups create the illusion of collective formidability, we no longer want to mess with them.
>
> b) When tribes start to become equally powerful, or start to appear equally powerful due to mass media, it creates an intergroup stalemate, a kind of mutually assured destruction. Hot wars turn into cold wars. Cold wars turn into culture wars.
>
> 3. It’s a side-effect of democracy (itself a side-effect of capitalism)
>
> a) When marginalized groups flex their muscles and win the right to vote, savvy politicians compete to attract their votes, and the coalition that recruits them gains political power. The partisans who find themselves in a political coalition with the marginalized groups start to look upon them with fondness. We like our allies—they’re on our team. So you get performative allyship and a decline of overt racism among whichever political coalition joins up with ethnic minorities. If that happens among cultural elites, who shape social norms, then you might get some new social norms about “political correctness” or “wokeness” or whatever you want to call it. And you might get a backlash to these norms among the elites’ political rivals (i.e., the working class “populists”).
>
> This is all very interesting, but don’t miss the point: moral progress was an accident. In fact, it must have been it accident, because our motives were designed by natural selection, and a motive for “moral progress” makes no evolutionary sense. Which means we shouldn’t feel too proud of ourselves. We’re the same old primates we always were—selfish, nepotistic, and groupish. We have the same capacity for evil, and the same capacity to rationalize it, as our forebears." - [Darwin the Cynic, by David Pinsof](https://www.everythingisbullshit.blog/p/darwin-the-cynic#:~:text=You%20don%E2%80%99t%20need,as%20our%20forebears.)

> "I'm saying it's more insightful, useful, and predictively powerful to focus on the deeper goal, because that is the lever we must pull if we want to shape the behavior, and that is the key to understanding and predicting when and where the behavior will be performed. We must choose insight over idealism." - [Darwin the Cynic, by David Pinsof](https://open.substack.com/pub/everythingisbullshit/p/darwin-the-cynic?r=7omg8&utm_campaign=comment-list-share-cta&utm_medium=web&comments=true&commentId=42426004)

> "I don’t think it really matters whether the motive is conscious or not. Worldviews help us predict and explain people’s behavior. That’s their job. If I’m trying to predict and explain behavior, cynicism is going to help me do that, regardless of whether the cynical motives are conscious or not. It doesn’t matter why people *think* they’re donating to charity. What matters is why they are *actually* donating to charity—the specific causal factors that are influencing their decision. Those factors are inevitably going to be reputational, status-driven, nepotistic, reciprocal, and/ or groupish in nature. If I’m trying to design institutions with incentives that promote charitable giving, I need to look at people’s *actual* motives, not the motives they say they have... Motives are the things that causally influence and explain our behavior across a range of situations, regardless of whether we’re aware of them or not. Motives (and psychological systems) are the things that natural selection selects—not behaviors. When you understand the process that created our motives, there is simply no other option than to say those motives are selfish, nepotistic, or groupish. If you can think of another way for a motive to evolve that doesn’t involve replicating the genes that built it, I’d love to hear it. But until then, I’m going with Darwinian cynicism as the best way to explain and predict people’s behavior." - [Darwin the Cynic, by David Pinsof](https://open.substack.com/pub/everythingisbullshit/p/darwin-the-cynic?r=7omg8&utm_campaign=comment-list-share-cta&utm_medium=web&comments=true&commentId=45901765)


██████████████████████████████████████████████████████████████████
# SECTION: Cooperation
██████████████████████████████████████████████████████████████████

> "A cooperative enterprise. Co-, together + operari, work. Acting in concert. Coordinating individual behavior in pursuit of shared goals." - [Kevin Simler](https://meltingasphalt.com/minimum-viable-superorganism/#:~:text=a%20cooperative%20enterprise.%20Co%2D%2C%20together%20%2B%20operari%2C%20work.%20Acting%20in%20concert.%20Coordinating%20individual%20behavior%20in%20pursuit%20of%20shared%20goals.)

> "Nature promotes cooperation, collaboration, and synergy because it is thermodynamically beneficial for all parties, and for that reason, synergistic collective configurations will eventually be discovered by any many-component system that is exploring various states or configurations through the blind-variation-and-selective-retention mechanism. Organisms only compete until they finally figure out that working together makes everyone’s task easier, and that goes for humans too." - [Bobby Azarian](https://twitter.com/BobbyAzarian)

> "If a zero-sum mindset is what we're wired for, positive-sumness has to be learned." - [The Rise of Positive-Sum Thinking, by Erik Torenberg](https://eriktorenberg.substack.com/p/the-rise-of-positive-sum-thinking#:~:text=If%20a%20zero%2Dsum%20mindset%20is%20what%20we%27re%20wired%20for%2C%20positive%2Dsumness%20has%20to%20be%20learned.)

> "Non-zero-sumness (NZS) is the evolution of culture toward deeper and vaster social complexity—an increasing intertwining of our fates. In other words, the growing extent to which we become interdependent on each other." - [The Rise of Positive-Sum Thinking, by Erik Torenberg](https://eriktorenberg.substack.com/p/the-rise-of-positive-sum-thinking#:~:text=Non%2Dzero%2Dsumness%20(NZS)%20is%20the%20evolution%20of%20culture%20toward%20deeper%20and%20vaster%20social%20complexity%E2%80%94an%20increasing%20intertwining%20of%20our%20fates.%20In%20other%20words%2C%20the%20growing%20extent%20to%20which%20we%20become%20interdependent%20on%20each%20other.)


> "Just as blueprints don't necessarily specify blue buildings, selfish genes don't necessarily specify selfish organisms. As we shall see, sometimes the most selfish thing a gene can do is build a selfless brain. Genes are a play within a play, not the interior monologue of the players." - [Steven pinker](https://www.goodreads.com/quotes/122032-just-as-blueprints-don-t-necessarily-specify-blue-buildings-selfish-genes)


The Price of Anarchy (PoA) is a concept in economics and game theory that measures how the efficiency of a system degrades due to selfish behavior of its agents. It is a general notion that can be extended to diverse systems and notions of efficiency.
https://en.wikipedia.org/wiki/Price_of_anarchy

In game theory, the price of stability (PoS) of a game is the ratio between the best objective function value of one of its equilibria and that of an optimal outcome.
https://en.wikipedia.org/wiki/Price_of_stability

The concepts of price of anarchy and price of stability were introduced to capture the loss in performance of a system due to the selfish behavior of its participants. The price of anarchy captures the worst-case performance of the system at equilibrium relative to the optimal performance possible. The price of stability, on the other hand, captures the relative performance of the best equilibrium of the system.

the evolution of trust
https://ncase.me/trust/notes/
https://prnt.sc/K5nzWpUw8XJh
https://prnt.sc/o5LZhIhNqIFX

> "Take the case of academic publishing, given as a classic coordination failure by Eliezer Yudkowsky in Inadequate Equilibria: Where and How Civilizations Get Stuck. Academic journals publish research within a given field and charge for access to it, often at exorbitant rates. In order to get the best jobs and earn prestige within a field, researchers need to publish in the most respected journals. If they don’t, no one will take their work seriously.
>
> Academic publishing is broken in many ways. By charging high prices, journals limit the flow of knowledge and slow scientific progress. They do little to help researchers, instead profiting from the work of volunteers and taxpayer funding. Yet researchers continue to submit their work to them. Why? Because this is the Nash equilibrium. Although it would be better for science as a whole if everyone stopped publishing in journals that charge for access, it isn’t in the interests of any individual scientist to do so. If they did, their career would suffer and most likely end. The only solution would be a coordinated effort for everyone to move away from journals. But seeing as this is so difficult to organize, the farce of academic publishing continues, harming everyone except the journals." - [Coordination Problems: What It Takes to Change the World](https://fs.blog/coordination-problems/#:~:text=Take%20the%20case,except%20the%20journals.)

> "It’s possible to change things on a large scale if we are able to communicate on a much greater scale. When everyone knows that everyone knows, changing what we do is much easier.
>
> We all act out of self-interest, so expecting individuals to risk the costs of going against convention is usually unreasonable. Yet it only takes a small proportion of people to change their opinions to reach a tipping point where there is strong incentive for everyone to change their behavior, and this is magnified even more if those people have a high degree of influence. The more power those who enact change have, the faster everyone else can do the same.
>
> To overcome coordination failures, we need to be able to communicate despite our differences. And we need to be able to trust that when we act, others will act too. The initial kick can be enough people making their actions visible. Groups can have exponentially greater impacts than individuals. We thus need to think beyond the impact of our own actions and consider what will happen when we act as part of a group." - [Coordination Problems: What It Takes to Change the World](https://fs.blog/coordination-problems/#:~:text=It%E2%80%99s%20possible%20to,of%20a%20group.)

> "All human groups frown on, make pronouncements against, and punish the following: murder, undue use of authority, cheating that harms group cooperation, major lying, theft, and socially disruptive sexual behavior. These basic rules of conduct appear to be human universals." - [Christopher Boehm](https://www.goodreads.com/quotes/11025360-all-human-groups-frown-on-make-pronouncements-against-and-punish)

> "The arc of the moral universe is long but it bends toward cooperation." - [Martin Luther King Jr.](https://www.goodreads.com/quotes/646750-let-us-realize-the-arc-of-the-moral-universe-is), probably


██████████████████████████████████████████████████████████████████
# SECTION: Constraints
██████████████████████████████████████████████████████████████████

Constraints are freedom

> "Freedom is obedience to self-formulated rules." - [Aristotle](https://www.goodreads.com/quotes/671308-freedom-is-obedience-to-self-formulated-rules)

> "The question is never whether you can keep all of your sovereignty; history says you can’t; all along it has been the fate of humankind to have its fate increasingly shared." - [Robert Wright](https://books.google.bg/books?id=-KTPK5XipEgC&pg=PT303&lpg=PT303&dq=%22The+question+is+never+whether+you+can+keep+all+of+your+sovereignty;+history+says+you+can%E2%80%99t;+all+along+it+has+been+the+fate+of+humankind+to+have+its+fate+increasingly+shared.%22&source=bl&ots=SlmIyHEKDw&sig=ACfU3U0LWKvZstk83f8nZq8c39-9PXwulg&hl=en&sa=X&ved=2ahUKEwiQr4ab0s2BAxVe1wIHHbaoCVkQ6AF6BAgNEAM#v=onepage&q=%22The%20question%20is%20never%20whether%20you%20can%20keep%20all%20of%20your%20sovereignty%3B%20history%20says%20you%20can%E2%80%99t%3B%20all%20along%20it%20has%20been%20the%20fate%20of%20humankind%20to%20have%20its%20fate%20increasingly%20shared.%22&f=false)

> "The game B synthesis at its deepest is if you're not constraining a society in relationships and obligations and trustworthy people and you've undermined the concept of virtue ethics - of course game theory is going to run amok and what is late game A but game theory run extensively amok." - [Jim Rutt](https://youtu.be/vUwlp6R57p0?t=1259)

> "You do not rise to the level of your goals. You fall to the level of your systems." - [James Clear](https://www.goodreads.com/quotes/9536717-you-do-not-rise-to-the-level-of-your-goals)

> "“Disciplined” people are better at structuring their lives in a way that does not require heroic willpower and self-control. In other words, they spend less time in tempting situations." - [James Clear](https://www.goodreads.com/quotes/9941975-when-scientists-analyze-people-who-appear-to-have-tremendous-self-control)

> "Societies need rules that make no sense for individuals. For example, it makes no difference whether a single car drives on the left or on the right. But it makes all the difference when there are many cars!" - [Marvin Minsky](https://www.azquotes.com/quote/699378)

> "We’re going towards a world where individuals relinquish freedom for the good of society, but do so in a decentralized way: we create the rules and enforce them together." - [Society Is a Brain, by Tomas Pueyo](https://unchartedterritories.tomaspueyo.com/p/society-is-a-brain?r=36xnz&utm_campaign=post&utm_medium=web#:~:text=we%E2%80%99re%20going%20towards%20a%20world%20where%20individuals%20relinquish%20freedom%20for%20the%20good%20of%20society%2C%20but%20do%20so%20in%20a%20decentralized%20way%3A%20we%20create%20the%20rules%20and%20enforce%20them%20together.)

██████████████████████████████████████████████████████████████████
# SECTION: Common knowledge
██████████████████████████████████████████████████████████████████

> "As Michael Suk-Young Chwe writes in Rational Ritual: Culture, Coordination, and Common Knowledge, “Successful communication sometimes is not simply a matter of whether a given message is received. It also depends on whether people are aware that other people also receive it.” According to Suk-Young Chwe, for people to coordinate on the basis of certain information it must be “common knowledge,” a phrase used here to mean “everyone knows it, everyone knows that everyone knows it, everyone knows that everyone knows that everyone knows it, and so on.” The more public and visible the change is, the better." - [Coordination Problems: What It Takes to Change the World](https://fs.blog/coordination-problems/#:~:text=As%20Michael%20Suk,is%2C%20the%20better.)

> "Common knowledge depends not only on me knowing that you receive a message but also on the existence of a shared symbolic system which allows me to know how you understand it." - [Rational Ritual: Culture, Coordination, and Common Knowledge](https://www.goodreads.com/work/quotes/1103225-rational-ritual-culture-coordination-and-common-knowledge)

> "Bullshit is also fragile--it relies on common knowledge to maintain--so it can collapse at any moment. Bullshit bubbles can burst pretty easily (assuming there’s not a state apparatus to prevent the bubble from bursting)." - [You Will Find This Interesting, by David Pinsof](https://open.substack.com/pub/everythingisbullshit/p/you-will-find-this-interesting?r=7omg8&utm_campaign=comment-list-share-cta&utm_medium=web&comments=true&commentId=17264686)

██████████████████████████████████████████████████████████████████
# SECTION: Coherence
██████████████████████████████████████████████████████████████████

Coherent pluralism - Jim Rutt

Most people have read at leats a couple of books in their life. What if we could socially nudge ourselves into coherence for what is most important and point to the most important books?

> "Coherence is one of the most important concepts in the management of complexity." - [Understanding the Blue Church, by Jordan Hall](https://medium.com/deep-code/understanding-the-blue-church-e4781b2bd9b5#:~:text=Coherence%20is%20one%20of%20the%20most%20important%20concepts%20in%20the%20management%20of%20complexity.)

> "Society cannot function without a regulatory structure adequate to its level of complexity." - [Understanding the Blue Church, by Jordan Hall](https://medium.com/deep-code/understanding-the-blue-church-e4781b2bd9b5#:~:text=Society%20cannot%20function%20without%20a%20regulatory%20structure%20adequate%20to%20its%20level%20of%20complexity.)

██████████████████████████████████████████████████████████████████
# SECTION: Alignment
██████████████████████████████████████████████████████████████████

Alignment is predicated on transparency

The only way to alignment is through transparency and interpretability

> "If I were a stakeholder I would simply be aligned." - [@jdan](https://twitter.com/jdan/status/1699870400513982624)

> "If it's wrong when they do it, it's wrong when we do it." - [Noam Chomsky](https://www.goodreads.com/quotes/599016-if-it-s-wrong-when-they-do-it-it-s-wrong-when)

> "The eternal struggle between good and evil takes place within our own bodies and has since the origin of multicellular organisms roughly a billion years ago." - [David Sloan Wilson](https://www.goodreads.com/quotes/11665166-the-eternal-struggle-between-good-and-evil-takes-place-within)

> "It is not the strongest of the species that survives, nor the most intelligent that survives. It is the one that is the most adaptable to change, that lives within the means available and works co-operatively against common threats." - [Charles Darwin](https://www.azquotes.com/quote/1397543)


this is how we solve all types of alignment: AI alignment & human alignment


██████████████████████████████████████████████████████████████████
# SECTION: Consequence capture
██████████████████████████████████████████████████████████████████

> "Have I done something for the common good? Then I share in the benefits." - [Marcus Aurelius](https://twitter.com/dailystoic/status/1688958269287755776)

> "The definition of the good society is one in which virtue pays." - [Abraham Maslow](https://minimalistquotes.com/abraham-maslow-quote-85683/)

> "Look deep into nature, and then you will understand everything better." - [Albert Einstein](https://www.goodreads.com/quotes/32930-look-deep-into-nature-and-then-you-will-understand-everything)

> "Any altruistic system is inherently unstable, because it is open to abuse by selfish individuals, ready to exploit it." - [Richard Dawkins](https://www.goodreads.com/quotes/567499-any-altruistic-system-is-inherently-unstable-because-it-is-open)

> "The older the problem, the older the solution." - [Naval Ravikant](https://twitter.com/naval/status/1001905796479778816)

> "Nature does nothing uselessly." - [Aristotle](https://www.goodreads.com/quotes/32921-nature-does-nothing-uselessly)

> "There is more wisdom in your body than in your deepest philosophy." - [Friedrich Nietzsche](https://www.goodreads.com/quotes/68916-there-is-more-wisdom-in-your-body-than-in-your)

> "Now, where do you look for models? Where do you go? The answer is so obvious. You go to nature. Nature has been playing this game for three billion years on this planet. We have been playing the game—we, the apostles of Christian scientism—for about 2,000 years. Nature has an economy, an elegance, a style that, if we could but emulate it, we could rise out of the rubble that we are making of the planet." - [A crisis in consciousness (1995), by Terence McKenna](https://www.organism.earth/library/document/crisis-in-consciousness#:~:text=Now%2C%20where,of%20the%20planet.)

> "So self-interest is good as long as its contained by the self-interest of a community. You see, that makes us always be aware of other levels. If we can learn this as humans to say when we're making a decision: Is this good for me, my family, for my ecosystem, for my nation for my world? And then if it's good at some levels and at least harmless at others, like the Hippocratic oath “Do No Harm” then go ahead and try it. You're a creative human being." - [After Darwin, by Elisabet Sahtouris](https://ratical.org/LifeWeb/Articles/AfterDarwin.html#:~:text=So%20self%2Dinterest,creative%20human%20being.)

> "Consequence capture - so basically what governance does is reflect back onto the individuals of the collective the consequences of their actions on the collective as a whole. If an individual within a collective - a cell in your body for example - does something to harm your body, then the governance will reflect that back on the individual cell and harm the cell. Similarly for anything beneficial." - [John Stewart](https://youtu.be/XFqjbuYczc8?t=2198)

> "We’d be wiser to negotiate a social contract that puts us in a positive-sum game: neither gets to harm the other, and both are encouraged to help the other." - [Steven pinker](https://www.goodreads.com/quotes/9102934-if-my-starting-offer-is-i-get-to-rob-beat#:~:text=We%E2%80%99d%20be%20wiser%20to%20negotiate%20a%20social%20contract%20that%20puts%20us%20in%20a%20positive%2Dsum%20game%3A%20neither%20gets%20to%20harm%20the%20other%2C%20and%20both%20are%20encouraged%20to%20help%20the%20other.)

> "When a subsystem’s goals dominate at the expense of the total system’s goals, the resulting behavior is called suboptimization." - [Thinking in Systems 2008, by Donella Meadows](https://subconscious.substack.com/p/fragments-vertebrate-technology#:~:text=When%20a%20subsystem%E2%80%99s%20goals%20dominate%20at%20the%20expense%20of%20the%20total%20system%E2%80%99s%20goals%2C%20the%20resulting%20behavior%20is%20called%20suboptimization.)

> "To be a highly functional system, hierarchy must balance the welfare, freedoms, and responsibilities of the subsystems and total system—there must be enough central control to achieve coordination toward the large-system goal, and enough autonomy to keep all subsystems flourishing, functioning, and self-organizing." - [Thinking in Systems 2008, by Donella Meadows](https://subconscious.substack.com/p/fragments-vertebrate-technology#:~:text=To%20be%20a,and%20self%2Dorganizing.)



> "We argue that enforcement is an underappreciated, and often critical, ingredient for cooperation across all scales of biological organization." - [Enforcement is central to the evolution of cooperation](https://sci-hub.se/10.1038/s41559-019-0907-1)

> "The evolution of cooperation is central to all living systems. Evolutionary history can be defined by a series of major transitions in which replicating units came together, lost their independence and formed new levels of biological organization. As a consequence, life is organized in a hierarchy of cooperation: genes work together in genomes, genomes in cells, cells in multicellular organisms and multicellular organisms in eusocial groups." - [Enforcement is central to the evolution of cooperation](https://sci-hub.se/10.1038/s41559-019-0907-1)

> "We define enforcement as an action that evolves, at least in part, to reduce selfish behaviour within a cooperative alliance. Selfish behaviours are those that benefit an actor and reduce its cooperation with one or more recipients in the alliance." - [Enforcement is central to the evolution of cooperation](https://sci-hub.se/10.1038/s41559-019-0907-1)

> "All models identify conditions under which enforcement will evolve and increase cooperation. As is typical for evolutionary models, benefits and costs matter. In particular, high costs to enforcement can make it less likely to evolve, or less effective when it does evolve. Nevertheless, enforcement is predicted in every system, and importantly, this occurs over a wide range of parameters, which is consistent with the general importance of enforcement independently of both biological details and scale." - [Enforcement is central to the evolution of cooperation](https://sci-hub.se/10.1038/s41559-019-0907-1)

> "There is now a large body of evidence that enforcement shapes cooperation across all levels of biology. This includes systems that have undergone a major transition, like some social insects, as well as those that have not, like many mutualisms... While high costs can be prohibitive, a given cooperative system may explore diverse enforcement strategies over evolutionary time until a low-cost solution arises. Low costs to enforcement are further facilitated by power asymmetries. Enforcement can be enabled by a single powerful individual, such as a host who exercises control over symbionts, or by majority rule, such as within an animal society. There is also a role for pre-adaptations: pre-existing features of the biology of a system can enable enforcement and promote its effectiveness. Systems in which enforcement is not possible will be less likely to see increases in cooperation over evolutionary time, or they may even see cooperation fall away. It is in those systems where enforcement does arise that we see the full extent, and wonders, of cooperative evolution." - [Enforcement is central to the evolution of cooperation](https://sci-hub.se/10.1038/s41559-019-0907-1)


> "A free society that allows each individual to seek his or her own selfish ends (without deliberately trying to harm anyone else) will produce a state in which everyone's interest is optimized without any individual knowing in advance what that state might be." - [Stuart Kauffman](https://www.azquotes.com/quote/580554)

> "Evolution is not the enemy of ethics but its first source." - [Stuart Kauffman](https://www.azquotes.com/quote/792121)






> "Maintaining punishment (and thereby policing) as a public good by natural selection requires that individuals producing the good obtain sufficient fitness benefits that compensate for the associated costs. These benefits can be both direct (affect personal reproduction) and indirect (affect reproduction of relatives), so they are best considered in an inclusive fitness framework." - [Policing and punishment across the domains of social evolution](https://sci-hub.se/10.1111/oik.02064)

> "We thus define ‘punishment’ as ‘a behavior that inflicts a net cost on, or removes net benefits from, a target individual in response to a specific behavior by that target individual’. Under an inclusive fitness approach, we can make two assumptions about the evolution of punishment. First, the imposed costs or removed benefits should on average be high enough to make the target behavior unprofitable, and second, ... punishment should only evolve when it provides a punisher with net inclusive fitness benefits." - [Policing and punishment across the domains of social evolution](https://sci-hub.se/10.1111/oik.02064)

> "We therefore define ‘policing’ as ‘a punishing behavior that reduces average inclusive fitness losses of group members resulting from within-group competition for direct fitness gains’... Our policing definition excludes punishing behaviors that disrupt group stability, like some instances of retaliatory or coalitionary violence, because these behaviors do not benefit average inclusive fitness within groups and can sometimes be subject to policing themselves." - [Policing and punishment across the domains of social evolution](https://sci-hub.se/10.1111/oik.02064)

> "" - [Policing and punishment across the domains of social evolution](https://sci-hub.se/10.1111/oik.02064)

> "" - [Policing and punishment across the domains of social evolution](https://sci-hub.se/10.1111/oik.02064)

> "" - [Policing and punishment across the domains of social evolution](https://sci-hub.se/10.1111/oik.02064)

> "" - [Policing and punishment across the domains of social evolution](https://sci-hub.se/10.1111/oik.02064)

> "" - [Policing and punishment across the domains of social evolution](https://sci-hub.se/10.1111/oik.02064)

> "" - [Policing and punishment across the domains of social evolution](https://sci-hub.se/10.1111/oik.02064)

> "" - [Policing and punishment across the domains of social evolution](https://sci-hub.se/10.1111/oik.02064)

> "" - [Policing and punishment across the domains of social evolution](https://sci-hub.se/10.1111/oik.02064)


We can fail nature - we’ve surpassed it but have not fully learned from it
We’ve not fully integrated everything nature has to tell us
It is disrespectful to nature to not learn from it - nature is wisdom


██████████████████████████████████████████████████████████████████
# SECTION: multipolar traps & anti-rivalry
██████████████████████████████████████████████████████████████████

> "Exponential tech is inexorable. We cannot put it away. So, we either figure out anti-rivalry, or we go extinct. The human experiment comes to a completion. That’s the core thing." - [Daniel Schmachtenberger](https://www.sloww.co/daniel-schmachtenberger/#:~:text=%E2%80%9CAs%20technology%20is%20empowering%20our%20choices%20and%20we%20are%20getting%20something%20like%20the%20power%20of%20gods%2C%20you%20have%20to%20have%20something%20like%20the%20love%20and%20the%20wisdom%20of%20gods%20to%20wield%20that%20or%20you%20self%2Ddestruct.%E2%80%9D)


██████████████████████████████████████████████████████████████████
# SECTION: Incentive design
██████████████████████████████████████████████████████████████████

> "How does society work? Five words or less: Behavior is determined by incentives." - [Incentives Are Everything, by David Pinsof](https://www.everythingisbullshit.blog/p/incentives-are-everything#:~:text=%E2%80%9CHow%20does%20society,determined%20by%20incentives.%E2%80%9D)

> "The particular arrangement of incentives across time, space, and causality is called an incentive structure." - [Incentives Are Everything, by David Pinsof](https://www.everythingisbullshit.blog/p/incentives-are-everything#:~:text=The%20particular%20arrangement%20of%20incentives%20across%20time%2C%20space%2C%20and%20causality%20is%20called%20an%20incentive%20structure.)

> "What about free will? It’s the ability to respond to our incentives. Being a good person? It’s having an incentive to behave in ways we call “good”—that is, wanting to win the virtue game... Let’s give this worldview a name. Let’s call it incentive determinism.
>
> Incentive determinism is obvious. It’s just a bunch of tautologies: we are who we are, we want what we want, and we do what we’re caused to do. And yet, barely anybody thinks this way. It’s a cold, alien way of thinking." - [Incentives Are Everything, by David Pinsof](https://www.everythingisbullshit.blog/p/incentives-are-everything#:~:text=What%20about%20free,way%20of%20thinking.)

> "We spend very little time discussing which incentive structures are the best, and tons of time talking about which sets of words are the right words and which sets of people are the right people. It’s why we write words at all: we think we’re the right people with the right words, and if we just say those words loudly enough, we’ll improve the world." - [Incentives Are Everything, by David Pinsof](https://www.everythingisbullshit.blog/p/incentives-are-everything#:~:text=We%20spend%20very,improve%20the%20world.)

> "People don’t like incentive determinism because it’s disorienting. It tells us that our single greatest obsession, likability, is a distraction. It’s bullshit—a destroyer of insight, an enemy of understanding. It plays no special role in explaining how the world works. All it does is give us the illusion of understanding—the feeling of superiority to our apparently unlikable rivals (another big incentive for us)—while leaving us in ignorance of the causal structure of the world.
>
> And that causal structure is everything. If there are powerful incentives to help others, then even “evil” people will help others. If there are powerful incentives to hurt others, then even “good” people will hurt others. In fact, if being a “good” person just means being strongly incentivized by others’ moral approval (i.e., really wanting to win the virtue game), then good people are more likely to hurt people when it wins them moral approval. The “good” members of ISIS are the ones who bravely volunteer to commit suicide bombings, and the “bad” members of ISIS are the ones who cravenly fail to make the ultimate sacrifice. People are only as good as their incentives.
>
> But maybe there’s a way out. Maybe figuring out how this all works—understanding the machinery of society—can, itself, change our incentive structures. Insight is a thing in the world that human primates evolved to want, at least sometimes.
>
> If there’s any hope to be found in this cold, alien view of the world, it’s this: the more we all become aware of our incentive structures, the more incentivized we will be to choose them wisely." - [Incentives Are Everything, by David Pinsof](https://www.everythingisbullshit.blog/p/incentives-are-everything#:~:text=People%20don%E2%80%99t%20like,choose%20them%20wisely.)

> "If we're collectively aware of our incentive structures, and aware that others know that we're aware, then we have an incentive to pick one that makes everyone better off, so that people won't judge as selfish. So the key is achieving widespread awareness, or common knowledge, of our incentive structures." - [Incentives Are Everything, by David Pinsof](https://open.substack.com/pub/everythingisbullshit/p/incentives-are-everything?r=7omg8&utm_campaign=comment-list-share-cta&utm_medium=web&comments=true&commentId=47963804)

> "Randomness is hugely important, but we're trying to explain the part of reality that is not random. That is all we can do. And when we look at that part, incentives are everything." - [Incentives Are Everything, by David Pinsof](https://open.substack.com/pub/everythingisbullshit/p/incentives-are-everything?r=7omg8&utm_campaign=comment-list-share-cta&utm_medium=web&comments=true&commentId=51093816)

> "I don't see incentive determinism as a "theory" so much as a different way of thinking, or a useful conceptual framework. It's honestly just a way of activating a different part of the brain--the tool-use part--to understand society as a machine of moving parts. It's more of a metatheory, really, or a useful way of coming up with other theories. It can give rise to more specific theories about the incentive structures we face, and how they work, which can then be tested. Insofar as the theories it gives rise to are always false, then, sure, it's false. But given that incentive-based thinking lies at the heart of economics and much of social science (not to mention evolutionary biology), it seems like a pretty damn good metatheory and I don't know of a better one. I cannot even conceive a better one, to be honest." - [Incentives Are Everything, by David Pinsof](https://open.substack.com/pub/everythingisbullshit/p/incentives-are-everything?r=7omg8&utm_campaign=comment-list-share-cta&utm_medium=web&comments=true&commentId=51257762)

██████████████████████████████████████████████████████████████████
# SECTION: Cooperation, Altruism & Management Theory
██████████████████████████████████████████████████████████████████


> "If everybody here plays generous [Tit-for-tat](https://en.wikipedia.org/wiki/Tit_for_tat), and I play always cooperate, I'm a neutral mutant, I have no disadvantage. Random drift can lead to the takeover of the neutral mutant. Or, in other words, if birds go to an island where there are no predators, they lose their ability to fly. A biological trait, to be evolutionary stable, must be under selection. The retaliation, sometimes retaliation against defection goes out if nobody's trying to defect. So you've got to always cooperate by random drift. But if we'd always cooperate, now we can guess what happens next: we invite Always defect. You have oscillations here, you have a mathematical model of human history, of economic cycles, of ups and downs.
>
> There is one thing that I have learned in my studies of cooperation over the last 20 years: there is no equilibrium. There is never a stable equilibrium. Cooperation is always being destroyed and has to be rebuilt. How much time you spend on average in a cooperative state depends on how quickly you can rebuild it. The most important aspect is really how quickly you can get away from the Always defect again." - [The Evolution of Cooperation Edge Master Class 2011 by Martin Nowak](https://www.edge.org/conversation/martin_nowak-the-evolution-of-cooperation-edge-master-class-2011#:~:text=If%20everybody%20here,Always%20defect%20again.)

> "Indirect reciprocity. I help you and that gives me the reputation of a helpful person, and then others help me. So if I don't help you my reputation decreases, if I do help you my reputation increases.
>
> We know how this works from the way evaluations work on E-Bay. For example, you make a deal, you get a good evaluation, your value goes up. We have also played experimental games where people can purchase reputation, they can trade reputation if they have good reputation, so we can actually determine the price of a good reputation in experimental situations. This indirect reciprocity relies on gossip; some people might have an interaction and others observe it, and others talk about it. We are obsessed with gossip. We are obsessed with talking about others and how it would be to interact with them...
>
> What is very important for efficient indirect reciprocity is language. Indirect reciprocity leads to the evolution of social intelligence and human language. In order to evaluate the situation, you have to understand who does what to whom and why. And we have to have a way to talk about what happened, to gain experience from others.
>
> As my friend David Haig at Harvard put it very nicely, "For direct reciprocity you need a face; for Indirect reciprocity you need a name." And I find this beautiful because there is a lot in a face. A lot can be read from facial features. A big part of our brain is there to recognize faces, so we can recognize with whom the interaction was, to play simultaneous repeated games. But for Indirect reciprocity that's not enough; we also need a name." - [The Evolution of Cooperation Edge Master Class 2011 by Martin Nowak](https://www.edge.org/conversation/martin_nowak-the-evolution-of-cooperation-edge-master-class-2011#:~:text=Indirect%20reciprocity.%20I%20help,also%20need%20a%20name.)

> "Spatial selection is the idea that neighbors help each other. Neighbors form clusters, or you and your friends have many interactions and you cooperate, and you can even be an unconditional cooperator with your friends, and that can work out. This is an evolutionary graph theory where you have a social network and people interact with others on the graph. More recently, we also developed more a powerful mathematical approach that we call evolutionary set theory, where you belong to certain sets, for example, the Mathematics Department, the Biology Department, Harvard, or MIT, or the gym, or the tennis club, and I interact with people in that set. I cooperate with the people in the set and I try to join sets of successful individuals. So the extension to classical evolutionary game theory here is in classic evolutionary game theory, people imitate successful strategies. Here they imitate successful strategies in successful locations. They want to move into successful locations, and that can give rise to this clustering that allows evolution of cooperation." - [The Evolution of Cooperation Edge Master Class 2011 by Martin Nowak](https://www.edge.org/conversation/martin_nowak-the-evolution-of-cooperation-edge-master-class-2011#:~:text=Spatial%20selection%20is,evolution%20of%20cooperation.)

> "There can be no doubt that the tribe including many members who are always ready to give aid to each other, and to sacrifice themselves for the common good, would be victorious over other tribes. And this would be natural selection." - [Charles Darwin](https://www.edge.org/conversation/martin_nowak-the-evolution-of-cooperation-edge-master-class-2011#:~:text=There%20can%20be%20no%20doubt%20that%20the%20tribe%20including%20many%20members%20who%20are%20always%20ready%20to%20give%20aid%20to%20each%20other%2C%20and%20to%20sacrifice%20themselves%20for%20the%20common%20good%2C%20would%20be%20victorious%20over%20other%20tribes.%20And%20this%20would%20be%20natural%20selection.)

> "Five mechanisms for cooperation: kin selection: the idea is cooperation with genetic relatives; direct reciprocity: I help you, you help me; indirect reciprocity: I help you, somebody helps me; spatial selection: clusters of cooperators or neighbors to help each other; group selection: groups of cooperators out compete other groups." - [The Evolution of Cooperation Edge Master Class 2011 by Martin Nowak](https://www.edge.org/conversation/martin_nowak-the-evolution-of-cooperation-edge-master-class-2011#:~:text=I%20have%20discussed,compete%20other%20groups.)

> "What I find very interesting in these games of conditional reciprocity, direct and indirect reciprocity, we can make the point that winning strategies have the following three properties: they must be generous, hopeful and forgiving.
>
> Generous in the following sense: if I have a new interaction, now I realize (and this is I think where most people go wrong) that this is not a game where it's either the other person or me who is winning. Most of our interactions are not like a tennis game in the US Open where one person loses and one person goes to the next round. Most of our interactions are more like let us share the pie and I'm happy to get 49 percent, but the pie is not destroyed. I'm willing to make a deal, and sometimes I accept less than 50 percent. The worst outcome would be to have no deal at all. So in that sense, generous means I never try to get more than the other person. Tit-for-tat never wins in any single encounter; neither does Generous Tit-for-tat.
>
> Hopeful is that if there is a new person coming, I start with cooperation. My first move has to be cooperation. If a strategy starts with defection, it's not a winning strategy.
>
> And forgiving, in the sense that if the other person makes a mistake, there must be a mechanism to get over this and to reestablish cooperation." - [The Evolution of Cooperation Edge Master Class 2011 by Martin Nowak](https://www.edge.org/conversation/martin_nowak-the-evolution-of-cooperation-edge-master-class-2011#:~:text=What%20I%20find,to%20reestablish%20cooperation.)

> "In this indirect reciprocity, the added complication is with the social norm that is used by people to evaluate interactions between others. That social norm itself should be the product of evolution, and that's something that nobody has really described yet because that's usually a given in a group. We think that cooperating with somebody with a good reputation gives you a good reputation. Cooperating with somebody with bad reputation gives you a bad reputation. This kind of social norm also must evolve." - [The Evolution of Cooperation Edge Master Class 2011 by Martin Nowak](https://www.edge.org/conversation/martin_nowak-the-evolution-of-cooperation-edge-master-class-2011#:~:text=In%20this%20indirect,also%20must%20evolve.)





> "In other words, cooperation in groups on a genetic basis tends to be self-destructive. This may be clarified by introducing the concept of an evolutionary stable strategy. The strategy of the altruists, helping others even if they do not reciprocate the help, may lead to an increased fitness for the group but it is not stable, since it can be easily invaded by egoistic strategies that take advantage of the altruists' sacrifice, but without giving anything in return. Though the selfish strategies will globally lead to a decrease of fitness for the group, they are locally stronger than the altruist strategies. This is another expression of the principle of suboptimization: genetic evolution works at the level of the subsystem (the individual or the individual together with his kin), and what is optimal at that level will be selected, even though it is far from optimal at the level of the group. Campbell has summed up this predicament by the phrase "genetic competition among the cooperators": on the level of the genes rivalry continues, and that will eventually erode any cooperation on the level of the group." - [Evolution, Selfishness and Cooperation, by Francis Heylighen](http://pcp.vub.ac.be/Papers/MemesCooperation.pdf)

> "Selection for reciprocal altruism
>
> The characteristics of "tit for tat" (and of the other more successful strategies) can be summarized by three concepts: 1) the strategy is "nice": this means that it will never be the first to defect; 2) the strategy is "provocable": if the opponent defects, it retaliates by defecting too; 3) the strategy is "forgiving": as soon as the opponent cooperates again, the strategy forgets about the previous defection, and cooperates.
>
> Niceness is advantageous because it opens the way to mutually beneficial cooperation. Retaliation is necessary in order to avoid being invaded by selfish profiteers. Forgivingness has the advantage of avoiding mutual rounds of retaliation. Indeed, suppose that an individual because of distrust, by way of test or just because of a misunderstanding would defect just once, then a non- forgiving strategy would continue to defect in reaction, and mutual cooperation could never emerge or be restored.
>
> In a second study Axelrod generalized his game theoretic simulation to an evolutionary setting. In this setting, fitness was explicitly introduced by giving a strategy an amount of offspring proportional to the number of points it got in the previous tournament. The tournament was then repeated by playing all members of the new population of strategies (in which more successful strategies were now more numerous) against each other. Again the points of this tournament were used to produce a second generation of offspring. This generation played a following tournament, and so on. After many generations the less successful strategies would have been eliminated by natural selection, while the most successful ones would become more and more numerous. This setting is not equivalent to the previous one, since the fitness of the strategies depends on the opponents against which they play, and the field of opponents changes in the course of the simulated evolution. Hence a strategy that is successful in the original field of opponents may no longer be fit after the field has drastically changed. Yet Axelrod found out that it was still "tit for tat" that was most successful.
>
> However, "tit for tat" does not turn out to be an evolutionary stable strategy in the strict sense. Indeed, once the field is dominated by "tit for tat", other strategies that are less retaliatory (or more forgiving) become as fit as "tit for tat" since there are no longer cheaters to take advantage from their unconditional altruism. However, once a sufficient percentage of strategies becomes too altruistic, selfish strategies can again gain in fitness by exploiting their altruism. The end result seems to be some kind of equilibrium mixture of strategies in which reciprocal altruists such as "tit for tat" dominate, but in which there may also appear small amounts of "nasty" (the opposite of "nice") strategies together with non-retaliating altruists.
>
> In how far can these simulation results be generalized to real evolution? The most important restriction in the experiment seems to be that opponents interact with each other for a long, consecutive sequence of exchanges. This may be true for two individuals engaged in a close and stable relation. Reciprocal altruism may thus explain how a symbiotic relationship between two organisms can develop (e.g. a hermit crab and the sea anemone living on its shell) (cf. Axelrod & Hamilton, 1981). In the kind of situations involving a large number of individuals that interest us, on the other hand, it seems more likely that opponents will encounter each other only once, or now and then with long interruptions and exchanges with different opponents in between.
>
> "Tit for tat" is only successful in an indefinitely repeated prisoner's dilemma. If there is only one transaction, no retaliation is possible afterwards, and rationality dictates that you should defect. If there is a finite number of transactions, it pays to defect during the last one, but if you expect your opponent to defect at the last one, you should also defect at the last-but-one, and hence your opponent would be wise to already defect at the last-but-two, and so on. Hence games with a fixed number (known by the participants) of transactions would lead to continuous defection. In practice, that does not seem to be the problem, since normally opponents do not know how often they will meet each other again.
>
> However, the basic practical limitation is that of memory: the reciprocal altruist should not only remember how his opponent treated him during the last transaction (which may be a long time ago) he should also be able to recognize and distinguish all opponents with whom he has ever had transactions. This requirement does not seem to be realistic in large groups, such as human societies. Moreover, in such large systems, many encounters will take place for the first (and perhaps the last) time. In such cases reciprocal altruism does no good, and the "nice" individual who starts by cooperating may be cheated most of the time by others he will never see again. When I buy something in a shop in a city where I will never come back again, I do not expect to be cheated (though that is possible of course), even though I have no power to retaliate. In conclusion, reciprocal altruism seems still insufficient to explain the ultrasociality of human society." - [Evolution, Selfishness and Cooperation, by Francis Heylighen](http://pcp.vub.ac.be/Papers/MemesCooperation.pdf)

> "The basic weakness of reciprocal altruism in explaining ultrasociality is that it starts from dyadic relationships, of the type "I'll scratch your back if you scratch mine". It is difficult to imagine how such one-to-one exchanges could be enlarged in order to form the basis for large collective organizations. Therefore we would like to see some evolutionary stable strategy that directs behaviour towards groups rather than towards other individuals.
>
> It has been proposed that one such strategy is moralism, that is to say behavior that rewards or reinforces altruistic behavior by others, and punishes or inhibits cheating or defection. For example, Trivers (1971) has postulated selection for "moralistic aggression", and Lorenz (1975) speaks about "innate ethical sense". The advantage of moralism compared to pure altruism is that the costs of moralizing towards others are clearly less than those of being altruistic yourself (Campbell, 1983). However, if everybody around you is continuously moralizing, and ready to ostracize or even kill you if you do not behave altruistically, it becomes quite difficult to behave in a selfish way. Hence groups consisting of moralizing individuals will also tend to be altruistic, though the individuals are not motivated to be altruistic on their own. Moralism is also more stable than real altruism because cheaters will find it very difficult to invade a population that tends to make their life as difficult as possible. A disadvantage of moralism is that it encourages hypocrisy, that is to say behavior that does everything to look altruistic but is in fact selfish.
>
> A basic weakness of the argument is that it is difficult to imagine how something as complicated as an "ethical sense" might develop through genetic evolution. It seems quite difficult to put down rules distinguishing moral or altruistic behavior from selfish behavior that are applicable to all situations and all individuals. We might perhaps imagine the evolution of simple behavior patterns such as aggressive reactions against the selfish wolf who does not want the others of the pack to share in the food, but that does not seem sufficient to explain ultrasociality.
>
> Another weakness of the moralistic selection argument, is that moralism mainly functions to maintain an already functioning cooperation system, by reducing the fitness of those who do not obey the rules. However, the argument does not explain how the cooperative pattern, and the moralistic attitude that maintains it, may have developed from selfish behavior in the first place." - [Evolution, Selfishness and Cooperation, by Francis Heylighen](http://pcp.vub.ac.be/Papers/MemesCooperation.pdf)

> "The theory of natural selection on the basis of fitness is in principle applicable to all replicating systems, not only to genes. Recently, a new type of replicator has been proposed as a unit of cultural evolution. Memes are defined as cognitive or behavioral patterns that can be transmitted from one individual to another one by learning and imitation (Dawkins, 1976; Moritz, 1991). Examples of memes in the animal world are most bird songs, and certain techniques for hunting or using tools that are passed from parents or the social group to the youngsters (Bonner, 1980). In human society, almost any cultural entity can be seen as a meme: religions, language, fashions, songs, techniques, scientific theories and concepts, conventions, traditions, etc. The defining characteristic of memes as informational patterns, is that they can be replicated in unlimited amounts by communication between individuals, independently of any replication at the level of the genes. Storing a concept or a habit in memory after having encountered it through another individual, does not require any change of the DNA." - ['Selfish' Memes and the Evolution of Cooperation, by Francis Heylighen](http://pcp.vub.ac.be/Papers/MemesCooperation.pdf)

> "Though that process will be subjected to the same basic principles of blind variation and natural selection on the basis of fitness, memetic evolution is basically a much more flexible mechanism. Genes can only be transmitted from parents (or parent in the case of asexual reproduction) to offspring. Memes can in principle be transmitted between any two individuals (though it will become more difficult the larger the differences in cognitive mechanisms and language are).
>
> For genes to be transmitted, you typically need one generation, which for higher organism means several years. Memes can be transmitted in the space of hours. Meme spreading is also much faster than gene spreading, because gene replication is restricted by the rather small number of offspring a single parent can have, whereas the amount of individuals that can take over a meme from a single individual is almost unlimited. Moreover, it seems much easier for memes to undergo variation, since the information in the nervous system is more plastic than that in the DNA, and since individuals can come into contact with much more different sources of novel memes. On the other hand, selection processes can be more efficient because of "vicarious" selection: the meme carrier himself does not need to be killed in order to eliminate an inadequate meme; it can suffice that he witnesses or hears about the troubles of another individual due to that same meme.
>
> The conclusion is that memetic evolution will be several orders of magnitude faster and more efficient than genetic evolution. It should not surprise us then that during the last ten thousand years, humans have almost not changed on the genetic level, whereas their culture (i.e. the total set of memes) has undergone the most radical developments. In practice the superior "evolvability" of memes would also mean that in cases where genetic and memetic replicators are in competition, we would expect the memes to win in the long term, even though the genes would start with the advantage of a well- established, stable structure." - ['Selfish' Memes and the Evolution of Cooperation, by Francis Heylighen](http://pcp.vub.ac.be/Papers/MemesCooperation.pdf)

> "Meme fitness will depend basically on three factors: 1) survivability of the carrier; 2) individual learnability of memes; 3) tendency of memes to spread or to be transmitted. The first criterion is similar to the one determining gene selection, so we won't go into much detail about it. Basically it states that, all other things being equal, memes leading to decreased probability of a carrier's survival, e.g. because they are bad for the health, or lead to dangerous or suicidal behavior, will tend to be eliminated. However, we must add that survival is to be interpreted on the level of the group of all carriers, rather than on the level of the individual." - ['Selfish' Memes and the Evolution of Cooperation, by Francis Heylighen](http://pcp.vub.ac.be/Papers/MemesCooperation.pdf)

> "It is this contagiousness that most strikingly differentiates meme selection from gene selection. Genes, indeed, are not contagious. You can never get a gene, that you did not already have, from someone else. At most you can produce a child that shares some of your genes with some genes of another person." - ['Selfish' Memes and the Evolution of Cooperation, by Francis Heylighen](http://pcp.vub.ac.be/Papers/MemesCooperation.pdf)

> "All memes have the implicit goal of making their carriers more fit, since an increased number of carriers signifies that there will be more memory space available for meme replication. If, as we have argued previously, cooperation among the carriers tends to increase the overall fitness of the group of carriers, it will be in the interest of memes to promote that cooperation. Moreover, since cooperation requires communication, and since meme spreading critically depends on communication, the "motivation" of memes to bolster cooperation should be even stronger than that of genes." - ['Selfish' Memes and the Evolution of Cooperation, by Francis Heylighen](http://pcp.vub.ac.be/Papers/MemesCooperation.pdf)

> "The selective advantage does not mean that the less fit group will be physically eliminated during the competition with the cooperative group. On the level of memes, elimination can happen when the selfish group gives up its belief in the meme for selfishness and adopts the meme for altruism from the other group. This conversion of one group by another one may happen by direct physical force, for example because the altruist group is better organized to win a war between the groups, and can thus subdue the other one. It can also happen in a peaceful way because the less successful group simply imitates the more successful one.
>
> The basic argument against group selection is that group strategies can be easily invaded. However, that is not the case for memetic strategies. Indeed, suppose that a "mutant" meme promoting selfishness would appear in an altruist group. According to genetic reasoning, its carrier would be more fit than an altruist one, since he can profit from the altruism of the other carriers without paying the corresponding costs. However, the fitness of a meme is different from the fitness of its carrier. Though the selfish carrier might have enhanced fitness in the sense that he gets more food or other resources, the fitness of the meme he carries depends on how easily other members of the group can be converted to it.
>
> Now memes are selfish, which means that they have the implicit goal of thwarting all rival memes that compete for the same memory space. Hence the majority meme in the group will tend to consolidate the memory space it already occupies in the majority of carriers. A likely mechanism for that might be that the different carriers continuously reinforce each other's belief by communication and imitation. The carrier of the mutant meme, on the other hand, is alone and does not get any reinforcement from his fellows. He will find it very difficult to convert any of them to his non-conformist ideas, since the influence on any individual of a majority of conformists will be much stronger than that of a single dissident. This tendency of the majority meme to impose itself on minorities leads to intra-group homogeneity, as confirmed by Boyd and Richerson's (1985) mathematical model of cultural evolution" - ['Selfish' Memes and the Evolution of Cooperation, by Francis Heylighen](http://pcp.vub.ac.be/Papers/MemesCooperation.pdf)

> "Memes will even succeed in transcending the problem of the genetic competition between the cooperators... Our criticism of the argument on the basis of moralism, namely that a complete ethical system seems too complex to evolve by genetic selection, does not apply to memetic evolution, which is much faster, and which adapts more readily to abstract models of the world." - ['Selfish' Memes and the Evolution of Cooperation, by Francis Heylighen](http://pcp.vub.ac.be/Papers/MemesCooperation.pdf)

> "When two individuals, after sufficient interactions, have reached a stable cooperative relationship or pact, based on reciprocity, that agreement or convention can be viewed as a meme with two carriers. If there is communication, that same meme can be transferred to a third and a fourth carrier, and so on, who would thus come to join the convention. Indeed, an individual who observes an existing reciprocal relationship between two other individuals, and who notices the advantages following from their mutual cooperation, would be tempted to imitate their behavior. If a certain behavioral pattern tends to be imitated, that makes it a meme by definition. If that meme, in addition to it being contagious, also furthers the genetic fitness of its carriers, we may conclude that it has a high memetic fitness, and thus will tend to replace rival memes with a lower fitness." - ['Selfish' Memes and the Evolution of Cooperation, by Francis Heylighen](http://pcp.vub.ac.be/Papers/MemesCooperation.pdf)

> "The limitations on memory that make reciprocity difficult for large groups, can also be evaded by memetic mechanisms. Indeed, a meme can easily evolve mechanisms for making members of the same cultural group easy to recognize. Individuals belonging to the same culture or ethnical group will usually distinguish themselves by clearly perceivable attributes or behavior... If such signs allow you to identify a member of your group, you can expect that he will also follow the group's agreement on reciprocity, and hence you can trust that he will cooperate, without you having to renegotiate a pact. If he does not, you can still alarm the other members of your group, and he will be subjected to moralistic aggression. In that sense it is to the advantage of both the group and separate individuals to wear the appropriate attributes." - ['Selfish' Memes and the Evolution of Cooperation, by Francis Heylighen](http://pcp.vub.ac.be/Papers/MemesCooperation.pdf)

> "Many ethical systems explicitly refer to the ideal of "fraternity", and sometimes members of the same cultural group (e.g. monks or Freemasons) are supposed to call each other "brother". Though these are not brothers in the biological sense, the meme attempts to harness the innate tendency to behave altruistically towards kin and to use it for purposes different from the increase of genetic inclusive fitness." - ['Selfish' Memes and the Evolution of Cooperation, by Francis Heylighen](http://pcp.vub.ac.be/Papers/MemesCooperation.pdf)

> "It is possible to discern a clear progression from pure selfishness, to kin-restricted limited altruism, to "tit for tat" based dyads, to multi-individual reciprocal agreements, to moralism and group ideologies, and finally to the complex ultrasocial systems of cooperation characterizing present society." - ['Selfish' Memes and the Evolution of Cooperation, by Francis Heylighen](http://pcp.vub.ac.be/Papers/MemesCooperation.pdf)

> "With the capacity for language appears the capacity to rapidly spread complex memes, and that gives memes a definite advantage over genes in directing further evolution. In recent times, the memes that seem to be dominating are those that tend to make the ideal of altruism or brotherliness universal, ignoring the distinctions created by older memes such as languages or religions. We will not go into detail about why that is happening but note that the evolutionary tendency towards more and more far-reaching or inclusive cooperation seems to continue, albeit with many ups and downs. Such an evolution towards stronger integration of subsystems, allowing optimization at the global level, is exemplified by Turchin's concept of a metasystem transition. Such an evolutionary transition is characterized by the appearance of a control system at the metalevel, steering and optimizing the actions of the subsystems at the level below." - ['Selfish' Memes and the Evolution of Cooperation, by Francis Heylighen](http://pcp.vub.ac.be/Papers/MemesCooperation.pdf)

> "A basic conclusion of our general analysis is that you need communication before you can have cooperation, that is to say information must be shared. In organisms cooperating because of kin selection, the medium of communication is sexual reproduction: genetic "messages" are transmitted through special cells (sperm or egg cells) that cannot survive or develop independently of the process of sexual reproduction. It is this shared information that creates the connection between parents and offspring or, indirectly, between relatives. In primitive multicellular organisms, such as algae, the "communication" might be based on simple spatial contiguity (sharing of the same location). In complex organisms where there is differentiation of functions among cells, you need special chemical signals to coordinate the different cells (this can be modelled by "genetic networks", Kauffmann, 1991). In sociocultural systems, the basic medium supporting cooperation is meme spreading." - ['Selfish' Memes and the Evolution of Cooperation, by Francis Heylighen](http://pcp.vub.ac.be/Papers/MemesCooperation.pdf)

> "The complete evolutionary sequence would be something of the following form: competition, communication, stable interaction patterns, internal models of pattern, shared models, shared replicators, cooperation promoted by shared replicators, integration with the shared replicators as coordinators. In Turchin's terminology, the shared information will become a control for the systems of the level below, coordinating, monitoring and directing their cooperation. Hence the process of development of cooperation between initially competing subsystems through the development of shared replicators can be seen as a true metasystem transition." - ['Selfish' Memes and the Evolution of Cooperation, by Francis Heylighen](http://pcp.vub.ac.be/Papers/MemesCooperation.pdf)

> "It is clear that the whole issue of how competing subsystems can start to cooperate and thus become (partly or completely) integrated into a globally optimizing supersystem is very complex. Many questions about cooperation, shared information, and higher levels of control still have to be answered. Yet I think it is equally obvious that these problems are of the utmost importance if we wish to understand our own further evolution, as individuals, as a species, as a culture, or as parts of the global world system." - ['Selfish' Memes and the Evolution of Cooperation, by Francis Heylighen](http://pcp.vub.ac.be/Papers/MemesCooperation.pdf)

> "The more complex societies get + the more complex the networks of interdependence within + beyond community + national borders get, the more people are forced in their own interests to find non-zero-sum (NZS) solutions. That is, win-win solutions instead of win-lose solutions." - [Erik Torenberg](https://twitter.com/eriktorenberg/status/1120199593478647808)

