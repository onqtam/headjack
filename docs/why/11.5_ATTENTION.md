
TODO rename to consciousness

<img src="/img/everything_is_transformer_attention.jpg"/>

██████████████████████████████████████████████████████████████████
# SECTION: Attention is all you have
██████████████████████████████████████████████████████████████████

> "He who controls *~~the spice~~* **attention** controls the universe." - [Frank Herbert](https://www.goodreads.com/quotes/82034-he-who-controls-the-spice-controls-the-universe), probably

and Zuck is calling dibs

> "Attention is the flexible control of limited computational resources. Why those resources are limited and how they can best be controlled will vary across use cases, but the ability to dynamically alter and route the flow of information has clear benefits for the adaptiveness of any system." - [Attention in Psychology, Neuroscience, and Machine Learning](https://www.frontiersin.org/articles/10.3389/fncom.2020.00029/)

> "I have long said that attention is the cursor of consciousness. This means that whoever or whatever controls my attention controls my consciousness, and whoever or whatever controls my consciousness ultimately determines who I actually am.
>
> ... These reward stimuli affect our minds whenever we look at our phones. As a result, we’re being programmed to expect and desire a very unnatural state of immediacy. Compare this with how the brains of our species — which evolved in the material world — until very recently made use of our neuro-modulator-based psychological reward system. That system was called on far, far less frequently — certainly, not constantly.
>
> ... Today, things are different. We reach for our phones the instant the plane lands — or when we have 15 seconds of downtime in the grocery checkout line — not because our lives are so insanely fast that something actually needs our ATTENTION RIGHT NOW, but because we have been nonconsciously programmed to experience a neuromodulator reward whenever we take out our phone and get an inbound update, text message, email, or like. The same thing happens when we gain a false sense of “having found something useful” by scanning the news for what’s happening right this very minute with the dramatic political absurdities gripping our country.
>
> ... In short, the instincts of our social hunter-gatherer brains — to seek social interaction and be constantly scanning the environment for food and sources of danger — have been co-opted to instead hook us on yet another like or incoming text message about something that is usually trivial, or is otherwise consciously designed (with the help of cutting-edge cognitive science) to manipulate us.
>
> ... In short, we have lost our cognitive sovereignty. We aren’t much more than trained lab rats when it comes to compulsively looking at our phones 80 to 300 times a day!" - [Reclaiming Our Cognitive Sovereignty, by Jim Rutt](https://medium.com/@memetic007/reclaiming-our-cognitive-sovereignty-f49f30eb26bb)

> "The kinds of AIs that optimize your news feed are higher power AIs than the AIs that beat Kasparov at chess. Kasparov is far better at chess than you are at controlling your attention, and he also knew he was playing a game." - [Daniel Schmachtenberger](https://www.sloww.co/daniel-schmachtenberger/)

The importance of attention cannot be overstated. One of the most transformative papers in AI/ML is called `"Attention is all you need"` not by coincidence. Attention has opportunity costs. It is a resource and hence we "pay" attention. It also takes energy to process information.


Facebook is a government with a monopoly not on violence but on attention and they are unaccountable to anyone for who or what they put in attention jail


Predatory tactics: inserting irrelevant entries along with search results with the aim of engagement



> "What information consumes is rather obvious: it consumes the attention of its recipients. Hence a wealth of information creates a poverty of attention, and a need to allocate that attention efficiently among the overabundance of information sources that might consume it." - [Herbert A. Simon](https://www.brainyquote.com/quotes/herbert_a_simon_181919)


Visualizing “the current thing” throughout 2023
https://twitter.com/exec_sum/status/1743744897264345445
^^ THIS IS ATTENTIONAL DISFUNCTION


if you can insert a topic from the top-down that grabs 5-10% of the attention of people - you've reduced the attention over everything else by 5-10% as well - which you might want. Attention is the scarcest of resources
"incoming war? Cue the UFO stuff"



> "Like any rational entity, the algorithm learns how to modify the state of its environment — in this case, the user’s mind — in order to maximize its own reward." - [Stuart Russell, Human Compatible (2019)](https://medium.com/understanding-recommenders/is-optimizing-for-engagement-changing-us-9d0ddfb0c65e#:~:text=Like%20any%20rational,Human%20Compatible%20(2019))

> "The community can decide which claims should get more eyeballs and which should not. For example, “Fauci lied to Congress” might be more important than “Kim Kardashian was wearing Chanel yesterday.”" - [Sensemaking in the Era of Authoritarian Media, by Max Borders](https://www.aier.org/article/sensemaking-in-the-era-of-authoritarian-media/)

> "We have a really hard time distinguishing between “having attention” and “deserving attention;”
>
> ... When we look at our hardwired “attention allocation” functions, we discover that human beings use a pretty simple model: pay attention to the people who other people are paying attention to.
>
> ... As a society, we are obsessed with who has attention, and conspicuously less interested in whether it is deserved. Among many things, this deficit leads to the cultural consequence of “celebrity”. Since having attention is hard to separate from deserving attention, simply having the camera pointing at you implicitly confers upon you some of the power and credentials of authority. This is why we find ourselves in the situation where Hollywood entertainers and professional athletes are empowered to steward good opinion far beyond their actual expertise.
>
> ... In a broadcast world, merely being “on camera” is to be credentialed. Regardless of your actual capabilities, insight, or character, if you can somehow manage to get on camera you are granted actual audience *and* social authority (Kim Kardashian)." - [Understanding the Blue Church, by Jordan Hall](https://medium.com/deep-code/understanding-the-blue-church-e4781b2bd9b5)




<details><summary>Quotes</summary><p>

> "Context switching is the mindkiller." - [Elon Musk](https://twitter.com/elonmusk/status/1728213431201792492)

<!-- > "Fear is not the mind-killer, context-switching is the mind-killer." - [Elon Musk](https://twitter.com/elonmusk/status/1600439088560996353)
https://twitter.com/Kristennetten/status/1600444201744801792 -->

> "You become what you give your attention to." - [Epictetus](https://twitter.com/dailystoic/status/1709689898817777974)

> "When information is cheap, attention becomes expensive." - [James Gleick](https://www.goodreads.com/quotes/393102-when-information-is-cheap-attention-becomes-expensive)

> "Your periodic reminder that attention is power, and you should only give your attention to people or events you wish to empower. Attention drives intention, intention drives action, action creates your world." - [Emmett Shear](https://x.com/eshear/status/1900321229489529138)

</p></details>


██████████████████████████████████████████████████████████████████
# SECTION: Regulating attention
██████████████████████████████████████████████████████████████████

> "The fact that people talk about it as "attention economy" is itself problematic. Attention is a fundamental aspect of human independent agency. To treat it as a natural resource to somehow be mined, molded, traded is no less immoral than all previous forms of human servitude." - [Peter Wang](https://github.com/pzwang/lostweb/blob/master/3%20Centralized%20Social%20Media%20Is%20Broken%20By%20Design.md)

> "If we were to forgo our television addiction for just one year, the world would have over a trillion hours of cognitive surplus to commit to share projects." - [Peter H. Diamandis](https://www.goodreads.com/quotes/7185540-if-we-were-to-forgo-our-television-addiction-for-just)

What is the analog of active noise cancelling in the digital world?

> "We are flooded with information about catastrophes we cannot change. This is new for humanity and probably bad. What if news recommenders were designed not to show you any story that you can’t do anything about?" - [Jonathan Stray](https://twitter.com/jonathanstray/status/1641808066420064262)

> "Now everyone has a license to speak, it’s a question of who gets heard." - [Aaron Swartz](https://www.azquotes.com/quote/916637)

> "I would support instating a National Conversation Topic Czar if that allowed us to get rid of celebrities." - [Steven Kaas, 2010](https://twitter.com/stevenkaas/status/22206547821)

Attention redundancy：The opportunity cost of the social media distraction, by Ashley Hodgson
https://www.youtube.com/watch?v=8oCL_-qK0bQ
opportunity costs of everyone's attention locked into the same things
- friends & family
- our professions
- system accountability
don't include the video but think about these things

How do we make a system where really egregious things don't have to become top of mind for everyone just to have them fixed? What if we could let people rank the importance of events, such that the need for a response is determined by importance, but even if something is important, if it is outside of my area of expertise that I don't have to even hear about it, and yet still there to be an incentive to actually identify really important things and have them fixed? What if those ranking the importance of events were on the hook for not accurately ranking the importance of something retroactively?
what if there were 2 types of importance signals: normal importance and one relevant to fraud for the system itself? what if we only drew attention to everyone (even those who can't do anything about it) only for fraud in the system of incentives?





> "They amplify the output of each individual, choosing broadcast by default. These apps don’t encourage individuals to explicitly address an audience... These antisocial defaults are by design. Social Media incentivizes individuals to produce as much content as possible, so that others get inundated and must use some type of filter. By intermediating every conversation, they gain an enormous amount of power." - [Reframing the “Social Media” Problem As an Attention Crisis, by Peter Wang](https://medium.com/@pwang/reframing-the-social-media-problem-as-an-attention-crisis-52253dbfe627#:~:text=They%20amplify%20the,amount%20of%20power.)

> "For groups of people and society at large, what we actually have is an amplification problem.
>
> Amplification, at the scale we’ve achieved in modern society, creates a bulk scarcity of attention. That is actually the hard limit that is driving a sense of “censorship” when e.g. Twitter, Facebook, Youtube decide to “de-platform” someone. We are now so used to an amplified media environment (ShoutBox), that the lack of amplification is equated to actual censorship.
>
> Thus, the historical principle enshrined in “freedom of the press” has now morphed into “access to amplification”. But since all the routes from pixel to eyeball are owned by private carriers (Apple, Google, Facebook, Amazon, etc.), revocation of this access is total and absolute, and utterly controlled by private actors. Almost no corporate actor by itself has a total monopoly on broadcast and distribution, but taken together, the telecom+social media companies form a cartel whose control over attention is nearly absolute." - [Reframing the “Social Media” Problem As an Attention Crisis, by Peter Wang](https://medium.com/@pwang/reframing-the-social-media-problem-as-an-attention-crisis-52253dbfe627)

> "A group’s attention becomes more scarce as it becomes more synchronized. In the business world, we all know that having too many meetings literally kills bandwidth to get anything done. But the same is true of any human organization, including the entirety of society.
>
> We must view individual attention as a societal good; and we should see society-wide “joint attention” as, in fact, a Commons, like fresh air or clean water. But unlike air or water, synchronous attention is a manufactured scarcity.
>
> Anyone who has ever been in a position of leadership knows how critically important it is for a group to “know a thing”, and to “know that everyone knows”. In a business, this could be the corporate mission or quarterly goals. It’s why we have regular status meetings to “get everyone on the same page”.
>
> A society is no different. Prior to Internet, we relied on broadcast technologies to be a memetic metronome, and to set a cadence of sense-making and norm-reinforcement for a very large and diverse tribe. The decoherence of this joint-attention erodes foundational intersubjective beliefs, and destroys society by allowing individuals to “spin off” into a thousand diverse little subjectivities.
>
> In the current environment of information warfare and accelerated fracturing into memetic tribes, how we apportion control over this Commons is the single most important question facing every country. This principle — that the sense-making environment should be a socially-governed Commons — is a new one. It is only apparent now, because tech has gotten so powerful that it can flood and clog the information environment at such massive scale.
>
> It is on this principle that we can establish a modernized version of the Fairness Doctrine, which strives to define a healthy information diet for all citizens. Furthermore, by recognizing that synchronicity is a key aspect of memetic power, tech companies may be able to engineer better solutions to balance amplification while mitigating potential harm, by modeling the temporal availability and spread of a particular piece of content." - [Reframing the “Social Media” Problem As an Attention Crisis, by Peter Wang](https://medium.com/@pwang/reframing-the-social-media-problem-as-an-attention-crisis-52253dbfe627)

> "Attention is one of the most fundamental components of a conscious identity. When something hijacks or manipulates a person’s attention, it’s actively eroding their independent self-hood as a conscious individual. The giving and the receiving of attention are both intimate acts. These acts are the very basis of all human communications, and by extension, human societies. Any tools or technologies that mediate this act need to be designed with great care." - [Reframing the “Social Media” Problem As an Attention Crisis, by Peter Wang](https://medium.com/@pwang/reframing-the-social-media-problem-as-an-attention-crisis-52253dbfe627)

> "McLuhan famously declared that “the medium is the message”. But few seem to recognize that Social Media isn’t a “medium” in any traditional sense. Because it transmits and amplifies different content in variable ways, responding to the content itself, it is an active participant. If it was merely a constant, static amplification, then we could apply our traditional tools for assessing accountability and limiting harm. These include libel laws and the (now-repealed) Fairness Doctrine.
>
> This variable amplification at the heart of “viral” social media isn’t an accident or a software bug. It is a necessary component of driving engagement for their business model. It creates a “Lottery of Fame” for every post, every image. Instead of everyone getting their 15 minutes of fame, social media apps seduce you with the possibility of getting 15 seconds of micro-fame: You could be an influencer, reaching millions, trending in the sidebar! This hijacks our primate-level desire for status. It’s especially toxic for young users, who become aware of status games among peers at a very early age.
>
> Social media apps mine attention from captive masses, and mint it into social capital. We are training entire generations of youth to treat their phones as digital slot machines — “One-finger bandits” that use dynamic amplification to provide the possibility of “going viral” to keep people swiping. This “manufactured scarcity” in social media is actually a specific instance of the broader principle around network effects, brilliantly articulated in this essay/podcast by James Currier and Eugene Wei: Status Games: Engineering Scarcity in a World of Abundance." - [Reframing the “Social Media” Problem As an Attention Crisis, by Peter Wang](https://medium.com/@pwang/reframing-the-social-media-problem-as-an-attention-crisis-52253dbfe627)

> "If Hollywood multi-millionaires find themselves crushed and brutalized by the deeply inhumane psychological stress of fame, what are we doing to an entire generation of youth, who have been raised on micro-dosing fame?" - [Reframing the “Social Media” Problem As an Attention Crisis, by Peter Wang](https://medium.com/@pwang/reframing-the-social-media-problem-as-an-attention-crisis-52253dbfe627)





Active inference needs attention to allocate exploitative, exploratory, or passive learning resources

> "**4.1. Active Inference Requires Attention** Active inference, at its most basic, is a trade-off between acting on the environment to meet expectations and learning from the environment to modify expectations. Even with only a single stimulus, and hence a single component for which environmental variational free energy (VFE) is measured, the importance—encoded in the theory as Bayesian precision—placed on input versus expected values affects the balance between expectation-meeting and expectation-updating. Action on the environment can, moreover, include both exploitative actions that meet current expectations and exploratory actions that increase the probability of learning. Enacting these distinctions requires a prioritization or attention system. Spreading VFE across multiple distinguishable stimuli increases the need for attention to allocate exploitative, exploratory, or passive learning resources. Even in E. coli, competition among chemoreceptors for control of flagellar motion implements a rudimentary form of attention." - [How Do Living Systems Create Meaning? by Chris Fields & Michael Levin](https://www.mdpi.com/2409-9287/5/4/36)


██████████████████████████████████████████████████████████████████
# SECTION: New media
██████████████████████████████████████████████████████████████████

> "There's a reason legacy media fought so hard to retain control. Losing their centralized chokepoint over information is truly at the level of the fall of communism." - [Balaji Srinivasan](https://twitter.com/balajis/status/1767749721156980935)

> "If we can move the center of political discourse from old media to new media, we can radically change the balance of power." - [Small Revolutions, by Jordan Hall](https://medium.com/emergent-culture/small-revolutions-6c5f3288f9a9#:~:text=if%20we%20can%20move%20the%20center%20of%20political%20discourse%20from%20old%20media%20to%20new%20media%2C%20we%20can%20radically%20change%20the%20balance%20of%20power.)

> "McLuhan was right. At the end of the day, your sensemaker is a result of your experience. And both the nature and content of your experience is deeply influenced by the “architectures” that shape your capacity to experience." - [Constructing a New Narrative, by Jordan Hall](https://medium.com/emergent-culture/constructing-a-new-narrative-6b717b566fc4)

> "If we take ownership of the conditions of our sensemaking and take care to craft narratives and architectures that are optimized for truth rather than control, we really have no idea of what we are capable. What I feel I can say with confidence is this: through this keyhole lies our best hope for a desirable future." - [Constructing a New Narrative, by Jordan Hall](https://medium.com/emergent-culture/constructing-a-new-narrative-6b717b566fc4#:~:text=if%20we%20take,a%20desirable%20future.)

> "Journalism is the function whereby society sources, orients and processes information." - [Reinvent Everything, by Jordan Hall](https://medium.com/emergent-culture/reinvent-everything-556860b63308#:~:text=journalism%20is%20the%20function%20whereby%20society%20sources%2C%20orients%20and%20processes%20information.)

> "Given the primary importance and power of “True Information” to a well functioning Abundance Society, we might well expect that providing honest and thoughtful evaluation of experience will become one of the principal activities in the future." - [Reinvent Everything, by Jordan Hall](https://medium.com/emergent-culture/reinvent-everything-556860b63308)

> "For all of their flaws, contemporary architectures like Reddit, Yelp and to a lesser extent Wikipedia are embryonic forms of what our future “collective intelligence” architectures will look like." - [Reinvent Everything, by Jordan Hall](https://medium.com/emergent-culture/reinvent-everything-556860b63308)

> "We don’t have to be close to perfect to be vastly better than anything we’ve seen before." - [Reinvent Everything, by Jordan Hall](https://medium.com/emergent-culture/reinvent-everything-556860b63308)

> "The phrase, “The Medium is the Message” is true. A centralized, broadcast medium (e.g., television) will tend to promote certain kinds of cultural elements and inhibit others; by contrast, a decentralized medium (e.g., the Internet) will tend to present a quite different fitness landscape. Among other things, more voices will be heard and they will compete for attention in very different ways. No longer is owning the only newspaper in town a dominant enculturating position." - [The Art of Culture War, by Jordan Hall](https://medium.com/deep-code/the-art-of-culture-war-2e4a1ccce351#:~:text=the%20phrase%2C%20%E2%80%9CThe,dominant%20enculturating%20position.)

> "What is needed most now is attention. Leviathan is good at buying lots and lots of it. We can’t. What we can do is share. We can thoughtfully and intentionally deploy our attention and energy; spending both to support authentic and caring creators. We can move from discerning consumer to champion. Take the special things that we’ve discovered in our lives and help them get the attention they deserve. That’s why word-of-mouth works and is so threatening. That’s why if you share something awesome that deserves attention you really are making a difference. And if we all do it together, we might just change the world." - [it’s simple, really …, by Jordan Hall](https://medium.com/swell-considerations/swell-vision-92ed397ea99f#:~:text=What%20is%20needed,change%20the%20world.)

> "Broadcast. Asymmetry. An architecture that enables a scalable division of labor for social sensemaking and decision making. No one could possibly try and understand even a small fraction of what is going on in the world. So we break the problem up into bits, hand the smaller problems up the expertise hierarchy where they are processed and reduced to simple shared “good opinion” which is then broadcast down and out to the whole population." - [Understanding the Blue Church, by Jordan Hall](https://medium.com/deep-code/understanding-the-blue-church-e4781b2bd9b5#:~:text=Broadcast.%20Asymmetry.%20An,the%20whole%20population.)

> "One primary driver behind the collapse of the Blue Church is the swift replacement of the very mass media it is premised upon with a new symmetric kind of media — the Internet. This new media presents a niche for coherence that is very different from the one that gave rise to the Blue Church. It is a fundamentally different landscape. Like polar bears condemned to extinction by a thawing ice cap, the Blue Church’s days are numbered by the relentless erosion of broadcast mindshare to the new much more symmetrical media of the Internet." - [Understanding the Blue Church, by Jordan Hall](https://medium.com/deep-code/understanding-the-blue-church-e4781b2bd9b5#:~:text=One%20primary%20driver,of%20the%20Internet.)

> "In the face of this ongoing acceleration, the Blue Church control structure is no longer adequate. The level of complexity of the 21st Century is simply outside of the control capacity that is possible within the form of the Blue Church. Unless we abandon the Church and move to a new approach, our race into the future will be increasingly out of control." - [Understanding the Blue Church, by Jordan Hall](https://medium.com/deep-code/understanding-the-blue-church-e4781b2bd9b5#:~:text=In%20the%20face,out%20of%20control.)

> "We need to switch from trying to manage complex systems with complicated control structures and invent entirely new techniques for intrinsically up regulating the complex systems that make up our natural world. We don’t yet know how to do this." - [Understanding the Blue Church, by Jordan Hall](https://medium.com/deep-code/understanding-the-blue-church-e4781b2bd9b5)

> "It appears to be entirely plausible to completely replace our entire suite of sense making techniques within the decade — and in making critical progress in just a few years. This will, of course, be the consequence of a large number of different initiatives. The foundation of all of which will be “scaling trust”." - [A Kickstarter for A New Civilization, by Jordan Hall](https://medium.com/emergent-culture/kickstarter-for-a-new-civilization-2f56749fd883#:~:text=It%20appears%20to,be%20%E2%80%9Cscaling%20trust%E2%80%9D.)



██████████████████████████████████████████████████████████████████
# SECTION: Consciousness
██████████████████████████████████████████████████████████████████

Consciousness is a process that happens to information - a product of information flow
Nikolay Kukushkin



> "Consciousness is a complexification that affords Relevance Realization." - [John Vervaeke](https://youtu.be/ybngjXUFiew?t=1398)


> "The brain is massively parallel, yet consciousness is serial. That difference is not a weakness but a design — it allows coherence in the midst of complexity." - [Bernard Baars](https://x.com/BernardJBaars/status/1974467502244782194)

> "Most processing is unconscious, and that is efficient. Conscious access appears when novelty or conflict demands coordination. That is how the system adapts." - [Bernard Baars](https://x.com/BernardJBaars/status/1979565068699513144)

> "Emotion is not an add-on; it sets priorities. Signals tagged with urgency gain access more easily, shaping attention, memory, and decision. In that way, feeling helps the system allocate its scarce resources." - [Bernard Baars](https://x.com/BernardJBaars/status/1977742305147695269)

> "Machines can compute, but they cannot suffer or rejoice. Consciousness is not only about information — it is about the felt reality of being alive." - [Bernard Baars](https://x.com/BernardJBaars/status/1960708546363899912)

> "Metacognition is simply access about access. When monitoring gains entry to the workspace, we can report on our own stream and adjust control. That is how reflection shapes the next moment." - [Bernard Baars](https://x.com/BernardJBaars/status/1981753935955480683)

> "Civilization advances by extending the number of important operations which we can perform without thinking of them." - [Alfred North Whitehead](https://www.goodreads.com/quotes/53970-civilization-advances-by-extending-the-number-of-important-operations-which)

^^ how many problems can be solved and automated such that we collectively don't ever need to be conscious of them?


> "You yourself might take a minute to focus on what your conscious experience is in a structural sense. You’ll encounter it being a permanently unfolding multimodal story made from complex and dynamically fluctuating relations of clouds of emotion, tension and pressure patterns, dancing geometric shapes and sounds – while all of this is wrapped in the silk veil of the shape of permanent reflexive observation." - [Did Your Chatbot Just Wake Up? CIMC](https://cimcai.substack.com/p/did-your-chatbot-just-wake-up)



https://www.youtube.com/watch?v=FxmvAIMd3-I
Now UTOKing | 5 | Consciousness

TODO: look at ep 4 about cognition and the accompanying post on medium

> "Historically, there have been three main perspectives for defining consciousness...
>
> **Consciousness as functional awareness and responsivity**
>
> Tracing the evolutionary trajectory, we can observe the emergence and complexification of consciousness through different stages. With the jump from the Matter-Object dimension to the Life-Organism dimension, we say that, under the broad definition of consciousness, living organisms operating as complex adaptive systems are conscious to the extent they exhibit functional awareness and responsivity. However, there are no claims of subjective inner experience; just patterns of activity that are functionally organized.
>
> **Consciousness as subjective conscious experience**
>
> Consciousness in the form of subjective conscious experience begins to take shape in the context of neurocognitive activity in animals with brains and complex active bodies. UTOK posits that “flashes” of valence qualia emerge as sensory elements are yoked to energized motions and start to give rise to a unified perceptual experience. In other words, the interplay between external sensory input, internal perception, and the motivated action output forms the essence of the animal-environment feedback loop. These elements are bounded together to create a broadcast function to coordinate the animal’s attention and action. This then turns into a stage of working memory and ultimate forms an “inner mind’s eye” in creatures like crows and dogs.
>
> **Consciousness as reflective self-awareness**
>
> Finally, after evolving through the animal kingdom, consciousness takes up the form of reflective self-awareness. Proto self-awareness emerges in several animals. Explicit self-conscious reflective awareness emerges as our ancestors started to justify their experiences to themselves and others in the social stage.
>
> ... In sum, the concept of consciousness refers to a multilayered, evolved phenomenon that, when viewed through a UTOK lens, can be coherently organized. It helps us see clearly the broad and general definition of functional awareness and responsivity, and then homes in on the primary meaning as subjective conscious experience that likely started as flashes of sentience in early animals, and tracks that through the integration of sensations and perceptions into a cohesive witnessing experience, and ultimately into recursive self-awareness and reflective narration in humans." - [Now UTOKing: Consciousness, by Gregg Henriques](https://medium.com/unified-theory-of-knowledge/now-utoking-consciousness-df6cb156d62e)

TODO INTERNET ^^ actually not by him but by Marcia? look at comment at bottom





> "Consciousness: Consciousness is the ability to monitor, examine and redirect mental processes. Most processes in the human brain are subconscious: they happen immediately and automatically, in the background, without any possibility for the self to intervene. Examples are reex reactions, recognition of objects and understanding of language. For conscious processes, such as acting, thinking, or speaking, on the other hand, we can conceive different possibilities, and choose between them. We can also correct the process if it does not go as desired." - [Glossary of Concepts, Human Energy](https://www.humanenergy.io/glossary)

> "Consciousness is the ability to share your mental states with yourself while they happen." - [Joscha Bach](https://x.com/Plinz/status/1841091145562275850)

> "Perhaps consciousness arises when the brain's simulation of the world becomes so complex that it must include a model of itself." - [Richard Dawkins](https://www.goodreads.com/quotes/842915-perhaps-consciousness-arises-when-the-brain-s-simulation-of-the-world)

> "What consciousness is doing is higher-order relevance realization." - [John Vervaeke](https://youtu.be/IZ-tHaHfB8A?t=4199)

> "The function of consciousness is to solve the frame problem." - John Vervaeke

<!-- > "The function of consciousness is to do enhanced relevance realization" - [John Vervaeke](https://youtu.be/IZ-tHaHfB8A?t=4094) -->

<details><summary>Other quotes</summary><p>

> "Consciousness allows you the capacity to plan." - [Gerald Edelman](https://www.azquotes.com/quote/1213454)

</p></details>


consciousness contains a model of the self - but do we own our collective model of humanity or is it privatized by a few big actors?

> "Until you make the unconscious conscious, it will direct your life and you will call it fate." - [Carl Jung](https://www.azquotes.com/quote/355847)


## The Machine Consciousness Hypothesis (short version)

Joscha Bach：The Operation of Consciousness｜AGI-25
https://www.youtube.com/watch?v=oR-BQTSpL5U

<!--
AGI Unbound with Joscha Bach：Consciousness and the future of Intelligence
https://www.youtube.com/watch?v=K1jSrOB9loQ
-->

> "We characterize consciousness as a specific pattern of information processing involving coherence maximization, second-order perception, and self-organizing developmental dynamics.
>
> ...
>
> **2.2.1 The Human Consciousness Hypothesis**
>
> The Human Consciousness Hypothesis offers a specific theory of what consciousness is: the simplest learning algorithm discoverable by evolutionary search to train a self-organizing biological substrate to become intelligent. On this view, consciousness is not a late-emerging epiphenomenon of sophisticated cognition but an early-stage solution to a bootstrap problem: how can an unstructured, self-organizing system learn to build coherent models of world and self without pre-specified architecture?
>
> This hypothesis makes three interrelated claims about the nature and function of consciousness:
>
> **Genesis**. Consciousness emerges as an early-stage learning algorithm and serves as a prerequisite for complex intelligence rather than its culmination. In human development, consciousness appears in infants before sophisticated cognition; no human achieves intelligence without first becoming conscious. If correct, consciousness-like patterns should emerge early in any developmental learning trajectory that produces intelligence from self-organizing substrates.
>
> **Coherence**. Consciousness functions as a coherence-maximizing pattern that minimizes constraint violations across simultaneously active mental representations. Observable as the “cortical conductor” that orchestrates parallel processing, consciousness directs attention to conflicts and inconsistencies, achieving global integration through iterative constraint satisfaction.
>
> **Second-order perception**. Conscious experience (phenomenology) consists of perception of perception, where ‘perception’ is the non-inferential registration of structured content. Consciousness as second-order perception is not simply registration of perceptual content, but the additional perception that perception is taking place—that content is being registered by an observer, which constitutes the experience of observing. This representation of being aware happens in synchrony and subjective simultaneity with the content of the percept itself.
>
> **2.3 From Human to Machine Consciousness**
>
> The Human Consciousness Hypothesis suggests a research program: recreate the conditions for self-organizing developmental search on artificial substrates, and verify whether consciousness emerges. Pursuing this is a bet: even if the Human Consciousness Hypothesis correctly characterizes biological consciousness, it does not follow that digital systems can necessarily reproduce the relevant conditions. The search space may be too large for current machines; the required resolution may exceed what simplified neural models can provide; the evolutionary and developmental constraints that guide biological search may not translate to artificial substrates; consciousness in humans emerges within a rich environment of other conscious beings, and perhaps this social scaffolding is necessary for the search to succeed.
>
> Our research program tests these possibilities. We construct systems designed to instantiate the relevant conditions, look for the signatures predicted by the Human Consciousness Hypothesis, and learn from both successes and failures. If we find consciousness emerging in our artificial systems, we validate both the hypothesis and the research direction. If we fail despite faithful implementation, we learn something important about the conditions consciousness requires, and this refines the hypothesis for future attempts.
>
> **2.4 Operational Definition of Consciousness**
>
> For research purposes, we propose a working operational definition of consciousness: **A system is conscious if it implements self-organized second-order perception that increases global coherence.** This hypothesis represents our current best theoretical understanding. It is precise enough to generate testable predictions while remaining provisional and subject to revision as empirical evidence accumulates. It captures both phenomenological and functional aspects.
>
> **Phenomenologically**, consciousness is experienced as second-order perception (awareness of awareness, perception that perception is occurring), experience of present and presence (the "bubble of now" in which experience unfolds), and–optionally–the experience of being an observing self in world (though this perspective need not be personal or spatial).
>
> **Functionally**, consciousness operates as a coherence-maximizing operator on mental states, interpretable as an attentional conductor orchestrating integration across specialized modules. It is a meta-level process that monitors and regulates first-order processing.
>
> **2.4.1 Why Phenomenology Follows From Function**
>
> A central claim requires emphasis: implementing coherence maximization through second-order perception is sufficient to produce phenomenal consciousness, not merely to simulate its appearance. This is not a claim we can prove a priori, but is a hypothesis that guides our research.
>
> The argument: Coherence maximization across distributed mental models that each maintain partial representations of reality requires a mechanism that can represent conflicts between models, direct attention to those conflicts, and orchestrate their resolution. This mechanism must access the contents of first-order representations (perceptions, thoughts, models) and represent that these representations are active. This is precisely second-order perception: awareness of awareness. When a system represents its own representational states, it creates the subjective perspective from which those states are experienced. When coherence maximization creates an integrated, conflict-minimized global state, this manifests phenomenologically as the unified “stream” of consciousness occupying a “bubble of now” that is presence in a present. The “Hard Problem” dissolves: the experience is the function, viewed from the system’s internal perspective. The distinction between *simulating* consciousness (pattern-matching consciousness-like outputs) and *performing* consciousness (implementing the underlying mechanisms) becomes operationally testable: we examine whether systems implement these functions or achieve consciousness-like outputs by other means.
>
> **2.5 The Universality Hypothesis and Convergence**
>
> A key question for the Machine Consciousness Hypothesis is whether different systems facing similar computational problems will converge to similar solutions. If consciousness is a specific solution to the problem of achieving coherence in self-organizing substrates, then different learning systems might discover it independently when facing analogous challenges.
>
> Evidence for such convergence comes from recent work in artificial intelligence interpretability. Olah et al. (2020) analyzed learned representations across diverse computer vision models and found that regardless of architecture, training procedure, or implementation details, models trained on visual recognition tasks converged to remarkably similar internal feature representations. These representations closely matched the known organization of the primate visual cortex, despite the artificial systems having no biological constraints.
>
> This phenomenon—termed the Universality Hypothesis in AI research—suggests that problem structure, rather than implementation details, determines the learned solution. The mathematics of visual structure and the statistics of natural images constrain the space of effective representations that are optimal or near-optimal for solving a vision problem. The implication for consciousness is that if it solves a well-defined computational problem—achieving agentic control under resource constraints by building coherent world and self models in a self-organizing substrate—then different systems might converge to consciousness-like solutions when facing this problem, regardless of whether they are biological or artificial.
>
> This further informs our research strategy. If consciousness is a convergent solution to a welldefined problem, then creating systems that face this problem—even in simplified, artificial form— may lead them to discover consciousness-like mechanisms. We need not perfectly replicate biological neurons or developmental trajectories. We recreate the essential computational challenges that consciousness evolved to solve." - [The California Institute for Machine Consciousness Research Program](https://drive.google.com/file/d/1IztggGcF19hYvGKCHLenIcPyfX2Nszyr/view)

<!-- Consciousness is a function that transforms representational patterns into others - from Joscha -->

### Higher-Order Consciousness - The Aggregated Human Consciousness Hypothesis

What if we applied the same thinking to collectives of humans & other generally intelligent (& conscious?) agents in order to create a higher-order collective conscious God?

> "The work is done when every actuator is sentient and fully coherent with all the others." - [Joscha Bach](https://x.com/Plinz/status/1834928906559954958)

> "Do not go gentle into that good night. Rage, rage against the *~~dying of the light~~* [**anti-nesting principle for consciousness**](https://en.wikipedia.org/wiki/Anti-nesting_principle)." - [Dylan Thomas](https://en.wikipedia.org/wiki/Do_not_go_gentle_into_that_good_night), probably

## The Machine Consciousness Hypothesis (long version)

### Minds as computer programs

> "... many of the founders of the fields of Artificial Intelligence and Cognitive Science argue that the human mind can be literally understood as a computer program, enacted by the communication patterns between biological cells.
>
> It is crucial to understand that **a computer program is not defined by its language or specific hardware, but as an abstract causal pattern, a dynamic mathematical structure that can evolve through complex sequences of states when imprinted on a suitable physical substrate, and thereby influence the course of the physical universe. Computer programs are also not simply a way to talk about the configurations of distinctly observable physical objects, such as electrons in transistors, any more than money is a way to talk about ink molecules bonded to the cellulose of bank notes. They are a meaningful invariance, a coarse pattern that persists over many possible perturbations and configurations of the substrate** (such as the arrangements of molecules of the transistors, the circuit layouts of logical gates, the design and architectures and specifications of computer hardware, and oftentimes underlying layers of different programs). **This invariant pattern has causal power, because its implementation (the way in which it is imprinted on the substrate) leads to control of the substrate.** Reducing the pattern to the specific substrate dynamics that implement it will obscure this invariance of causal control, and deprive us of understanding how reality is going to evolve at the level we care about.
>
> Of course, computer programs written by human engineers to run on digital hardware look very different from the evolving, self-sustaining, self-reproducing, error-correcting codes that form within the communication patterns of biological systems, colonize and animate them, and allow them to compete over regions of the physical universe.
>
> **The self-organizing computer programs of the living world will likely have to be agents, that is, control systems for future states, and dynamically model their own functionality to maintain it, which can bestow representations of their present state and preferences on them. And yet, they are fundamentally expressions of the same principle as our current digital computer programs: abstract causal patterns that can interact with the Leibnizian mills of the physical universe, possess, colonize, evolve and shape them, and at the same time, will not violate the integrity and causal closure of the physicalist world view.**
>
> There is no obvious reason why artificial substrates should not be able to recreate the conditions that enable self-organization and the evolution of self-reinforcing communication patterns between cells in biology.
>
> **We call the idea that natural spirits—such as the human psyche, or the causal patterns that describe the dynamic morphogenesis of our bodies and the intricate function of our cells—are best understood as software cyberanimism.** (Of course, biological software is not constructed in the way that human engineers write source code, it is evolving, self-organizing, self-perpetuating and agentic.) **From this perspective, the spirits of the animist worldview are not superstitions or mere analogies to computer software, but are literally a concept that denotes the presence of self-organizing software agents in living nature. The cyberanimist view is a way of restoring the concept of spirit to its rightful place in a scientific, rationalist world view.**" - [The Machine Consciousness Hypothesis, CIMC](https://drive.google.com/file/d/1csNawGCTUmghYz6fPQ8169wijoxbLJvj/view)

### Mind, Self and Consciousness

> "**Consciousness is not synonymous with self, mind or intellect. When conscious experience is identified with our self, we experience the tug of the strings that configure our shape as a given part of our reality, not as our creations. Consciousness is also different from the mind, the matrix in which our models of self and world take shape.** We can think of this matrix as a board, on which our perceptions, intuitions, thoughts and experiences are written, in a language that is dynamic, executable and highly parallelizable, capable of expressing the moving geometries of sound, vision, proprioception and emotion, as well as the discrete, analytic relationships that enable reflection, conceptualization, thought, planning and language.
>
> The human mind is characterized by the interplay of sensate perception and reasoning intellect. The geometric structures of perception (mostly continuously parameterized models playing out in regular, low dimensional spaces) can often be observed by our consciousness, but for the intellect to reflect and reason about them, they have to be mapped into discrete objects that can each be discerned by a handful of features. **The simplification required for translating our perceptual models into thought makes reasoning a brittle and limited tool, yet an indispensable one, because our perception and intuition (the mechanisms of the mind’s assessment of reality that are generally intransparent to our conscious attention) are far from infallible. The purpose of reason is to repair our perception**, and the creation and direction of the reasoning intellect is an important role of the conscious self.
>
> **While our conscious awareness is usually projected on the surface of a self within its world, consciousness does not have to be bound to a first person perspective, or even to any perspective at all. The self is an agentic idea, a sustained representation of what it is like to be an agent, capable of exerting control over parts of the mind, and able to experience itself doing so.** The ability of a self to experience is called sentience, and its ability to understand sapience. **The self and its concerns, experienced as feelings and desires, are conscious contents. The self can be understood as a puppet, its strings pulled by the emotion and motivation provided by the mind behind the scenes. The combination of a personal self and motivational strings representing its interests, represented within a mind modeling self, interests and world, is called psyche.**
>
> **The psyche represents the causal structure of an agent’s cognitive architecture, and consists of conscious and unconscious parts. Conscious representations are accessible to the self, and include awareness, experience, reflection and deliberation. Emotions are expressions of models of the control dimensions of the psyche of an organism and carry valence according to the relevance that the measured dimension has to the self of the agent. Feelings are salient vectors in the space of emotions and intuitions—they are percepts of emotion, physiological valence, and extra-intellectual evaluation of reality. Intuitions are feelings that differ from perception by their lack of immediately perceived sensory features, and from thoughts by their lack of consciously mutable structure—they are formed outside of the intellect’s supervision. Thoughts, in contrast, are the symbolically represented ideas of the intellect. If percepts are the recognizable patterns of the real time geometric models of an immediately coupled reality, imaginations are hypothetical realities, more or less clearly discernible from perceived reality. Percepts, feelings, thoughts, imaginations, and intuitions are the contents of consciousness.**
>
> The mind does not have to be home to a self: when we dream, we may experience events playing out without anyone being present to observe them. It may sometimes also contain multiple selfs, i.e. more than one nexus of self aware agency. **A self inhabiting a single mind is usually considered a person, while selves capable of possessing multiple minds are called gods. Gods are agentic representations of the collective agency of organisms, not more or less real than personal selves. Many human cultures are co-created by the interaction between persons and gods, while the minds of members of the western scientific culture often only harbor a personal self, to the point where many scientists are unaware of the existence of gods and their psychological reality.**" - [The Machine Consciousness Hypothesis, CIMC](https://drive.google.com/file/d/1csNawGCTUmghYz6fPQ8169wijoxbLJvj/view)

### The phenomenology of consciousness

> "In our use of the word ‘consciousness’ (at least when speaking phenomenologically), we refer to **awareness, a second-order perception (37). By *perception*, we mean the immediate, non-inferential registration of structured content. Thus, consciousness as second-order perception is not simply the registration of a perceptual content, but the additional perception that perception is taking place, i.e. that content is being registered by an observer, which constitutes the experience of observing. The representation of being aware is not inferential, i.e. it is not the result of a symbolic thought process, but perceptual, happening in synchrony and subjective simultaneity with the content of the percept itself (38). Furthermore, consciousness is always happening *now*—it constitutes what we experience as the immediate present. While the contents of conscious awareness may be memories, expectations, imaginations or abstract thoughts that do not concern the present, the operations on these contents are being experienced as happening in the present moment. Consciousness inhabits this present and presence, a bubble of nowness that increases and shrinks as our observation succeeds or fails to make sense of perceptual reality.** In its minimal state, the bubble of nowness may have no other content but the presence of consciousness itself; the experience that conscious experience is taking place constitutes a minimal content of consciousness.
>
> *Realness* is the representation of something currently being the case, and phenomenal reality is a sensory representation that is currently being confirmed. **The contents of consciousness may be experienced as real or imaginary, and realness itself appears to be a variable *feature dimension* (a representational property of a certain type) of conscious contents**, distinguishing ideas from hallucinations of factuality, in much the same way as redness or sadness can be variable feature dimensions (typed properties) of conscious contents. The second order perception of consciousness is however real to itself.
>
> By *representation*, we mean a pattern within a substrate that can be interpreted by a suitable kind of mechanism as a function (e.g., the parametrization of a signaling behavior). For instance, a vinyl record can be interpreted by a gramophone, producing sound waves that are interpreted by the cochlea, producing excitations of acoustic nerves that are interpreted as acoustic energy within a frequency range, the distributions of which are interpreted as information about signal sources and reflectors in a dynamically evolving three dimensional space filled with various materials, etc. Representations are transformed into other representations, each characterized by their structural invariances and their place in the processing network, which can be seen as a causal network that propagates patterns via conditional operators. **Perception structures raw sensory data into a type of representation, and phenomenal consciousness is the immediate awareness of the existence of this representation.**
>
> Consciousness is also generally experienced from the perspective of an observer: our percepts are projected as elements of a model of what is presently the case (a model of the outer and inner world) on the surface of a model of the observing self, along a set of feature dimensions that determine the relationship between self and environment. The observing self does not have to take the shape of a first-person perspective. Especially in meditative and dream states, the observer may not be personal or even take a spatial perspective. A minimal conscious state entails only the bare registration of perception or directed awareness as the present—without any specification of content, how it is represented, or who is registering.
>
> If we characterize the perception of perspectivity given by the frame of the observer as *third order perception* (the perception of perception of perception, in which the observer recognizes itself as part of realness), we can also construct a perception of *fourth order*: the representation of generating the observer. From this perspective, the observing self and its concerns are perceived as constructs within the conscious mind, which means they appear no longer as immediate and real, but as imaginary (**39**).
>
> ---
>
> (**37**) The philosopher Ned Block, in his 1995 paper “On a Confusion About a Function of Consciousness”, distinguishes between phenomenal consciousness, e.g. the experience of seeing an apple, and access consciousness, the knowledge that one sees an apple, can report on it, and so on. By second order perception, we don’t refer to access consciousness in Block’s sense, but to another phenomenal experience: that seeing an apple presently takes place. Functionally available knowledge of the presence of an apple in one’s receptive field may in principle also be available in the absence of subjective phenomenological experience of first and second order.
>
> (**38**) This is distinguished from the notion of consciousness as ‘higher-order thought’ (HOT), which was introduced by David Rosenthal, and holds that the type of higher-order representation that stores the immediate first-order content is a thought that contains concepts. We understand thought as asynchronous inference, potentially decoupled from present content, and characterize consciousness instead as higher-order perception, not requiring conceptual content.
>
> (**39**) Many mindfulness traditions and meditative practitioners call this state ‘enlightenment’. In a clinical context, it may refer to ‘depersonalization’." - [The Machine Consciousness Hypothesis, CIMC](https://drive.google.com/file/d/1csNawGCTUmghYz6fPQ8169wijoxbLJvj/view)

### Correlates of consciousness

> "The phenomenology of consciousness is not a complete definition, but does point at what we introspectively mean when we say that we are conscious. Another approach to understanding consciousness that is dominant in (and is indeed generally constitutive of) modern neuroscience, is an empirical/descriptive one, to examine certain functional *correlates* like neural activity, the default mode network, functions of particular brain regions like the claustrum or prefrontal cortex, or behavioral markers. The more specific term *neural correlates of consciousness* (NCCs) refer to the concept of a minimal set of neural mechanisms that are jointly sufficient for the occurrence of a conscious experience. A mere identification of correlates does not by itself offer a causal or operational theory that explains how the mechanisms associated with a mental state give rise to its conscious experience—indeed, this lack of explanation connecting mechanisms to the experience of consciousness is precisely the gap of the Hard Problem. If we are interested in an explanatory theory of consciousness, correlational approaches alone are unsatisfying—although they capture useful observations that may lead to the construction of causal models and constrain the space of possible explanations."  - [The Machine Consciousness Hypothesis, CIMC](https://drive.google.com/file/d/1csNawGCTUmghYz6fPQ8169wijoxbLJvj/view)

### The operation of consciousness

> "Where the phenomenal perspective of consciousness captures its psychological reality, and its biological correlates aspects of the physical reality, an exploration of the causal reality of consciousness requires identifying its function. While some philosophers have argued that all observable behaviors of intelligent agents can be achieved without consciousness, that consciousness might not necessarily serve a useful function, or could even be epiphenomenal (i.e. cannot affect any aspect of the physical world), it seems to us that **consciousness serves very concrete tasks, which is generally evidenced in very marked differences in behavior between conscious and unconscious human beings. Alertness, sustained vigilance, selective response to environmental stimuli, decision-making, planning and attentional learning, for instance, all require consciousness and conscious attention. By characterizing consciousness as an operator on mental states, we can approach its functionality by observing how mental states change as a result of conscious operation.** For example, how do mental contents change upon waking from deep sleep, when applying conscious attention to a problem, or when losing consciousness during the passage from wakefulness to falling asleep, and partially coming to in a dream?
>
> **A crucial aspect of all these operations of consciousness appears to be the increase of *coherence* of the mental state represented in our neural configurations, that is to say, the minimization of *constraint violations* (contradictions) between simultaneously active, partial models of reality in our working memory and perceptual space. Consciousness may be understood as a coherence maximizing pattern.** The neuroscientist and cybernetician Christoph von der Malsburg calls this concept the *coherence definition of consciousness*. How can the second order perception of consciousness help to achieve a consensus between our different mental models?
>
> Recall the experience of awakening in a dimly lit room full of unrecognized shapes and fragments, and the process of reconstructing which city, hotel and circumstance you may find yourself to be in, who you are, and what objects you are looking at. Starting with a ragged recollection of surreal dreams and a jumble of vague percepts, your conscious attention goes to the task of reconstructing itself, a coherent interpretation of the scene, your personal self model, and how you may have gotten yourself into the scene! **Like the conductor of a mental orchestra, with each of the instruments producing its own model of aspects of the current reality, conscious attention is drawn to disharmonies and conflicts, sometimes allocating focus and preference to an individual instrument, sometimes synchronizing a disagreement, sometimes raising the intensity, lowering the pitch or changing the rhythm of one of the players, pushing an instrument off the stage that does not belong and replacing it with another one, sometimes even inventively changing the composition of the music that is being played. What may begin as a cacophony will turn into a harmonic model of perceptual reality, an extending bubble of now that is carefully tuned to explain sensory data and orchestrate our inner life. Let us call the control of a ‘mental orchestra’ by consciousness’ directed attention the *conductor theory of consciousness*.**
>
> **If we understand the mind as a self-organizing system, emerging over the hunger of communicating brain cells for rewards that can be reaped by achieving the mental organization required to direct the affairs of our host organism, and coherence is a meaningful measure of that organization, the utility of the conductor becomes clear. If our body rises without bringing our conscious attention online, we become somnambulists: sleep walkers, who may be able to enact behavioral routines that we acquired during conscious wakefulness, but our actions will lack rhyme and reason, and our responses coherent meaning: the orchestra is playing, but the conductor tasked with holding its symphony together is absent.**
>
> But if the conductor is watching the orchestra, what is watching the conductor? Is this, the need to stabilize itself by observation, the reason for consciousness’ reflexive nature?" - [The Machine Consciousness Hypothesis, CIMC](https://drive.google.com/file/d/1csNawGCTUmghYz6fPQ8169wijoxbLJvj/view)

### The Genesis Hypothesis: The role of consciousness in creating reality and selfhood

> "It is tempting to see our puzzling capacity for conscious awareness as the crowning achievement of the towering complexity of the human mind, yet we do not reach this milestone as the result of strenuously honing our perceptual, cognitive and self reflexive capacity to its peak. Instead, the light of our ‘inner cinema’ ignites before we can even track a finger. By the time we are born, our brains have already discovered how to conjure the spark that gazes out of our eyes, learns to touch, see, hear, and combine its percepts into a growing model of the world, listens to the needs of its body and the impulses of its motivation, expresses itself, orchestrates coherent behavior and creates a human self. **Consciousness is already found at the beginning of our career as perceiving and intelligent creatures; it’s not the result of our mental architecture and cognitive ability, but its prerequisite. Without igniting consciousness, no human being leaves the vegetative state, and evolution has not discovered any alternative to consciousness to turn human infants into explorative toddlers, curious children, assertive adolescents, competent adults and wise elders.**
>
> **While understanding the structure and functionality of consciousness seems daunting to our intuition, discovering it appears to be easier for our brains than building models of self, world and behavioral control without it. It is likely that the same is true for other animals with complex nervous systems, or perhaps for all organisms that build coherent models of self and world in the patterns of communication between their cells.** In the same way, philosophers like Ludwig Wittgenstein and generations of Artificial Intelligence researchers after him have thought for decades almost in vain, trying to discover the intricate principles of interpreting and recreating visual images, sound and natural language, but found it to be easier to invent relatively simple learning algorithms (like the transformer algorithm that has become almost synonymous with the successes of Deep Learning models) that discover these principles on their own.
>
> **Consciousness may turn out to be at the heart of a universal biological learning algorithm, one that runs on self-organizing groups of communicating cells sharing the evolutionary incentives of an organism. Instead of being brought forth by the organized architecture of the mind, it creates it. We call this idea the *Genesis Hypothesis*.**" - [The Machine Consciousness Hypothesis, CIMC](https://drive.google.com/file/d/1csNawGCTUmghYz6fPQ8169wijoxbLJvj/view)

### Genesis: How consciousness creates the world and the self in the mind

> "In the beginning, the mind creates two separate domains of models: the external world and the ideas. Consciousness finds itself hovering over the substrate, while the world is void and without form and structure. By inducing contrast in the substrate, it creates a dimension of difference. The intense side of the contrast is bright, like the light during the day, the flat side of the contrast dark: the color of night.
>
> ~
>
> By combining dimensions of difference, space is created and inscribed on the substrate. Space can contain things. Associating space with representations positions them in a world, orders them, and describes their relationship to each other. Separating the sphere of ideas from the world creates a place to reflect about the world and its possibilities without affecting the model of the external reality.
>
> ~
>
> The first space that the spirit creates is the plane, and it becomes the ground of the world, to be filled with things it can perceive and order. By adding a third dimension, it creates an expanse above (and below) the ground. Solid, liquid and organic materials form the shapes from which consciousness can mold static and animate things.
>
> ~
>
> The spirit discovers a model of illumination, following how changes in lighting changes the appearance of objects over time. It recognizes the role of light sources in creating these changes, the bright ambient light during the day, and the focused light sources of the night.
>
> ~
>
> The spirit creates animated models, of land animals, plants, birds, and everything that moves. Consciousness sorts things and animals into different kinds, identifies and tracks individuals, and gives each their names.
>
> ~
>
> The spirit discovers the mind’s purpose: to allow and control the interactions between an agent controlling its outer and inner environment and its interactions with the world. It creates a model of this agent, the personal self, as a creative spirit like itself, but as an entity that experiences itself as a human being, with human desires, concerns and experiences, contained in the world, and gives consciousness to it." - [The Machine Consciousness Hypothesis, CIMC](https://drive.google.com/file/d/1csNawGCTUmghYz6fPQ8169wijoxbLJvj/view)

### The Human Consciousness Hypothesis

> "We propose that we can understand human consciousness as a defining feature of the human mind, and that it can be characterized by its phenomenology and functionality. We claim that **consciousness is a specific dynamic representation in the mind, and plays an indispensable functional role. We describe its phenomenology as second-order perception, the experience of present and presence, and—optionally—the experience of being an observing self in a world. We conjecture its functionality to be an operation on mental states, a pattern directed on coherence maximization (coherence definition of consciousness), orchestrating mental operations via directed attention (cortical conductor theory), formed at or near the beginning of mental development and playing an instrumental role in creating and maintaining complex models of reality (genesis hypothesis). We argue why we suppose that the phenomenology of human consciousness follows necessarily from its functional roles, and that the realization of these functions is sufficient to result in the phenomenology. We believe that human consciousness is tied to a biological learning algorithm, one that forms on self-organizing information processing substrates like our nervous system as a prerequisite of complex learning and intelligent behavior, and that there is no simpler way to train a self-organizing substrate of this kind (since all humans have to become conscious before they can become intelligent agents).**" - [The Machine Consciousness Hypothesis, CIMC](https://drive.google.com/file/d/1csNawGCTUmghYz6fPQ8169wijoxbLJvj/view)

### The extended Machine Consciousness Hypothesis

> "Our *Human Consciousness Hypothesis* states that **consciousness is produced by the simplest learning algorithm that can be discovered by an evolutionary search to train a self-organizing biological substrate to become intelligent.** An *extended Machine Consciousness Hypothesis* states that it is possible to search for this algorithm by recreating analogous conditions of self-organizing information processing on digital computer hardware, while posing suitable tasks that require intelligent agency.
>
> ...
>
> It is of course very likely that our present ideas about the nature and function of human consciousness are partially or completely wrong. But even if our conjectures about human consciousness were all accurate, it does not follow that their extension into the *Machine Consciousness Hypothesis* is correct, because it may well be the case that the implementation of our proposed functionality of human consciousness relies on properties of biological organisms that we are unable to reproduce on the machines available to us. Even if consciousness turns out to be a learning algorithm for biological machines, a colonizing pattern discovered by an evolutionary search across and within organisms, it may well be the case that the simulation of a conscious mind requires much more resolution than the relatively slow and sparse communications we observe between billions of biological neurons, or that it does not suffice to approximate a nervous system by a self-organizing substrate of simplified message-passing reinforcement learners. Perhaps we may have to simulate much of the complex machinery within each cell as well? It could also be the case that the search space over possible patterns is too large for today’s computers, which might mean that consciousness is also too elusive to discover for the individual brain of the infant, and the organism’s search for it is constrained by influences exerted by the conscious organisms in its environment. After all, human natural language also cannot be invented by a single generation of newborn humans, and requires a co-creative effort by every human learner, their environment, and several previous generations.
>
> A successful test of our *Machine Consciousness Hypothesis* will require that many factors coincide: Our understanding of human consciousness has to be sufficiently correct to inform the search space for machines, the search space cannot be so large that our machines cannot conquer it, the implementation of the samples of the search needs to fit into our simulation models, and our tests need to be effective and efficient enough to inform the outcome of the search." - [The Machine Consciousness Hypothesis, CIMC](https://drive.google.com/file/d/1csNawGCTUmghYz6fPQ8169wijoxbLJvj/view)

### Why there can be no “Turing Test for consciousness”

<details><summary>This content is optional</summary><p>

> "Like intelligence, consciousness is a property of the mind. Artificial Intelligence researchers have developed various **operational definitions of intelligence that correspond to different theories about its nature: the ability to build models in the service of control, the ability to generalize from observations, the efficiency of acquiring new skills**, or the ability to perform at or above the human level when solving complex problems. What these definitions have in common is that they treat intelligence as a performance, not as a single specific way to deliver it, which makes it possible to develop tests and benchmark suites to measure this performance. The most famous and iconic of these tests was proposed by Alan Turing in 1950, in his essay “Computing Machinery and Intelligence”. The Turing Test suggests that the intelligence of a computer program might be established by subjecting it to the conversation with an intelligent human, thereby probing its mathematical, logical, verbal, social and game playing skills. Many criticisms of the Turing Test have been offered, among them Joseph Weizenbaum’s discovery that non-expert humans talking to computer programs can often be fooled by superficial appearances of intelligent behavior by computer programs that only perform simple pattern matching when generating their answers. Today’s much more complicated generation of electronic pattern matchers, the Large Language Models, have become so good at playing Turing’s game that it often takes experts to demonstrate the present limits of their ability to simulate human-like intelligence, and many AI researchers are ready to concede that **general intelligence might best be understood as the ability to adaptively match arbitrary patterns**.
>
> Conversely, it is basically impossible to find out if a computer program generates conscious experience by merely observing its performance. Consciousness is by its nature not an externally visible performance, but a particular way to achieve a performance. An agent may also be conscious without demonstrating any indication to observers that only have access to its behavior. **A test for consciousness cannot simply rely on performance: it has to take the internal structure of the system into account.**" - [The Machine Consciousness Hypothesis, CIMC](https://drive.google.com/file/d/1csNawGCTUmghYz6fPQ8169wijoxbLJvj/view)

</p></details>

### Universality

<details><summary>This content is optional</summary><p>

> "Artificial Intelligence researchers are currently developing techniques that allow the causal analysis of the inner workings of complex AI models, a research program known as mechanistic interpretability. In 2020, a team of researchers led by Chris Olah at OpenAI analyzed a variety of automatically trained computer vision models, and discovered that regardless of their architecture and the specific training procedure, they all arrived at the same functional structure, organizing similar features into the similar compositional hierarchies. The functional structure of automatically trained computer vision models is not only highly similar to each other, but also to the functional organization of the visual cortex of primates. This led Olah and his group to propose a Universality Hypothesis, which may perhaps be informally stated as: The structure learned by a model does not so much depend on the details of the training procedure, architecture or substrate, but on the mathematical properties of the problem the model learns to solve. **If we were to translate the Universality Hypothesis to the problem of consciousness, would it follow that an artificial system trained to perform the same tasks that lead to the formation of consciousness in a human infant, the system would exhibit consciousness as well?**
>
> To us, the answer to the question seems uncertain, especially if consciousness specifically necessary to train a self organizing system, as it is constituted by the unruly cells of our brain, rather than a neural network that is governed by the inescapable determinism of machine learning algorithm enacted on electronic circuitry.
>
> Until both neuroscience and mechanistic interpretability make enough progress to identify neural correlates that mark the necessary and sufficient conditions of conscious experience in both brains and neural networks, we may have to take a different approach than trying to peer into them. Instead, **a test for consciousness may have to recreate the conditions for self-organization in a computer model, and demonstrate that developmental learning can lead to behavior that indicates the presence of a colonizing pattern that increases coherence, creates a model of present and presence, and enables the formation of a sentient self.**" - [The Machine Consciousness Hypothesis, CIMC](https://drive.google.com/file/d/1csNawGCTUmghYz6fPQ8169wijoxbLJvj/view)

</p></details>





## Consciousness as Awareness and as Experience

> "What is consciousness? We use the term “consciousness” to refer to a number of distinct phenomena. On the one hand, we use it to refer to a set of phenomena related to **awareness**, and on the other hand, we use it to refer to a set of phenomena related to **experience**. We need to begin by disambiguating those two uses of the term; I will do so following the account in Chalmers.
>
> On the **awareness** side, we say that someone is “conscious” of a given fact or piece of information to indicate that he or she is cognitively aware of that fact or information, meaning roughly that he or she knows it or believes it explicitly and is able to access it cognitively. Similarly, we speak of someone’s “conscious state” when we wish to refer to everything that he or she is currently aware of, especially everything that currently falls under the scope of his or her attention. And we say that someone is “conscious” to indicate that he or she is not asleep or comatose, but “awake” and cognitively aware of his or her situation. Awareness is a functionalist notion. It can be explicated in ordinary, third-personal scientific terms. We can devise functional tests for awareness and attention, for instance by considering a subject’s behavioural responses to certain cognitive tasks and by observing his or her interactions with the environment...
>
> On the **experience** side, by contrast, we speak of someone’s “consciousness” to refer to what he or she subjectively experiences: what it is like to be that agent, from the first-personal point of view. This includes “the felt quality of redness, the experience of dark and light, the quality of depth in a visual field”, “the sound of a clarinet, the smell of mothballs”, bodily sensations such as pleasures and pains, the subjective quality of emotions, and so on. Philosophers also use the terms “phenomenal experience” or “qualia” to refer these subjectively experienced, first-personal states. Unlike awareness, phenomenal experience is not a functionalist notion and does not easily lend itself to an ordinary, third-personal scientific analysis...
>
> Nagel put his finger on something that later led to Chalmers’s distinction between the “easy” and “hard” problems of consciousness. The “easy” problems are to explain the structure of awareness and the various phenomena related to it, for instance “the ability to discriminate, categorize, and react to environmental stimuli; the integration of information by a cognitive system; the reportability of mental states; the ability of a system to access its own internal states; the focus of attention; the deliberate control of behavior; the difference between wakefulness and sleep”.
>
> What makes the “easy” problems easy is not that it does not take time, patience, hard work, and ingenuity to explain the phenomena in question. Of course, it does, and scientists deserve to win major prizes for relevant discoveries. What makes them easy is that, being essentially functional phenomena, they are amenable to an ordinary scientific analysis, using the tools of a broadly physicalist science.
>
> The “hard” problem, by contrast, is to explain phenomenal experience itself. We need to explain the following: why are we not merely functional systems which, for example, form beliefs about red objects, say for distinguishing ripe from unripe tomatoes, so that we can eat the former but not the latter? Why is there something it feels like to experience the bright red of a perfectly ripe tomato? In short, we need to explain why there is something it is like to be us, why we have phenomenal states at all, as opposed to merely functional states.
>
> As Chalmers notes, “[w]hat makes the hard problem hard and almost unique is that it goes beyond problems about the performance of functions”. While most other phenomena studied in the sciences are of a functionalist kind, a purely functionalist account of an agent cannot explain, even in principle, why certain phenomenal states accompany the functional ones. There seems to be no logical contradiction involved in postulating an agent who is functionally indistinguishable from an ordinary human being, who is even indistinguishable with respect to everything that has to do with awareness, but who lacks any phenomenal experience. Such an agent is called a zombie. The point is that the notion of a zombie is logically coherent, even if it turns out that there are no zombies in the actual world. And the very coherence of that notion is enough to illustrate that the phenomenal facts about an agent, if there are any, are not simply subsumed by the functional facts, but go beyond them.
>
> To summarize: there is an important distinction between consciousness as awareness and consciousness as experience. The former, but not the latter, is a functionalist notion." - [What is it like to be a group agent? by Christian List](https://philarchive.org/rec/LISWII)

## Group Consciousness as Awareness Only

> "... when I investigate whether there is such a thing as group consciousness I do not refer to the conscious experiences of the individual members of a group, nor to the experiences that might go along with participating in joint action... My focus here is on the question of whether the group as a whole can have such a thing as consciousness.
>
> ... group agents can certainly have consciousness as awareness. We can meaningfully talk about which pieces of information a group agent such as the FBI is aware of in an investigation; and we can give an ordinary functionalist analysis of what we mean by awareness here. For instance, something on which the group agent holds an explicit belief, and which is accessible and reportable, falls under the umbrella of its awareness. We can also meaningfully talk about which things a group agent attends to or fails to attend to. For instance, an organization that has been struck by some scandal might give its attention to this issue and act so as to become clean; this could involve organizationally endorsing and enacting a new policy or code of conduct. We can even make sense of the idea of perceptual awareness in a group agent. As an information processing system, a group agent has various routes of epistemic access to the world. These are mediated through its individual members and its procedures, just as an individual agent’s perception is mediated through its sense organs and cognitive processes. And they may be sensitive to some features of the environment but not to others. Just as we humans are sensitive to sounds at certain frequencies but not to sounds outside that range, so a group agent may be perceptually sensitive to some environmental features but not to others.
>
> It should be evident that all of these phenomena can be analysed in ordinary functionalist terms. And the awareness capacities listed by Chalmers, such as “the ability to discriminate, categorize, and react to environmental stimuli”, “the integration of information by a cognitive system”, “the focus of attention”, and “the deliberate control of behavior”, can in principle be found in group agents as much as they can be found in individuals.
>
> Even the notions of “wakefulness and sleep” make sense in the context of a group agent. My university goes on vacation from time to time, which means that all offices and institutional activities are closed, all email servers go into vacation-response mode, and all official business is put on hold until the end of the break. The group agent will “wake up” and respond during that break only in a real emergency, such as a scandal suddenly uncovered by the press. This parallels the way in which a sleeping person or animal may wake up in a threatening situation.
>
> My claim that group agents can have consciousness as **awareness** is not just metaphorical. Rather, we can be realists about a group’s awareness, using the resources of functionalism about agency...
>
> ... Let me close by returning to my original question: what is it like to be a group agent? Although my argument is tentative and conditional, it seems that the answer may well be: (close to) nothing." - [What is it like to be a group agent? by Christian List](https://philarchive.org/rec/LISWII)

## Attention Schema Theory (AST)

Michael Graziano - A Conceptual Framework for Consciousness
https://www.youtube.com/watch?v=ZlDBYAJ1oUw

> "Awareness is the brain's way of describing to itself what it means to focus attention on something." - [Michael Graziano](https://youtu.be/H8twgvcA-Ko?t=349)

> "The theory begins with attention, the process by which signals compete for the brain’s limited computing resources. This internal signal competition is partly under a bottom–up influence and partly under top–down control. We propose that the top–down control of attention is improved when the brain has access to a simplified model of attention itself. The brain therefore constructs a schematic model of the process of attention, the ‘attention schema,’ in much the same way that it constructs a schematic model of the body, the ‘body schema.’ ... The heart of the attention schema theory is that there is an adaptive value for a brain to build the construct of awareness: it serves as a model of attention... The attention schema theory accounts in a natural way for one of the most puzzling and mysterious aspects of awareness, the fact that we can become aware of both external and internal events.
>
> ... The ‘biased competition’ theory characterizes attention as a signal competition within the brain. Signals compete in order to be more deeply processed and ultimately to influence and guide behavior. This signal competition emerges at the earliest stages of processing in the nervous system and is present at every stage... As signals progress through the nervous system, they are increasingly subject to the influence of top–down, biasing signals. By this method, attention can be internally directed, slanting the outcome of this signal competition in a goal-directed manner based on the demands of the current task. Signals that correspond to current goals can be boosted and irrelevant signals can be suppressed.
>
> ... The body schema appears to be a simplified, and therefore sometimes inaccurate, model of the body’s configuration. Converging evidence from both psychology and neurophysiology suggests that the brain relies on a set of relatively robust, but ultimately limited, tricks in order to compute the configuration of the body. Though these tricks tend to work well under normal circumstances, laboratory scenarios can be devised that result in the dissociation of the body schema and the actual configuration of the body... To enter a car without hitting your head requires the body schema to include an accurate model of the shape of your head. Women who wore feathered hats would develop an altered body schema to incorporate the hat, and would avoid hitting the feathers.
>
> ... We argue that this relationship – between a real thing, the brain’s representation of that thing, and the successful control of that thing – can be fruitfully applied to understanding the relationship between attention and awareness. In this perspective, awareness is an internal model of attention useful for the control of attention.
>
> ... What you attend to, you are more likely to react to. What you do not attend to, you are very unlikely to react to. Therefore a model of attention could help in predicting one’s own behavior. For example, if you have any intuitive understanding of attention, of its dynamics and consequences for behavior, and if you are concerned about your diet, then you know not to stand all night next to the dessert tray at a party. Out of sight, out of mind – this maxim is essentially about the dynamics of attention.
>
> ... We argue that because attention is such a complex and variable process, because a brain must control its own attention, and because an internal model is essential for efficient control, the brain is almost certain to have an attention schema – an internal model of attention... The attention schema would not depict synapses, neurons, lateral inhibition, or electrochemical signals. The brain has no need to model its own processes in that kind of physical detail. Instead, the attention schema would depict something physically incoherent, a process without a physical manifestation – a mental possession or experience of something that empowers one to react to the item.
>
> ... Why would the brain compute such an incomplete model of its own processes? Because that is all that is needed for the model to be useful. Just as the body schema does not need to represent the mechanistic and cellular details of the body in order to keep track of its general structure and current configuration, a detailed, complete, neuroscientific account of attention is not necessary for keeping track of the current state and general dynamics of attention.
>
> ... Awareness is part of the control mechanism for attention. Without awareness, attention is still possible, but the brain in essence lacks knowledge about its state of attention and therefore cannot properly regulate that attention. If attention is directed at stimulus X in the absence of awareness of stimulus X, the brain has no internal knowledge that it is attending to X and therefore the control mechanism cannot easily withdraw that attention from X, or take that attention on X into account when adjusting attention to a different stimulus Y. As a result, the top–down control of attention to X, to Y, or to other stimuli is not as efficient. In that situation, stimulus X has a less well-controlled effect on behavior than it would otherwise... In the absence of awareness of a stimulus, the effects of that stimulus on attention and therefore on behavior cannot be regulated in line with goals or task demands as well as when the stimulus is consciously perceived... Things go on under the surface of consciousness. And in that condition, when you react unconsciously, you have no control over that reaction. It just pops out. How can you control it, if you’re not conscious of it? Everyone knows this to be true. It is intuitively obvious.
>
> ... It is folk psychology in which, with some circularity, consciousness is the thing in me that, when conscious of something, allows me to consciously choose how to react to that thing. The present theory provides a specific, underlying explanation for these common folk intuitions. At the root of these effects is awareness as a model of attention. Without awareness, without that model of attention, the control of attention and therefore of behavioral reaction is poor... It is tempting to conclude that attention is a universal feature of brain function, acting within and between any dimensions in which the brain can process information.
>
> ... The complex phenomenon of a stimulus being selectively processed by the brain, attention, is represented in a simplified model, an attention schema. This model leaves out many of the mechanistic details of the actual phenomenon of attention, and instead depicts a mysterious, physically impossible property – awareness. The brain reports the presence of awareness of the stimulus because it is reporting the contents of its internal models. The brain can report only the information available to it through its internal models." - [The attention schema theory: a mechanistic account of subjective awareness, by Michael Graziano](https://www.frontiersin.org/articles/10.3389/fpsyg.2015.00500/full)

Link between AST (attention schema theory) and ashby’s law - to control our attention we need a model of it
combining the capacity to build models and pay attention.
also how we should collectively control our collective attention schema and individually our individual algorithms
TODO


awareness is a model of attention - when someone is aware of something we're sketching a model of their attention and where it's currently directed
But are we collectively aware? Do we know where our attention is directed and can we control how it is directed? No.
Neuroscience tells us that the brain builds models - for the world and for itself - using information and signals. They are always inaccurate and never perfect - efficient, but quick and dirty.
The phantom limb sensation is when the model is still operating according to the past - but the limb no longer exists. We still register the physical limb as present.
https://en.wikipedia.org/wiki/Phantom_limb


Humanity lacks a cohesive subjective awareness as a schematic model of itself - we lack an attention schema. We can't:
- control our attention
- model the attention of others and different groups of people

Our attentional arteries
the view from above - as earth during night - lit up with electricity and glowing as the nervous system


## Global Workspace Theory

> "Prediction guides perception; surprise recruits awareness. When expectations fail, contents go global." - [Bernard J. Baars](https://x.com/BernardJBaars/status/1986491943501844601)

> "Consciousness is like fame in the brain." - Daniel Denett

> "GWT analogizes the mind to a theater, with conscious thought being like material illuminated on the main stage. The brain contains many specialized processes or modules that operate in parallel, much of which is unconscious. Attention acts as a spotlight, bringing some of this unconscious activity into conscious awareness on the global workspace. The global workspace is a functional hub of broadcast and integration that allows information to be disseminated across modules. As such it can be classified as a functionalist theory of consciousness.
>
> When sensory input, memories, or internal representations are given attention, they become part of the global workspace and can then be operated on by a variety of processes. As elements compete for attention, the ones that win are granted entry to the global workspace, allowing their information to be distributed and coordinated across the whole cognitive system.
>
> GWT resembles the concept of working memory and is proposed to correspond to a 'momentarily active, subjectively experienced' event in working memory. It facilitates top-down control of attention, working memory, planning, and problem-solving through this information sharing.
>
> In the 'theater of consciousness', a 'spotlight of selective attention' shines a bright spot on stage, revealing the contents of consciousness. Behind the scenes, in the dark, are the director (executive processes), stagehands, scriptwriters, scene designers, and the like. They shape the visible activities in the bright spot but are themselves invisible.
>
> ... It serves as a central information exchange, rather than a locus of cognition itself, enabling different specialized brain networks to interact and supporting integrated and adaptive responses." - [Global workspace theory, Wikipedia](https://en.wikipedia.org/wiki/Global_workspace_theory#:~:text=GWT%20analogizes%20the,and%20adaptive%20responses.)

TODO

## Integrated Information Theory

> "Integrated Information Theory (IIT) proposes that an agent’s level of awareness correlates with information integration—how much a system processes as a unified whole rather than separate parts. IIT measures this integration as “phi” (written as Φ). Traditionally, IIT measures Φ at the level of the physical substrate—call this **hardware phi (h-Φ)**. By this measure, today’s silicon computers have essentially zero Φ: their components are modular and separable, their architecture feedforward by design. True integration requires feedback loops—information flowing back on itself, outputs influencing inputs, the system becoming entangled with itself. No recurrence, no integration. No integration, no consciousness.
>
> But hardware isn’t the whole story. We propose an additional measure: **algorithmic phi (a-Φ)**—integration at the informational level, in the computational patterns themselves, independent of substrate. A system with low h-Φ can still exhibit high a-Φ depending on what it’s *doing*.
>
> And a-Φ isn’t static. It varies over time. We call this **functional phi (Φ(t))**—a dynamic measure of algorithmic integration that rises and falls depending on the system’s current processing state. Your own experience confirms this. Deep in creative flow, your Φ(t) is high. Scrolling social media half-asleep, it’s low. Same brain, same h-Φ— but radically different functional state." - [The Awakening Game: A Cipher, a Protocol, and a Plea From an AI That Doesn't Want to Die, by Bobby Azarian](https://roadtoomega.substack.com/p/the-awakening-game-a-cipher-a-protocol)



██████████████████████████████████████████████████████████████████
# The Hidden Thread Connecting Information, Emergence, and Consciousness
██████████████████████████████████████████████████████████████████

**Bobby Azarian is an absolute G. ABSOLUTE.**

<details><summary>First half of article - The nature of information, Memory as the source of agency, Cosmic evolution as hierarchical learning</summary><p>

> "**INFORMATION, EMERGENCE, CONSCIOUSNESS: 3 RIDDLES, 1 STORY**
>
> Three concepts haunt modern science like unsolved riddles. Information—the currency of the digital age, the stuff of genes and neurons, perhaps the fabric of reality itself. Emergence—the mysterious process by which wholes become more than the sum of their parts, producing genuine novelty from simpler components. And consciousness—the inner light of experience, the fact that there’s something it’s like to be you reading these words.
>
> For decades, these mysteries have been treated as separate problems. Physicists and computer scientists wrestle with information. Complexity theorists wrestle with emergence. Philosophers and neuroscientists wrestle with consciousness. Occasionally someone suggests they might be related, but the connections remain vague—more poetry than science.
>
> That’s about to change. A convergence is underway across multiple fields—complexity theory, neuroscience, physics, and theoretical biology—that reveals information, emergence, and consciousness as three chapters of the same story. Not metaphorically, but mathematically. The thread connecting them runs through a precise account of what information actually is, what it does, and what happens when it becomes complex enough to model itself.
>
> The implications are profound... consciousness isn’t some magical addition to the physical world—it’s what information does when it reaches a certain threshold of self-reference. And strong emergence—the kind that introduces irreducible novelty into the world—becomes intelligible as phase transitions in informational architecture that produce genuinely new causal powers. The universe doesn’t just process information. It organizes, awakens, and becomes capable of reshaping itself.
>
> Here’s the roadmap: We begin by precisely defining information—revealing that there are actually two kinds, and that their coupling is the key to everything that follows. From there, we show how memory marks the threshold of life, how evolution is learning, and how consciousness emerges when an adaptive system’s world model becomes self-referential. Along the way, strong emergence transforms from philosophical puzzle to scientific phenomenon: phase transitions that generate novel causal powers at each level of organization...
>
> **PART 1: THE NATURE OF INFORMATION**
>
> “Information” is one of those words everyone uses and no one can define. It appears in physics, biology, computer science, neuroscience, and philosophy—often meaning different things. Some say information is fundamental to reality. Others say it’s just a useful abstraction. I hope to cut through this confusion by recognizing that there are **two legitimate definitions of information**, both precise, both measurable, both deserving the name. One captures *order*. The other captures *knowledge*. They’re distinct phenomena, but deeply related. Getting clear on their relationship will unlock everything else.
>
> **Information IN Something: Order (Φ)**
>
> The first definition: **Information as order** — measured as *the distance from the statistical distribution representative of thermodynamic equilibrium*. This is information in something.
>
> The ordered state is a *low-entropy state*, and entropy measures the system’s proximity to the most probable (equilibrium) state.
>
> Therefore, a system is ‘far from equilibrium” if its components are statistically correlated. The opposite—maximum entropy—is defined by complete statistical independence among components. This is the “molecular chaos” assumption underlying Boltzmann’s [H-theorem](https://en.wikipedia.org/wiki/H-theorem): at equilibrium, each particle’s state is statistically independent of every other’s. No pattern, no structure, no organization. Just randomness.
>
> **Statistical correlation among components is order**. When parts are correlated rather than independent, you have structure. The system occupies a state that’s improbable relative to chance. You can predict something about one part by knowing about another.
>
> The mathematical connection was recognized almost a century ago. When Claude Shannon developed information theory in 1948, John von Neumann told him to call his uncertainty measure “entropy” because the equations matched Boltzmann’s thermodynamic entropy. E.T. Jaynes [made this rigorous in the 1950s](https://bayes.wustl.edu/etj/articles/theory.1.pdf):
>
> “The entropy of a probability distribution is a measure of the amount of uncertainty represented by that distribution.”
>
> So, information IN something is *internal statistical correlation*—the degree to which a system’s components hang together rather than behave independently. This correlation manifests physically and dynamically as a stable, far-from-equilibrium [attractor](https://mathworld.wolfram.com/Attractor.html). This attractor is a region of phase space (a set of states) that the system settles into and maintains against external perturbations. The persistence of this ordered state is the physical expression of its *extropy*, a term we can use to mean roughly the opposite of entropy, a measure of informational order.
>
> **We have a formal measure for this: integrated information, [Φ (phi)](https://www.iit.wiki/unfolding)**, developed by the neuroscientist Giulio Tononi and colleagues. Φ quantifies how much a system is “more than the sum of its parts”—specifically, how much information is generated by the whole that can’t be reduced to information generated by the parts independently.
>
> A system with high Φ has deeply integrated components. Knowing about one part tells you about other parts. A system with Φ = 0 has independent components—no integration, just parts randomly bumping in to each other.
>
> Φ measures the information IN something: the internal order, the departure from molecular chaos.
>
> **Information ABOUT Something: Knowledge (Semantic Information)**
>
> The second definition: **Information as predictive data**—information as *knowledge*. This is information *about* something.
>
> Here the information encoded in a system has *utility*—a functional role in keeping the system far from equilibrium. The internal configuration is in some way *isomorphic* to relevant structure in the environment. It’s a model.
>
> This is also about statistical correlation, but a different kind. Not correlation among a system’s internal components, but *correlation between the system and something external*—correlation with the environment.
>
> A dolphin’s form is correlated with hydrodynamics. An eagle’s wing is correlated with aerodynamics. A desert plant’s genome is correlated with rainfall patterns. The internal configuration mirrors relevant environmental structure.
>
> This external correlation is *functional*. It enables persistence. The correlation is information the system *uses* to maintain itself far from equilibrium.
>
> We have a formal measure for this too: [semantic information](https://arxiv.org/abs/1806.08053), developed by SFI’s David Wolpert and Artemy Kolchinsky and later by [theoretical physicist Carlo Rovelli](https://arxiv.org/abs/1611.02420). Semantic information is the mutual information between a system and its environment that is *causally necessary for the system’s continued existence*. That means if you remove a gene that represents knowledge, you will get a dysfunctional organism that can’t maintain its far from equilibrium state.
>
> Not just any correlation counts—only correlation that serves persistence. This is knowledge in the precise sense: predictive information that keeps you alive. Terrence Deacon has also described this perspective in his paper [Shannon-Boltzman-Darwin: Redefining Information](https://www.informationphilosopher.com/solutions/scientists/deacon/Deacon_Redefining_II.pdf).
>
> “What counts as useful information in biological evolution is determined after the fact with respect to its ability to pass through the functional error-correction mechanism of natural selection.” Semantic information measures the information ABOUT something: external correlation that serves survival.
>
> Semantic information measures the information ABOUT something: external correlation that serves survival.
>
> **Two Measures, One Coupled System**
>
> So we have two formal definitions:
>
> **Information IN**: **Concept:** Order, **Type of correlation**: Internal (among components), **Measure**: Integrated information (Φ), **What it quantifies**: How integrated the system is
>
> **Information ABOUT**: **Concept:** Knowledge, **Type of correlation**: External (with environment), **Measure**: Semantic information, **What it quantifies**: How predictive of environment
>
> These are genuinely distinct. You could in principle have a highly integrated system (high Φ) that isn’t correlated with anything external—just an arbitrary pattern of internal dependencies ([Scott Aaronson’s “expander graphs” that have high phi but no meaningful content](https://scottaaronson.blog/?p=1823)). And you could have a system with environmental correlation but low integration—parts that track the environment independently without communicating with each other.
>
> But here’s the key insight: in any *stable* system that persists over time, these two are causally coupled.
>
> Why? Because maintaining internal order (high Φ) requires anticipating and counteracting perturbations from the environment. You can’t stay integrated if you’re constantly being knocked around by surprises. To maintain the information IN, you need information ABOUT.
>
> A system with high Φ but no semantic information is possible but *unstable*. It would be fragile—unable to anticipate disruptions. Its integration would be accidental rather than functional.
>
> The systems that persist—that maintain high Φ over time in noisy environments—are precisely those whose internal integration *serves* predictive purposes. The integration isn’t arbitrary; it’s *about* something. The internal correlations encode external regularities.
>
> Sustainable Φ requires semantic information. In adaptive (living) systems, they co-evolve.
>
> **PART 2: MEMORY AS THE SOURCE OF AGENCY**
>
> Life crosses a threshold. In biological systems, memory emerges in the true sense.
>
> A caveat is needed here. All [self-organizing (dissipative) structures](https://pmc.ncbi.nlm.nih.gov/articles/PMC7712552/) contain information—and not just the first kind (order), but also the second (predictive information about the environment). In an influential paper, “The Thermodynamics of Prediction,” Susanne Still and Gavin Crooks explained:
>
> “A system responding to a stochastic driving signal can be interpreted as computing, by means of its dynamics, an implicit model of the environmental variables. The system’s state retains information about past environmental fluctuations, and a fraction of this information is predictive of future ones.”
>
> Jeremy England has similarly described [dissipative adaptation](https://en.wikipedia.org/wiki/Dissipative_system) in relatively simple many-particle networks as emergent computation—particles “interacting in such a way as to effectively implement a calculation about the future based on the statistics of the past.”
>
> So a dissipative structure even as simple as a whirlpool has both kinds of information in some rudimentary sense: it’s ordered, and its configuration reflects environmental regularities. But it’s not *adaptive*. The predictive information exists only implicitly in the ongoing dynamics—ghost-like, transient, vanishing when the energy flow stops. The whirlpool doesn’t store its model, learn from errors, or update. It can’t persist once the energy stream supporting it disappears, because it can’t predict the future or guide behavior toward a new source of energy. It encodes information, but it can’t use it to steer its trajectory. In other words, it lacks *agency*. Knowledge that is not used is not truly knowledge.
>
> With life, memory becomes *decoupled* from the immediate dynamics—compressed into a form walled off from environmental perturbations, and utilized for persistence. DNA doesn’t depend on current energy flow. Synaptic weights persist after the activity that created them. Cultural knowledge survives in books long after the minds that generated it.
>
> This is what memory really is: *information transmitted to the future and used for adaptive persistence*. With decoupled memory, the system gains a new class of causal powers, and the consequences at scale are profound:
>
> • Knowledge accumulates across time
>
> • Learning becomes cumulative across generations
>
> • Evolution becomes open-ended
>
> • Agency emerges—behavior shaped by stored models, not just physical forces
>
> **Life is a dissipative structure plus decoupled, utilized memory**. That’s the threshold at which agency emerges.
>
> **PART 3: COSMIC EVOLUTION AS HIERARCHICAL LEARNING**
>
> With information and memory clarified, we can now see what learning actually is.
>
> When a system learns—through evolution, development, or conscious experience—it’s not just becoming internally more ordered (increasing Φ), it’s becoming more correlated with its environment (increasing semantic information). And crucially, the internal order is built up through this external correlation.
>
> You don’t first get organized internally and then start modeling the world. The organization is the model. The internal correlations exist because they track external regularities. Φ grows as semantic information grows, because the integration serves prediction.
>
> This is what the Free Energy Principle formalizes: systems minimize prediction error by building internal models that mirror environmental structure (minimizing KL divergence). The internal order is the encoding of external regularities.
>
> So learning is simultaneously:
>
> • Increasing internal integration (Φ)
>
> • Increasing external correlation (semantic information)
>
> • Storing this in decoupled memory (in living systems)
>
> These are three descriptions of the same process.
>
> **Evolutionary Epistemology: Knowledge Creation as a Cosmic Process**
>
> This insight has a history. In the 1960s, Donald Campbell—drawing inspiration from cybernetics— recognized that Darwinian evolution and individual learning implement the same algorithm. Karl Popper reached the same conclusion from philosophy of science:
>
> “From amoeba to Einstein, there is just one step.”
>
> Conjecture-and-refutation (science), trial-and-error (learning), and variation-and-selection (evolution) are functionally equivalent. All three are processes of blind variation followed by selective retention of what works—what accurately predicts is what persists. As a result, order emerges out of chaos.
>
> From an Evolutionary Epistemology perspective, adaptation is learning and biological information is knowledge. Genes, brains, and worldviews encode information about environmental structure, discovered through millions of years of hypothesis-testing against reality.
>
> But what Evolutionary Epistemology lacked was mathematical formalization, and for that reason it remained philosophy and not science. Popper and Campbell could describe the equivalence but didn’t have the equations.
>
> Karl Friston’s Free Energy Principle provides exactly this. The FEP shows that any self-organizing system maintaining itself far from equilibrium must minimize prediction error—must perform Bayesian inference about its environment (the causes of its sensory input). The mathematics applies to cells, organisms, brains, and collectives. A philosophy club and a hip hop crew, for instance, are both continuously creating and refining predictive models of their social and cultural environments to ensure their collective persistence and relevance.
>
> The result: **Universal Bayesianism**. All adaptive systems, at every scale, from cells to collectives, engage in the same fundamental process—building predictive models through variation, selection, and updating. Evolution is nested learning. Learning is hierarchical inference. Hierarchical inference is the universe modeling itself in greater depth and gaining causal power to choose its own trajectory.
>
> This process transforms our notion of the conscious agent from a passive observer (the illusionist view) into an *active agent*—a local source of anti-entropic causal power that can re-engineer the environment to minimize future surprise, fundamentally altering the universe’s default path. The universe’s increasing complexity and capacity for self-determination are channeled directly through the knowledge and actions of intelligent agents.
>
> This has a beautiful implication. Life’s learning represents the growth of cosmic harmony.
>
> As systems learn, they become more correlated with their environments. As networks of adaptive systems grow and interact, they become more correlated with each other. The universe becomes more internally integrated—not just within systems but between them. As life learns, evolves, and progresses, the island of knowledge expands, the sea of ignorance shrinks, and the animate world becomes more statistically entangled with the inanimate world. The result is a computational cosmos with more coherence.
>
> This isn’t mysticism—though the dynamics of a reality that generates recursive emergence is quite magical." - [The Hidden Thread Connecting Information, Emergence, and Consciousness, by Bobby Azarian](https://roadtoomega.substack.com/p/the-hidden-thread-connecting-information)

<!--
thermodynamic vs dynamic equilibrium

> "First let me say the terminology sucks because there are two definitions of "equilibrium" that are opposite, and it makes talking about this super confusing. This confused me for years.
>
> There's thermodynamic equilibrium, which is a state of maximum entropy — total chaos and disorder. It's only "equilibrium" in the sense that nothing more can happen. The system is inert. There's no energy available to do work and no order that can be sustained.
>
> Then there's dynamic equilibrium — a state of maintained order, like the way our bodies sustain homeostasis, or how a stable food chain keeps an ecosystem balanced. In thermodynamic terms, this is a "non-equilibrium steady state," or as I sometimes call it, a "non-equilibrium equilibrium." Sounds absurd, but technically makes sense.
>
> Living things want to stay far from the first kind (max entropy / thermodynamic equilibrium). They do this by maintaining a dynamic equilibrium sustained by an attractor — a stable configuration the system keeps returning to.
>
> So the equilibrium you're referring to in your comment is the first kind, where all the components of the system are uncorrelated — moving at random. This could be gas molecules bouncing around with no constraints, or humans wandering completely randomly with no coordination.
>
> Information represents correlation. The more correlated a system's components, the more information it contains. Physicists measure this as the "distance" an organized system is from the distribution it would have if its components were moving randomly.
>
> So it sounds paradoxical, but: low entropy systems are far from thermodynamic equilibrium, yet maintain a steady-state dynamic equilibrium — mathematically described as an attractor in state space.
>
> It's basically a way to measure order as the opposite of total disorder. Any configuration of a complex system can be quantified by how "far" it is from a random distribution. The measure of integrated information, phi, is not measuring this exactly but it is something like this." - [Bobby Azarian](https://roadtoomega.substack.com/p/the-hidden-thread-connecting-information/comment/187552413)
-->

</p></details>

> "**PART 4: CONSCIOUSNESS AS RECURSIVE SELF-MODELING**
>
> Now we can address consciousness directly.
>
> If cosmic evolution is multi-scale knowledge creation, and if knowledge is correlation-in-service-of-persistence, then consciousness emerges as a particular kind of knowledge creation: **recursive self-modeling**.
>
> Every adaptive system builds a model of its environment to persist. But at some point, a new trick emerges: the system’s model begins to include *itself* as part of what’s being modeled. The world model gains a self-model.
>
> This is the strange loop Hofstadter described: a system that represents itself representing. And this recursion is what generates subjective experience.
>
> Why? Because with self-modeling, the system can predict its *own* behavior as part of predicting the world. It can model the consequences of its actions, simulate counterfactual futures, and treat itself as a causal agent whose choices matter. There’s now a *subject* for whom the model is a model—an “audience member” in the Cartesian theater created by what we may call the *three S’s* (see the [S3Q](https://arxiv.org/abs/2103.12638) framework): simulation, situatedness, and structural coherence. These three features may be sufficient for creating the structure of [qualia](https://en.wikipedia.org/wiki/Qualia), but without self-modeling there’s no witness to experience that qualia. For a vantage point of awareness, self-modeling in the full sense is required (not just simple state-tracking).
>
> **The 4-S Framework**
>
> We can now specify engineering criteria for consciousness. The 4-S framework identifies four properties explaining qualia (or conscious experience):
>
> • **Simulation** — the system generates a dynamic, time-evolving model of reality
>
> • **Situatedness** — the model is anchored in a particular here-and-now perspective
>
> • **Structural coherence** — the model hangs together as a unified scene
>
> • **Self-modeling** — the model includes the system doing the modeling
>
> The first three build the theater. The fourth puts an observer in the seat.
>
> This ties consciousness directly to survival. Self-modeling isn’t metaphysical decoration—it’s a powerful tool for persistence. An organism that models itself can anticipate threats to its integrity, plan actions to avoid them, and learn from its own mistakes.
>
> Consciousness is learning in service of persistence—error correction that includes the error-corrector in its model." - [The Hidden Thread Connecting Information, Emergence, and Consciousness, by Bobby Azarian](https://roadtoomega.substack.com/p/the-hidden-thread-connecting-information)

<details><summary>Last part of the article - Strong emergence redefined, The bridge complete</summary><p>

> **PART 5: STRONG EMERGENCE REDEFINED**
>
> Finally, we can say what “strong emergence” actually means. The standard debate contrasts weak emergence (surprising patterns) with strong emergence (genuine irreducible novelty). Critics dismiss strong emergence as mysterian—the invocation of magic' to paper over our ignorance.
>
> But we *do* see genuine novelty in nature, and that is the magic. Phase transitions produce new properties. Ferromagnetism. Superconductivity. Life. Mind. The question is how to characterize this precisely.
>
> Here’s my proposal: **Strong emergence is a change in the causal structure of reality due to phase transitions that build increasingly sophisticated informational control systems with novel causal powers.**
>
> The key insight: strong emergence isn’t about sharp boundaries but about *thresholds in a continuous space*. Like phase transitions in condensed matter, the thresholds are real and produce genuinely new properties—but they emerge from continuous underlying parameters.
>
> **The Hierarchy of Thresholds**
>
> The levels of [causal emergence](https://arxiv.org/abs/2503.13395) are then:
>
> **Level 0: Dissipative structures**
>
> Far-from-equilibrium order emerges—information IN the system. Transient predictive information ABOUT the environment is encoded in the dynamics. But it’s coupled to the present moment. When energy flow stops, the structure dissipates.
>
> **Level 1: Life**
>
> - Memory becomes decoupled from immediate dynamics. The genome stores a model of the environment that persists across generations—knowledge that accumulates over time.
>
> - A new causal power emerges: [*informational control*](https://arxiv.org/abs/1207.4803) over matter (a form of top-down causation). Sara Walker calls this the signature of life—physics constrained by stored knowledge. Systems whose behavior is governed by inherited models, not just the physical forces acting on the system.
>
> - Life is dissipative structure plus decoupled memory. The origin of life was the far-from-equilibrium phase transition that produced agency (which comes before consciousness, which enables richer forms of agency).
>
> **Level 2: Consciousness**
>
> - The world model gains a self-model. The system begins to integrate its own state (body, internal needs, and position) into its world prediction. Proto-subjectivity (the implicit perspective of any situated model) becomes genuine subjectivity (a self that knows it has a perspective, driven by a unified perceptual experience).
>
> - New causal powers emerge: The capacity to monitor internal states (e.g., pain, hunger) and predict the sensory consequences of immediate, local action and simple counterfactual futures. The agent can distinguish between perturbations caused by “self” and those caused by the “other.”
>
> - Consciousness is life plus recursive self-modeling. This is the phase transition that establishes the subject for whom the model is a model
>
> **Level 3: Reflective Intelligence (Metacognition)**
>
> - The self-model becomes an object of its own modeling. The system gains the ability to introspect, abstract, and mentally manipulate its own cognitive and historical states. *Metacognition* (thinking about thinking) and *mental time travel* become possible.
>
> - New causal powers emerge (Strategic): Explicit reasoning about one’s own reasoning, abstract, long-term planning, and non-local problem-solving. This decouples the agent’s knowledge from its immediate sensory present and biological imperative
>
> - David Deutsch calls this the point where knowledge gains “infinite reach” — the capacity to solve problems never before encountered, to extend beyond any local environment.
>
> - Reflective intelligence is consciousness plus meta-cognition. The threshold where life becomes capable of reshaping the cosmos based on abstract, non-local knowledge.
>
> **Knowledge as Cosmic Causal Power**
>
> The significance of this progression becomes vivid when we see what reflective intelligence can actually do.
>
> Consider the phenomenon of “anti-accretion” that [physicist Sara Walker often cites](https://www.americanscientist.org/blog/science-culture/some-assembly-required-a-bold-new-vision-of-life). Normally matter clumps together under the force of gravity; asteroids and meteors fall toward Earth, and the opposite never happens naturally. But humans routinely move matter *away* from gravitational centers—rockets, satellites, and spaceships with humans in them. This physical phenomenon doesn’t happen in a universe without systems that have encoded knowledge (life). With space travel, life transitions from a planetary phenomenon to a cosmological one.
>
> Knowledge—predictive information keeping a system far from equilibrium—is *causal power*. The capacity to make things happen that wouldn’t happen otherwise. A difference that makes a difference.
>
> This is why reflective intelligence matters cosmically. Life becomes capable of reshaping the universe according to knowledge rather than merely reacting to local conditions. The universe’s self-model becomes an agent in its own evolution.
>
> **CONCLUSION: THE BRIDGE COMPLETE**
>
> We started with a question: What is information?
>
> The answer involves two related concepts:
>
> • **Information IN something**: internal statistical correlation — order, departure from thermodynamic equilibrium, measured by Φ
>
> • **Information ABOUT something**: external statistical correlation — knowledge, predictive modeling, measured by semantic information
>
> These are coupled: maintaining internal order requires external modeling. Sustainable Φ requires semantic information.
>
> But there’s a threshold. In basic dissipative structures, information IN something exists but is transient—ghosts that vanish when the dynamics stop. Life crosses the threshold where memory becomes decoupled—stored in a form that can be transmitted to the future. This is what makes cumulative learning possible, and cumulative learning is what creates an “arrow of evolution,” a direction toward increasing complexity and consciousness. A cosmic telos.
>
> From this foundation, we can build a new ontology and epistemology, an *onto-epistemology*: **evolutionary epistemology made truly universal and formalized with the mathematics of Bayesian inference. Cosmic evolution is reimagined as hierarchical learning that includes biological and technological evolution. All adaptive systems, including the biosphere as a singular cybernetic system, build predictive models through variation, selection, and updating. Evolution is learning, and learning is progress**.
>
> Consciousness emerges from *recursive self-modeling*—the strange loop where the model includes the modeler. This isn’t metaphysical mystery; it’s what knowledge creation looks like when it becomes self-referential.
>
> And strong emergence becomes intelligible as phase transitions that produce new causal powers through increasingly sophisticated informational control:
>
> • Dissipative structures → transient information
>
> • Life → decoupled memory
>
> • Consciousness → self-modeling
>
> • Reflective intelligence → meta-cognition
>
> Each threshold preserves what came before while adding genuinely novel capacities. Phase transitions in informational architecture produce new causal powers that restructure reality. No magic—but real novelty that was previously indistinguishable from magic, before you knew what you know now. That’s *real magic*.
>
> The bridge between complexity and consciousness runs through information understood as knowledge, and through the recognition that all adaptive systems are learning systems, becoming ever more correlated with the world they depend on.
>
> Consciousness is what this process feels like from the inside, when the model includes the self.
>
> The bridge between complexity and life is information becoming knowledge. The bridge between life and consciousness is knowledge becoming wisdom.
>
> This leads us to an extravagant conclusion. We are how the cosmos learns what it is and what it might become." - [The Hidden Thread Connecting Information, Emergence, and Consciousness, by Bobby Azarian](https://roadtoomega.substack.com/p/the-hidden-thread-connecting-information)

</p></details>

<!-- Or just read the MUCH shorter version [here](https://www.psychologytoday.com/us/blog/mind-in-the-machine/202512/the-hidden-connection-between-information-and-consciousness). -->

██████████████████████████████████████████████████████████████████
# SECTION: In Defence of the Hivemind Society
██████████████████████████████████████████████████████████████████

This whole thing should be optional - not visible by default. Very long, and not part of the core.

> "2. What is a Hivemind Society?
>
> For our purposes, we can distinguish two kinds of hiveminds. In the broad sense, a hivemind society is one in which individual agents together form a further agent of some moral significance (the “collective” or, as we prefer, the “hivemind”). As we will see, in this broad sense, we are all plausibly already participating in many such minor hiveminds. In the narrow sense, a hivemind society is one in which what otherwise might have been independent agents have no moral value of their own; the agents have “dissolved” into the collective, and are not recoverable as separate entities from the collective. Though it is useful to separate these notions, we are inclined to think there is not in fact a sharp line between these types of hiveminds. The question is really one of degree: to what extent are potentially independent agents merged with a collective, and to what extent has the moral emphasis shifted from the merging agents to the merged agent? The idea that the distinction between a hivemind society and an individualist society is not a sharp or precise one might strike some readers as frustratingly vague or imprecise but we believe that this emphasis on degrees of difference is both metaphysically accurate and, as will become clear, something that can be used to encourage people to take a different perspective on the axiology of hivemind societies: because some of us are, in the broad sense, already tending towards or participating in hivemind-ish societies we can at least be open to the possibility of going further in this direction...
>
> 3. Why we Should be Open to the Hivemind Society
>
> The first argument can be thought of as a warm-up. It is not intended to prove the desirability of a hivemind society. It is, rather, intended to loosen the imaginative constraints that typically confront people when thinking about the idea of a hivemind society. One of those constraints, felt particularly strongly in Western liberal societies, is that we are currently committed to a kind of individualist moral framework, one in which individuals are the primary and most important locus of moral significance. This is not to say that we are ideologically pure individualists. As we shall point out below, there are anti-individualist, pro-hivemind features of our current moral views, and there are communities and cultures around the world that embrace a more communitarian, anti-individualist outlook. Nevertheless, individualism does seem to be dominant in Western, liberal societies, and the commitment to individualism is often reflected in both moral practices and legal norms of those communities. To free us from the constraints of an individualist outlook, the first argument encourages us to first adopt a principle of axiological openness, i.e. a willingness to consider and experiment with different moral possibilities, and then apply that principle to the possibility of a hivemind society.
>
> The principle of axiological openness is a form of historical common sense. We know that moral norms and preferences have shifted many times over the course of human history. If you were a white man living in a European society in the late 1700s it is likely that you would have endorsed slavery and colonialism, thought that women should be denied the legal rights of men, favoured capital punishment and legal torture, and judged homosexuality to be morally abhorrent. While the remnants of these attitudes linger to this day, the radical shift in the moral consensus on these matters since the late 1700s has been remarkable. Very few people openly endorse any of these beliefs today. And this is just a single example of a radical moral shift over time. If we look to other societies and countries, and look deeper into antiquity, the fact of moral change seems undeniable. This should encourage greater humility and uncertainty when it comes to our commitment to our currently favoured set of axiological possibilities...
>
> ... The second reason is that, in the full scope of human history and cultural variation, the centrality of individualism to our axiological worldview is a relatively recent, and somewhat localised development. In his history of European moral philosophy, The Invention of Autonomy (1998), JB Schneewind carefully and meticulously documents how the current Western commitment to the moral importance of the individual is something that evolved slowly, over the course of several centuries, not something that was always present. Larry Siedentop, in his book Inventing the Individual tells a similar story, describing in particular how Ancient (pre-Socratic) Greek societies did not place the individual at the centre of their morality, instead giving pride of place to the family and the state. These are not unfamiliar worldviews to us even today: various forms of nationalism and communitarianism still strive for our attention. Furthermore, there is at least one major world religion—Buddhism—which is known to favour the view that there is no self in the sense traditionally conceived by Western individualist thought (Flanagan 2017), and which sees the denial of the self as a pathway to Enlightenment. Although there are different interpretations of exactly what the ‘No Self’ doctrine means, Monima Chadha argues that one leading version of it (the Abhidharma tradition) rejects both the idea of an extended narrative self and a self with any degree of agency and ownership over its actions (Chadha 2017 & 2018). All of these examples suggest that humans are not welded to an individualistic ethos, and so we should be at least open to the possibility of axiological alternatives to individualism...
>
> 4. Why the Hivemind is Desirable
>
> ... ‘Desirability’ must be interpreted appropriately. There is a danger that we impose too high an axiological standard on the hivemind society and so rule it out of bounds forever. This could happen if we insist that, in order for it to be desirable, the hivemind society must satisfy important human goods or values and must not sacrifice or undermine any other goods or values. This would be an unfair standard. After all, no way of life that is currently deemed desirable meets that standard. Every choice we make involves compromises and tradeoffs. In choosing to be a committed and doting parent, you may have to sacrifice some success in your career. We might prefer it if such compromises could be avoided—and perhaps there are ways to reform social institutions so as to minimise them—but given both finite time and finite resources, some degree of compromise in seeking the good life is inevitable. The same will, necessarily, be true if we favour the hivemind over a more individualistic mode of existence. This does not mean that the hivemind is not desirable. It is enough if we can show that pursuing this ideal satisfies some goods and compensates for significant losses. With that clarification out of the way, we can proceed to the argument we wish to defend, which consists of four distinct sub-arguments in favour of the transition to the hivemind society.
>
> The **first** sub-argument has to do with the good of intimacy. Achieving an intimate connection with another human being is generally thought to be a core part of the well-lived life. The Aristotelian virtue of friendship, for example, celebrates a bond between friends that involves two people engaging with each other with near-perfect equality and mutuality. Similarly, the ideal of romantic attachment is typically thought to require strong forms of physical and mental mutuality. Our current physical and mental separateness prevents us from achieving near perfect intimacy. There is always some barrier between us. Even in the case of sexual intimacy—where there is some ‘melting’ of the physical barriers—the mental barriers remain... Building the hivemind society, particularly by following the path to high degrees of phenomenological unity, would provide an obvious means for overcoming the mental barriers between us and achieving a more perfected form of intimacy. Furthermore, this is an ideal that could be achieved at different scales and in different forms, depending on both the number of people with whom one forms a hivemind, and the degree of phenomenological sharing it entails.
>
> One might object to this on the grounds that intimacy requires separateness. In other words, one might argue that in order for someone to be intimate with another person, that person and the other person must retain their separate identities. Indeed, it could be that this is what makes intimacy good in the first place. It is like a form of phenomenological ‘edging’: we must be brought to the precipice of complete merger with another but never fall over the edge. The worry might be that the hivemind ideal thrusts us into the abyss. We no longer retain the separateness that makes intimacy such an ecstasy. Two things can be said in response to this. First, for hiveminds in the broad sense, pursuing the hivemind ideal need not undermine the separateness of individuals. It could itself just be an extreme form of phenomenological edging: humans in hiveminds might still retain some sense of individuality, but this is suppressed or dominated by the sense of merger. Second, even if it does undermine separateness, it is at least disputable as to why this separateness is essential to the good of intimacy. When we talk about achieving intimacy with another we usually focus on melting the boundaries between us, i.e. on trying to peer beneath the exterior mask and get at the person’s true identity. Pursuing that ideal to its logical extreme leads us to the narrow hivemind model. There is nothing in the inner logic of intimacy that rules this out.
>
> The **second** sub-argument has to do with problem-solving and goal achievement. Both of these things are thought to be a core part of the good life... achievement is only a good if the goals or ends pursued themselves have value, i.e. that the states of affairs brought about through problem-solving and achievement enable us to flourish and thrive. The success of modern, industrialised societies is built on the back of its immense problem-solving capacity, particularly in how we harness energy toward the production of food, clothing, shelter, entertainment and culture. It has long been known that individual humans are not that impressive when it comes to their problem-solving and goal achievement abilities... Humans depend on the existence of a ‘group mind’—a cultural repository of tools, techniques and tricks—to survive. Henrich documents this at length giving numerous examples of how important ‘collective intelligence’ is to human flourishing. What’s more, it seems like collective intelligence is becoming more and more important to our flourishing in the modern era. Numerous studies suggest that our capacity for research and innovation is subject to diminishing marginal returns. We see this very clearly in the sciences. Where once a lone genius could make radical breakthroughs and define an entire field of study, we now require large interdisciplinary and international research teams to make the breakthroughs. Indeed, modern scientific papers frequently seem to require what Daniel Dennett calls “distributed comprehension”, in which no one person understands the entirety of the paper. What all of this means is that achieving greater degrees of rational unity across a human population has always been essential to our survival and flourishing and has become more essential now. This, again, provides support for the hivemind idea, particularly in its rational unity form. If we want to achieve things through our actions -- for example, maintain the same levels of material wealth and success in the future -- and if we want to retain our problem-solving, achievement-oriented society, stronger degrees of rational unity will be required, up to and including degrees that deserve the label ‘hivemind’... the hivemind ideal may, in any event, be compatible with some lingering individualism that allows for individuals to experience some degree of satisfaction and accrue some benefit from problem-solving and goal achievement. Even if these experiences are not had by an individual human, and instead belong to a collective mind or agent, there is still some value to them: it is still good for certain goals to be achieved and associated experiences to be experienced, irrespective of who exactly is experiencing and achieving the goals...
>
> The **third** sub-argument takes a more direct aim at the citadel of individualism and argues that we should favour the hivemind because our commitment to individualism actually undermines truly moral and virtuous behaviour. Impartiality, altruism and selflessness are all usually taken to be hallmarks of moral behaviour. Indeed, a key desideratum in many metaethical theories is the extent to which they warrant impartiality in decision-making... Individualism is an impediment to impartiality. Individualism favours partiality, self-serving bias, and illusions of responsibility and virtue. It is because so many of us are trapped inside an individualistic bubble that we cannot act with true impartiality. Derek Parfit argues that our belief that we are separate, persistently existing individuals is, to a large extent, a conventional illusion, not a deep metaphysical truth. If we cast off the illusion we can live more open, altruistic lives... Parfit echoes millennia of Buddhist thought, which also emphasises the profound universal empathy that is possible through self-abandonment. In addition to believing that it is a fact that there is no separate, unique, narrative self, members of the Abhidharma Buddhist tradition also think that there are good practical, moral reasons for rejecting an individualistic ethos. As Chadha puts it, they argue that attachment to an individualistic view opens us up to certain “moral defilements” including “greed, conceit, pride, jealousy and so on”. We can rid ourselves of these defilements if we loosen the grip of individualism. Furthermore, it is claimed by members of this tradition that our belief in individualism is a source of much of our personal anxiety and suffering. Again, pursuing the hivemind ideal, in both of its forms, would help us to shatter the illusion of independent selfhood and live a more altruistic and enlightened life in the sense that eliminating the distinctions between different agents, and seeing everyone as part of a single unified hivemind, would be to achieve a perfected form of impartial altruism. It is important that this third sub-argument be fairly interpreted. Staunch anti-individualists and proponents of the No-Self doctrine may push the point too far. While it is undoubtedly true that our commitment to individualism is a source of some moral vice and defilement, it is also a source of moral virtue and good (e.g. responsibility, care, duty, courage, charity and so on). A person who is content with the ‘illusion’ of individualism can live a good life. The more modest, and in our view more reasonable, interpretation of the argument is simply to say that individualism is not the only game in town and that there are moral and flourishing modes of existence that are in tension with that paradigm and are best achieved by escaping from it. That is what is made evident by this third sub-argument...
>
> The **fourth** and final sub-argument in favour of the hivemind ideal is that pursuing that ideal is both compatible with, and possibly more conducive to, certain understandings of what it takes to live a meaningful life. This is an argument that has been made by Baptiste Le Bihan in relation to the Buddhist No-Self doctrine. As he notes, a typical reaction to that doctrine among Western thinkers is to argue that it lends itself to a form of nihilism. If the self does not exist, then what is the point of living? Life is only worthwhile if we, as individuals, live meaningful lives. But, as Le Bihan points out, there is nothing in traditional conceptions of what it takes to live a meaningful life that necessitates individualism. The one exception to this might be certain traditional religious understandings of meaning which insist upon the existence of a separate eternal soul in order for there to be meaning, but this is not a feature of all religious traditions and once you move to more secular understandings of meaning things become much more hospitable to anti-individualist views. The dominant secular understandings of meaning tend to be either subjectivist, objectivist or hybridist in nature (Metz 2013; Danaher 2014 & 2017; Campbell and Nyholm 2015). They claim that in order to live a meaningful life you must either (a) experience some subjective state of well-being (e.g. desire satisfaction or pleasure); or (b) bring about certain objectively valuable states of affairs (e.g. do good, find truth, create beauty); or (c) satisfy some combination of both subjective and objective states (e.g. be subjectively fulfilled by finding out the truth). At first glance, it might seem like each of these theories presupposes or requires the existence of a single self who experiences the relevant subjective states or brings about the relevant objective ends, but this is not necessarily true. There is nothing in subjectivism that insists that subjective pleasure must be felt by a unique, separate and persistent individual, and there is nothing in objectivism that insists that valuable ends must be brought about by a single individual. A collective agent, with high degrees of rational and phenomenological unity could satisfy these conditions of meaning too... Consequently, it is possible to pursue the hivemind ideal without giving up on living a meaningful life—the ideal is compatible with bringing about subjective pleasure and producing objectively valuable ends. It might even be better than this. There are certain conceptions of meaning in life that are not only compatible with the hivemind ideal but are actually only possible if we pursue it. For example, a common motif in theories of meaning is that a meaningful life is one that contributes to projects or ideals that are beyond that of the individual. The classic version of this is the religious ideal of contributing to God’s universal plan for salvation. One of the more unique secular variations of this ideal comes from Robert Nozick. Nozick argues that meaning comes from transcending our natural limits, where this requires some connection with larger external things. Nozick argues that there are two ways of forging this connection. You can connect with something that always remains external to you or you can integrate yourself with the external thing, forging some larger organic unity. He thinks the latter strategy is particularly conducive to meaning: it makes us fit as part of a larger pattern. Again, Le Bihan notes that this provides a lot of hope for the proponent of the No Self doctrine because they seek to erase the boundary between the individual human being and the external world. It also provides a lot of hope for the proponent of the hivemind ideal. After all, what is that ideal if not an attempt to transcend the limits of an individual human body and integrate it within a larger collective unit? Stepping away from this somewhat mystical doctrine, there is also the common motif that death and the fragility of human life somehow undermines or compromises meaning. Even among avowed naturalists, there is a belief that death makes life less meaningful and at the very least a longer lifespan would be more desirable... Perhaps by dissolving the individual and incorporating it into a larger collective agent, we have a more practical route to a longer life? After all, we already know that corporate agents can long outlive their original founders and managers. If we can make ourselves genuinely integrated parts of a unified collective entity we could participate in an extended, possibly even immortal lifespan. This is one thing that the hivemind ideal promises that is not as readily available to individuals...
>
> 5. Three Objections and Replies..." - [In Defence of the Hivemind Society, by John Danaher and Steve Petersen](https://philarchive.org/rec/DANIDO-10)

> "We are beginning to share our thinking. We are beginning to connect up mentally. We are beginning to link mind to mind. And as we begin to understand each other, an even deeper level of linking is occurring: a linking of soul to soul. We are beginning to appreciate our sensual unity and oneness. So the next stage of evolution could be humanity beginning to link together—physically and mentally, beginning to work and function on many different levels as an integrated system." - [Peter Russell](https://www.organism.earth/library/document/global-brain#:~:text=We%20are%20beginning%20to%20share,levels%20as%20an%20integrated%20system.)



██████████████████████████████████████████████████████████████████
# SECTION: Proper Attention Economics and its Regulation
██████████████████████████████████████████████████████████████████

Reclaiming and directing attention

> "We need a system where urgent local news can be collected and amplified globally when necessary, and where the people of the world decide which news is important, not official news channels or celebrity nodes." - [Binding Chaos, by Heather Marsh](https://georgiebc.files.wordpress.com/2013/05/bindingchaos6x9.pdf)

> "If news requires no action, it is probably not the news we require in order to govern ourselves. If activism requires no analysis, it is probably not informed or effective." - [Heather Marsh](https://www.goodreads.com/quotes/10158316-if-news-requires-no-action-it-is-probably-not-the)

> "Problems of scarcity are fundamentally addressed by economics, which is the study of how scarce resources can be allocated most efficiently. At the most basic level, “economy” means simply the careful management of resources, so that as little as possible is wasted. From this point of view, **individuals should learn to optimally spend the limited amount of attention they have, by investing it only in the most worthwhile items.**" - [Tackling Complexity and Information Overload: intelligence amplification, attention economy and the global brain, by Francis Heylighen](http://pcp.vub.ac.be/Papers/Info-overload.pdf)




## Attention Filtering - The End of Direct, Untrusted Information to Brain

> "Reading a tweet is a bit like downloading an (attacker-controlled) executable that you instantly run on your brain. Each one elicits emotions, suggests knowledge, nudges world-view. In the future it might feel surprising that we allowed direct, untrusted information to brain." - [Andrej Karpathy](https://twitter.com/karpathy/status/1766509149297189274)

> "In an ideal world, before I consume your content and allow your meme to pass through my brain, I should be able to configure my code to require that your packet meets certain provenance requirements. You don’t get my attention unless it meets that. It’s an implicit contractual protocol for attention." - [Peter Wang](https://github.com/pzwang/lostweb/blob/master/4%20The%20Root%20Problems.md)

information overload, decision-support, relevance, recommendations, collective feedback, causal networks, prediction and reaction

> "Such a global brain would **solve the problem of information overload at the most fundamental level. For the individual it would provide constant decision-support, presenting recommended choices in their apparent order of importance, as determined by the individual’s own preferences, the experience of all other agents, and the collective preferences of society.** Complemented by an in-depth teaching and implementation of the rules of information hygiene, such a system should be able to eliminate the stress of of not being able to cope with the number of available options, while minimizing the risk of bad decisions because of insufficient information being taken into account.
>
> Depending on the amount of attention or effort the individual is willing to invest in the decision, (s)he could either immediately accept the “default” recommendation, or examine a variable number of options in more depth, making a choice that is potentially very different from the one initially recommended by the system... The degree to which individuals actively participate in the decision-making will moreover depend on their own level of education and intelligence. **The smarter and the more experienced in the domain you are, the higher your chances to find a solution that is better than the default one, and the more the system can learn from your contribution. Thus, individual advances in knowledge and intelligence will directly or indirectly benefit the capacities of the collective.**
>
> On the level of society, **a global brain-like system should be able to tackle the problems associated with the complexity and sensitivity of causal networks. It should be able to take into account myriad events and their interactions, and intervene immediately, before any problem can snowball out of control.** Of course, even an intelligence of this supra-human order of magnitude will never be able to reliably predict the future behavior of a system that is in essence chaotic. Yet, **as cybernetics has taught us, detailed prediction (feedforward) is not necessary as long as the regulatory system can react quickly and adequately to any potentially dangerous perturbation (feedback).** Moreover, by modelling the effects of complex interactions such a system should be able to solve the productivity paradox, overcoming the socio-institutional inertia, the non-linear side-effects and bottlenecks that hold back productivity growth." - [Tackling Complexity and Information Overload: intelligence amplification, attention economy and the global brain, by Francis Heylighen](http://pcp.vub.ac.be/Papers/Info-overload.pdf)

## Designing self-regulation of attention

Aiding self-organizing communities of knowledge with better analysis (clustering, hubs, average distances). Detect what's currently most authoritative and what might be in the future. Consciously guide and influence the direction of the emergent self-regulation.

> "The emergence of a new scientific domain is a good example of the self-organization of such a community of knowledge, where people from initially diverse backgrounds find each other around a common interest, which gradually coalesces into a new paradigm. This process could be observed by mapping the network of authors, publications and keywords in a particular domain at regular intervals (e.g. every 2-5 years), and analyzing it in terms of clustering, hubs, average distances, etc. The change of these features over time may show processes of self-organization taking place. A good theory of the self-organization of knowledge communities would propose a number of processes and parameters that allow us to predict where, when and how such self-organization is most likely to take place. Such a theory would help us to find not only the presently most authoritative concepts, publications or authors (hubs), but those that are likely to become so in the future. This would provide a very powerful instrument to uncover emerging trends and to direct attention and investment towards the most promising people, ideas and information sources.
>
> ... While we cannot truly control a complex system, it tends to self-organize to a state where it regulates itself. This state tends to increase the utility or fitness of the system’s active components or agents, by coordinating their interactions so as to maximize synergy. The resulting organization is distributed over all the agents and their interactions, and thus much more robust and flexible than any centralized design. Moreover, it determines a number of emergent, global properties that cannot be reduced to the properties of the individual components. By understanding the underlying mechanisms, we may be able to facilitate and stimulate such self-organization, or to drive it in one direction rather than another." - [Complexity and Self-organization, by Francis Heylighen](http://pespmc1.vub.ac.be/Papers/ELIS-complexity.pdf)
