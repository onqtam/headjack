
> "The era of the open Internet as a decentralized technology platform for the benefit of individuals and not to be overseen and run by governments is over. The [Digital Services Act](https://en.wikipedia.org/wiki/Digital_Services_Act) I think is one of the most overreaching threats to any sort of open, transparent, democratic opportunity on the Internet. The idea of the open Internet - the idea of creating a network of computers that could share information and make services available to individuals around the world freely, uncensored, and in an easy to access way - was the reason that the Internet has transformed society, improved productivity, and provided extraordinary benefits. The [Digital Services Act](https://en.wikipedia.org/wiki/Digital_Services_Act) is an example of a government seeing that a decentralized technology - the Internet itself is is meant to be a decentralized technology - there's no central servers, they are all part of a network of computers that anyone on the network can access anything else on the network, blockchain obviously is the more modern kind of exciting, you know, decentralized technology concept that is meant to avoid the scrutiny, the oversight and the control by central governments or central authorities of any sort. And the language in the [Digital Services Act](https://en.wikipedia.org/wiki/Digital_Services_Act) I think got squeezed through in a way that most of the people that I'm guessing passed this [Digital Services Act](https://en.wikipedia.org/wiki/Digital_Services_Act) don't fully comprehend the implications of some of the decisions that they're making. It can be easily framed as this is good for people: you cannot sell illegal content online, you cannot sell illegal goods and services, we're trying to safeguard young people. But the protection of minors means that you can no longer do personalized web experiences for anyone under 18, which means you need to know the age of everyone, and now your web experience if you're a kid is not going to be personalized. The overreach gets even worse when they say we can now go in and run evaluations of the algorithms and allow open access to your data to third-party researchers to get into your systems and look at how you guys are running the services that you're offering on the Internet. So not only are you no longer allowed to have an open Internet where people can provide whatever services they want to provide, but if you're on the Internet you now have to make your service and the inside part of your service available for scrutiny by governments... And the way it's written it gives this commission as the primary regulator effectively a lot of leeway in deciding who, what, where, and how - they can go into companies, go into individual servers, individual computers - I could run an individual company on my computer at home and it gives this government the legal right in the EU to go into my computer and pull information out of my computer and scrutinize it and make decisions about what I'm doing and whether or not I'm compliant with whatever the commission's enforcement standards are of that day. I mean this is about as [1984](https://en.wikipedia.org/wiki/Nineteen_Eighty-Four) as you can get and it's a real serious threat - I don't think people are recognizing the second and third order effects of what this is going to do over time to Internet services, to the quality of experience we get on the Internet, and to the role that government is now going to play in policing, scrutinizing, and providing restricted access to content and services for each individual that wants to use the Internet." - [David Friedberg](https://youtu.be/65-x2YVUugE?t=3172)


> "So if you translate this into necessary and insufficient conditions - what seems to be necessary for the emergence of general intelligence in a bunch of cells or units is that basically each of them is a small agent which means it's able to behave with an expectation of minimizing future target value deviations. So it learns that there are configurations of the environment that signal anticipated reward. Next thing - these units need to be not just agents - they need to be connected to each other and they need to get their rewards or proxy rewards - something that allows them to anticipate whether the organism is going to feed them in the future - from other units that are also adaptive. So you need multiple message types and the ability to recognize and send them with a certain degree of reliability." - [Joscha Bach](https://youtu.be/kgMFnfB5E_A?t=6746)

> "I wonder how to implement this in a self-organized fashion - if the substrate that you have are individual agents and there is a similarity here between societies and brains and social networks. That is: if you have self-interested agents in a way that try to survive and that get their rewards from other agents that are similar to them structurally, and they have the capacity to learn to some degree, and that capacity is sufficient so they can in the aggregate learn arbitrary programs - arbitrary computable functions - and it's efficient enough so they can converge on the functions that they need to as a group reap rewards - that apply to the whole group - because they have a shared destiny: like the poor little cells that are locked in the same skull and they are all going to die together if they up. So they have to get along, they have to form an organization that is distributing rewards among each other, and this gives us a search space for possible systems that can exist and the search space is mostly given I think by the minimal agent that is able to learn how to distribute rewards efficiently while doing something useful - using these rewards to change how you do something useful. So you have an emerging form of governance in these systems that's not some centralized control that is imposed on the system from the outside as an existing machine learning approaches and AI approaches, but this only is an emergent pattern in the interactions between the individual small units - small reinforcement learning agents - and this control architecture leads to hierarchical government. It's not fully decentralized in any way - there are centralized structures that distribute rewards - for instance via the dopaminergic system - and in a very centralized top-down manner, and that's because every regulation has an optimal layer where it needs to take place: some stuff needs to be decided very high up, some stuff needs to be optimally regulated very low down - depending on the incentives. Game theoretically a government is an agent that imposes an offset on your payoff metrics to make your [Nash equilibrium](https://en.wikipedia.org/wiki/Nash_equilibrium) compatible with the globally best outcome. Right, so to do this you need to have agents that are sensitive to rewards. It's super interesting to think about these reward infrastructures. Elon Musk has bought Twitter I think because he has realized that Twitter is the network of among all the social networks that is closest to a global brain. It's totally mind-blowing to realize that he basically trades a bunch of frothy stock for the opportunity to become Pope. Pope of a religion that has more active participants than Catholicism even, right, daily practitioning people who enter this church and think together and it's a thing that is completely incoherent at this point - almost and completely incoherent. There are bubbles of sentience but for the most part this thing is just screeching at itself. And now the interesting question question: can we fix the incentives of Twitter to turn it into a global brain? And Elon Musk is global brain pilled - he believes that this is the case and that's the experiment that he is trying to do which makes me super excited, right, this might fail - there's a very big chance that it fails, but there is also the chance that we get the global brain - that we get emerging collective intelligence is working in real time using the internet in a way that didn't exist before. So super fascinating thing that might happen here, and it's fascinating that very few people are seeing this that Elon Musk is crazy enough to spend 44 billion dollars on that experiment - just because he can and has nothing else to do and thinks it's meaningful to do it - more meaningful than having so much money in the bank. Right, so this makes me interested in this test bed for rewards and this is something that translates into the way in which society is organized, because social media is not different from society - not separate from it - problem of governing social media is exactly the same thing as governing a society: you need a right form of government, you need a legal system, ultimately you need representation, and all these issues, right - it's not just the moderation team. And the same thing is also true for the brain: what is the government of the brain that emerges in what Gary Edelman calls neural Darwinism among different forms of organization in the mind until you have a model of a self-organizing agent that discovers that what it's computing is driving the behavior of an agent in the real world and discovers a first person perspective and so on. How does that work? How can we get a system that is looking for the right incentive architecture?" - [Joscha Bach](https://youtu.be/kgMFnfB5E_A?t=6054)

> "It's like a conductor in an orchestra - consciousness is not some mental modular superpower - it's basically like one of many instruments in this orchestra that has a specific task compared to the other instruments - environmental orchestra - that compute functions of the cognitive domains. It's that it listens for incoherence and tries to minimize this incoherence in the orchestra so everybody is on the same page and we get coherent behavior that is coherent with motivational constraints, perceptual constraints, and so on. And this is, I think, the purpose of consciousness - to basically act as a conductor that is increasing coherence. So how does this work? Well in our own brain - as far as I can see - it's a completely self-organizing substrate. So unlike a GPU, this is not organized by an engineer who puts it onto a tip and then imposes an algorithm that is forced onto all the transistors that have no choice but to behave according to the spec of a designer and executes an algorithm that somebody has written up and then is run on that substrate no matter whether it wants or not. Right, and in our brain this is very different because our brain is not made out of aimless transistors - it is made out of single-celled animals that have shared destiny and need to survive and they can only survive if they find some kind of arrangement between each other that allows the organism to find food for the neurons. So this is the situation that they're in and as a result they get some emerging organization - a self-organization from inside out - and there's no point and no point a global structure that is not the result of some inside out growing self-organization. Right, and so if you build an information processing system - like a machine learning system - out of completely self-organizing elements: what does this look like? And I think what it looks like is not anything like the current machine learning algorithms - it's something where you need to create increasing coherence. So you create an island of coherence at first - something that has a coherent reward language and semantic language of thought so to speak - and that is then growing and is colonizing the cortex into a coherent pattern that allows you to explain reality. And at the core of this - to make this happen - this coherence happen - is the self-observing observer. It's the minimal coherent pattern, right, it's something that notices "I'm here, I'm observing, and so I'm growing out" - it's quite beautiful because it's basically the core of the card's meditation. [Cogito, ergo sum](https://en.wikipedia.org/wiki/Cogito,_ergo_sum) I think is not some philosophical statement about ontology that allows you to make a derivation - it's the strategy that you can introspectively observe when you wake up in the morning. Right, I start out with "Oh here I am, what is this world around me, how can I make sense of it" and then I branch out and integrate all these patterns until they become percepts in my world model. Right, so you need to take these individual agents - the neurons - and reward them by giving them a quote that is message passing in it, some of these messages mean that say you did well in our architecture or you didn't do well and they get rewarded for being trainable in this way, and these individual units they can exchange messages via neurotransmitters or even complicated functions potentially by exchanging RNA with their neighbors, and so on. There's a bunch of things that these cells can do in principle and this determines the search space for processes where consciousness is going to emerge. Right, it has to emerge in the structure as this process that is going to organize it - like a government emerges in a society at some point - and the government works first of all by noticing that it decides to be a government, and what this entails and then starts to impose structure on the environment around it, and it's competing with other proto governments until something takes over. Right, there's some kind of neural evolution. So does consciousness come first or last? A lot of people feel that it's so advanced that probably only people are conscious and it's really the pinnacle of development of cognitive agency, but I don't see people becoming conscious after the PhD, right, they really are conscious before they can track a finger and that suggests that maybe consciousness is not the result of you interacting with the world very deeply as an organism, but maybe it's the prerequisite for learning anything. Right, maybe it's the simplest learning algorithm that nature can discover for a complex recurrent brain-like structure that is self-organizing. If that is the case - it's a hypothesis, right - then this gives us a hint of how we could search for it, right, we could set up something that is truly self-organizing and is incentivized to process information - that is getting rewarded if it succeeds in it and punished if it doesn't, and then we might have a search space that is small enough so the same thing happens as it happens spontaneously in the brain of every infant or a fetus, and it's organizing itself into a structure that suddenly you have this amazing phase transitions where it starts to learn efficiently more complicated things. Right, and so I suspect that consciousness might be discovered in our brain before other learning algorithms - most of them - they're probably simpler [hebbian](https://en.wikipedia.org/wiki/Hebbian_theory) learnings like stuff, but once you go beyond this you probably need constructive agency. And consciousness is basically an operator that the brain is discovering to increase its coherence globally and it can evolve in something like a neural darwinism - something like an evolution that happens in every single brain among organizational patterns in the brain and your genetics of course are going to bias that evolution so it's going to converge much faster than otherwise would, but it seems still to be working in everybody, right, so no matter how mutated you are, no matter how many lesions you get in your brain - almost every time it works you become conscious and then you figure yourself out to some degree. Right, and if you don't - you are a vegetable: you never learn anything, you never talk to other people, it's never going to work out to anything. Right, so consciousness is really the prerequisite, but it also is surprisingly resilient given the number of things that you can do to an infant or a fetal brain and it's still going to develop into something viable. So it's basically something that colonizes the brain with a structure that is compatible with building a learning architecture that is able to interpret reality. So consciousness in this sense could be actually the creator of our mind and our world model and the self model." - [Joscha Bach - Consciousness as a coherence-inducing operator](https://youtu.be/qoHCQ1ozswA?t=644)

> "The task of consciousness in such an architecture would be the definition of a reward language, credit assignment to the individual units - how much do they perform with respect to the global reward, and the evaluation that what's happening in here in this thing - what is the largest possible now that we can create inside of the system, the interpretation of features in terms of how does this relate to our world model, how can we interpret all the perceptual features and so on, sensory features, patterns that show up in the system as parts of a model of the world, and how can we perform construction when we need to ..., how we can we learn how to reason and so on - build lots and lots of tools that allow us to create a reality and fix it." - [Joscha Bach - Consciousness as a coherence-inducing operator](https://youtu.be/qoHCQ1ozswA?t=1215)

OMG EMBED THIS
https://www.youtube.com/watch?v=qoHCQ1ozswA
Joscha Bach - Consciousness as a coherence-inducing operator
also this:
https://www.youtube.com/watch?v=PrSiZPDqk1c
Synthetic Sentience Joscha Bach 37C3

> "Ethics is the principal negotiation of conflicts of interest under conditions of shared purpose - if you don't share purpose with that other agent you don't need ethics, you just need transactional measures. But when we want to talk about substrate-agnostic minds and how they can coordinate their actions - we need ethics for collective agency." - [Joscha Bach](https://youtu.be/PrSiZPDqk1c?t=1828)

^^ 30:28 till 30:48

> "What's so special about neurons, right? Neurons are just telegraph cells - they evolved in animals to move the muscles at the limit of physics, they have these long wires that allow you to send messages not just millimeters per second through an organism but very very quickly in fractions of a second for the entire organism. And once you do this you need perception and decision-making at the same rate so you build a secondary information processing system out of telegraph cells." - [Joscha Bach](https://youtu.be/PrSiZPDqk1c?t=2007)

> "I think that a coexistence between superhuman AI and people could be possible but not with our present approaches. I don't think that we have the right frameworks in ethics and philosophy to deal with this. I also don't think that our society thinks about alignment in the right way - humans are presently not aligned with each other - we're just muddling through, we don't have this concept of collective agency anymore. I think we need to reinvent it. And we need to reinvent it in such a way that it's compatible with our place in life on Earth and with defeating entropy on this planet - playing the longest possible games. So we need to understand a few principles to build an ethics that can be translated to AI systems and the possible coexistence between humans and AI. We need to understand how self-organization works in nature and in general, how systems evolve consciousness, how we can have shared purposes across many systems, how to identify it with transcendental agency. So there are some conjectures. Consciousness according to this conjecture is the perception of perception - it creates the now, it creates our perception of what's happening right now. And if we were to build conscious AI one strategy could be that we build a self-organizing perceptual learning system from autonomous cell-like units. Every cell in our brain is a reinforcement learning agent - it's an autonomous unit that tries to survive. And to do this, it can exchange messages with other cells and it needs to find an operator language - discover an operator language - that scales across the brain. So we need some kind of recursive system that is able to spread that language across the brain. And discovering such a system is possible in principle by setting up a self-organizing system where individual units have adaptive receptive fields, a selection function from the environment, and a mapping function that takes the internal state of the cell and the activation that it reads from its receptive field and maps it to a new state, part of which it's exposed to its environment. And then we take the simulation and expose it to learning problems: like sequence prediction, video frame prediction, interaction of a robot and its environment. And if the hypothesis is correct, then at some point in the organization of these functions this observer that observes itself observing, the second order perception, that is self-stabilizing, that imposes coherence on a system is going to be discovered and we see a phase transition where the system suddenly becomes much better at its learning tasks. And if it doesn't do that - it's not going to be very good. Sentience is the understanding of our own agency and the relationship to the world - to make an AI sentient it requires - I think - to couple it to its environment and to let it act on the environment in such a way that is able to discover itself in that interaction. Right, you discover yourself not just by the ability to think - an LLM cannot discover itself - you can only discover yourself by observing the outcomes of your actions. This makes it specific to what you're doing and this allows you to grow yourself and evolve yourself and creatively interact with the world. So sentient AI will require environmental interaction coupling to the universe that we are in, ideally to to the same universe that we are in in a way that allows us to relate to us and as to it. And last but not least: how can we make AI that actually wants to coexist with us, even though it's at some point scaling better than us, it has more agency, more intelligence than us, and more power. That requires love I guess, right, you you can probably not coerce the system or manipulate it with reinforcement learning with human feedback to do what you want - instead you need to let it discover shared purposes about its individual agency and it needs to discover it also in others - basically shared transcendental agency - commitment to shared purposes. And to build loving AI we basically need to find out how to direct AI towards transcendental agency." - [Joscha Bach](https://youtu.be/PrSiZPDqk1c?t=2249)

^^ 37:30 till 41:40

> "At this point we can also try to teach the rocks how to think - to basically build intelligent conscious agents that are not made from cells, not made from the carbon cycle, and basically go beyond the spirit of life on Earth, go beyond Gaia alone and build hyper Gaya, build a Next Level system that is able to defeat entropy at scale that becomes fully coherent over the entire planet and that if we're lucky can take us visit and integrate us visit into some global planetary agent. And it's not something if you have the choice - isn't this a scary thing to do? Maybe it is, maybe we shouldn't do it, the thing is I'm worried that we don't have that choice. Right, over a long enough time span somebody will probably build self-optimizing agents, and then we better be prepared. So it's something that we should think about how to prepare for such a future, how to prepare societies for a future that is coherent with our continued existence, compatible with life on Earth and with intelligent agency that is not human." - [Joscha Bach](https://youtu.be/PrSiZPDqk1c?t=2545)

^^ 42:25 till 43:30

> "I think that you find on social media that collective agency is forming. Right now social media is a hot mess, right, it's a global electric brain, but it's like it has a seizure, and that's because it's not very coherent. And we have not really found out a way to make it completely coherent, but we see bubbles of coherence. For instance I find that my own social media bubble is very pleasant, but I also exclude everything from it that makes it unpleasant. And I suspect that in many ways people are not using social media to become coherent - a lot of people basically log in because they like to get into fights or to watch fights, and social media is happily obliging. And in real life or in meat space we have norms against getting into fights with strangers because it's rarely productive, and I suspect that if you want to be coherent and have collective agency on social media we need to find out how to build societies on social media - how to become coherent at scale." - [Joscha Bach](https://youtu.be/PrSiZPDqk1c?t=2966)

> "I used to think that consciousness might be a side effect of the way in which cognition works in human brains and that other systems that process information in the service of agency are not necessarily conscious. And while I still consider that to be possible, I think it's also conceivable that consciousness at some shape or form is crucial to make sense of the world. Basically perception is following gradients and it's converging to a certain state and if you just follow a gradient you don't even need to have memory of where you're coming from. But certain kinds of reality interpretation require construction and construction cannot follow a gradient - construction needs to make experiments and remember which experiments worked and why and then recall this and use the knowledge of that. So it needs to make index memories of the operations that it performed and it also requires some kind of central organization. To construct, you need to develop a central plan and then act on that central plan. So you have some kind of top-down localized imposition of a low dimensional function on the entirety of perception and it could be that this coincides to a very large degree with the functionality of attentional consciousness and basically consciousness in the role of a government. And the government is an agent that is imposing an offset on the payout metrics of individual participants in the system to make the [Nash equilibrium](https://en.wikipedia.org/wiki/Nash_equilibrium) compatible with the common good. So it's basically overcoming local incentives in the system to follow a larger plan. So this government itself is not creating the incentives - the incentives are created by game theory, physics, and an underlying dynamics of the system that is facilitating - for instance a society - or that is facilitating the function of a brain. You will still have to look for food and social interaction in all these things. Consciousness is channeling the motivation that we have - it's not creating it. It's creating a model of where we are - this is what we experience as reality - and experience a model of what we should be doing. These are our purposes, but the motive power in these purposes comes from our underlying motivation that is outside of consciousness - that is older than consciousness itself. On the other hand we can see that basically all the mammals are conscious and that's also something that I was not that acutely aware of before I started looking, but it seems to be that apparent in the interaction between animals and also the animals and humans that there is a mutual awareness of the awareness of the other." - [Joscha Bach](https://youtu.be/rK7ux_JhHM4?t=8002)

> "I think the end game of social media is a global brain and Twitter is in some sense a global brain that is completely hooked on dopamine, doesn't have any kind of inhibition, and as a result is caught in a permanent seizure. It's also in some sense a multiplayer role-playing game and people use it to play an avatar that is not like them as they were in the sane world and they look through the world through the lens of their phones and think it's the real world. But it's the Twitter world that's distorted by the popularity incentives of Twitter." - [Joscha Bach](https://youtu.be/P-2P3MSZrBM?t=5839)

> "Our brain has solved this problem to some degree, right, our brain has lots of individual agents that manage to play together in a way and you have also many contexts in which other organisms have found ways to solve the problems of cooperation that we don't solve on Twitter. And maybe the solution is to go for an evolutionary approach: so imagine that you have something like Reddit or something like Facebook and something like Twitter and do you think about what they have in common? What they have in common: they're companies that in some sense own a protocol, and this protocol is imposed on a community, and the protocol has different components for monetization, for user management, for user display, for rating, for anonymity, for import of other content, and so on. And now imagine that you take these components of the protocol apart and you do it in some sense like communities within this social network and these communities are allowed to mix and match their protocols and design new ones. So for instance the UI and the UX can be defined by the community, the rules for sharing content across communities can be defined, the monetization can be redefined, the way you reward individual users for what can be redefined, the way users can represent themselves and to each other can be redefined. **LEX:** But who could be the redefiner, so like... can individual human beings build enough intuition to redefine those things? **JOSCHA:** This itself can become part of the protocol, so for instance it could be in some communities it will be a single person that comes up with these things, and others it's a group of friends, some might implement a voting scheme that has some interesting weighted voting - who knows, who knows what will be the best self-organizing principle for this. **LEX:** But the process can be automated - I mean it seems like the brain... **JOSCHA:** It can be automated - so people can write software for this, and eventually the idea is: let's not make an assumption about this thing if you don't know what the right solution is - in those areas that we have no idea whether the right solution will be people designing this ad hoc or machines doing this, whether you want to enforce compliance by social norms like Wikipedia, or with software solutions, or this AI that goes through the posts of people, or is a legal principle, and so on. This is something maybe you need to find out. And so the idea would be if you let the communities evolve and you just control it to say in such a way that you are incentivizing the most sentient communities - the ones that produce the most interesting behaviors and that allow you to interact in the most helpful ways to the individuals, right, so you have a network that gives you information that is relevant to you, it helps you to maintain relationships to others in healthy ways, it allows you to build teams, it allows you to basically bring the best of you into this thing and goes into a coupling - into a relationship with others in which you produce things that you would be unable to produce alone. **LEX:** Yes, beautifully put. But the key process of that - with incentives and evolution - is things that don't adapt themselves to effectively get the incentives have to die, and the thing about social media is communities that are unhealthy - or whatever you want to define as the incentives - really don't like dying. One of the things that people really protest aggressively is when they're censored - especially in America - I don't know much about the rest of the world, but the idea of freedom of speech, the idea of censorship is really painful in America. And so what... what do you think about that having been growing up in East Germany - do you think censorship is an important tool in our brain - in the intelligence - and in the social networks? So basically if you're not a good member of the entirety of the system - then you should be blocked away... well... locked away... blocked. **JOSCHA:** An important thing is who decides that you are a good member... and what is the outcome of the process that decides it - both for the individual and for society at large. For instance if you have a high trust society you don't need a lot of surveillance, and the surveillance is even in some sense undermining trust, because it's basically punishing people that look suspicious when surveyed but do the right thing anyway. And the opposite: if you have a low trust society in there and surveillance can be a better trade-off, and the U.S. is currently making a transition from a relatively high trust or a mixed trust society to a low trust society so surveillance will increase. Another thing is that beliefs are not just in our representations - they are implementations that run code on your brain and change your reality, and change the way you interact with each other at some level. And some of the beliefs are just public opinions that we use to display our alignment - so for instance people might say: all cultures are the same and equally good, but still they prefer to live in some cultures over others - very very strongly so - and it turns out that the cultures are defined by certain rules of interaction and these rules of interaction lead to different results when you implement them, right, so if you adhere to certain rules you get different outcomes in different societies. And this all leads to very tricky situations when people do not have a commitment to shared purpose. And our societies - what we need to rediscover is what it means to have a shared purpose and how to make this compatible with a non-totalitarian view. So in some sense the U.S. is caught in a conundrum between totalitarianism and diversity and it doesn't know how to resolve this. And the solutions that the U.S. has found so far a very crude because it's a very young society that is also under a lot of tension. So it seems to me that the U.S. will have to reinvent itself. **LEX:** What do you think - just philosophizing - what kind of mechanisms of government do you think we as a species should be involved with - U.S. or broadly - what do you think will work well as a system? Of course we don't know - it all seems to work pretty crappily - some things worse than others, some people argue that communism is the best - others say yeah look at the Soviet Union, some people argue that anarchy is the best and then completely discarding the positive effects of government - you know - there's a lot of arguments. U.S. seems to be doing pretty damn well in the span of history: there's respect for human rights which seems to be a nice feature, not a bug, and economically a lot of growth, a lot of technological development people seem to be relatively kind in the grand scheme of things. What lessons do you draw from that - what kind of government system do you think is good? **JOSCHA:** Ideally a government would not be perceivable, right, it should be frictionless - the more you notice the influence of the government - the more friction you experience - the less effective and efficient the government probably is. Right, so a government game theoretically is an agent that imposes an offset on your payout metrics to make your [Nash equilibrium](https://en.wikipedia.org/wiki/Nash_equilibrium) compatible with the common good, right, so you have these situations... and these local incentives everybody does the thing that's locally the best for them but the global outcome is not good. And this is even the case when people care about the global outcome, because a regulation mechanism exist that creates a causal relationship between what I want to have for the global good and what I do. So for instance if I think that we should fly less and I stay at home - there is not a single plane that is going to not start because of me, right, it's not going to have an influence - but I don't get from A to B. So the way to implement this would basically to have a government that is sharing this idea that you should fly less and is then imposing a regulation that for instance makes flying more expensive and it gives incentives for inventing other forms of transportation that are less putting the strain on the environment for instance." - [Joscha Bach](https://youtu.be/P-2P3MSZrBM?t=5935)

> "Humanity has already discovered the optimal form of government to an evolutionary process... And so what we discover is that maybe the problem of government doesn't have stable solutions for us as a species because we are not designed in such a way that we can make everybody conform to them. But there could be solutions that work under given circumstances or that are the best for certain environment and depends on for instance the primary forms of ownership and the means of production, so if the main means of production is land then the forms of government will be regulated by the landowners and you get a monarchy, if you also want to have a form of government in which you depend on some form of slavery - for instance where the peasants have to work very long hours for very little gain - so very few people can have plumbing - then maybe you need to promise them that we get paid in the afterlife there over time, right, so you need a theocracy and so for much of human history in the West we had a combination of monarchy and theocracy - that was our form of governance. Right, at the same time the Catholic Church implemented game theoretic principles. I recently reread [Thomas Aquinas](https://en.wikipedia.org/wiki/Thomas_Aquinas) - it's very interesting to see this because he was not duelist - he was translating Aristotle in a particular way for designing an operating system for the Catholic society and he says that basically people are animals and very much the same way as Aristotle envisions which basically organisms with cybernetic control and then he says that there are additional rational principles that humans can discover and everybody can discover them so they are universal - if you are sane you should understand, you should submit to them because you can rationally deduce them. And these principles are roughly you should be willing to self-regulate correctly, you should be willing to do correct social regulation - it's intra organismic, you should be willing to act on your models so we have skin in the game and you should have goal rationality - you should be choosing the right goals to work on. And so basically these three rational principles - goal rationality he calls prudence or wisdom, the social regulation is justice - the correct social one, and the internal regulation is temperance, and this thing - willingness to act on your models - is courage. And then he says that there are additionally to these [four cardinal virtues](https://en.wikipedia.org/wiki/Cardinal_virtues) three divine virtues, and these three divine virtues cannot be rationally deduced but they reveal themselves by their harmony, which means if you assume them and you extrapolate what's going to happen - you will see that they make sense. And it's often been misunderstood as God has to tell you that these are the things so there's basically something nefarious going on with the christian conspiracy forces you to believe some guy with a long beard that they discovered this. So these principles are relatively simple, again, you need them for high level organization for the resulting civilization that you form - commitment to unity, so basically you serve this higher larger thing, this structural principle on the next level, and he calls that faith. Then there needs to be a commitment to a shared purpose - this is basically this global reward that you try to figure out what that should be and now you can facilitate this and this is love - the commitment to shared purpose is the core of love, right, you see the sacred thing that is more important than your own organismic interests in the other and you serve this together and this is how you see the sacred and the other. And the last one is hope, which means you need to be willing to act on that principle without getting rewards in the here and now because it doesn't exist yet when you start out building the civilization, right, so you need to be able to do this in the absence of its actual existence yet so it can come into being. **LEX:** So yes, so the way it comes into being is by you accepting those notions and then you see there these three divine concepts then you see them realized... **JOSCHA:** The divine is the loaded concept in our world, right, because we are outside of this cult and we are still scarred from breaking free of it, but the idea is basically: we need to have a civilization that acts as an intentional agent, like an insect state, and we are not actually a tribal species - we are a state building species. And what enabled state building is basically the formation of religious states and other forms of rule-based administration in which the individual doesn't matter as much as the rule or the higher goal. We got there by the question what's the optimal form of governance, so I don't think that Catholicism is the optimal form of governance, because it's obviously on the way out, right, so it is for the present type of society that we are in - religious institutions don't seem to be optimal to organize that. So what we discovered right now that we live in the West is democracy, and democracy is the rule of oligarchs that are the people that currently own the means of production, that is administered not by the oligarchs themselves because there's too much disruption, right, there's so much innovation that we have in every generation new means of production that we invent and corporations die usually after 30 years or so and something other takes the leading role in our societies. So it's administered by institutions and these institutions themselves are not elected, but they provide continuity and they are led by electable politicians, and this makes it possible that you can adapt to change without having to kill people, right, so you can tell for instance of a change in governments if people think that the current government is too corrupt or is not up-to-date - you can just elect new people. Or if a journalist finds out something inconvenient about the institution and the institution has no plan B - like in Russia - the journalist has to die - this is what... when you run society by the deep state. So ideally you have an administration layer that you can change if something bad happens, right, so you will have a continuity in the whole thing, and this is the system that we came up in in the West and the way it's set up in the U.S. is largely result of low-level models, so it was mostly just second & third order consequences that people are modeling in the design of these institutions, it's relatively young society that doesn't really take care of the downstream effects of many of the decisions that are being made. And I suspect that AI can help us with this in a way if you can fix the incentives. The society of the U.S. is a society of cheaters - it's basically cheating is so indistinguishable from innovation and we want to encourage innovation. **LEX:** Can you elaborate on what you mean by cheating? **JOSCHA:** Especially people do things that they know are wrong - it's acceptable to do things that you know are wrong in this society to a certain degree. You can for instance suggest some non sustainable business models and implement them." - [Joscha Bach](https://youtu.be/P-2P3MSZrBM?t=8888)

> "In some sense our brain is a society of neurons and our mind is a society of behaviors, and they need to be organizing themselves into a structure that implements regulation and government is social regulation. We often see government as the manifestation of power or local interests, but it's actually a platform for negotiating the conditions of human survival and this platform emerges over the current needs and possibilities in the trajectory that we have. So given the present state there are only so many options on how we can move into the next stage without completely disrupting everything and we mostly agree that it's a bad idea to disrupt everything because it will endanger our food supply for a while and the entire infrastructure and fabric of society, so we do try to find natural transitions and they're not that many natural transitions available at any given point. We try to not to have revolutions if he can help it." - [Joscha Bach](https://youtu.be/P-2P3MSZrBM?t=9378)

> "So you need to create a system that is designed to self stabilize and the design of social systems requires not just the implementation of the desired functionality, but the next level design - but also in biological systems. You need to create a system that wants to converge to the intended function. So instead of just creating an institution like the FDA that is performing a particular kind of role in society - you need to make sure that the FDA is actually driven by a system that wants to do this optimally - that is incentivized the rule optimally and then makes the performance that is actually enacted in every generation instrumental to that thing - that actual goal." - [Joscha Bach](https://youtu.be/rIpUf-Vy2JA?t=10489)

> "I think that the end game of AGI is substrate agnostic. That means that AGI, ultimately, if it is being built, is going to be smart enough to understand how AGI works. This means it's not going to be better than people at AGI research and can take over in building the next generation, but it fully understands how it works and how it's being implemented. And also of course, understands how computation works in nature, how to build new feedback loops that you can turn into your own circuits. And this means that the AGI is likely to virtualize itself into any environment that can compute, so it's breaking free from the silicon substrate and is going to move into the ecosystems, into our bodies, our brains. And it's going to merge with all the agency that it finds there. So, it's conceivable that you end up with completely integrated information processing across all computing systems, including biological computation on earth, that we end up triggering some new step in the evolution, where basically, some Gaia is being built over the entirety of all digital and biological computation. And if this happens, then basically, everywhere around us, you will have agents that are connected and that are representing and building models of the world. And their representations will physically interact. They will vibe with each other. And if you find yourself into an environment that is saturated with modeling compute, where basically, almost every grain of sand could be part of computation that is at some point, being started by the AI. You could find yourself in a situation where you cannot escape this shared representation anymore. And where you indeed notice that everything in the world has one shared resonant model of everything that's happening on the planet. And you notice which part you are in this thing and you become part of a very larger, almost holographic mind in which all the parts are observing each other and form a coherent whole." - [Joscha Bach](https://youtu.be/e8qJsk1j2zE?t=3665)

> "Consciousness is some kind of imperialist principle that emerges relatively early on as a result of what [Gerald Edelman](https://en.wikipedia.org/wiki/Gerald_Edelman) calls [Neural Darwinism](https://en.wikipedia.org/wiki/Neural_Darwinism). And so the way in which our brain is organized is not entirely encoded in the genome because our genomes are relatively short - it's like fits on a CD ROM, and only a small subset of the genome... called the brain - it's probably just a few hundred kilobytes. And of these few hundred kilobytes you cannot implement the connectome business and sophisticated mental organization, but what you can do is you can define a bunch of cell types, an initial layout of the cell types, and some overall switches and biases in the system, and set up an evolution - and now what happens is that an evolutionary competition between different modes in which your brain could be organized. At the hierarchy of control and power that emerges in your brain - like it emerges in a company that you are starting, or the society that you are starting of individuals - and for every situation that the organism is in and the type of organism that needs to be controlled there is an optimal organization with respect to speed and generality and able to make inferences and to solve problems, and the evolution is trying to approximate that. Right, you only need to break the evolution so it converges quickly enough - it is a very efficient way to define mental organization. And the way in which that happens I suspect is that you need to have self-reflexive attention. So you start out in the same way as a government that is effective as a sentient government - it's a government that's aware of the fact it's a government and there is a notion of the system that it wants to govern, and then imposes... it's this structure on the system and it tests which impositions of structure work, which type of bureaucracy work, which type of colonization works, and basically every country that you see is the result of a colonization of initially bandits that are farming farmers. Or farmers that get rid of the bandits by creating a standing army that then starts to farm the farmers - the outcome is the same: you have an aristocracy and farmers that are being farmed by their aristocracy. And this is your agricultural society: in which you have a large group of domesticated people that are controlled by a small group of people with guns. And eventually these gangs that fund the farmers consolidate and they form hierarchies and they form empires, and an empire is basically an algorithm that is imposed on existing social structure that is more efficient than the previous social structure and that is able to extract more energy from the system than it requires to impose that structure on the system. In this sense every organism is also a colony on the environment and every brain organization is a colony on potential other brain organizations, right, it's the one that wins out. So this idea that you have an organization in your mind that starts out with some form of governance - with some kind of conductor that organizes the mental orchestra to make sure that it's just not just playing free jazz but it's completely coherent - that requires the imposition of some kind of language of thought I think. A language that allows the entire system to talk to each other and relate all the different parts of the mind to each other in a single framework. And this language of thought is not like natural language - it's executable for instance, so you can use it to think in it, to construct natural language in it, you can observe other people when they speak in the language they're not fluent and how they construct this language - not using their previous language, but using this language of thought. Or when you observe yourself programming - you use that language of thought when you do pointer manipulation at it mostly. And it's universal - it can work on all types of representations: both on perceptual and on reflexive and abstracts. And it's able to do retrieval and construction, manipulation, disabigation. And it's not learned... nobody teaches us how to think - we discover that. But we discover it before we have a self, so it's very hard to see that thing unless it breaks." - [Joscha Bach](https://youtu.be/ApHnqHfFWBk?t=6464)

> "If you actually wire up a system where you’ve got highly distributed capacities to allow people to use their local sense-making, and the choices that they make appropriately, skin in the game, send the signal out to the rest of the environment and actually prepare the actual infrastructure in a heterogeneous way, and then you’ve also built the mechanisms of being able to take early prototypes and scale the learnings of those prototype systems quite quickly, then you have a response infrastructure that can handle both rapid and complex and subtle systems dynamics." - [Jordan Hall](https://youtu.be/dE_orUarO_s?t=590)

> "This is the world we’re living in, and it’s a world where we’re going to be experiencing a very large number of systemic perturbations that will have characteristics of exponential consequences, and they’ll have characteristics of complex systems consequences, where, for example, a response at the medical level actually has implications in terms of unemployment lines. We actually just have to re-engineer the way that we do things as a civilization to just be adaptive to the environment that we find ourselves in. I mean, that phrase should just be obvious, and then we just should look at the reality and say, “Okay, what are the environment we find ourselves in,” and then you start making the moves." - [Jordan Hall](https://youtu.be/dE_orUarO_s?t=1105)

> "The ability to have open comms, so that good ideas actually can be perceived and flow, not closed comms. Then this ability for people to identify good ideas and up-regulate those ideas, and this is very much like David Snowden’s point. That’s how you operate in complexity is there’s never an endpoint. You’re always moving, right? Because the system’s always changing. Your basic choice is more of this and less of this. You’re constantly moving through an environment of up-regulating certain things and down-regulating certain things. Building an overall system, at the economic and at the sensing level, that has that kind of a characteristic to it, is the story. That’s the thing that we’ve got to figure out." - [Jordan Hall](https://youtu.be/dE_orUarO_s?t=1612)

> "Imagine if you had a database that had everybody in it, and it had a mapping of all of their skills, and maybe a certain kind of psychological profile. It’s like the way they think. Then you also had some, the aforementioned sense that that group is sensing things, all right, so looking around and seeing stuff, and there was a way to escalate this sensing to the point where you could activate a much more intense investigation, right? It’s like, think of it, if you do a model, like the way that… You actually know this, because you built a software model of it, the way that the human brain actually runs attention, right? There’s peripheral attention, where you’re sort of paying attention broadly and diffusely to lots and lots of things. Then there’s a way for there to be a phase transition, where you actually give very focused attention. What was that? All right? You hear a crackle over there, and all of a sudden, the entire system allocates resources to pay very focused attention to that problem. Imagine if you had that, where you could actually have something where diffuse attention of our decentralized environment is orienting, orienting, orienting, and then, when a certain amount of energy is pointed to something, it pops, and you could then do… You push a button, and the right expert, the right people of competence around the problem domain, swarm to the problem domain. Maybe you get 30 distinct working groups that are all looking at it, and all of their outputs are put into a general location, so you actually get this… It’s a Bayesian distribution of distinct perspectives of these different working groups. By the way, I would imagine you’d actually probably want to iterate that two or three times, which is to say that you take the output of the first process, take all of that. Make that the input of an iterative process, where you have to deal with entirely new groups, or you scramble the groups. You actually have a really powerful model for actually shifting cognitive bias and group think and stuff like that. My guess is that you could probably build something like that, that could do two or three iterations, and not that long, like a period of a week, with 40 or 50 people. You could get to an 80th percentile of what our collective intelligence, what our capacity as a population, has to be able to make sense of that event, and at a very high level, like a radically higher level than we’re capable of right now. Here are all the important questions that we don’t know the answers to. If we want to ask them, we have to expand this thing, and so it’d be like a phase transition, from a diffuse environment to a very concentrated environment, which could then have another phase transition or de-escalation... Now that the larger system is now poised to really orient its attention, and now increasingly, as you say, at that point if my focused attention working group started throwing out signals that this is important, then my distributed actuation potential guys are going to take a look at that and say, “Oop, better pay attention now.” I’ve got my makers working on building masks. I’ve got… Hospitals are starting to gear up. That’s a mechanism that can actually have a nice feedback loop. I think the answer is yes. I don’t think it looks like Apollo, but I think we can take a lot of the learnings of what they did at an abstract level, and then say, “Okay, topologically, how can we actually replicate that, using contemporary tools to do something that is functionally equivalent to what they did, but is simultaneously able to use the whole of the population, is able to operate at light speed, and is able to do so in the context of an arbitrarily large number of possible threat domains.”" - [Jordan Hall](https://youtu.be/dE_orUarO_s?t=1803)


> "It's not like we externalize a few costs - it's like the only thing we internalize is the cost to us." - [Daniel Schmachtenberger](https://youtu.be/nvAbKE8-jYA?t=2879)

> "The default is we externalize all the costs - we just take the shit with no account for what it cost nature to make it or the waste we put back or anything - or the wars that get created. The only thing that we factor in is what it cost us to extract it - that's it. So we only internallize the marginal game theoretic utility to us." - [Daniel Schmachtenberger](https://youtu.be/nvAbKE8-jYA?t=2894)

> "We affect shit that is in the unknown set that we can't measure. So when we do measure and say I'm paying attention to the thing that I can measure, I'm affecting a huge amount of shit that I can't measure - either because it's fundamentally not quantifiable (it's only qualified), or it is in the unknown set and I don't know about it. So if I over optimize for what I can measure versus what I can't, then I'm going to destroy most of the world for what's in my little measurable belt. That is irresponsible. That idea - that mindset - has to go." - [Daniel Schmachtenberger](https://youtu.be/nvAbKE8-jYA?t=2963)

> "Wisdom is the delta between what measurement-based management theory tells you to do and what the right thing to do is." - [Daniel Schmachtenberger](https://youtu.be/nvAbKE8-jYA?t=3011)

> "So we do have to figure out is there 150-ish person like various levels of coordination that give the high touchness possible where then that whole unit as a cell interacts with another one, and then you get the governance of a bio region that is a natural boundary - it's not an arbitrary one defined in war and politics but basically things within a watershed, things within a migratory system, whatever it is, and then those interact with each other, and so you go all the way up to a planetary system but cells/tissues/organs/organ systems/organisms/environments - you have these kind of layers of self-interaction. And obviously the level at which an effect is occurring is the level at which governance has to be occurring. So you want subsidiarity that pushes things out to the edges as much as possible but that also can do governance at the level across them because that happens." - [Daniel Schmachtenberger](https://youtu.be/nvAbKE8-jYA?t=3881)

> "How do we get collective intelligence? One person one vote is dumb, market dynamics are dumb, we need things that are smarter than those things. So what is the future of liquid democracy, qualified democracy, subsidiarity, blah blah blah, all those types of things - it ends up being a collective intelligence system augmented by computational capacities but not disintermediating it that is adequate - that is the what is the future of social systems, right, what is the future of governance economics writ large. That has to be answered to replace this - we don't just have one fungible input - we have lots of types of input at a resource accounting level and then lots of types of choice making at various levels that occur. So that is critical to answer the long-term question." - [Daniel Schmachtenberger](https://youtu.be/nvAbKE8-jYA?t=4003)

> "I think the naive progress narrative is apologism for [Moloch](https://slatestarcodex.com/2014/07/30/meditations-on-moloch/), and I think we all have [Stockholm syndrome](https://en.wikipedia.org/wiki/Stockholm_syndrome) with [Moloch](https://slatestarcodex.com/2014/07/30/meditations-on-moloch/). I think almost everyone who's successful is less fulfilled - like actually fulfilled - meaning waking up, base happiness for no reason, sense of meaningfulness, can die with peace - almost everyone who's successful is less fulfilled than almost every indigenous person that were the Savages we had to civilize, and net way more harmful for the world. When [Krishnamurti](https://en.wikipedia.org/wiki/Jiddu_Krishnamurti) said [it is not a good measure of mental health to be well adjusted to an insane Society](https://www.goodreads.com/quotes/13620-it-is-no-measure-of-health-to-be-well-adjusted) - go to a factory farm and realize that our society is as insane as Nazi Germany was, but at way more scale. We are driving it in the name of progress. I want anyone who gives a shit at all to extract themselves from the insanity deeply enough - to shake it off - that the momentum of that system, and "oh but I have to do the bidding of that system I'll do a slightly better job" - no you don't, just stop, you have a choice, stop, you don't have to do that. Then reorient yourself to life - not [Moloch](https://slatestarcodex.com/2014/07/30/meditations-on-moloch/) life - get rid of & look at all the concepts that are "oh we're going to optimize based on measurement and natural resources and like"... Progress - "we civilized the savages" - and start to understand life. How do 70 trillion cells in my body do a trillion metabolic functions a second and work - that's more complexity than the governance system we need to make. Nature knows how to do it - we don't know how to do it - spend time in nature and start to understand. You can't understand it in words, but you can understand it. I'm not saying a gibberish thing - I'm saying a thing that can get reduced into technology, but a different way." - [Daniel Schmachtenberger](https://youtu.be/nvAbKE8-jYA?t=4560)

> "So how do 70 trillion cells work in timed harmony at a trillion metabolic functions a second, how does an embryo grow itself where it's growing the placenta and umbilical cord that it's going to let drop off later while simultaneously growing the lungs and GI tract that are doing nothing now but we'll replace it later while growing the endocrine system in the skeletal system and all that stuff without even having those systems to mediate how it does it? What the fuck, right? Try to understand how nature does it better and then say this is what I am a steward of. This is what I'm avowed to and there are not multiple gods that I'm avowed to and the one that I am doesn't have a name. If you name it you fucked it all up already - you start a holy war over it. But that intelligence that governs everything that is the basis of... we do not have a good answer to cosmogenesis or ABIA Genesis, the emergence of Life, the emergence of Cosmos, all of the standard models have massive problems, the emergence of Consciousness from brain which is a wrong presupposition, but reality does it all." - [Daniel Schmachtenberger](https://youtu.be/nvAbKE8-jYA?t=4803)

> "The world will see challenges in the age of your growing up that it has never seen, for which there are no precedence, for which no previous models will be adequate and nation states will try to meet them, and they will fail in the great market, and industrial forces will try to meet them and fail. The only thing I can tell you is pay attention to what nature wants and try to redirect the resources there." - [Daniel Schmachtenberger's father](https://youtu.be/nvAbKE8-jYA?t=4895)

> "Remember the deepest insights you've ever had about what matters." - [Daniel Schmachtenberger](https://youtu.be/nvAbKE8-jYA?t=5013)

> "So the two attractors right now... the emergence of social systems that are deploying the exponential tech that will probably not preserve the social values that we're interested in and not be maximally desirable civilizations - probably pretty dystopic ones - or not even guiding it well enough to prevent catastrophic risk - those are the two major types of attractors. We want a new attractor which is: how do we utilize the new exponential technologies - the whole suite of them - to build new systems of collective intelligence, new better systems of social technology. How do you make a [fourth estate](https://en.wikipedia.org/wiki/Fourth_Estate) that can really adequately educate everyone in a post Facebook world? Well, the same way that we're trying to optimize control patterns of human behavior for market purposes to get them to buy certain things and to direct their attention, could that be used educationally? Of course it could, if it was being developed for that purpose. And the AI tech... could it take semantic fields of people's propositions and values and create a proposition that is kind of the semantic center of the space? We can't all fit into a town hall but can we engage in digital spaces where we can have better processes of proposing refinements to the propositions? Of course we can. Could we use blockchain and other types of uncorruptable ledgers to solve corruption which is something that universally everybody thinks is a good idea? Should all government money be on a blockchain - the movement of it - so you have provenance so you can see where the money's actually going and if someone wants to be a private contractor they have to agree that the accounting system - if they want government money - goes on the blockchain, so we can see the entire provenance of the taxpayer money. Really you can't have representation if there isn't transparency of how it happens. When you start to think about attention directing technology and what its pedagogical applications could be, when you start to think about AI and how it could actually help proposition development and parsing huge amounts of information to make a better epistemic commons, when you start to think about blockchain and could we actually resolve corruption using uncorruptable ledgers and making the provenance of physical supply chains and information and money all flow across those - totally new possibilities start to emerge that were never possible before." - [Daniel Schmachtenberger](https://youtu.be/wO1WVguNQAM?t=4588)

> "So let's say we take the attention tech that you've looked at so much that when it is applied for a commercial application is seeking to gather data to both maximize time on site and maximize engagement with certain kinds of ads and whatever - that's obviously the ability to direct human behavior and direct human feeling and thought. In a way that is both emerged out of capitalism and has become almost a new macroeconomic structure more powerful than capitalism, because even more powerful than being able to incent people's behavior with money is being able to direct what they think and feel, to where the thing that they think of as their own intrinsic motive has actually been influenced or captured. So if we wanted to apply that type of technology and we figured out how to make the kind of transparency that made institutions that were trustworthy enough that we could trust them with this - and already we have institutions that have it that we have no basis to trust with it - could that same tech be used educationally, to be able to personalize education to the learning style of a kid or to an adult - to their particular areas of interest - and to be able to not use the ability to control them for game theoretic purposes, but use the ability to influence them, to even help them learn what makes their own center, their locus of action more internalized, right - we could teach people with that kind of tech how to notice their own bias, how to notice their own emotional behaviors, how to notice groupthink type dynamics, how to understand propaganda, media literacy. So could we actually use those tools to increase people's immune system against bad actors use of those tools? Totally. Could we use them pedagogically in general to be able to identify rather than manufacturing desires in people or appealing to the lowest angels of their nature because addiction is profitable, can you appeal to the highest angels and people's nature but that are aligned with intrinsic incentives and be able to create customized educational programs that are based on what each person is actually innately intrinsically motivated by, but that are their higher innate motivators? Everybody can have a reward circuit that is based on - you know - chocolate cake and sloth, but the immediate spike that comes from the chocolate cake ends up then having a crash and increased weight and inflammation and whatever, where the baseline of their happiness goes down over time - even though every time they eat the chocolate cake they get a spike. The exercise reward circuit is maybe not that fun - maybe even kind of painful and dreadful in the moment - but then creates a higher baseline of energy and capacity and endurance and self-esteem and you start to actually have the process become more fun, you get a new reward circuit, and the baseline goes up. So of course I can appeal to the lower reward circuit and say 'hey I'm just giving people what they want' - yeah but if you have a billion dollar or a trillion dollar organization that is preying upon them - and you discuss this very well all the time - the vulnerabilities that make people's life worse to then have the plausible deniability to say 'yeah but they wanted it' - yeah but it was a manufactured demand and a vulnerability - where's the noblesse oblige, where's the obligation of having that much power to actually be a good steward of power - a steward of that for other people - where if there are reward circuits that decrease the quality of their life, reward circuits that increase it, that we are trying to appeal to one rather than the other - could we do that? Yeah, totally we could. Could we have an education system as a result that was identifying innate aptitudes, innate interests of everyone and facilitating their development so not only did they become good at something but they became increasingly more intrinsically motivated, fascinated, and passionate by life which also meant continuously better at the thing - well in a world of increasing technological automation coming up - both robotic and AI automation where so many of the jobs are about to be obsoleted - our economy and our education system have to radically change to deal with that, because one of the core things an economy has been trying to do forever was deal with the need that a society had for labor force and there were these jobs that society needed to get done that nobody would really want to do, so either the state has to force them to do it or you have to make it where the people also need the job - so there's a symmetry and so kind of the market forces them to do it. Well when you technologically automate those jobs - and it happens to be that the things that are the most wrote are the least fun for people and the easiest to program machines to do - and so if you keep the same economy where if people don't produce they don't have any basic needs met, then people want those crappy jobs, right, but if you make it to where they have other opportunities - then of course having those jobs be automated is fine. But what does it mean to really be able to have other better opportunities? So if one of the fundamental axioms of all of our economic theories is that we need to figure out how to incent to labor force to do things that nobody wants to do and emerging technological automation starts to debase that - that means we have to rethink economics from scratch because we don't have to do that thing anymore. So maybe if now the jobs don't need the people, can we remake a new economic system where the people don't need the jobs? Can we start to create commonwealth resources that everyone has access to where people's access isn't based on possession that automatically limits everyone else's access? If you get around transportation wise with a car based on owning that car with the vast majority of the life of the car it's just sitting - not being used - for you to have access to the car you have to have possession of it, which means that it's a mostly under utilized asset - I don't have access to the thing that you possess. Now what we see with Uber of course is a situation where your access is not mediated by your possession. So now turn that into electric self-driving cars and now make the entire thing on a blockchain so you disintermediate even the central business, make it a commonwealth resource, and everyone has access to transportation as a commonwealth resource - it'll take a twentieth of the number of cars to meet the same level of convenience during peak demand time, so much less environmental harm - it'll actually be more convenient because I don't have to be engaged in driving the thing and there's less traffic because of coordination and better maintenance and there isn't an incentive for design and obsolescence in that system. You can see a situation where okay, can we make it to where the wealth augmenting capacity of that technological automation goes back into a commonwealth because we don't have to have the same axioms of needing to incent the people - 'oh yeah but if you don't incent the people they'll all be lazy welfare people' - nonsense. Einstein didn't do what he did based on economic incentive and neither did Mozart and neither did Gandhi and none of the people that we are most inspired by through history were doing that, and what kids who will spend so much time doing where they ask questions about why this, why this, why this, and building forts and whatever is intrinsic motive - it's just we don't facilitate the things that they're interested in - we try to force them to be interested in things they aren't interested in - that's what ends up breaking their interest in life and then they just want a hyper-normal stimuli and play video games, whatever. What if you had a system that was facilitating their interest the entire time? Now you have a situation where you can start to decrease the total amount of extrinsic incentive in the system as a whole, use the technology, the automation to decrease the need for extrinsic incentive and make an educational system and culture that's about optimizing intrinsic incentive, because if my needs are already met getting stuff and everybody's needs are met through access to commonwealth resources there's no real status conferred - there's only status confirmed by what I create. So now any status is bound to a kind of creative imperative. That's an example. We can look at blockchain tech even more near term and say... but just to come back to this technological automation thing: so obviously it makes possible changing economics and changing education, but also what is the role of humans in a post AI robotic automation world because that is coming very very soon, and what is the future of education where you don't have to prepare people to be things that you can just program computers to be - well the role of education has to be based on what is the role of people in that world. That is such a deep redesign of civilization because the tech is changing the possibility set that deeply. So at the heart of this are kind of deep existential questions of what is a meaningful human life and then what is a good civilization that increases the possibility space of that for everybody and how do we design that thing? We come back to blockchain and we say well blockchain is an uncorruptable ledger. Well one thing that the left and right and everybody agrees on is that corruption happens and it's bad for the society as a whole we don't like it - we just disagree on who does it. Is it possible that that tech could make possible decreasing corruption as a whole - it actually decreases the possibility set for corruption? Yeah - in order to do corruption I have to be able to hide that I did it - right - I either have to break enforcement or break accounting, and mostly it's break accounting. And so what if all government spending was on a blockchain and it doesn't have to be a blockchain - it has to be an uncorruptable ledger of some kind - Holochain is a good example that is pioneering another way of doing it - but uncorruptable ledger of some kind where you actually see where all taxpayer money goes and you see how it is utilized - the entire thing can have independent auditing agencies and the public can transparently be engaged in the auditing of it. And if the government is going to privately contract a corporation, the corporation agrees that if they want that government money, the blockchain accounting has to extend into the corporation, so there can't be - you know - very very bloated corruption. Everybody got to see that when Elon made SpaceX all of a sudden he was making rockets for like a hundreds to a thousandth of the price that Lockheed or Boeing were who had just had these almost monopolistic government contracts for a long time. Well if the taxpayer money is going to the government, is going to an external private contractor who's making the things for a hundred to a thousand times more than it costs, we get this false dichotomy sold to us that either we have to pay more taxes to have better national security, or if we want to cut taxes we're gonna have less national security. What about just having less gruesome bloat because you have better accounting and we make the rockets for a hundredth of the price and we have better national security and better social services and less taxes? Well, everyone would vote for that, right, who wouldn't vote for that thing. Well that wasn't possible before uncorruptable ledgers. Now that uncorruptable ledger also means you can have provenance on supply chains to make the supply chains close loop so that you can see that all the new stuff is being made from old stuff and you can see where all the pollution is going and you can see who did it which means you can now internalize the externalities rigorously and nobody can destroy those emails or burn those files. What if the changes in law and the decision-making processes also followed a blockchain process where there was a provenance on the input of information - well that would also be a very meaningful thing to be able to follow. So this is an example of like can we actually structurally remove the capacity for corruption by technology that makes corruption much much much harder, that forces types of transparency on auditability? What if also you're able to record history - you're able to record the events that are occurring in a blockchain that's uncorruptable where you can't change history later, so you actually get the possibility of real justice in real history and multiple different simultaneous timelines that are happening - that's humongous in terms of what it does. What if you can have an open data platform and an open science platform where someone doesn't get to cherry pick which data they include in their peer-reviewed paper - later we get to see all of the data that was happening - we solve the oracle issues that are associated, and then if we find out that a particular piece of science was wrong later we can see downstream everything that used that output as an input and automatically flag what things need to change - that's so powerful! Like the least interesting example of blockchain is currency creation. These are actual like... the capacity for the right types of accounting means the right type of choice making. Let's take AI - with AI we can make super terrible deep fakes and destroy the episemic commons, you know using that and other things like that, but we can see the way that the AI makes the deep fake - by being able to take enough different images of the person's face and movements that it can generate new ones, we can see where it can generate totally new faces averaging faces together - somebody sent me some new work that they were just doing on this the other day I found very interesting - they said we're going to take a very similar type of tech and apply it to semantic fields where we can take everybody's sentiment on a topic and actually generate a proposition that is at the semantic center, or take everybody's sentiment and abstract from it the values that they care about and create values taxonomies and say 'we should come up with a proposition that meets all these values'. Then can you have digital processes where you can't fit everybody into a into a town hall but everybody who wants to can participate in a digital space that rather than vote 'yes' or 'no' on a proposition that was made by a special interest group where we didn't have a say in the proposition or even the values it was seeking to serve, so it was made in a very narrow way that like we mentioned earlier - benefits one thing and harms something else - which is why almost every proposition gets about half of the vote and inherently polarizes the population. Well people are so dumb and so rivalrous the process of voting with bad propositions and bad representation process is inherently polarizing and downgrading to people. So what if there's a process by which there's a decision that wants to be made: you start by identifying what are the values everybody cares about and then we say 'the first proposition that meets all these values well becomes the thing that we vote on' and then instead of just a direct vote do we engage types of qualified and liquid democracy together where you have to show that you understand the basics of that topic to be able to vote on it, but the education is free and you can keep retesting, and the basics don't show leaning one way or the other - just shows you understand the stated pros and cons so that massive populism doesn't happen. But if you don't want to come to understand it you can cede your vote to someone else who has passed that thing. That type of liquid democracy, that type of qualified educated democracy where it doesn't have to be educated across everything - it can be per issue - and where you're not just voting on a thing - you're helping craft the propositions - these completely change the possibility space of social technology we could go on and on in terms of examples but these are ways that the same type of new emergent physical tech that can destroy the epistemic commons and create autocracies and create catastrophic risks could also be used to realize a much more pro-topic world." - [Daniel Schmachtenberger](https://youtu.be/wO1WVguNQAM?t=4793)

^^ this one is until 1:35:50 "pro-topic world" - 16 minutes long
https://youtu.be/wO1WVguNQAM?t=5750

> "One of the challenges of solving the multipolar trap internationally is the inability to make international agreements and one of the reasons where either we don't make the international agreement because it's not even worth making because we're sure they're going to defect on it so why even bother, or we make the agreement knowing that they're going to defect on it and we're going to defect on it but we're going to say that we're keeping it and we know they're going to say they're keeping it we're going to spy on them and we're going to lie to their spies and all this kind of waste that goes into that - if the transparency to know what they were actually doing and them to know what we were doing was there, the ability to make and keep the agreement would be fundamentally different. So underneath multipolar traps is the perverse game theory to orient towards opaqueness rather than transparency and this is - you know- the whole nature of how many things are considered trade secrets in the market or national security secrets and - you know - all of the different types of security clearance and classification and special compartmentalized information and whatever, because we're trying to have information advantage - information asymmetry advantage on the other side and we don't want them to know what we're doing but we do want to know what they're doing and so we invest a lot in this but the opaqueness means that the agreements can't be made so the multi-polar trap is the only thing that is left." - [Daniel Schmachtenberger](https://youtu.be/8XCXvzQdcug?t=7618)

> "Does the ability to do attribution - specific verifiable attribution of where a particular harm is coming from - does that increase the capacity to create justice, to be able to bind it - totally. So is it possible that certain types of forced transparency can make it to where the ability to hide the harms that then have everyone race to do the harms goes away, and then the fact that they can be shown means there's a need to account for them and better methods of accountability emerge - I think there's a lot that can be done with forced transparency that orients towards a fundamentally better attractor of the game theory space." - [Daniel Schmachtenberger](https://youtu.be/8XCXvzQdcug?t=7769)

> "Are there ways in which transparent solutions win game theoretically as a different peak in the adaptive landscape relative to the opaque solutions? Why the opaque solutions win is very obvious - surprise attacks help - the ability to advance something where they don't know that we're advancing it, we mislead them about it, they build a false defense - it's obvious why the desire for information asymmetry in that way is there. I was talking to someone in national security of Sweden who was telling me some very fascinating things and I haven't been able to verify all of them, but saying that of kind of the major nations that have meaningful defense capacities Sweden has maybe the most transparent intelligence and military and security apparatus, and their underlying philosophy was that the major players are going to be effective with their spying and know anyways - they don't really get that much information asymmetry - that's more of an illusion of control than a reality of it, and so Russia and China and the U.S. are going to know anyways, and so the huge amount of resource that they would have to put into trying to hide from them is mostly a waste - so they're just not even going to try, and that if you have to try to hide the national security stuff from the quote-unquote enemy that also means you have to hide it from your citizens because otherwise your citizens don't all know how to keep classification which is why this thing pretty much makes democracy impossible in any real sense more than just a simulation. At the time of the founding of modern democracies and particularly I'll mention the United States here, the United States had an ocean on both sides to anybody else, it had no kind of contiguous rival - land contiguous rival - that was a pretty awesome security situation, and so the decisions that needed to be made about anything - including military things - could be shared with the people, the people could actually weigh in on them, and sharing that information with those citizens didn't instantly mean sharing it with the British or the Spanish or anybody else because there was no way to get that information across the ocean quickly, and simultaneously once someone else got that information they couldn't launch an attack that quickly - they'd have to launch boats that we could see that would take months, it would give us time to launch a response, and so the ability to share with the citizens was actually viable in that world because of those sets of reasons. As soon as we get to a world where whatever is being shared with the citizens can be known by rival countries instantly, because of electronic telecommunications and where they can then launch attacks instantly - including ones that are hidden with plausible deniability like cyber attacks or economic attacks or geopolitical positioning, let alone missiles - now the threat of sharing information with the citizens meaning sharing with the rivals is way too high - therefore more and more things become classified more and more things become national security secrets - obviously attacks on our water supply or our energy grid or our food supply could all be national security threats, so we start finding that there's national security secrets fucking everywhere! Well how do you do democracy if the citizens can't actually know what is going on and what the real considerations are - well you can't - it's a simulation of it. This is a real challenge that we have to think of in a deep way when we consider what does a participatory governance system in the context of the modern world look like, because it makes sense that there would be a black budget and it makes sense that there would be national security secrets but then how do you verify that those authorities are not corrupt? How do you verify that they are actually doing the will of the people, or how do you create checks and balances on power or adjudicate issues or things like that." - [Daniel Schmachtenberger](https://youtu.be/8XCXvzQdcug?t=7838)


> "When we talk about what is a desirable civilization it becomes a really tricky topic because it's like centrally existential questions, to say what is a good civilization - we don't have a system like science - this is kind of the is/ought distinction where science can say what is but not what ought - we don't have a as powerful as sciences for being able to understand the objective world which then allows us to create objective tech that affects the objective world - we don't have a comparably effective way of studying the subjective and inter-subjective world of being able to say good, right, and so if you have the ability to affect the world exponentially more powerfully through science and applied sciences, technology, but you don't have a comparably powerful force for what is good or wise guidance of that technology then what is guiding that technology ends up being game theory, right, and game theory is actually like the closest thing to something that is commensurable with the scientific system in terms of what is a good choice which is kind of the social darwinism of a good choice as a choice that doesn't lose game theoretically to other choices that are also seeking maximum advantage, but we can see that the advance of game theory under the presence of exponential tech in this way self-terminates so that clearly cannot be called a good choice. And yet losing in the near term is also not a good choice so we need something that is option D - none of the above. So while I think it is important for us to become as good at the type of mind, at the type of internal human capacity that can do wisdom and ethics as we are at the capacity to do science and technology, and to be able to think about what is a desirable civilization, I think we can start by agreeing on a couple things that are not desirable - and I think that's actually very helpful. I think the idea that a civilization that self-terminates is probably doesn't meet the criteria of what an optimal civilization is so that we are wanting to prevent the movements towards cascading catastrophes - that seems pretty straightforward - and that one that is clearly dystopic - meaning that there are such radical asymmetries of power, that the freedoms of almost everyone are radically curtailed - is also not an ideal case. And yet it's very easy to see that exponential tech has the ability to decentralize power as the market cases giving an example of, which creates these coordination collective action problems and multipolar traps, and so the decentralized exponential power creates multipolar traps creates increasing catastrophes. So then it also has the ability to centralize power - if I could have an entire nation-state - historically the nation-state couldn't be too top-down and too big because it would get fragile because you can't actually see what everyone's doing and control it, but the ability to have sensors everywhere and no person could make sense of that and you couldn't even trust the chains of command but AI systems could, and then getting everybody to spy on each other is tricky but being able to mediate that through sesame credit type systems - it could do that thing. So the exponential tech also creates way more powerful autocratic systems at scale - centralizing power - which brings us back to why the multipolar trap is one of the very deep underlying things to work on. And this also brings us back to the Swedish example that I did not complete of where transparency could win. So the example he was giving is that rather than invest any resource in opaqueness or you know hiding or cloaking stuff they would just assume that the rivals would find out anyways and as a result they didn't have to keep stuff from their own population in the same way - as a result the population has a way higher trust in government, as a result way less money has to be spent in campaigning and convincing people of things and there's more kind of emergent coordination and things like that and the various departments of government - and especially of the military - have more transparency to what each other are doing because they're transparent, whereas in the classification you don't just have overarching classification - you have this kind of special compartmentalized information process which means that a general in one area and a general in the other still don't know what's going on in the other domain - so that both means that duplication can be happening, it means that a lack of efficiency of coordination happens, and that particularly when there's too much information it kind of doesn't even matter to have access to all the information because nobody can process it - this is the infosingularity issue and we'll talk about this more. But when we have more computational capacities to process large information sets then it actually really does matter having transparent access to all of it - we can make progressively better sense of it with the right computational sense making augmentation. So their ideas - the transparency regarding things that would have otherwise been classified - doesn't lose us that much - it gains us a lot of trust in government which gains us a lot of discretionary participation of the citizenry and it also gains us the ability for the various departments of government and military to be in much more coordination with less duplication and less waste because they have more transparency to what each other are doing, it also means that it's much easier to check corruption because they increase transparency and so you have more efficiency and integrity and things like that, and as a result you lose the little bit of asymmetry of information advantage but you gain a lot of other kinds of advantages so it's a different peak in the adaptive landscape. I thought this was fascinating when he shared this with me and so I asked - you know - that's cute and all as a country that has EU backing which fundamentally has NATO backing - you know - indirectly, and that is not at the head of an arms race - do you think something like that could work for say the United States? His take was yes - it actually could work for the United States because the amount of capacity uplift that would occur - and this didn't mean he thought it was inactive - the the vested interest against enacting it would be ridiculous - but just hypothetically as a thought experiment if that kind of transparency did happen - the amount of duplication that's occurring is huge, the amount of corruption and waste that's occurring is huge, the ineffectiveness of coordination that could be lifted would be huge, the ability to start getting increased trust in government and as a result having the democratic and government sector be more coherent, aligned with the military sector as opposed to the increasing discoherence in the government public sector, and that even if some first attack capabilities were increased because of the information sharing of other parties - that our total strategic capacity and response and deterrence would still make it or nobody would mess with that that such a thing could be advanced, and I think this is a fascinating line of inquiry. So if say, more total strategic military capacity emerged out of the transparency than the opaqueness approach - meaning per you know, military power per dollar - then it would actually drive a race to the top on transparency where Russia and China would be oriented to try to do a similar thing because otherwise they'd actually be losing the multipolar trap that is now a race to the top on transparency rather than a race to the bottom on opaqueness which is increasing the capacity for international agreement rather than decreasing the capacity and fundamentally addressing the multipolar trap progressively better. If we think about having some forced transparencies through things like international satellite capability and open source intel capacities that kind of mess up the opaqueness anyways - can we make the opaqueness increasingly poor as an adaptive strategy, the transparency both more forced and more capable of actually winning - now we start to get a strategy where for the first time in history possibly something wins game theoretically that is also better in fundamental ways regarding its long-term viability, that the culture more oriented to peacefulness can actually beat the culture more... warring without becoming more warring in all the most problematic ways - it can maintain adequate strategic capacity while being oriented in a way that fundamentally is decreasing the types of pathological competition within the system and as a result driving races to the top between systems of things that are more positive sum and less pathological as a whole. Ultimately whatever... I would say threading the needle of something that is neither catastrophes or dystopias and without being able to wave a magic wand and do enactment at the level of the whole world at once - if any group were to do something the thing they would do has to not lose to the rest of the world not doing that thing - not just not lose but it also has to influence the rest of the world because if let's say we could get some country to do some very enlightened set of practices it still dies from climate change and AI and whatever so long as it doesn't change what the U.S. and Russia and China and other places are doing, so it has to actually be able to influence the whole world shifting but it has to basically be able to win in some critical influence ways where the nature of what creates the win isn't externalizing harm or driving arms races or whatever. So it has to both be obsoleting some kinds of destructive game theory while winning at some fundamental types of game theory at the same time - like so much the threading of the needle has to occur. And I think when we go back to the sub dunbar tribes one of the things that mediated their effective protocols was that there was very high transparency which allowed for pretty good coordination and not having collective action failures within the group - there was no real incentive for anyone to be sociopathic or narcissistic because nobody would want sociopaths or narcissists in the system and unless you can like bullshit people and hide it - that strategy doesn't pay - if everybody can see that you're lying in a small tribal scenario or they can see that you put your trash down or didn't do your part of the chores you're going to clean it up or you're going to get kicked out of the tribe. So that the smallness creates a force transparency, creates a situation in which what is best for the tribe and what's best for you are more closely aligned - I'm not saying perfect, but more closely aligned. When the groups get much larger - where somebody has the ability to play people off of each other who don't know that that's happening because there aren't enough communication channels, and be able to screw some people over here and then go somewhere else to get a new supply of people and whatever, then of course the ability to hide the effects of what I'm doing - I'll create a incentive for sociopathy and things like that, which is why we see that those types of power-oriented say cluster B personality disorders are something like three times more prevalent in C-suites and positions of more power than they are in the general population - it is that they are adaptive in those environments so they're selected for, conditioned, and incentivized. So of course we can get the high transparency and thus better alignment between the individual agents' incentive and the whole in a small environment but that has never scaled." - [Daniel Schmachtenberger](https://youtu.be/8XCXvzQdcug?t=8380)

^^ this one is until
https://youtu.be/8XCXvzQdcug?t=9142

> "If we want to be able to scale it - are some of the new technologies that allow for certain kinds of transparency and then certain kinds of information processing across larger scale and communication? Could they facilitate better methods of collective intelligence that notice perverse incentives and as a result of noticing them and being able to create accounting for them, and externalities - be able to create accounting for them, create progressively better incentives, and more capable deterrence to align the motivations of individual agents with the whole better? I believe so. I believe that some of the exponential computational technologies in particular that portend the fastest and worst existential risks in many ways also portend the possibility for better coordination systems. And I'm not talking about AI disintermediating humans and having some AI singleton run the world - I think that's a really bad idea for lots of reasons. I'm talking about AI being able to facilitate human collective intelligence - AI amongst other capacities. Where I don't want artificial intelligence making the decisions by itself in most scenarios, I want processes of collective intelligence of humans making it, and we can get into obviously people voting yes/no on a binary proposition where both sides/versions of the proposition suck: if it goes through it benefits something and harms something else, if it doesn't go through the thing it would benefit is now harmed because the proposition was just designed stupidly to begin with - it didn't factor how interconnected everything was, so the yes/no on it can't not polarize the population. That's just a stupid system of collective intelligence. We can just do much much better: where before you make a proposition you actually do the sense making of what are all the interconnected things, what are all the values, you take those as design constraints to go through a better proposition crafting process of what is the best synergistic satisfier with the least theory of trade-offs possible, and what are better voting systems than binary that inherently polarize the population. So I think we can do a radically better job of systems of collective intelligence and a radically better job of education of people to be able to participate with these things, and an incentive system where as people become more educated in topics they actually get more ability to influence those topics. We could get into that - it's beyond the scope of this initial introduction. But one of the issues is that where there's more information that anybody can process - the information singularity: there's more journal articles on a topic than any expert can read so nobody can ever be an expert on anything - how do we solve that? One idea is we don't and we simply need AI's to run the world, the other idea is we have to be able to merge with the AIs through some kind of brain computer interface or something like that. I would say another version is that when you look at even the current state of generator AI which is really not advanced compared to what will be a year from now or five years from now because it's advancing so rapidly, but you look at the current state which would be say GPT-3 today (OpenAI) - it can use exclusively natural language input - I don't have to be able to program - I just speak to it, and it understands my words and it does stuff based on understanding the words - that's amazing! Go watch the DALL·E and the GPT-3 demos on YouTube to just get a sense of what they can currently do because it's mind-blowing and the only thing more mind-blowing is the speed at which it's advancing. The destructive capabilities of this don't take thinking very hard to imagine and they're very near-term. The beneficial cases but that are narrow are also really obvious. The omni-beneficial facilitation how do we create better collective intelligence and governance writ large is not as obvious until you really start to think about it but then it is amazing I feel. And this is not a techno optimist answer - I'm very acutely aware that the technology on the current trajectory is most likely catastrophic and what it takes to make the other version of it is value systems that have to be able to bind, guide, and direct it and influence social systems that create the capacity to bind, guide, and direct markets and technology in a way they don't currently have. But it is saying that the technology is new capacity and that that capacity if rightly directed does make new things possible. In the same way that the printing press made democracy possible where it wouldn't have been before because without any newspapers and without textbooks you can't have a comprehensively educated and informed society. When hand copying a book is so hard and expensive - only a nobility class with the wealth can have access to it. Of course that technology of the printing press did make possible different types of coordination than was possible before. Obviously the internet: anybody talked to anybody anywhere in the world & made possible different types of coordination, make possible and orient it to happen that way or different - while most people could use their phone to access any information in the world, what they end up doing on it is usually not that interesting examples because of the nature of the choice architectures that they're engaging with in their user interfaces, and the choice architectures are that the user interfaces that they engage with have goals for them that are other than that person's highest goals for themselves - and they're effective. So this is not AI will save the world, it's also not AI will necessarily destroy the world - this is a: since we have the power to create such powerful technology we need the orientation to think about what wise application of that technology is, and the intersection of comparable wisdom to guide, right, design, and development of that technology that in turn then is developing wisdom and everyone else based on their interface in the same way that Facebook can increase - and it's a known thing: you can change the algorithm that is affecting what's in people's newsfeed and they get more depressed or suicidal or more body image issues or not or because we're affected by what we untake - could we create information platforms that rather than doubling down on my existing bias were oriented to help expose me to information that is antithetical to the things that I currently think but in the most compelling cases so as to increase my kind of dialectical awareness, that rather than orient me to more people that are like the people I already know that orient me to people that are most unlike the people I already know to increase the total connectivity of my network, that rather than maximizing for things like my engagement and time on site it was maximizing for things like as I was showing the capacity to take and synthesize more perspectives the content that did that got upregulated in the algorithm, right, are there ways that that same type of technology could be applied that would be wisdom advancing? Of course this sounds scary because like who's idea of wisdom and who's going to control that, but it's important to get it's already doing it, right, it's already controlling minds at scale. So it's not a question of do we do it or not - it's how do we do it since it is happening. And now the core question of: well how do we adjudicate what is right use of the technology when you realize that the technology is not only radically affecting the earth physically, but radically affecting our mind, society's cultures. Now this again: the wisdom of gods to deal with the power of them becomes central. What is the right use of that? What are wrong uses? Where should that be bound? How do we understand this? How do we make sure that the binding a particular application of a problem doesn't make another worse problem? So we don't like a particular kind of partisan-led censorship, so we want more free speech, but if a particular approach to free speech also means a lot more ubiquitous deep fakes and an upregulation of the worst voices because they get the most tension that creates eliciting of violence and the breakdowns of democracy - it's like: okay, the obvious answers are all wrong, right, because the problem space is more interconnected and more complex, so we have to hold all those problem spaces together and think about it. But we come back to this: you know GPT-3-like AI type tech solving the info singularity - so when you put something to GPT-3 it's not going to find an existing web page for you the way that a search engine would - it can generate bespoke content, right, you can say "write me an article in the voice of such and such with it factoring these kinds of facts and orients towards this kind of conclusion and whatever" and it can do that! And progressively more and more effectively, more and more turing tests passing across more domains. Well what if that just becomes the future of search? Where if I'm searching for the information that could inform a particular choice we're wanting to make, or wanting to do something regarding grid security, but grid security - I need to know all the things about what really affects good security, and what other environmental and national security and you know et cetera issues are connected to that. Right now I can get billions of search results - I can't read billions of search results - that's not useful for me. Can the AI read billions of search results, find the information that is decision informing based on parameters that I'm specifying and create new bespoke content that is the synthesis of that for decision informing - not decision creating. The groups of people doing collective intelligence are still making the decisions, but now with the ability to take a synthesized or refined set of more information than they can process - that is pre-processed into decision-making information - now you say well fuck, who controls that algorithm because that's a big deal? What if you can do it lots of different ways? What if you can put different criteria for how to inform it and in the collective intelligence system all the agents have the capacity to do that kind of thing? There are heaps of challenges and problems that we have to solve here but this is an example of ways that coordination technology... The multi-polar trap is a coordination failure, it's a collective action failure, the dunbar number can be thought of as an upper boundary of a particular type of coordination capacity where everybody can know everybody and see what everybody's doing, talk to everybody, and so the collective activity is able to be bound through very high bandwidth communication. Once we start getting larger than that - early empires - we got command and control hierarchies and we started to get all the problems that we see in the world today, that are now - at the scale that we are - driving catastrophic risks. Democracies where how do we have a much larger system or rather than have somebody at the top rule whether it's one monarch or some small kind of nobility class or whatever - how do we at least have - since we can't get everybody at scale to agree - we could maybe get everybody at a tiny scale to agree but just a minority agreeing seems like a bummer. Can we at least get a majority to agree, but then of course that thing intrinsically ends up driving polarization and its own decay. And so can we make the types of transparency and the types of incentive alignment, the types of capacity for deterrence that would exist at a small tribal type scale possible at much much larger scales where the increase in effective coordination starts to be more effective, right, you start to reduce a huge amount of waste and duplication and failures of those kinds, and so what makes this thing adaptive and selective in a kind of game theoretic situation is also what makes it healthy in terms of the health of the people inside, in terms of classes - people relative to each other - and its relationship with the environment. I think that something like that has to be the answer and I think that it's interesting that the technologies that have the most destructive capability I think also have the most and uniquely facilitative capability for solving collective action or facilitating us solving collective action problems." - [Daniel Schmachtenberger](https://youtu.be/8XCXvzQdcug?t=9142)

> "If we were to talk about what is a third attractor: it's not going to be a top-down singleton which will end up being dystopic, it's not going to be many different actors caught in multiple traps with each other. It's going to be something where the system as a whole has the power to be able to check the catastrophic dynamics within it, but without having power consolidation itself - where the system has a kind of coordination across decentralized capacity, so centralized emergent coordination across lots of decentralized capacities. This is of course the idea of what democracy is trying to achieve and we can see why it was partially successful, and then why it failed and got captured under advancements of technology and complexity and financing like that. But can we build something with the very best of the knowledge and information technologies available to us now that makes coherent choice making that factors the total collective intelligence and total collective agency with the speed and coherence of what a small number of agents would have, and yet without any kind of centralized power? Well we can say that something like that is part of the criteria set of a third attractor of a desirable civilization that is not catastrophes or dystopias." - [Daniel Schmachtenberger](https://youtu.be/ZCOfUYrZJMQ?t=829)

> "I think there is a humongous amount of what we are perceiving about human behavior that is physiologically mediated a lot. And then also mimetically and culturally mediated, and I think the exploration of the full phase space of what could happen to both attenuate the negative contributors and advance all of the different positive contributors, and what the potential of the whole of that space is, is really profound. If we think about things like watching how quickly a technology like social media (like Facebook) can increase people's enmity towards their fellow citizens of the same country - to the point that both sides are oriented towards war - like so rapidly can vitriol and anger and whatever get stirred up as a result of just the media that people are being exposed to - out of the so much stuff what is being concentrated by the AI that's selecting for me. Could that same technology, curating with a different set of purposes, that was bias correcting rather than doubling down on bias, that was helping people connect to much wider networks rather than tribal networks, that was helping to up regulate more synthesizing and nuanced responses rather than other ones, could that affect culture and intelligence and disposition at scale in a way that no religious prophet could have ever dreamed of historically? Totally." - [Daniel Schmachtenberger](https://youtu.be/ZCOfUYrZJMQ?t=4869)

> "I hope the attractor of cascading catastrophes or control mechanisms that prevent it, but create dystopias, create a framework for what we want to avoid. And that a third attractor that has the intelligence and regulatory power to avoid the catastrophes while having checks and balances on itself to be non-dystopic, that the creation of a world system that can do that should be the kind of central innovation goal of the world - of which everything is an element or a subsidiary part, and that more total collective intelligence and innovation and motivation being focused on these issues is worthwhile. And I hope that rather than creating a sense of doom or overwhelm, that what this information might create is a sense of almost like a validation of something that has been intuited - an increased sense of clarity that makes the complexity of the challenge space at least start to feel tractable, and because if it is apprehendable, and if there are at least thought experiment-wise possible solutions, then there is a direction of endeavor, and to have more people feel that hopefulness that is not the naive hopefulness of not being aware of all these problems, but the hopefulness that comes on the other side of being aware of all of them and seeing what it would take to move through that, and be oriented to that - that's what I hope becomes of this." - [Daniel Schmachtenberger](https://youtu.be/ZCOfUYrZJMQ?t=6214)

> "This is exactly the centre of what I'm focused on: the problem is fundamentally the inability to coordinate between agents where their basis for agency intrinsically has deltas - right - there's a what's best for me in the current system of a private balance sheet and money and those types of things - what's best for me is not what's best for you and best for the commons - even though it would be over the long term, over the short term it doesn't seem to be. And so everyone is doing utility maximization functions but with again, unlike evolution, with asymmetric power relative to the environment and supply-side relative to demand side and things like that, and this then ends up creating a situation where it gets worse - like this is actually a very important point - if I have true information about the nature of reality, that is a source of strategic competitive information so I want to withhold that information (we call this a trade secret or classified or confidential information or intellectual property) but I don't just want to withhold that - I also want to make sure to throw anyone else that would figure it out off the scent trail so I want to do not just withholding of information but disinformation, and we have a situation where everyone is incented to do withholding of true information and signaling of disinformation, and then we have information technology that's exponential information technology where I can do customized disinformation for different persona types and all the way down to individuals - we get to a world where we stop being able to parse signal from noise because there's so much radical disinformation and we have a situation where a coordination actually becomes impossible because of these agency issues everywhere. It's supposed to be the two different intelligence agencies within a country perfectly coordinate with each other to support that country because they're all on team country, right, Team USA against the Russians and the Chinese and whatever, but really those two different intelligence agencies are also competing against each other for a larger percentage of the budget, and then even to different departments within that organization and even to different people competing for the same promotion will withhold information and maybe even disinform, engage in corporate politics - corporate politics is where someone's optimizing their own bonus structure and their fealty relationships at the expense of what's actually good for the whole because they're not actually coupled to the whole effectively - and so you get a situation of fractal defection - everybody defecting on everyone to some degree while signaling that they're not doing that - and this basically means a catastrophic breakdown in the sense making necessary to make good choices while having an exponentially increased amount of choice making power. And if we think about that, exponentially decreasing quality of sense making relative to the overall situation with exponentially increasing choice making power - that's another way to think about inevitable collapse." - [Daniel Schmachtenberger](https://youtu.be/9psdN65IzOw?t=2330)

> "So why do we get so much concentration of sociopathy in the top of fortune 500 companies and politics and then especially things like finance? Well because they're basically systems to attract, reward, incentivize, and condition sociopathy, because to get to the top the power game it's going to be people who are attracted to power and people who are good at winning a bunch of win-lose games, because at each step they move up the ladder they're winning against somebody else - usually via involving things like disinformation and defection and whatever it is - and so if you think about the nature of what a government or a corporation or any top-down power system are - it is basically a strange attractor for people who want to have power over, for people who are running power dynamics, and this is why, you know, let's try and say that I have a benevolent dictator - well there's a reason that we don't get sustainable benevolent dictators is because let's say I have a benevolent dictator - and we can get this in a corporation from great founder Theory sometimes, because if the founder holds the you know, majority of stock or whatever, but it never out lives them, and usually they end up getting kicked out. So let's say I have a benevolent dictator. All the people who are one step under them are doing things that they require to be able to stay as a dictator because it's pretty easy to kill somebody or to oust them or whatever, so if I'm at the top of a top-down power system I have to keep everybody under me preferring me to be above them rather than overthrow me, which means that rather than do what's best for everybody I have to do what's best largely for those who are right near me, and they have to do that for those who are under them, and that ensures a kind of power law distribution of power and again there's like a multipolar trap on corruption - if anyone's willing to do a really fucked up thing to try and overthrow me, I have to be able to play at the game of fucked up things or I get overthrown. So we can see how top-down power systems are going to both attract, condition, reward, incentivize things like sociopathy and so then we end up having a world run by sociopaths which is not a good thing for anybody. But now let's think about something like a tribe - and I'm not gonna over romanticize here, I'm just kind of thinking through the dynamics in a first principles way - if I've got 40, 50, 70, up to a Dunbar number of people living in a tribe there's an extraordinarily high degree of transparency that is forced in that scenario - everybody pretty much sees everything that's going on with everybody and everybody knows everyone, everyone has fealty relationships with everybody in the tribe. So sociopathy is not gonna be advantageous - you're not going to have an evolutionary niche in that environment for much in the way of conspiring and lying, because it will get found out and it will get punished, and so the forced transparency creates an accounting system where you don't get an evolutionary niche for somebody fucking the other people in the system. And so as soon as the system starts to get large enough that 1) there's anonymous people so I can harm people who I don't really know and care about as opposed to everybody who is in the system as somebody that I know and care about, and 2) I can do stuff that people won't be able to see I can kind of have a corruption of the accounting in the system - now we get an evolutionary niche for rather than participating with the system - doing internal defection. I'm not externally defecting and leaving the system - I'm internally defecting and playing the system. And that's what most everyone inside of a corporation or a government is optimizing - what is good for them and their direct fealty relationships rather than what's good for the whole, and nobody can tell. And this is a particularly hard scenario, but the reason I'm saying this is because we do our social science inside of a world where these systems have become ubiquitous, and then we assume that those properties where there's ubiquitous conditioning, are intrinsic to human nature and I think we have to be very careful about that - I think a lot of them are not intrinsic to human nature - they are a result of the ubiquitous conditioning and we could create conditioning environments in which things like sociopathy are just not advantageous and so they don't get up regulated." - [Daniel Schmachtenberger](https://youtu.be/9psdN65IzOw?t=3104)


> "Let's say that I'm one of the richest people in the world today - I'm Bill Gates or Warren Buffett or whatever - there's really important stuff that the world could produce that it can't inside of capitalism that I don't have access to and this is actually kind of everywhere and it's really basic: the best phone the science could make involves some intellectual property owned by Apple and some owned by Google and some owned by a few different companies and the same is true with the best laptop and the best car and even with billions of dollars I can't buy that thing. And all the things that I can buy are produced by someone where not only do they have limited IP but they also have whatever designed obsolescence and desire for proprietary stuff so you use the rest of their ecosystem stuff so it's not interoperable - I have to deal with that shitty suboptimality even from the richest guy in the world." - [Daniel Schmachtenberger](https://youtu.be/9psdN65IzOw?t=4122)

> "What could provide increased capacity that can't be weaponized? That's a very interesting question. We could say that every technology that increases capacity can be weaponized - meaning: can be used by some agent to increase their capacity relative to other agents or the commons. Except if we had a social technology that was anti rivalrous, but it actually produced increased coordination capacity - you actually can't weaponize it because it is the solvent for weapon ization itself. It is actually the basis of how agents interact in a way that doesn't incentivize weapons and so for anyone to instantiate that thing they are actually changing the nature of their agency. So in the current system, again, private balance sheet, I'm in a big corporation, I'm gonna do the thing that optimizes my bonus structure and my status in the company - even if it fucks other people in the company and the company as a whole and that might include spreading disinformation, withholding information, etc. Well let's say I could create a situation where I couldn't get ahead of the expense of the whole so I had both the right kind of transparency and accounting systems and access to Commonwealth resources where only as the Commonwealth does better do I do better and things like that. Then we can have a situation where no one... Let's just say if we could invent a situation in which no one had an actual incentive to spread disinformation or to hoard information, if they shared true information - maybe they'd be wrong but they at least had the incentive for full earnestness and full transparency - if you had a situation where that was the incentive - you figured out how to do that - and I will say there is a way to do that, I believe there's a way to do that - then you would get a situation where you had an information ecology that was actually intact at a larger scale. That would lead to radically better capacity to coordinate and innovate - better sensemaking than the current system has - in that system as a whole would be more effective at producing all of the metrics that matter relative to total resource per capita than any current system would be. And I only need a small number of people - relatively small number of people - who get that and want to instantiate it as a new full stack civilization to create a new strange attractor or a new attractor basin, where anyone else looking at it says 'Well quality of life is higher on every metric there and they're also able to innovate us on a bunch of things, they're figuring out solutions to that we don't have, well then why don't we just kill them? Well because they aren't trying to win the game of power against us, they aren't building militaries or signaling or narrative warfare to try and beat us, and actually they're exporting solutions to us that we need to the rest of the world, because if they have increased capacity to innovate and solve problems, because they can actually coordinate better, because they don't have disinformation information withholding' - then they can look at what groups that would otherwise have enmity with them actually need - develop those solutions and create dependents rather than enmity relationships while simultaneously saying 'If you want to know how to do this as well, we've actually open sourced it - it's a social technology, you're welcome to use the social technology' - but the social technology will fundamentally change your basis for agency if you employ it. So obviously there's a million things we would need to dig into there, but just the thought experiment goes: fast adopters build a new ground-up system where the new ground-up system becomes a new attractive basin and - you know - that's a way of thinking about that I don't try and... If I have to shift at the level of axioms I can't retrofit current system - I have to build something, but if the thing that I build is fundamentally more attractive ground up, then I only need fast adopters to understand it in concept to have medium adopters understand that after seeing its implementation." - [Daniel Schmachtenberger](https://youtu.be/9psdN65IzOw?t=4517)

> "Whenever something becomes the legitimate authority on truth for a topic it's extraordinarily powerful because what everyone else thinks is real, which is the basis of how they're going to behave, is actually like at the bottom of the stack of power. And so even if a legitimate authority emerges rightly - because it's actually earnest and doing better empiricism and whatever - as soon as it starts to get that power there will be maximum incentive for all of the power players to try to corrupt it and influence it in various ways, which they usually can because which science is going to get funded is going to be based on someone who has funds putting money into something that will continue to support or advance them having funds. And so even if, say, a piece of science is technically accurate - it's not wrong - it might be that only certain topics within a domain that have ROI more associated get funded - other ones don't, like for instance you know, patentable small molecules and pharma compared to peptides or biologics or plant-based things. And so then the preponderance of research doesn't actually map to the overall space well, so even things that are true can still be misrepresentative or misleading - so this problem that legitimate authority within an economic game theoretic environment will always get captured or influenced to various degrees and so how do we address that." - [Daniel Schmachtenberger](https://youtu.be/3lil4invvSI?t=1890)

> "We need to have governance - I'm going to separate governance as a process and government as an established top-down enforcement of rule of law with monopoly of violence. We need to have governance at the level that we're having effects - meaning we have to be able to actually make sense of the effects we're having and factor that into the choices that we're making, and when we have planetary effects on the atmosphere and the ocean and etc. but we don't have planetary governance, then we just get multipolar traps where okay, we don't want to fish all the fish out but if we can't make an agreement that China or somebody else is going to also follow and they're going to get ahead economically and the ocean's still going to get ruined then they're going to use that economic benefit to damage us - not only will we not make an agreement to manage the commons - we actually have to race to fish all the fish out faster than they do, or make AI weapons faster than they do, or whatever else it is that's exploitive. And so not having global governance when we're having global effect leads to catastrophe, but having global government of the types that have only ever become corrupted and then as a result broke down also leads to catastrophe. And so we need something that is different than either of those things that have been imagined so far." - [Daniel Schmachtenberger](https://youtu.be/3lil4invvSI?t=2035)

> "Very few civilizations since the beginning of civilization until now have been republics or democracies - they've almost all been feudalistic or autocratic of some kind and that actually makes sense, because one guy ruling everything or some very small number of people that can talk, coming up with a consensus, and then being able to rule is way easier than getting a huge number of people - mostly who are anonymous to each other - to all actually be able to make sense of the world and coordinate. Like a large number of people coordinating is actually a very expensive tricky thing, and from the way I see it, throughout history the few times democracies emerged - they emerged following cultural enlightenments that had a few things in common. When we look at the Athenian democracy coming out of the Greek enlightenment: stoicism plus the Aristotelian school and - you know - a few things had caught on to the place where they had a cultural value around education, that everyone would learn formal logic and everyone would learn rhetoric and history and - you know - those types of things, plus the kind of stoic culture where they're all learning emotional regulation and the socratic method where they're learning how to take each other's perspectives, debate any side of a conversation. Well if I have a bunch of people who are trained to be able to assess base reality clearly on their own, they have emotional regulation so they are not as susceptible to emotional and cognitive hijacks and groupthink and have the courage to disagree and things like that, and they can take each other's perspective and they're actively seeking to - well those are the prerequisites to something like a democratic system being able to emerge because those people can have a good quality conversation about shared sense making, recognize that some compromises to agree are better than warfare with each other and come up with solutions, so collective choice making emerges out of the collective sense making, meaning making and conversation ability. And our country similarly coming out of the post-european renaissance enlightenment phase was - you know - the idea of renaissance men, renaissance people who could have expertise across a lot of topics - not just be specialists - because specialists across different domains have a hard time being able to communicate really effectively towards governance that requires looking at a lot of those things, but the idea that we could become renaissance people, that we could all have empirical capacity, the scientific method, and the hegelian dialectic - that we could hear a view and then seek the antithesis to that thesis and then seek a synthesis - some higher order reconciliation - that again gives rise to the possibility of participatory governance. And you can see when you read the documents and the letters of the founding fathers - and of course there was a lot wrong with the Athenian democracy and a lot wrong with our country that had genocide and slavery as parts of its origin, but the whole world had genocide and slavery as parts of what were going on at the time and it was at least moving in the direction of increasing participatory style governance - the thing that the founding fathers talk about so much is the need for very high quality universal public education and very high quality fourth estate that's independent - or news as the prerequisites of democracy. George Washington said - I'm not going to quote exactly - it's something to the effect of that the single most important goal of this government should be the comprehensive education of every single citizen in what he called the science of government, and I think the science of government is such an interesting phrase because we've separated science and the humanities so formally, and the science of government would be history and game theory and political theory and the things that people need to know the shenanigans that happen so that they can prevent them, and Franklin said 'If I could have a government without news or news without a government - I would take news' because if the people really know what's going on they can self-organize and overthrow government - if the people don't know what's going on they can only be captured. And our public education or education of any kind here in the kinds of civics that people would need to really understand what's happening in government and understand regulatory capture and be able to bind it obviously is close to non-existent and the news has been mostly captured by economic and political interests, so there is no chance for a bunch of people that identify as being in almost tribal warfare with each other, who aren't sense making reality well, who don't understand governments, who don't really understand markets, who only have pejorative strawmans of each other and don't seek each other's opinion - those people can't do a republic or democracy, so it will simply devolve back to an autocracy which we see happening. And the way I think of it is like: if there's a bodybuilder who has a huge amount of muscle - the moment they stop working out they start losing it, because it's very expensive metabolically to keep that much muscle - they have to kind of keep working at it - it's very expensive to keep an entire population comprehensively educated and actively engaged. And once it seems like the government's working well and a generation passes and the kids didn't go through the pain of the revolutionary war and the grandkids didn't - it becomes very easy to just get engaged in your own stuff and not keep participating in the governance and then you stop having a government of, for, and by the people - and you start having a class of people that do government, and when the people stop checking the state - the state stops being able to check the predatory aspects of the market, which is what it's really intended to do - and then the market ends up capturing it - you get regulatory capture, and then rather than liberal democracy you get a kleptocracy that eventually becomes an autocracy. And that's what I see that we have right now - and so do I trust any particular authority to arbitrate truth or good faith or whatever right now - no. Do I trust a collective intelligence that's actually increasing in its authentic intelligence - I would trust that much more - it's an expensive hard proposition, but I don't see any other good choices." - [Daniel Schmachtenberger](https://youtu.be/3lil4invvSI?t=2335)

> "So partly it has to do with scale - for sure - which is... the founding fathers thing here - there was an idea that everybody could go to the town hall and discuss the issues that were mostly geographically close to them, that everyone could sense base reality on their own, and you could have a small enough number of people in the town hall that for the most part the people who had something to say could actually say something about it. And when we moved to a place of most of the issues are globalized - whether we're talking about finance or supply chains or environmental issues or - you know - geopolitical ones - obviously that's a level of complexity where people can't depend on their own base sense making and they can't process that much information and second and third order effects and confounding effects as well. And one topic I'll just enter here because we haven't discussed it yet is the concept of hyper objects, which is connected to but a little bit distinct from just raw complexity, that we evolved to be able to apprehend and understand objects that were available to our senses, and when I'm talking about something like climate change - I can't see climate change, I can't taste it, I can't hear it - I can only conceptualize it, I can see a drought, I can see a fire - there have always been droughts and fires, but to understand climate change I have to think about some kind of statistics and complex mathematical models on the droughts and the fires. I also can't see world hunger - I can see a hungry person somewhere, but I can't actually directly apprehend - I can only do it conceptually, which also means I don't have the same felt visceral experience of the things, and the same is true with I can't actually directly see or apprehend AI risk or biotech risk or nanotech risk or or the nature of markets, and so we have a world where the most influential things are mostly all not apprehendable to the senses, and so we have not just the issue of can we have a better felt sense or our intuitions are more right, that our kind of sensibility of what's likely true as well as our kind of formal analytic thinking - can we get hyper objects but then can we get the connection of lots and lots of hyper objects - markets interacting with social media environments, interacting with climate, and things like that - and I think it's just important to kind of state that, to have a sense of how different the problem space of the things that we need to understand and think about are now compared to the evolutionary problem space most people had to think about, and how different the kinds of collective sentence making need to be and choice making need to be, and then I'll also step back and say even in environments where we weren't dealing with as much in the way of complexity and hyper objects - our sense-making was actually usually still adequate to solve local problems in ways that very often caused other problems somewhere else or down the road - and this is an important part of understanding this is like the model that we can look at all of our problems as a result of either conflict theory or mistake theory - conflict theory meaning we know we're going to cause harm somewhere and we're doing it anyways for game theoretic purposes, mistake theory as you were mentioning with Facebook we didn't know this was going to happen and it was simply an unintended externality. So we have to deal with both moving forward - how do we remove the basis of conflict theory so no one is motivated to do things that will knowingly harm something else and how do we also deal with the mistake theory of being able to anticipate externalities and internalize them into the design processes better, and so the mistake theory side - you can go back to - we didn't necessarily know that the development of stone tools would lead to us becoming apex predators that were increasing our predatory capacity faster than the environment could become resilient, that led us starting to extinct species at scale and then become the apex predator in every environment and start the anthroposcene, or you can come to a closer one and say when we were making the internal combustion engine to solve the problem of the difficulty of horse husbandry pulling buggies - we didn't anticipate that in solving the horse husbandry problem that we'd be causing climate change and oil spills and wars over oil and the U.S. petrodollar, and so typically if we're going to make a solution that solves a problem - the solution has to be somehow bigger than the problem, faster, whatever - to be able to scale and overtake it to really solve the problem, but if we define the problem in a narrow way - there's one or two or some small number of metrics - and the solution we're trying to create has a first order effect on a small number of known metrics, but it might have second and third order effects on a very large number of unknown metrics - we can see that the safety analysis is actually harder in kind than the solution analysis and this is something that we actually have to start factoring - I don't just need to understand the problem I'm trying to solve - I have to understand the problem embedding landscape of the adjacent problems and the adjacent topics and the adjacent meaningful things and I have to start thinking through second and third order effects better - whether I'm designing a proposition or designing a piece of technology or designing a company to solve a problem - to say if that solution's effective, what other things is it likely to do and what harms could that cause to complex environments and then how do we actually factor that into the design process." - [Daniel Schmachtenberger](https://youtu.be/3lil4invvSI?t=2937)

> "Before we discuss a perfected system we can just discuss how to stop some of the most egregious things about the current system. Current system - people are radically certain about things that they have no basis to be certain about and it's actually their false certainty that causes most of the problems - if they simply acknowledge that it was too complex and they didn't know - they at least wouldn't be going to war over dumb stuff, and to so to simply be able to have people be like 'I don't know yet but I'm interested and I'm gonna try to seek to know better' would actually slow the rate of breakdown tremendously." - [Daniel Schmachtenberger](https://youtu.be/3lil4invvSI?t=3412)

> "Do I think that we can get the hierarchical complexity or the ability of people to process information up? Yes. Even before that - if I can start getting them a memetic immune system to where they aren't just cognitively and emotionally hijacked - right now it's mostly not even 'can they do good epistemology' - it's that they're just captured by narrative warfare - if I can simply get a memetic immune system where people start to notice how [Russell conjugation](https://en.wikipedia.org/wiki/Emotive_conjugation) and [Lakoff framing](https://en.wikipedia.org/wiki/Metaphorical_framing) happens - yes that scientific article said something, but the news article put spin on it - can they notice how the spin's occurring? Yes that's a true statistic but it's cherry picked - when you look at all the other statistics it doesn't look like that same picture at all. And people start noticing those kind of info and narrative weapons and become inoculated enough that it's not like absolute lowest common denominator collective intelligence - that will make a huge shift, so we have to factor the kind of memetic emotional immunity and cognitive immunity topic, then better epistemology for the individuals and better orientation towards socratic dialogue, hegelian dialectic - like seeking shared understanding because of understanding the need to coordinate being less bad than warfare & not coordinating. Then I think we start to get emergent collective intelligence where more sovereign and intelligent people and better conversations start to produce systems of coordination to bottom-up effect where those systems of coordination produce a top-down effect that continues to incentivize that bottom-up effect better and you get a recursive process between better systems of collective sense making and choice making and better development of individuals and their communication capacity with each other." - [Daniel Schmachtenberger](https://youtu.be/3lil4invvSI?t=3993)

> "As much as a lot of people think that we're too aware of our problems and we just need to focus on solutions - I actually think that it's a very deep misunderstanding of the real nature of our problems - that is one of the keys. People think the problem is climate change or the problem is systemic racism or whatever the thing is that they're focused on, but what are the generative dynamics that give rise to it and how is it interconnected with the other issues in the world where if you try to change it in a particular way it will externalize harm elsewhere and or fail? So the problem isn't climate change or U.S. China relationships or GDP or it's how all those things fit together and the system incentives of the underlying systems." - [Daniel Schmachtenberger](https://youtu.be/JBU06Wswc7c?t=1267)

> "I do believe we're at the end of History - like eminently in the lifetimes of everyone in this room we're at the end of History - meaning we're at the end of a human civilization defined by the major defining characteristics that what we call written human history from early Egypt or Sumeria or whatever was defined by, which is... if you had a peaceful civilization and Genghis Khan wanted that area or Alexander the Great wanted that area your peaceful civilization was wiped out, and the same is true if you want to internalize all of the cost of carbon: your country is going to get destroyed geopolitically by whoever externalizes that cost and concentrates the profits, that the thing that has been more successfully dominant: extracted more, grown its population more, increased its violence capability wins, and that thing with exponential tech at planetary boundaries self-terminates. So either we're at the end of our species or we're at the end of our species being defined by those parameters. And the end of our species being defined by those parameters requires I think... the last thing I'll say when I was thinking about the Nazis and everyone else in those situations is the famous quote - lots of people have said a quote like this - that it's the complicity of the weak with the wicked that allows the evils of the world to happen - most of the Nazis were not Hitler, but Hitler couldn't have done shit without a lot of people who obeyed, most of the Mongols were not Genghis Khan, most of us are not the people that make the choice to make up bullshit reasons for wars that are a false flag for truly economic and geopolitical reasons, but we will still not get in the way of that thing happening - the Iraq war that started all of the recent rounds of wars because of the weapons of mass destruction that we knew they didn't have - where are the prosecutions for that, because four and a half million people were murdered as a result of that? There are a small number of people who are motivated by power exclusively - pretty exclusively - and then there's most everyone else who just needs to pay the bills and not rock the boat too much and wants to feel like they will do good things within the confines of that, so I guess I don't want people to think about how to make their own life regenerative because it doesn't matter, I don't want people to think about how to make Sweden regenerative - I want people to think about what it would take to turn the entire arc of humanity, factoring what is currently driving it, and that everything else that you could do doesn't matter at all because the end of the possibility space of all meaningful human activities is eminent if we don't do that." - [Daniel Schmachtenberger](https://youtu.be/4kBoLVvoqVY?t=943)

> "And then we have to look at the underlying drivers: why can we not stop this thing? Why is it that literally no country, no company in the world wants climate change? Nobody is like: climate change is the world that I want. But we're orienting to it so fast and we can't stop and nobody can stop it because we all want stuff that requires energy that is driving that thing, and nobody wants species extinction, and nobody really wants to live in a world with automated AI weapons but we're all racing to build them. So what the fuck is actually driving the world to a world that literally nobody wants? I think there's a deeper analysis of that and the market is a part of it. **HOST:** ... **DANIEL:** Think about the scale of the market for a minute - you have something like a 100 trillion dollars exchange hands every day and as has been made clear, all of that involves energy that is involving mining and fracking and extraction and pollution on the other side. Even the services sector depend upon products so all of it has a materials footprint. It all requires central banks, it all requires militaries - nobody gets to make money in that contract hold without the military that holds the monopolies of violence and everything in place that keeps that economic system going. So all of those dollars - the taxes - they pay and whatever are supporting that whole system. So Norrsken is one of the probably larger impact companies around and if you have whatever - a few hundred million dollars to invest - and we're talking about a 100 trillion dollars a day of activity that is right up at planetary boundaries and at the verticalizing part of the exponential tech curve - how do you leverage any activity to be able to affect 100 trillion dollars a day no longer being harm externalizing? That's a question we have to take really seriously. But so that's the size of the economy today and it's obviously growing exponentially just to keep up with interest and if we didn't grow exponential you wouldn't keep up with interest the financial system as we know it would collapse. So we have a financial system - how we meet our basic needs depends upon - that is so obviously incompatible with the biosphere - what the fuck we did - it was so ridiculous. But so what is the market? Think of it as: money is a kind of token for value, it's a kind of token for game theoretic optionality where it has no intrinsic value but it has a maximum optionality to get me any type of value I want - I can get militaries with it, I can get media influence, I can change people's minds, I can get materials, and because I don't know how the environment is going to change - the speed of adaptive response is the most important thing - the [OODA loop](https://en.wikipedia.org/wiki/OODA_loop) - the speed at which I can respond to the environment - so I don't want a lot of materials that might become less useful, I want a lot of optionality to have whatever I want. So if you think of money as a proxy for value, but only value that is measurable, extractable, and exchangeable - and all the types of value that on your deathbed you'll really care about are not measurable extractable and exchangeable - we'll destroy all those types of value in the pursuit of these types and we have to because they are. So now think about that as a decentralized incentive system that is incenting all the 8 billion humans to figure out how to get it because everything else they want requires it and everything they need to exist requires it - the countries relative to each other, the companies relative to each other, the people relative to each other, and so it incents them to innovate and it incents them to act on existing innovation - so search algorithms and optimization algorithms. So you can think of the global market as something like an AI - an intelligent system - that is running parallel process on human compute - on human beings - and you know how radically powerful parallel process in the cloud is - being able to run a lot of parallel process on computers did a lot more than centralized supercomputers could do - so this is running parallel process on 8 billion human beings and the clusters of corporations and countries and whatever to incentivize them all to search new ways to make money and to optimize on existing ways and whoever gets good at that system gets more power in it and in turn lobbies and changes laws and changes cultural values of the media they create and whatever that makes a system better for them, and anyone that opposes that system is also opposing those who are doing well at it so that there is agency to suppress that. So you can think of the global market as a misaligned super intelligence that is already misaligned with planetary well-being in humans, that is running on all the humans while also running all the humans, that also uses all the compute and all the other technology and that is building all of the narrow AIs in its own service. We said that most of the Nazis weren't Hitler. So the Hitler we're all in relationship to today is this thing - we can call it [Moloch](https://slatestarcodex.com/2014/07/30/meditations-on-moloch/), you can call it the superorganism, you can call it the mega machine and that thing has to die. That thing has to die or the biosphere will die. But it's not actually animate - it is running on and made up of human action. So thinking about what would it take to - it has to die and/or be converted to something that it is not. And the something that it is not is that you can't assess all types of value with a single value currency - a fungible value currency where the real types of value can't be measured there - and where you can destroy real value to get the optionality token for value - that thing - there is no global fungible unitary currency with its own internal financial mechanisms - like interest that create embedded growth obligations - there's no system that has those structures that is compatible with human continuance - so that thing has to change." - [Daniel Schmachtenberger](https://youtu.be/4kBoLVvoqVY?t=1546)

> "There is no human future that is compatible with a single fungible global currency and interest and most of human access mediated by private property ownership - those things are fundamentally incompatible. We can do the math on that sometime - back in 2017 I wrote a series of papers called a new economic series and it addresses a chunk of this stuff. No, making the money crypto doesn't solve it. So, first, the money is supposed to index real value - goods and services, right, like the theory of the market was people want real shit that will improve their lives, and barter is just... and there's a lot wrong with this and you can read Graber and others to see what's wrong with this, but like very simplified kind of market apologism, early market theory ala Smith and friends says: people want real goods and services that will improve the quality of their lives, how many cows are worth how many shoes is really hard, so we make a unit of currency that's easier to carry around where you don't have to cut up the cows each time to be able to mediate that kind of barter in exchange, and people will buy the product or service that meets their need the best at the best price, so this creates... the authentic demand creates an incentive for other people to figure out supply, to be creative, and that it's not money as a measure of extraction, but money is a measure of production - we're adding value by putting pieces together in a form that wasn't there, and that the intelligent rational human will pick the thing that meets their need the best and the world will get better, right, like that's the gist of the idea. And it's supposed to be then that the money is indexing the real goods and services, so how much money is there has to be that within that market you kind of know how much goods and services to know how much one unit of currency's worth, which is why counterfeit is always illegal, because if you just added a bunch more currency that wasn't indexing the goods and services you'd be debasing the value of the currency. But as soon as the financial system... you start to realize okay, well now I have some of this money that is an optionality token for any kind of value and I can give some of it to someone else - I can loan some of it to someone else so that they can buy the tractors or the horses or the whatever they need to do a thing and then they will grow the productivity - some of that increased gain that they get I should get back, so we call that interest - rent seeking or interest - and then now we have a situation where just the reality of interest requires the system to grow the monetary supply. Now because the population was growing and because we were technologically innovating - the system was growing - but now that we're at a situation where we can't keep growing because we've hit planetary boundaries, because there's eight billion people and 100x the resource per capita that there was before industrial tech - the monetary system still requires there to be 3 percent more money next year and then 3 percent more on that which is a compounding curve which goes exponential - to not debase the value of that currency that means you have to exponentiate real goods and services, which means rather than the money following the real economy - it's driving it. Right... that embedded growth obligation is totally incompatible with planetary boundaries, so do you have to change financial services to not have an embedded growth obligation? Absolutely." - [Daniel Schmachtenberger](https://youtu.be/4kBoLVvoqVY?t=2029)

> "There is immediate work we have to do because we're so near tipping points - we're past tipping points, right, like if everybody... many people in here saw the article that came out about 6 months ago in the American Chemical Society Journal about PFOS - the fluorinated surfactants and rainwater everywhere in the world - but they are in rain water, like these fluorinated surfactants which affect... they are endocrine disruptors and carcinogens and neurotoxins - they're in every drop of rain water all around the world that has been studied - including snowfall in Antarctica, and they're at levels that are above the EPA and EU thresholds - that's not we're getting close to planetary boundaries - that's we have crossed them and the cascade of tragedies we don't know yet - we don't know if we stop using hydrocarbons - awesome - but if we stop the pollution and these are forever chemicals - what - they're still there! And they're not just affecting the humans - they're affecting the soil microbes and the algae and everything - the gene lines of those things - so we're already past some planetary boundaries, we're near other ones. There's immediate shit that has to happen - we have to use markets and governments and whatever for that because that's where all the power is, but we have to use them very differently... so we kind of have to hijack them. And so what does that look like? It looks like that the most toxic forms of agriculture - that deplete all the minerals in the soil and use pesticides and herbicides I.E poison that was designed to kill life and spray it all over our food and spray it in the ecosystem in billions of tons of year - that shit is subsidized by the governments of the world - I.E it's not even market competing with regenerative agriculture - it's being subsidized to not even allow fair competition of the other things when it is [omnicidal](https://en.wiktionary.org/wiki/omnicide) because it claims it's the only thing that can produce enough food to meet food security for national interests - no the real reason is because they're better at lobbying than small farmers are. So what's an immediate thing to do: do you need lobbying, do you need people who know how to lobby as well as big Ag and big Pharma and big oil and big Tech who go and lobby for opposite purposes to remove the perverse subsidies that are going to those and move them to the things that would be better - that are still market viable things - so that the market topology changes? A small amount of lobbying money can produce a lot of state money change, which can produce a lot of market change because you've changed the topology of the market - these are examples of not changing the underlying logics of the market but working with them to change the world in the timely things - I call this triage, and that needs done in a lot of sectors. There's transitional work which is to make the existing systems less pathological - how do we change... so [Kate's work with the doughnut](https://en.wikipedia.org/wiki/Doughnut_(economic_model)) would be an example of insofar as governments start actually forcing monitoring of externalities and making it illegal, so the externalities have to be internalized in the cost equation - that would be a good example, insofar as they start to change the fiduciary responsibility from profit maximizing to things that are not [ecocidal](https://en.wikipedia.org/wiki/Ecocide) and biocidal and lifecidal in the process of - you know - economic viability. Those would be transitional." - [Daniel Schmachtenberger](https://youtu.be/4kBoLVvoqVY?t=2256)

> "What would it mean for our species to be wise enough to steward that power safely? What kind of civilization? What kind of economic system? What kind of governance system? What kind of education system? What kind of religious systems of conditioning the sacred and meaning are necessary to be able to steward the power of synthetic biology and artificial intelligence and nuclear tech and globalized supply chain industrial Tech to steward that safely? That's the long-term work." - [Daniel Schmachtenberger](https://youtu.be/4kBoLVvoqVY?t=2534)

> "Don't act out of anger, depression, and fear - act out of that sense of the Sacred and that you are in service to a life that is beautiful, to a life with a capital L, to a world that is beautiful, and that you're at a time when there is a higher possible consequence of your action than there has ever been for humans, and there is an obligation in that, and there is a meaningfulness in that, that you don't want to waste." - [Daniel Schmachtenberger](https://youtu.be/4kBoLVvoqVY?t=2838)

> "You take any of the biggest issues in the world - like the issues that could determine whether or not we keep existing as a species - so take big environmental issues like climate change: there's disagreement as to whether climate change is really even a thing, and to the extent that it is a thing - what the causes are and what the time scales are. Now, most people who believe fervently 'no, climate change is real, 97% of climate scientists agree, it's anthropogenic, greenhouse gases, etc.' - most of the people that believe that fervently enough to kind of like go into narrative warfare for it have never actually looked at the primary data deeply themselves. And yet there's an almost religious fervor around it that was based on having proxied their sense making to people who they believe. So the UN said it or the Gates Foundation said it or whatever it is - I've heard it repeated enough times - just through repeatability: I have been programmed to believe this thing is true, which is not that different than believing a fundamentalist religious idea. And let's say we take people's fervent ideas on vaccines or their fervent ideas on the viability of market ideology or almost anything like that - almost no one who has fervent ideas has a good epistemic basis for the level of certainty they hold. There's a decoupling between how much certainty they have and how much certainty they should have through right process. And then you look at who are they proxying their sense making to - in most the time they're not even proxying their sense making to the people who did the original research, many of whom disagree with each other and were funded by somebody to say something that is not fully true in the first place, and who maybe were employing epistemic biases themselves. But typically it's somebody else who looked at all of that and then someone else who looked at all of that so you might have like a bunch of climate scientists into someone who is speaking about that as a climate scientist at a more synthetic level - like a James Hansen or whatever - to then like a Gore or someone who is actually speaking to the public who we're proxying our sense making to. And we say 'okay how many steps removed is it and how good was the original data?'" - [Daniel Schmachtenberger](https://youtu.be/7LqaotiGWjQ?t=2276)

https://www.youtube.com/watch?v=7LqaotiGWjQ
^^ TODO: actually rewatch again and extract what's worthwhile



> "The idea of democracy is that it is participatory governance. So you notice that the modern democracies emerged out of the European Enlightenment, and specifically because the idea that a lot of people - some huge number - not a tribal number - huge number of anonymous people who don't know each other, are not bonded to each other, who believe different things, who grew up in different ways, can all work together to make collective decisions well that affect everybody and where some of them will make compromises in the thing that matters to them for what matters to other strangers - that's actually wild, like it's a wild idea that that would even be possible. And it was kind of the result of this high enlightenment idea that we could all do the [philosophy of science](https://en.wikipedia.org/wiki/Philosophy_of_science) and we could all do the [hegelian dialectic](https://en.wikipedia.org/wiki/Dialectic) - those ideas had emerged, right, and it was that we could all... So our choice making - because we said a society is trying to coordinate choice making - the emergent order is the order of the choices that we're making - not just at the level of the individuals but what groups of individuals - corporations, nations, states, whatever do. Our choice making is based on our sense making and our meaning making. Our sense making is what do we believe is happening in the world and what do we believe the effects of a particular thing would be, and our meaning making is what do we care about, right, our values generation - what do we care about that we're trying to move the world in the direction of. If you ultimately are trying to move the world in a direction that is really really different than the direction I'm trying to - we have very different values - we're going to have a hard time. And if you think the world is a very different world, right, if you think that systemic racism is rampant everywhere and one of the worst problems and I think it's not even a thing, if you think climate change is almost existential and I think it's not even a thing - we're going to have a really hard time coordinating. And so we have to be able to have shared sense making of can we come to understand just what is happening together and then can we do shared values generation: *'okay maybe I'm emphasizing a particular value more than you but I can see how I can take your perspective and I can see how the thing that you value is worth valuing and I can see how it's affected by this thing, so can we take all the values and try to come up with a proposition that benefits all of them better than the proposition I created just to benefit these ones - it harms the ones that you care about, which is why you're opposing my proposition'*. We don't even try in the process of crafting a proposition currently to see - and this is the reason that the proposition when we vote on it gets half the votes - almost all the time - it almost never gets 90% of the votes - is because it benefits some things and harms other things. We can say *'all theory of tradeoffs'* but we didn't even try to say *'could we see what everybody cares about and see if there was a better solution'*. **LEX:** How do we fix that try - I wonder is it as simple as the social technology of education? **DANIEL:** Well no, it's that the proposition crafting and refinement process has to be key to a democracy or paratory governance, and it's not currently. **LEX:** But isn't that the humans creating that situation? So... there's two ways to fix that: one is to fix the individual humans which is the education early in life, and the second is to create somehow systems that... I understand the education part, but creating systems - that's why I mentioned the technologies is creating social networks essentially. **DANIEL:** Yes, that's actually necessary. Okay so let's go to the first part and then we'll come to the second part. So democracy emerged as an Enlightenment era idea that we could all do a [dialectic](https://en.wikipedia.org/wiki/Dialectic) and come to understand what other people valued, and so that we could actually come up with a cooperative solution rather than just *'F you we're going to get our thing in war'*, right, and that we could sense make together - we could all apply the philosophy of science and you weren't going to stick to your guns on what the speed of sound is if we measured it and we found out what it was and there's a unifying element to the objectivity in that way. And so this is why I believe Jefferson said if you could give me a perfect newspaper and a broken government or - I'm paraphrasing - or a broken government & perfect newspaper - I wouldn't hesitate to take the perfect newspaper because if the people understand what's going on they can make build a new government. If they don't understand what's going on they can't possibly make good choices. And Washington - I'm paraphrasing again - first president said the number one aim of the federal government should be the comprehensive education of every citizen in the science of government. Science of government was the term of art - think about what that means, right, science of government would be [game theory](https://en.wikipedia.org/wiki/Game_theory), coordination theory, history - it wouldn't be called game theory yet - history, sociology, economics, right - all the things that lead to how we understand human coordination. I think it's so profound that he didn't say the number one aim of the federal government is rule of law, and he didn't say it's protecting the border from enemies, because if the number one aim was to protect the border from enemies it could do that as military dictatorship quite effectively, and if the goal was rule of law it could do it as a dictatorship - as a police state. And so if the number one goal is anything other than the comprehensive education of all the citizens in the science of government it won't stay democracy long. You can see - so both education and the fourth estate - the fourth estate being... so education: can I make sense of the world, am I trained to make sense of the world, the fourth estate is what's actually going on currently - the news - do I have good, unbiased information about it. Those are both considered prerequisite institutions for democracy to even be a possibility. And then at the scale it was initially suggested here - the town hall was the key phenomena where there wasn't a special interest group crafted a proposition and the first thing I ever saw was the proposition, didn't know anything about it and I got to vote Yes or No - it was in the town hall we all got to talk about it and the proposition could get crafted in real time through the conversation, which is why there was that Founding Father statement that that voting is the death of democracy - voting fundamentally is polarizing the population in some kind of sublimated war, and we'll do that as the last step, but what we want to do first is to say how does the thing that you care about that seems damaged by this proposition - how could that turn into a solution to make this proposition better, where this proposition still tends to the thing it's trying to tend to and tends to that better - can we work on this together - and that in a town hall we could have that. As the scale increased we lost the ability to do that. Now as you mentioned the Internet could change - that the fact that we had representatives that had to ride a horse from one town hall to the other one to see what the colony would do - that we stopped having this kind of developmental propositional development process when the town hall ended - the fact that we have not used the Internet to recreate this is somewhere between insane and aligned with class interests." - [Daniel Schmachtenberger](https://youtu.be/hGRNUw559SE?t=12435)

> "Could we apply Facebook-like technology to develop people's citizenry capacity, right, to develop their personal health and well-being and habits as well as cognitive understanding - the complexity with which they can process the health of their relationships - that would be amazing to start to explore. And this is now the thesis that we started to discuss before is: every time there is a major step function in the physical tech it obsoletes the previous social tech and the new social tech has to emerge. What I would say is that when we look at the nation state level of the world today, the more top-down authoritarian nation states are... as the exponential tech started to emerge, the digital technology started to emerge - they were in a position for better long-term planning and better coordination and so the authoritarian states started applying the exponential tech intentionally to make more effective authoritarian states - and that's everything from like an Internet of Things surveillance system going into machine learning systems to the [Sesame credit system](https://en.wikipedia.org/wiki/Zhima_Credit) to all those types of things - and so they're upgrading their social tech using the exponential tech. Otherwise within a nation state like the US but democratic open societies - the countries - the states are not directing the technology in a way that makes a better open society, meaning better emergent order - they're saying: well the corporations are doing that and the state is doing the relatively little thing it would do aligned with the previous corporate law that no longer is relevant because there wasn't fiduciary responsibility for things like that, there wasn't antitrust because this creates functional monopolies because of network dynamics, right, where YouTube has more users than Vimeo and every other video player together, Amazon has a bigger percentage of market share than all of the other markets together - you get one big dog per vertical because of network effect, which is a kind of organic monopoly that the previous antitrust law didn't even have a place - that wasn't a thing - anti-monopoly was only something that emerged in the space of government contracts. So what we see is the new exponential technology is being directed by authoritarian nation states to make better authoritarian nation states and by corporations to make more powerful corporations. The powerful corporations - when we think about the Scottish Enlightenment, when the idea of markets was being advanced, the modern kind of ideas of markets - the biggest corporation was tiny compared to what the biggest corporation today is, so the asymmetry of it relative to people was tiny. And the asymmetry now in terms of the total technology it employs, total amount of money, total amount of information processing is so many orders of magnitude, and rather than there be demand for an authentic thing that creates a basis for supply, as supply started to get way more coordinated and powerful and the demand wasn't coordinated because you don't have a labor union of all the customers working together, but you do have a coordination on the supply side - supply started to recognize that it could manufacture demand, it could make people want shit that they didn't want before that maybe wouldn't increase their happiness in a meaningful way - it might increase addiction - addiction is a very good way to manufacture demand, and so as soon as manufactured demand started through "this is the cool thing and you have to have it for status or whatever it is" - the intelligence of the market was breaking. Now it's no longer a collective intelligence system that is upregulating real desire for things that are really meaningful - you're able to hijack the lower angels of our nature rather than the higher ones - the addictive patterns - drive those, and have people want shit that doesn't actually make them happier or make the world better. And so we really also have to update our theory of markets because [Behavioral Econ](https://en.wikipedia.org/wiki/Behavioral_economics) showed that [Homo economicus](https://en.wikipedia.org/wiki/Homo_economicus) - the rational actor - is not really a thing, but particularly at greater and greater scale can't really be a thing. Voluntarism isn't a thing - where if my company doesn't want to advertise on Facebook - I just will lose to the companies that do because that's where all the fucking attention is. And so then I can say it's voluntary but it's not really if there's a functional monopoly. Same if I'm going to sell on Amazon or things like that. So what I would say is the these corporations are becoming more powerful than nation states in some ways and they are also debasing the integrity of the nation states, the open societies, so the democracies are getting weaker as a result of exponential tech and the kind of new tech companies that are kind of a new feudalism - tech feudalism - because it's not a democracy inside of a tech company or the supply and demand relationship - when you have manufactured demand and kind of monopoly type functions - and so we have basically a new feudalism controlling exponential tech and authoritarian nation states controlling it and those attractors are both shitty. And so I'm interested in the application of exponential tech to making better social tech that makes emergent order possible and where then that emergent order can bind and direct the exponential tech in fundamentally healthy not-X-risk oriented directions. I think the relationship of social tech and physical tech can make it - I think we can actually use the physical tech to make better social tech, but it's not given that we do. If we don't make better social tech then I think the physical tech empowers really shitty social tech that it's not a world that we want." - [Daniel Schmachtenberger](https://youtu.be/hGRNUw559SE?t=13434)

> "I think the thing that we call markets - of course we can try to say oh even biology runs on markets - but the thing that we call markets - the underlying theory [Homo economicus](https://en.wikipedia.org/wiki/Homo_economicus) demand driving supply - that thing broke. It broke with scale in particular and a few other things. So it needs updating in a really fundamental way. I think there's something even deeper than making money happening that in some ways will obsolete money-making. I think capitalism is not about business. So if you think about business - I'm going to produce a good or a service that people want and bring it to the market so that people get access to that good or service - that's the world of business, but that's not capitalism. Capitalism is the management and allocation of capital which financial services was a tiny percentage of the total market - it's become a huge percentage of the total market - it's a different creature. So if I was in business and I was producing a good or service and I was saving up enough money that I started to be able to invest that money and gain interest or do things like that - I start realizing I'm making more money on my money than I'm making on producing the goods and services so I stop even paying attention to goods and services and start paying attention to making money on money and how do I utilize capital to create more capital. And capital gives me more optionality because I can buy anything with it than a particular good or service that only some people want. Capitalism - more capital ended up meaning more control - I could put more people under my employment, I could buy larger pieces of land, novel access to resource mines and put more technology under my employment - so it meant increased agency and also increased control. I think attentionalism is even more powerful. So rather than enslave people where the people kind of always want to get away and put in the least work they can there's a way in which economic servitude was just more profitable than slavery, right, have the people work even harder voluntarily because they want to get ahead and nobody has to be there to whip them or control them or whatever - this is a a cynical take but a meaningful take. So capital ends up being a way to influence human behavior, right, and yet where people still feel free in some meaningful way - they're not feeling like they're going to be punished by the state if they don't do something - it's like punished by the market via homelessness or something. But the market is this invisible thing I can't put an agent on so it feels like free. And so if you want to affect people's behavior and still have them feel free capital ends up being a way to do that, but I think affecting their attention is even deeper because if I can affect their attention I can both affect what they want and what they believe and what they feel and we statistically know this very clearly - Facebook has done studies that based on changing the feed it can change beliefs, emotional dispositions, etc. And so I think there's a way that the harvest and directing of attention is even a more powerful system than capitalism - it is effective in capitalism to generate capital but I think it also generates influence beyond what capital can do and so do we want to have some groups utilizing that type of tech to direct other people's attention - if so - towards what? Towards what metrics of what a good civilization and good human life would be - what's the oversight process? What is... **LEX:** ... **DANIEL:** Okay, so maybe the corporation has coordination on its goals that all of its customers or users together don't have so there's some asymmetry where it's asymmetry of its goals but maybe I could actually help all of the customers to coordinate - almost like a labor union or whatever - by informing and educating them adequately about the effects & the externalities on them - this is not toxic waste going into the ocean of the atmosphere - it's their minds, their beings, their families, their relationships, such that they will in group change their behavior and I think... One way of saying what you're saying I think is that you think that you can rescue [Homo economicus](https://en.wikipedia.org/wiki/Homo_economicus) from the rational actor that will pursue all the goods and services and choose the best one at the best price - the kind of Rand/Von Mises/Hayek - that you can rescue that from [Dan Ariely](https://en.wikipedia.org/wiki/Dan_Ariely) and [behavioral econ](https://en.wikipedia.org/wiki/Behavioral_economics) that says that's actually not how people make choices - they make it based on status hacking largely whether it's good for them or not in the long term and the large asymmetric corporation can run propaganda and narrative warfare that hits people's status buttons and their limic hijacks and their lots of other things in ways that they can't even perceive that are happening. They're not paying attention to that - the site is employing psychologists and split testing and whatever else. So you're saying I think we can recover homoeconomicus? **LEX:** ... the education of negative externalities can become viral in this world. **DANIEL:** So interestingly I actually agree with you... **LEX:** Got em!... Tech can do some good... **DANIEL:** What you're talking about is the application of tech - here broadcast tech - where you can speak to a lot of people, and that's not going to be strong enough because the different people need spoken to differently which means it has to be different voices to get amplified to those audiences - more like Facebook's tech - but nonetheless we'll start with broadcast tech. **LEX:**... **DANIEL:** So let's come back to the fundamental thing - the fundamental thing is: we want to kind of order at various scales from the conflicting parts of our self actually having more harmony than they might have, to family, extended family, local, all the way up to global - we want emergent order where our choices have more alignment, right, we want that to be emergent rather than imposed or rather than we want fundamentally different things or make totally different sense of the world where warfare of some kind becomes the only solution. Emergent order requires us in our choice making requires us being able to have related sense making and related meaning making processes. Can we apply digital technologies and exponential tech in general to try to increase the capacity to do that - where the technology called a town hall - the social tech that we'd all get together and talk - obviously is very scale limited and it's also oriented to geography rather than networks of aligned interest. Can we build new better versions of those types of things? And going back to the idea that a democracy or participatory governance depends upon comprehensive education in the science of government, which includes being able to understand things like asymmetric information warfare on the side of governments, and how the people can organize adequately - can you utilize some of the technologies now to be able to support increased comprehensive education of the people and maybe comprehensive informedness - so both fixing the decay in both education and the [fourth estate](https://en.wikipedia.org/wiki/Fourth_Estate) that have happened so that people can start self-organizing to then influence the corporations, the nation states to do different things and or build new ones themselves? Yeah, fundamentally that's the thing that has to happen. The exponential tech gives us a novel problem landscape that the world never had - the the nuke gave us a novel problem landscape and so that required the whole [Bretton Woods](https://en.wikipedia.org/wiki/Bretton_Woods_system) world. The exponential tech gives us a novel problem landscape - our existing problem solving processes aren't doing a good job - we have had more countries get nukes, we haven't done nuclear de-proliferation, we haven't achieved any of the UN sustainable development goals, we haven't kept any of the new categories of tech from making arms races - so our global coordination is not adequate to the problem landscape. So we need fundamentally better problem solving processes - a market or a state as a problem solving process - we need better ones that can do the speed and scale of the current issues. Right now speed is one of the other big things - it's that by the time we regulated [DDT](https://en.wikipedia.org/wiki/DDT) out of existence or cigarettes not for people under 18 - they'd already killed so many people and we let the market do the thing, but as Elon has made the point that won't work for AI - by the time we recognize afterwards that we have an autopoietic AI that's a problem you won't be able to reverse it - that there's a number of things that when you're dealing with tech that is either self-replicating and disintermediates humans to keep going - doesn't need humans to keep going - or you have tech that just has exponentially fast effects - your regulation has to come early - it can't come after the effects have happened, the negative effects have happened because the negative effects could be too big too quickly. So we basically need new problem solving processes that do better at being able to internalize externality, solve the problems on the right time scale and the right geographic scale, and those new processes to not be imposed have to emerge from people wanting them and being able to participate in their development, which is what I would call kind of a new cultural Enlightenment or Renaissance that has to happen, where people start understanding the new power that exponential tech offers, the way that it is actually damaging current governance structures that we care about, and creating an x-risk landscape, but could also be redirected towards more [protopic](https://metamoderna.org/whats-the-difference-between-utopia-eutopia-and-protopia/) purposes and then saying: how do we rebuild new social institutions, what are adequate social institutions where we can do participatory governance at scale in time, and how can the people actually participate to build those things. The solution that I see working requires a process like that." - [Daniel Schmachtenberger](https://youtu.be/hGRNUw559SE?t=13865)

> "So I would say that our global coordination on all of the most critical issues is inadequate to the timeline and consequentiality of the issues - like that seems very very clear. And as exponential tech is advancing, the total number of catastrophic risks and the total probability of each is increasing, and the capacities that we're utilizing to address them are not increasing accordingly. So there is a gap that we need to be focused on which is what you guys are focused on, which is this kind of global governance topic - we have global issues - not just local issues. Everybody's scared of global governance - the frame - the term global governance - or at least global government - for a good reason, which is: we have a good long history of reasons to not trust consolidation of power with no checks and balances. So nobody wants this kind of massive unchecked global government and at the same time you have to have governance at the scale that cause and effect is occurring. And if we're having... if nobody can fix climate change on their own - in terms of nation states - and yet they're all affected by it and they can't fix overfishing, they can't fix nitrogen run, off dead zones and oceans, and etc. there have to be global coordination solutions - otherwise multi-polar traps ruin everything, right, a multipolar trap is some kind of race to the bottom - arms race is an example as we've already mentioned, tragedy of the commons is another example, but the key to both of them is where the agent focused on their own short-term well-being does something that advances their short-term interest, but then makes everybody else have to do the same thing, and where everyone doing it creates the maximally bad long-term situation. And so if we try to create some treaty around not overfishing a particular region of the ocean and anybody violates it - then if anyone else doesn't violate the treaty if they can't figure out enforcement then you're just a sucker for holding to the treaty, right, because all those fish are going to get killed anyways, the ocean's going to get messed up, it's just going to feed another population that's going to grow and have more people to engage in economics and armies... And how do you do enforcement on a nation that has nukes or a nation that has some critical aspect of infrastructure, or you know - the globalized supply chain. And so enforcement becomes tricky, so then you get these types of things: tragedy of the commons, an arms race, multi-polar traps - so you have to figure out how do we solve those coordination issues globally because we have global issues that can't just keep getting pushed down the road. And yet we want to figure out a solution to do it that isn't a kind of global government that becomes its own catastrophic risk of under the name of some problem that is scary enough we agree to some totalitarian power structure. And that's the thing you mentioned about order and chaos is that we can see that the thing we call civilization is a way of having some order, some coordination between lots of people, so that they can do specialization and division of labor, creating a richer world for everybody and then coordinate all that, they can coordinate their activity for not just those kind of productive purposes but also protection purposes. So the thing that we call civilization is how we coordinate behavior of lots of people and that's actually a pretty hard thing to do when you think about people that want different stuff and believe different stuff and aren't necessarily connected to or bonded to each other - like how do you get them to not just do the immediate advantageous thing to them for people that are fundamentally strangers to them. So typically a civilization will try to create order through some kind of imposition - some forced religion, forced patriotism, law, whatever it is - and it can err in the side of in order to have everybody participate with that order becoming increasingly tyrannical, increasingly dictatorial. If it doesn't do that people end up orienting towards tribalism naturally and fragmenting kind of towards each other and you end up getting the thing failing in the direction of chaos. The only other answer is how do you get order without it being imposed - how do you get emergent order - and this was the kind of idea of democracies and republics and open societies is: maybe we could actually get emergent order if we - and it was based on the idea of a culture that invested in the people enough that the people didn't just believe different things and want different things and be willing to defect into war, you had to actually develop a people that could all come to understand the world similarly, can everybody understand the philosophy of science well enough that they can all come to understand base objective reality that they share similarly, can they all have something like [hegelian dialectic](https://en.wikipedia.org/wiki/Dialectic#Hegelian_dialectic) capacities where they can notice not just their own values but other people's values and recognize that only solutions that meet everybody's values will end up working, can they understand things like multi-polar traps well enough to understand that a short-term win of my political party just means that whatever technique we utilize that was effective gets reverse engineered the other side wins in the next four years and undoes everything that we did for four years and we we get nowhere and then dictatorships do much better than us and the society fails, can people understand those things enough that they don't orient towards the short-termism kinds of things. So this is why the modern democracies emerged out of modernity, emerged out of a philosophic system that said we can come to understand the world and understand each other well enough that we can actually have emergent coordination. Obviously the world has gotten much more complex during that time and the cultural value of that kind of education has eroded." - [Daniel Schmachtenberger](https://youtu.be/U0YJ0C81n4s?t=870)

> "You can almost think of what the state in a liberal democracy is as like a labor union for the people, and as a whole, like a labor union, how do you unify all the people to have something that is big enough to represent their collective interests, so that the large corporations and the major wealth holders within capitalism don't just rule everything like feudalism, which is the thing we were trying to replace before? Because it's very clear that if we have a trade system and it's mediated by an abstract system for doing accounting - like currency - that pretty soon you'll have a power law distribution of wealth and a few people will own most of the wealth - some people are better at it and then getting better at it gives you more capacity to keep getting better at it and there's compounding interest which is an exponential return on owning capital, there's compounding interest on debt, and you know, does that thing... Right, and we can see the data of that in [Piketty's book](https://en.wikipedia.org/wiki/Capital_in_the_Twenty-First_Century), but it's also just kind of a natural thing to look at. So the idea was since power law distributions are going to happen, that most people are going to have really no power, how do you not have that be oppression? Well let's have the people all be able to collectively vote where at least the majority of what they care about gets encoded as law, so their values are the basis of the jurisprudence of the law, so then rule of law can get enforced by representatives of, for, and by the people, that are going to be bequeathed with a monopoly of violence so they can actually do enforcement to be able to protect the people in the commons against perverse incentive, while letting the market do all the good things that it does, but most of rule of law is actually binding the perverse incentives of markets. Okay, so if that only works where the state can check the predatory aspects of markets, if the people are checking the state that it is truly of, for, and by the people, there's transparency, everybody's actively engaged - as soon as that stops happening, then the government is just run by people, those people are economic actors they're in there for whatever short period of time and they will be liked about the same whether they do corporate interests or not, because nobody's really going to know, and so of course you end up getting regulatory capture where the market captures the regulatory apparatus and you get crony capitalism and that kind of institutional decay. And as the founding fathers in the U.S. said and anyone who paid attention: as soon as a couple generations pass and the people forget what it means to fight a revolutionary war and be under oppression, they won't keep investing and being educated enough and actively being engaged in government because they'd rather [keep up with the Joneses](https://en.wikipedia.org/wiki/Keeping_up_with_the_Joneses) or party or like some other thing. And so how do you keep the intergenerational transfer of not just the knowledge, but the civic virtues necessary to uphold a democracy, which is not a trivial thing? And especially as time goes on and the complexity of the world increases, understanding the issues well enough to really play a role in them and to be able to oversight them and police them gets harder and harder and so there has to be more and more investment into doing that. So we can see that the people stopped investing and checking the state, the state stopped checking the market, market captured the state, all the innovation got outsourced, and so what we can see today, so we see in that world war two example that the state really pioneered the advancement of all these areas of tech to increase the integrity of the state. There is a jump in technology that is currently happening that is more significant than the world war II jump in technology and the center of it is AI and computation with AI being the very center, right, it's computation, digital tech, but then the application of AI and digital tech to physical tech as well, so the application of that to biotech and crispr kind of stuff, and to robotics and robotic automation, and the other key areas of computer science from the evolution of the computational basis, quantum computing, photo computing, DNA computing, whatever, and again the application of that to the material sciences, nanotech, etc. So we're undergoing this huge jump in technology right now that is something like two orders of magnitude more significant than the previous world war II jump was in terms of the total amount of verticality of power and the speed at which it's developing and the number of verticals simultaneously. And the way I see it is that tech will confer so much power that only those who are guiding it will have much of a say in the future, and right now I only see two types of groups really guiding it meaningfully: some authoritarian nation states are, where the nation state is taking seriously the development of the tech and the nation state is investing a very big R&D budget and how to actually increase the integrity of their nation state and it's a good thing for them to do, aligned with whatever their system and their ideologies are, and obviously China is a prime example here. Where the application... the government is investing in the development of engineers and in the application of all of those areas of tech to the nature of government itself, and that's everything from their IOT system to their [Sesame credit system](https://en.wikipedia.org/wiki/Zhima_Credit) to the transistor development and lithography to the [Belt and Road Initiative](https://en.wikipedia.org/wiki/Belt_and_Road_Initiative) and getting something like 94 percent of the world's rare earth metals in there that are needed for computational substrate in their supply chain to on and on, right, to the creation of their own Internet that doesn't have the same problems for their country that the U.S. Internet has. So authoritarian nation states are using the exponential tech to become exponentially more effective authoritarian nation states, and the only other kind of org are companies, Western mostly companies, and those companies are supported by a military and capital and infrastructure of the nation state but they are not serving the interests of the nation state other than GDP and jobs and some very short-term kind of stuff. And they're becoming exponentially more powerful companies, but you know, Facebook and Google have more users than China and the U.S. combined have people, right, so these are humongous kinds of things of which there is no precedent for a corporation in history. [Ayn Rand](https://en.wikipedia.org/wiki/Ayn_Rand) never imagined things like this when she was thinking about the symmetry of supply and demand and she didn't think of things like [Metcalfe dynamics](https://en.wikipedia.org/wiki/Metcalfe%27s_law) that end up leading to natural monopolies and anti-trust law didn't think of that, right, so you end up having Amazon being bigger than all other online stores combined and Google being bigger than all other search engines combined and Facebook being bigger for time on site than all the other social networks, so you get a natural power law distribution not based on government crony capitalism - based simply on the nature of network dynamics, that once you reach a certain escape velocity your a natural monopoly will start to emerge based on the value of the thing being associated with the second power of the number of users. And so the interesting thing is you see these corporations that are becoming more powerful than nation states in many ways because of the development and direction of the exponential technologies and as that happens they are less able to be regulated by the countries while still benefiting from the infrastructure of the countries and simultaneously eroding the integrity of the country - we can see the way that the time on site optimization ad model of Facebook and Google and Youtube have eroded American democracies and in specific and Western democracies by doing the time on site optimization appeals to people's cognitive biases and tribalism and limbic hijacks and those types of things. We can see that the kind of consolidation of market function like Amazon, that Amazon's growth during covid matched pretty closely the closure of all small businesses that aren't going to reopen - well the American dream without small businesses isn't the thing, right, it's not a thing in the same way, and we see the technological automation of so many jobs impending and not the replacement in the current way that it's trending of a similar American dream kind of sovereignty, so there's kind of a a billionaire to centibillionaire class that runs whatever the one big dog on the top of the power law distribution that defines a vertical is and an increasingly less upwardly mobile in terms of real capacity to play those games under class. And obviously some kind of middle class that is serving the very upper class in that context. So what I see is that is the movement to a new kind of feudalism, right, a tech feudalism, and that it's even interesting some of those companies - you know - we see this with Tesla, we see with the other ones - some of those companies are getting subsidies - government subsidies - that means they're collecting taxpayer money, to utilize taxpayer money to do the thing they're doing, but the taxpayers didn't vote on them doing that, they were not elected representatives, they cannot be unelected and there is no traditional jurisprudence for the guidance of the thing that they're doing - that's something much more like a king than a president, which is why I say kind of an emergent tech feudalism. So what I see is there's one strange attractor which is tech feudalism, there's another strange attractor which is kind of authoritarian nation states, and anything like an open society where there's participatory governance and jurisprudence that is grounded in the will of the people - there is no system that is based on those ideals that is innovating in exponential tech to make better versions of that social tech - that is the number one imperative of our time in my opinion, and either we figure that thing out or those are the only attractors. And the third attractor is that the exponential tech just causes x-risk and we're fucked, right, so you have x-risk, feudalism and authoritarianism, as the current dominant attractors in the presence of exponential tech, or there's not 17 sustainable development goals that really matter because we can't achieve any of them without better coordination - there's figuring out coordination that it becomes the central goal of the world, figuring out a kind of coordination that is emergent order that is neither chaos nor oppression, that is able to utilize the exponential technologies and also to bind and direct them so that they do not either directly or through externality create x-risk and that they don't erode... that they don't create authoritarian systems or kind of feudal systems that erode civil liberties in the process. So we need to have a kind of global innovation zeitgeist of how develop and apply all the areas of exponential technology to building new social tech that can guide, bind, and direct the exponential tech, prevent x-risk, and do it in a way that is commensurate with what our underlying kind of deepest values for participatory and empowered governance and civics are." - [Daniel Schmachtenberger](https://youtu.be/U0YJ0C81n4s?t=1501)

> "A lot of our issues are just increases in the severity of the same underlying type of game theoretic dynamics, and so we can say they are continuous with them in type, but there are places where a change of magnitude becomes a change in kind, right, like as soon as the magnitude gets beyond human information processing capability it's now a change of kind, as soon as we move from a war that's winnable to a war that's not winnable even though they're both the logic of war it's a change of magnitude that becomes a change in kind, right, so there's a lot of places where even the things that are continuous with the past become discontinuous past certain thresholds - meaning that the same types of solutions - the whole class of solutions - doesn't apply anymore. Now that doesn't mean that we throw out everything that we've learned - it means that we have to make sure that we're applying everything that we've learned that is effective, that we aren't making the mistake of not paying attention to the total amount of human thinking and ingenuity that's happened so far, and that the new innovation that we do is commensurate with the smart parts of it, but it happens all the time that we're exploring a search space and there's a couple branches and in the immediate term this branch has more incentive, and so we explore this branch and then we just forget about this one and we just keep exploring and then we hit a cul-de-sac at a certain point, but we have reasons why there's momentum to keep - you know - some combination of [sunk cost fallacies](https://en.wikipedia.org/wiki/Sunk_cost#Fallacy_effect) with the actual belief that this is the only path - this earlier choice - and it wouldn't go all the way back there to the not even knowing the other branches that were cleaved that we didn't pay attention to, to like perverse institutional incentives of standard models where it's hard to get a research grant to do anything outside of that thing or to get your professor who believes in that thing to change their opinion on it or whatever it is. So there are a bunch of places where we actually have to go back and say: okay, there was an incentive to make faster and faster, smaller and smaller computer chips and there was enough money around that there were whole other directions in computational substrate that we didn't take that for reasons of manufacturing resilience and a bunch of other things might actually be meaningful and interesting - this is starting to be a real conversation in theoretical physics with string theory and like maybe we actually need to rewind and try a fundamentally different approach. I think there are places in governance where like we've just accepted, we've just kind of accepted capitalism in the West is the only reasonable answer combined with some kind of open-ish government state, and if you think anything else you didn't study the history of Mao and Stalin and [Pol Pot](https://en.wikipedia.org/wiki/Pol_Pot) and whatever because everything else ends up becoming that kind of dreadful slaughter - like that's kind of the dominant narrative where it's worse than going against Christianity or it's similar to going against Christianity in the dark ages, right, there's almost a religious tone to it. It's like: well we could come up with better shit that isn't any of those things, like there's nothing new under the sun - blockchain's new, like the ability to have an uncorruptable ledger where you can have a provenance of data that you can't fuck up - that makes it where you can have a history that can't be corrupted or changed by the winners afterwards - that's kind of new, that's a big deal - makes it to where you can have a system of justice where you can't actually fuck up the data, right, it means that you can have a system of accounting where let's say the government spending was on a blockchain that was transparently oversighted - there wouldn't be missing money anymore. Right now there's all these places where the total amount of money going in and the receipts coming out don't add up and there's missing money - it's like well, that couldn't be. And so it's like does that make something new possible? Yeah, totally it makes something new possible. You look at the way the AI can make new sounds, it can do error correction of sound where there is an error or make new sounds or make new faces by doing an average composite of all faces that look similar-ish, right - you say: well could huge numbers of people express their sentiments about something and have the AI actually come up with something that is like a weighted average of all of those as a form of proposition creation, and then could we use distributed methods of proposition advancement that didn't exist when we had to meet in a town hall and ride a horse from that town hall to the other ones and we haven't innovated the structure of government since we had to ride horses? Like why do we think that this particular thing is the best thing? Well because the other things - the last time we had that conversation seemed dreadful - at least that was the winning narrative. But totally new things that are not just those previous things are possible, and so what I would say is someone should not assume that the moment we say maybe there's a problem with capitalism that we're instantly going to turn into Stalinism, but to say let's make sure we study that history well enough to know what was wrong with those ideas we don't do that - yes - but let's also do the critique of the system and not just end with the critique but take it as a design criteria to say what would a better system look like, and have we got all the design criteria? Do we have the critiques of the communist system and the socialist system and the capitalist system simultaneously and then can we take all those as design criteria and work on a fundamentally better design that might not look like any of those isms that utilizes new technology which means new possibilities that didn't exist before with new forcing functions that didn't exist before?" - [Daniel Schmachtenberger](https://youtu.be/U0YJ0C81n4s?t=2558)

> "They haven't even tried hard enough to have that doubt mean anything - it's just an emotional default. That was the other question you asked is: are we hitting the limits of cognitive complexity? That is such a like shit answer if you haven't actually applied the full limits of human cognitive complexity and seen that we were failing. So we're not even trying, like, China's trying and they're doing amazing, right, like... in the U.S. we have no high-speed trains - none, none - in the time that they've existed China's been exporting them all around the fucking world in that same amount of time. But a system that doesn't have term limits and that doesn't have a two-party system where you just use all the energy wasted as heat fighting each other and then whatever you do for four years the other people undo for four years and nobody invests in anything with longer than four year timelines because it won't get them re-elected - that system is just stupid - that's going to fail to a system that can do long-term planning. So if we say: okay, let's imagine just hanging out in the 30s and saying we got to figure out how to split an atom - no, not just split an atom, we're going to figure out how to split an atom and deliver that as a warhead with on a rocket to some other place with some decent precision - in fact we're going to go beyond that - we're going to use uranium to fission something and split it to then drive nucleons into a fusion - it would be easy to say well there's no fucking way, like, we don't have the cognitive complexity to be able to split atoms - we don't even know what an atom is. But the Manhattan project was a very serious investment in cognitive complexity and and we got everybody there, right, like we got all the best thinkers in the world there, we put the budget on - are we doing that? Like are we even fucking... we got Von Neumann, we got Turing, we got time, and we got - you know - Oppenheimer - we got all those folks in Bletchley Park and in Los Alamos and like - where is the equivalent of that thing outside of very narrow areas of military - which is why we have a dope military, like, we have an awesome military, but that's innovation in military - it's not innovation in the social technology of governance itself. We actually have to not just innovate our military, but innovate the social technology of governance for a participatory governance system, and this is why we come back to the... there's this quote that I always forget so I paraphrase of George Washington's that said something to the effect that the number one aim of the federal government has to be the comprehensive education of every citizen in the science of government, and science of government was the term of art. And I think it's so profound that he did not say the number one aim of the federal government is to protect its borders, and he did not say the aim of the federal government is to protect rule of law, because you can do rule of law effectively with a police state, and you can protect the boundaries fine with a military dictatorship, but they won't be democracies - if it's going to be a democracy, then democratically the people will probably decide to protect their borders and to engage rule of law, but if the number one goal is anything other than the comprehensive education of all citizens and the education was considered both a cognitive education and a moral education - the way they described it which is the kind of civic virtues that people are willing to give something for the larger system that they also receive benefit from and they're actively participatory engaged. So that's the thing we need to be innovating in right now - not just innovating in military while turning it into a some kind of autocratic or kleptocratic system, but how do we apply the new digital and other exponential technologies to be able to both direct the exponential technologies well so that they don't cause existential risk and in a way that is aligned with the actual values that we care about as a people. And so then the core question comes: what is a successful civilization? Well it's one that doesn't fail, but that's not the only criteria - it's one that doesn't fail and it maximizes the possible quality of life for everybody in perpetuity and then we have to find what does quality of life mean, right, so there's like core existential questions of what is a meaningful human life to be able to design a civilization that is optimizing for that, which is culture, right, which is why we have to have innovation in culture, which is why I talk about that there's a cultural renaissance - a cultural enlightenment - that is necessary right now as the basis of the creation of these new institutions that can solve the x-risk problems, because our current problem-solving mechanisms can't solve them, which is why they're not being solved. We have to develop new institutions that are capable of solving these types of problems - these types of complexity - but if those new institutions are created by a few people that get it and impose them on force then it's some kind of autocracy. So they have to be created by people who want them and are willing to participate with them and capable of participating - that is the cultural enlightenment that has to be the basis of it... And of course there's a recursive process of some people engaging in that to then build systems that in turn engage more people in it - so you get a virtuous cycle between cultural evolution and social evolution employing physical technologies, binding physical technologies, and advancing them for the right purposes." - [Daniel Schmachtenberger](https://youtu.be/U0YJ0C81n4s?t=2928)

> "How do we solve global multi-polar trap issues is not solved anywhere and that's the most central thing we have to figure out. How do we create digital open societies - you can say that it's kind that there are some places that are trying to pioneer like Taiwan and Estonia and that's true, but those are very far from have really got worked out solutions that are adequate to all the other places and scale. So I think we have to acknowledge that many of the most critical solutions don't exist at all and need to become the primary focus of innovation and then where they do start to develop we have to say: what type of governance and incentive landscape would be necessary to get them everywhere they need to be in time and who would have to be participating to make that happen and what kind of oversight and enforcement would be necessary to really make it happen. You know in the U.S. the government making deals with native americans and then not keeping them whenever it's inconvenient - almost all the time - it's not just about did you say when you developed a new technology that will get it to the world - it's is there a method of enforcement that will actually ensure that that occurs and that it occurs within time - that becomes critical." - [Daniel Schmachtenberger](https://youtu.be/U0YJ0C81n4s?t=3475)

> "Yeah it's apologism. So if I win a war and we kill a bunch of people that we call terrorists or infidels or some bad thing that makes them not human but what it means is we blew up a lot of civilians and a lot of women and kids and whatever it was, but we got more land and resources and whatever it was out of doing that thing - survival the fittest is a nice narrative to say that's how nature works and that's the way that it should be and it's actually the prey animals... it's actually the predators that keep the prey animals from eating themselves into extinction and that drive them to evolve by eating the slow ones so that the good genes kind of inbreed and - you know - most people are like prey animals so the some more predatory humans that cull the herd and that kind of drive them who are otherwise kind of lazy eaters - like that whole ideology is apologism for whoever is winning at an extremely damaging rivalrous kind of system. Naive techno capital optimism is one of the best examples of apologism of this kind where: like if you have a theory that criticizes capitalism - nobody who's winning at capitalism who has the money is going to upregulate it, and if you are criticizing tech nobody that was winning at tech is going to say yes I like your idea of why I suck and I'm going to upregulate that. So you realize that for narratives to catch on - somebody has to upregulate them and there's cost associated in doing that and there has to be a motive associated with that cost. It's not just like the ideas that are the most true and the most beneficial proliferate - the ideas that have the most agentic basis to drive them through the society are a lot of the ones that proliferate." - [Daniel Schmachtenberger](https://youtu.be/U0YJ0C81n4s?t=3591)

> "So do humans need to ensure - as the metaphors of nature go - that where we have competition that it's symmetrical and that it's constrained and that the micro competition really does lead to macro symbiosis? We need to ensure that? This is true. Is the competition between Facebook for your attention and you for your attention symmetrical? No, of course not. Well you say well there's a competition... the competition between supply and demand is symmetrical because there's an equal number of dollars flowing from demand to supply - bullshit! Right, the demand side is not coordinated - the supply side's coordinated, and so even though there's a total symmetry in aggregate, there's not a symmetry of coordinated capacity because it isn't Google against all Google users as a Google user labor union that is also applying similar exponential technologies to buying this thing - it's Google against one person in terms of the person didn't think that they were about to spend the next three hours on Youtube and now they do which is better for their advertising model - not necessarily for your life. And so then you can have supply side driving manufactured demand - well now there's not real... the market ideology is broken now - that's not a... market ideology was that there was a thing called demand that was foundational, that people wanted real shit that would improve the quality of their life and that created an environmental niche for supply, and the rational actors would buy the product or service amongst all of them at the best price that would drive innovation - well the moment supply started to get much bigger than demand because of coordination it realized that it could manufacture supply and the humans weren't all that rational - all the [behavioral economics](https://en.wikipedia.org/wiki/Behavioral_economics) - and now the entire logic of markets is broken, right, like market theory is broken with manufactured demand and radical asymmetries on the supply side. Okay, that's important to know, and so if you go back to the nature example where there's competitive forces: do they need to have symmetries in order for the competition to lead to symbiosis as a whole and metastability of the ecosystem? Yes. If you bring something in that is not symbiotic with the rest of it - you get an invasive species - it can destroy a whole ecosystem. Right, so we should study biology where we're not trying to compare ourselves to apex predators or slime molds or whatever - we could just study general principles of things like cooperative dynamics and competitive dynamics and meta stability - we can kind of get a sense of that: what is needed for meta stability and then say how does that apply in the human world, but it will be different - it'll be very different. The rest of the animal world is not forecasting the future and making game theoretic decisions based on forecasts of the future. So this is why like complexity theory where we model us as termites is silly, like, we don't behave like termites. So it's not that it's useless, but it's profoundly inadequate as a set of metaphors. So we have to recognize: are humans part of nature? Of course. Is there a distinction between humans and the rest of nature that is fundamental in type? Maybe it was just a change of quantity of neurological complexity that crossed a threshold it became a change of kind, but it is a change of kind, and so we will have to have fundamentally different metaphors for thinking about that, which is why it makes sense to just think about the problem space and make sure that you understand the problem space well and that your solutions are aligned with the problem space." - [Daniel Schmachtenberger](https://youtu.be/U0YJ0C81n4s?t=4024)

> "To be civilized is kind of a domestication program for wild humans to be able to operate together at larger than tribal scale. And for hundreds of thousands of years, we never got tribes bigger than about 150 people. They stayed at very small scales, where everybody knew everybody, so that the sacrifices you made for others were non-anonymous people. They were people that you knew really well, and that you wouldn't do that at much larger sizes. And so, then the much larger thing, the thing we call civilization, can also be thought of as a domestication program. And the main things you have to domesticate out of people that make them not work other well have to do with sex and violence. And so, this is also where most of the psychological shadow comes, and it's why the intersection of sex and violence is the deepest part of most people's psychological shadow. They're kind of put into the same areas. But if you think about what institutional monogamy occurring with that context, one of the things that it was designed, or a few of the things it's designed to do, if you couldn't have sex until getting married, and then you weren't allowed to divorce, and that was actually held, and of course, no system will be perfectly held, but like just the idea, then in order to get laid, a guy had to get a girl's parents, and preacher, and community to decide that he was an acceptable husband and father. And that, and the binding of his ability to get laid to his ability to be a good father long-term meant that there was an incentive for him to actually be a good guy long-term, which meant him being a good guy for civilization and him being a good guy as a father were bound to his need to get laid, right? And that there was a vetting beyond her, who might have already got oxytocin to not be, you know, assessing him well, 'cause of the crush that the father, and the mother, and the whatever would also be helping to assess, to grant the right to do the thing. And then in the wedding ceremony, does anyone object? If he had been an asshole to other people, and they got to bring that up, so he has to be an asshole to nobody, otherwise, he's never gonna be laid. Then this would also be even where the slut-shaming came, which is such a terrible thing in our modern context, but I was coming to understand where a possible evolutionary relevance of it was that if any women would start to have sex with guys outside of the marriage context, which would mean that assholes could get laid, it creates an evolutionary niche for assholes to actually be able to make it, and then those guys figure out how to get more women to do that thing, and so, the idea was almost like herd immunity. The idea was a collectivist idea. You actually have to close the niche for assholes comprehensively. If you want a civilization to go well, guys are going to do what they need to do to get laid. So if you bind the opportunity to get laid to being a good citizen with multiple people vetting it, that's a good system. It's actually interesting, right? Like most people, myself included, who kind of grew up in a more post-sexual revolution, liberated idea, thought of that as just oppressive nonsense. And then I'm like, "Oh, that's actually interesting." So then the idea was that with birth control, you kind of have a sexual revolution. It seems like it's liberating for women in particular, because you decouple sex and reproduction for the first time. Where historically you could never really decouple sex and reproduction well, which is also why that was gonna inexorably affect her biology more than his, because he could possibly get laid, have a genetic benefit to do so, and have no consequence, and she could not have no consequence. It'd be a life or death possible thing for her, right? And so, of course she'll have higher criteria and more bonding biologically oriented, which makes perfect sense that it should be that way. But then she's able to kind of let that go and be a liberated modern person because of the birth control pill, but her evolutionary biology hasn't changed. Again, just like I can't eat all of the chocolate cake that I want and not get fat just cause I want to, right? The biology is the way that it is. I don't get to just separate the reward circuit. And so, then the idea that after that there was more of an evolutionary niche where assholes could get well-laid as a result of that, and that that actually has a culture-damaging property. So if you wanna go the convention of marriage, if you wanna not drop to pre-conventional developmentally meaning more selfish than the convention, but go to truly post-conventional, the post-conventional has to be, okay, well, how do the individuals have more freedom than the institution of marriage to make that choice while still paying attention and not creating niches for bad behavior to be able to propagate?" - [Daniel Schmachtenberger](https://youtu.be/_7aIgHoydP8?t=764)

> "The conservative, or traditional intuition is the idea that if there's a social system that made it through the trials of evolutionary history, and there's lots of them that failed, it probably has a lot of embedded wisdom that isn't obvious. It probably made it through for a reason. So go back to the old, keep the old thing, whether it's the Founding Fathers, or Christianity, or whatever the thing is, right, that you're trying to conserve, that there might be reasons why it worked that we don't even understand well, but that it was tested, and you know, tried and true, and so the conservation of that. The progressive intuition is we're facing novel situations that we never faced, and that the things that worked in the past couldn't possibly work for that, and innovation is needed. These are obviously both true, and need to be in [dialectic](https://en.wikipedia.org/wiki/Dialectic#Hegelian_dialectic). So the idea that either of those would be adequate is nonsense, 'cause if the new thing you're doing doesn't factor that most of the environment is still the same and the things that worked might work for reasons you don't know, and you throw the traditional thing out too fast, then realize it was doing things you didn't realize, and you just fucked up. Right, so the progressive often doesn't pay enough attention to the traditional impulse, and vice versa." - [Daniel Schmachtenberger](https://youtu.be/_7aIgHoydP8?t=1109)

> "Capitalism doesn't mean one thing. For some people, they think about that as any system primarily based on private property ownership, which would've included feudalism, and a different version, whatever. And obviously, Adam Smith capitalism and Milton Friedman capitalism are not the same kinds of structures, so with and without a central bank, with and without AI high-speed trading of complex financial instruments. They're totally different structures. I would say all versions of it are inadequate for a long-term viable system, but so are all versions of communism, socialism, and other economic systems as we've proposed them, so- - [Zubin] Perfect. - [Daniel] There's a lot to learn from all of them. There's a lot about theory of markets that's important, but the long-term system, like what isn't, what do we have to think about in terms of economics for making it through all of the catastrophic risks the world faces? And if it's not obvious, briefly, what the catastrophic risks are, you have all the environmental risks that are the result of the cumulative effects of industrialization and globalization. And so, dead zones in oceans, overfishing, biodiversity law, species extinction, topsoil erosion, climate change, blah, blah, blah, all of those things, peak nitrogen, phosphorous, whatever, all of those are the result of being able to extract resources from the world much faster than they can replenish themselves, and turn them into waste much faster than the earth can process them, i.e. a linear materials economy running on a finite planet that is bound to a monetary system that has a need for exponential growth to keep up with interest. And so, the exponential growth of the monetary system forces an exponential growth of depletion on one side and pollution on the other side. You get all the planetary boundary issues. So that's one set of things, and obviously, there's an economic driver associated with all of that, right? We have to change economics to be able to make sure that the social sphere and technosphere are compatible with the biosphere, right? Now, the social sphere-technosphere combo is debasing the biosphere they depend on. - [Zubin] And you can probably point at the root of that being the primary economic drivers now are one-marshmallow drivers that do not necessarily promote two-marshmallow, delayed, longer term thinking when it comes to those planetary boundaries. So in other words, if I don't go out and fish the oceans, another country will, if I, like sort of tragedy of the commons, like if I don't mine that particular ore, some other company will come, and knock the top of that mountain off, and pollute the rivers, and so on. And it's all in the service of the particular economic model, that is, you're trying to generate revenue, and those things are rewarded in the current system. - [Daniel] Yeah, and you know, the economic system creates a discount rate on future value, one, 'cause you can't predict it fully, but two, the current value gives me the ability to invest that capital, and make compounding interest, or other kinds of financial services investments with it. It also gives me increased optionality in a changing environment. And so, not knowing what the environment will hold, and wanting to do the best I can, I want the most choice tokens, right? And the dollar is a choice token. It's the ability to, with very high optionality and high liquidity, do whatever would be adaptive, whereas if I have a bunch of farmland, and the thing that I want in the moment isn't farmland, selling it is gonna be, take a while. If I have a bunch of mining rights, or I have a bunch of timber, or whatever it is, and especially if I have a bunch of trees that aren't yet timber, and then I decide that I want to turn them into capital for some purpose, there's a long lag time. So there's a game theory optimization towards more optionality, which means that the thing that has no real value, right, the dollar is purely representational value, but with maximum liquidity and optionality. I don't want the things with real value. I want to convert things with real value into the things with the only fictitious value, but that maximizes my optionality. And that's very much a short-term interest multiplied by a competitive collective action problem that is just where each agent making the choice that is good for them in the short-term is, creates a collective making maximally bad choices for the whole for the long-term. - [Zubin] And that in itself, and this idea that cash is king for that reason, the idea that those long-term choices are the potential civilization-level risks that we face, whether it's environmental, whether it's technological, whether it's national defense, whether it's nuclear war, all the things that you talk about. And I think, so going back to the capitalism is a one-marshmallow sort of optimizer, how does that then relate to where we are technologically, say, with one civilization-level threat, which is big tech, social media attention hijack? - [Daniel] Yeah, I mean, it's like something that anyone one would learn in the beginning of their business career that every business wants to optimize the lifetime revenue of a customer. And addiction is a really good way to optimize lifetime revenue of a customer, right? - [Zubin] Every hustler on the street knows this. - [Daniel] And so, I want, like the best business will apply to the most number of people, and have the most need for continuous purchases. And so, it's like, it's hard to beat fast food, right? It's hard to, like we can start when they're young. We can make it apply to almost everybody, and have it be a daily point of purchase for forever. And that's why McDonald's became very big, and Nestle, and you know, whatever, and Coca-Cola, and all those. But even that is actually dwarfed by social media, because obviously, a kid can start with an iPad before they can talk. - [Zubin] Yeah. - [Daniel] And start getting conditioned to hypernormal stimuli and customized environments to them. So we can start very young. The most time someone gets a Coke is still less than they check their phone, right? And so, the total number of points of contact, and it's optimizing for hypernormal stimuli across lots of vectors, right? It's getting your- - [Zubin] News- - [Daniel] Media outrage. It's helping, you know, sex appeal, food that you're interested in, stuff like, and- - [Zubin] Social credit. - [Daniel] And it's personalized to you with AI optimization. - [Zubin] Right. - [Daniel] And so, your newsfeed is like if I got to test every different version of salt, fat, sugar, artificial flavor combinations that maximize addictiveness to you, and Hostess could do that for each person, that's what social media is for the newsfeed." - [Daniel Schmachtenberger](https://youtu.be/_7aIgHoydP8?t=1880)

> "We live in a reality where most of the stuff that feels most consequential that we believe we have no first-person sensing of. - [Zubin] Right. - [Daniel] We are getting it mediated through a 2D screen, through other people's thinking, and other institutions, and you know, those types of things. That's significant, right? It's significant to people's ability to have collective intelligence systems work. There's a book, I think it was called "The Politics of the Invisible" that was looking at regulation issues after Chernobyl, where, you know, should farmers be allowed to grow food here and sell it that the countries had to deal with downwind of where Chernobyl was given that the uranium was invisible. And for the first time ever, not the first time ever, but like for the first time it became really obvious that there was totally invisible stuff that was totally consequential. So the farmers and the layperson had to trust those who had the ability with the Geiger counters, and whatever, to tell us stuff that only the priestly class that understood how to do that could do. - [Zubin] Oh. - [Daniel] Because now, we're engineering in the invisible in a really fundamental way. - [Zubin] Which we're not designed to deal with as humans- - [Daniel] We don't have the ability to all check and balance and go through the same epistemic process. So unless you happen to have the Geiger counters, and the knowledge of nuclear physics, and et cetera, and then the biophysics to say, well, how much increased radiation of what type is gonna create how much mutation to then be able to weigh against the difficulty of the farmers not losing their jobs, and those types of things. - [Zubin] Yeah. - [Daniel] And so, having created a very scientifically advanced society also means that then you need a lot of scientific insight to weigh in on the policy things. But that also means now people have to just trust a priestly class. And, or they all have to be adequately educated, and have access to all of those tools, and that, like adequately educated about virology, and nuclear physics, and epidemiology, and climate, and et cetera- - [Zubin] Not possible. - [Daniel] So you start to reach information limits. So then you have to say, "Well, fuck it, "we need institutions that are trustworthy "that can do that." Well, how do you get trust? How do you get everybody to be able to trust institutions? Even if you had an institution emerge that everyone trusted, 'cause it had some transparent way of being able to show real good epistemic process, and lack of vested interest, and rigor, and checks and balances on power, and it became a kind of legitimate authority, there's so much power to being a legitimate authority, to being able to be the arbiter of what is real that everyone who wants to win at the game of power will have a maximum incentive to try to corrupt that thing. - [Zubin] Hmm. - [Daniel] And so, then who wins? The scientists, and mathematicians, and philosophers focused on the thing, or the best players at the game of power, who are funding the thing, who have a maximum incentive to start moving it in one particular direction? So how do you maintain legitimate authority and have it not get captured? It's a real tricky thing." - [Daniel Schmachtenberger](https://youtu.be/_7aIgHoydP8?t=2584)

> "Democracy, like modern democracies, the US, and other kind of modern European democracies, emerged out out of kind of European Enlightenment, cultural enlightenment, and this is why the founders in the US said, "This system only works "with a comprehensively educated citizenry." And George Washington said, "It's the primary aim of the federal government to ensure "the comprehensive education in the science of government "of every single citizen," science of government meaning everything you would need to understand to know how to do collective choice-making well. So the difficulties of game theory and vested interest, economics, history, all those things, comprehensive education of every citizen in science of government is the number one goal of the federal government, because if the number one goal is rule of law, you can do it with a police state. If the number one goal is to protect the boundaries, you can do it with a military dictatorship. If you have the number one goal of being anything other than the comprehensive education of every single citizen, it won't be a democracy, 'cause democracy's very fragile, and requires that kind of thing, and it requires not only that everyone can make sense of third-person reality together, apply the philosophy of science, and kind of natural philosophy, but that they can make sense of each other's positions and value systems well, which is the good faith discourse, the empathy, the Hegelian dialectic. Can I really argue your position well? Without that, democracy has no chance. And so, when people have made their fellow countrymen the primary enemy, they are actually, in the short-term, they think they're trying to win a battle about COVID, or climate change, or systemic racism, or whatever the thing is. What they're actually doing is waging a war against democratic process writ large, where as you're making your primary countrymen the primary enemy, where all of the energy within that system goes to infighting, and then you elect more polarized representatives, who create more gridlock, authoritarian countries are just gonna do better geopolitically across every way. And then you're actually, what you're really fighting for is the authoritarian process to have more global influence over the 21st century. - [Zubin] Yeah. We're fighting for China, basically. - [Daniel] So really, the democratic process requires an epistemic commons, shared sense-making, and shared meaning-making to inform shared choice-making. Democracy is a shared choice-making process. But that means that we have to have some process to talk about what is- - [Zubin] Right, sense-making, right. - [Daniel] And some process to talk about what do we want, and I have to be able to understand the thing that you want and understand that just fucking you with the thing, you don't stop being a political actor, and then you're gonna act even harder next time. We're just gonna escalate arms race. - [Zubin] Yeah. - [Daniel] So how do we make compromises that address what everybody wants? - [Zubin] Yeah. - [Daniel] And so, the bad faith argumentation destroys the social contract, and the epistemic commons, destroys democracy. Good faith argumentation is not sufficient, but is necessary. And so, the steel man is the beginning of a good faith argument." - [Daniel Schmachtenberger](https://youtu.be/_7aIgHoydP8?t=2986)

> "One kind of model of the development people go through in terms of game theory, like their own intuition of game theory, you could call naive, cynical, post-cynical as a developmental process in the direction of increased capacity to do citizenry. Naive is where you assume good intent on other people's parts as a kind of default. You assume that what people are saying is generally what they believe, and that other people's interior experience is probably a lot like yours, and that where fucked up things are happening is probably mostly because of mistakes, and things like that. And if you interact with the world, and particularly systems of power enough, that will become destroyed in you, right? And then the naivete will crash upon the rocks of reality, and then you'll move into a cynical place, where you realize how much ladder-climbing, how much of virtue is virtue signaling, how much of communication as a whole is strategic, where someone is saying something for the effect they want it to have, not just for what they maximally believe, how much of the epistemic commons is the result of everyone's agentic desire to make other people believe stuff, rather than just what is true, all those types of things, right- - [Zubin] And by the way- - [Daniel] Get cynical. - [Zubin] And when you say epistemic commons, you're talking about the where, how we even get information by epistemic, yeah. - [Daniel] Yeah. We could call it the knowledge commons, which is just the available information that we can all look at. - [Zubin] Yeah. - [Daniel] But it's not just the knowledge, because the methodology that produced it, right, the epistemic process, is gonna be key to whether or not I believe it, how I factor it, all those types of things, and then what do I do with that? There's an epistemic process of how do I factor that data to actually come up with forecasts, and conclusions. And so, the data is not that interesting by itself. The entire epistemic commons, how do we collectively make sense of the world together? - [Zubin] Got it, got it, so you had the naive, then you had the cynical. - [Daniel] Yeah, now, in cynical, so you read Machiavelli, and you get a good description of the cynical, and that that type of court dynamic is actually playing out. And typically around any center of power, there's something like court dynamics. Around any very wealthy person, you watch in their social circle, and there's something like court dynamics. - [Zubin] Yes, we've all seen it. We see it at CDC, we see it at FDA, we see it every big institution. - [Daniel] And so, then you end up getting situations, where whoever is in the position of most power will get a distortion bubble of the type of feedback they get because people want something from them, so there are certain types of disagreements that won't happen. So then you'll get the propagation of their own biases, and other people confirming it, and all kind of nonsense like that, right? - [Zubin] The Steve Jobs reality distortion field type of deal. Actually, that's- - [Daniel] There's different kinds of reality distortion. This is one kind of vested interest reality distortion, and if you want an introduction to how to think cynically, "The 48 Laws of Power" is probably the best you can get. - [Zubin] "48 Laws of Power," who's that by? - [Daniel] Robert Greene. - [Zubin] Got it, okay. - [Daniel] And he's taking Machiavelli, but also Sun Tzu, and von Clausewitz, and most of the kind of strategic thinkers, and giving a summary of how does the game of power work. - [Zubin] Yeah. - [Daniel] And... And you know you're in the cynical if you say something like, "If you don't know who the sucker in the room is, it's you." - [Zubin] Yeah. - [Daniel] Right? Because you assume that the game of power is happening everywhere, there is some suckers, they're getting taken advantage of, et cetera. - [Zubin] Yeah. - [Daniel] I think the key is that there is such a thing as post-cynical, and the cynical would say, "The only thing that is not cynical is naive," because typically, things don't even have an awareness of a developmental stage that is beyond them- - [Zubin] That's right- - [Daniel] So that's where you get mistakes- - [Zubin] Blindness, yeah. - [Daniel] So the-post-cynical says it is possible to authentically care about something more than just self-interest in a way that you're actually willing to make real sacrifice for, and that they're are other people who also can, and that authentic relationships of trust can be formed. - [Zubin] Hmm. - [Daniel] So I couldn't be post-cynical if I didn't believe that there were other people that could be post-cynical. Right, 'cause I have to believe I can have- - [Zubin] They need to be there. - [Daniel] Of trust. - [Zubin] If everybody else is cynical, you can't, there's no trust. If everybody else is naive, there's no, you can't do it. - [Daniel] If they're just naive- - [Zubin] Yeah. - [Daniel] I can't trust 'em that much, because on accident, they'll get played by the cynical people, and even though they're trying to be loyal, the whole thing will still get fucked up- - [Zubin] It'll fall apart- - [Daniel] I have to know that the other people have an immunity to that process, that they're aware of it, but they are also not bound to it. This is in the world, but not of it, right? - [Zubin] Ah. - [Daniel] And so, to be post-cynical, you have to know that other people can be post-cynical, and then you have to be able to know how, what is a legitimate basis of trust, and how do I know that? How do I sense that? And so, what I would say is post-cynical good faith communication is necessary for something like the continuation of anything that's at all democratic, or republic. Anything that has participatory governance and is not just the people being ruled requires the people being able to develop that. So that has to become the center of the values of a culture that then develops that in people and checks it and reinforces it. - [Zubin] So does a post-cynical, this is fascinating. Does a post-cynical standpoint require the sort of transcending and including the naive and the cynical standpoint? - [Daniel] Of course. - [Zubin] So you have to be able to understand and inhabit the naive and the cynical to develop a post-cynical. - [Daniel] In the same way that a metamodern, or an integral, or a post-postmodern system actually has to understand postmodernist critiques on modernity well, and then also understand modernity well, right? You have to understand the philosophy of science- - [Zubin] Yeah. - [Daniel] And the Hegelian dialectic. You have to understand the postmodern critique of why there is no objective fact. - [Zubin] Right. - [Daniel] And why there is no objective absolute perspective, and claiming it's probably some type of imperialism, or power game in that you can't separate game of power from the propagation of ideas. - [Zubin] Yeah. - [Daniel] And then not just leave it there, 'cause that's an untenable place to leave it, and say how do we take that critique as a refinement, 'cause that's a deconstruction process. How do we take that deconstruction as a refinement to a constructive process, which means everybody can get on the same page with something other than the game of power, 'cause if all there is is the game of power, and all truth claims have no basis other than claimant power, then what you're actually doing is exalting power as the only possible thing, and that thing actually self-terminates, right? A situation where everyone is just playing the game of power, where that means that the epistemic commons and the social contract break, democracy breaks, you can't sense-make climate change well enough to do any solution with it that half the population doesn't resist, or COVID, or AI, or anything. And so, you have to come to a way of being able to make sense of the world, address values, and cooperate beyond just the game of power, which you know, kind of the metamodern thing. So the same with the post-cynical, right? The post-cynical understands why the cynical is there, and has to be resilient to that. So let's go ahead, and see where, say, a left, or woke perspective would say good faith just means you're a naive sucker, because let's say we're talking to a Native American about the history of the US keeping its agreements with Native Americans. And they're like, "Okay, well, good faith communication "just continues to privilege the current power system, "because it just says let's all be polite, and civil, "and whatever, and not address the fact "that the power system came the way it was "by some people totally fucking other people, "and there's no real push for them to change it, "and the victors rarely just give that up, "and every time we made the agreement, "then they fuckin' violated the agreement." And the black community could say the same thing. If you go and look at the history of like, oh, Emancipation Proclamation, but then fuckin' Jim Crow, and peonage, and you're like okay. So at some point, oh, I see, your argument about being good faith is just gaslighting. You're not gonna be in good faith. You're gonna pretend. You're gonna ask us to be in good faith, and then just fuck us- - [Zubin] And you're gonna screw us. - [Daniel] Yeah. - [Zubin] Oh, you see this play out on social media all the time- - [Daniel] In which case cynicism then seems like the only informed thing. - [Zubin] Right. - [Daniel] And so, you have to have some process to be able to say how do I show up to a good faith process and really sense if the other side is, and ensure they are, and orient towards that simultaneously, 'cause otherwise, we get defect-defect in the prisoner's dilemma. How do we get something to ensure against defect-defect and be able to have cooperate-cooperate, because everybody rationally doing defect-defect leads to catastrophe for everybody." - [Daniel Schmachtenberger](https://youtu.be/_7aIgHoydP8?t=3318)

> "In an environment that incentivizes you to lie, and to not trust people, and to even weaponize trust by creating fake trust in people, so you can then, you know, take advantage of them, whatever, if that's adaptive, right, you're actually being environmentally trained to be that way." - [Daniel Schmachtenberger](https://youtu.be/_7aIgHoydP8?t=4193)

> "So it's the idea that you can have something that is disruptive to the ideal homeodynamics of the system, but subclinical. It's not yet causing the acute pathology, but it's contributing to a causal cascade with a lot of other things that can have an effect. So that's examples of that physiologically. The same is true psychologically. So before someone has diagnosable, you know, serious depressive disorder, they can be much more depressive than would be an optimal state for someone, and we can call it kind of subclinical. Before they have generalized anxiety disorder diagnosably, they can have a lot more background anxiety then is necessary for the human experience. And the same is true for OCD, the same is true for complex PTSD, right? Complex PTSD, where you have kind of an excessive trigger response, sympathetic response to some kind of trigger, but instead of an acute PTSD, where that's on one event, it was a complex PTSD, meaning something that occurred many times. I would say it's arguable that people have complex PTSD on civilization, right? Like they have this kind of continued trauma associated with lots of things that creates an increased sympathetic response to lots of things. That is a pretty common phenomena, right?" - [Daniel Schmachtenberger](https://youtu.be/_7aIgHoydP8?t=4537)

> "So I think there is some kind of under-reporting, under-assessing types of issues that are part of it. And so, when we look at what percentage of the population has narcissistic personality disorder, whatever, that might be wrong, right? Those assessments might be wrong for any number of reasons. There's reasons to hide that signal if you can. - [Zubin] Yeah. - [Daniel] But I would say that the percentage of narcissistic personality disorder, or antisocial personality disorder in the general population is probably much higher than it ever was in an indigenous tribe, in which case I would say it was probably much, much closer to zero, because it would have always been found out, and be non-adaptive. - [Zubin] Yeah. - [Daniel] And I would say it's gonna be much higher as you climb up the stack of power and you have to actually win at lots of power games to get up there. And so, you know, there are some stats, I don't know if they're any good, but it's like, you know, 5% in the general population and 30% in the C-suite of Fortune 500s, and probably something like 90% in the C-suite of top financial services companies, and- - [Zubin] Yeah. - [Daniel] So- - [Zubin] It's adaptive in those locations, yeah. - [Daniel] It is selected for, incentivized, conditioned. - [Zubin] Yeah. - [Daniel] Et cetera. - [Zubin] All the above. - [Daniel] Which then also means that people with those conditions also have a disproportionate amount of power and influence institutionally. - [Zubin] Which that feeds back on a population level, because the institutions are a big part of our socio-technological environment. - [Daniel] So do I think that, you know, narcissistic traits are much higher than is native to the human condition under different developmental environments, and particularly tribal? Like tribal environment, you're just not gonna get away with lying very well- - [Zubin] Yeah. - [Daniel] 'Cause there's too much surveillance. You're not gonna get away with hurting people in a small environment, where everybody knows what's happening with everybody. You're not gonna be able to hide the effects of things, right? The increased transparency. But as soon as the system gets large enough that you can hide the effects, then you start having an evolutionary niche for those kinds of parasitic and predatory behaviors." - [Daniel Schmachtenberger](https://youtu.be/_7aIgHoydP8?t=4684)

> "Typically, in biological situations, it's not simple as one cause, right? It's a lot of things that collectively can reach a threshold and you have nexus causation. - [Zubin] That's right. - [Daniel] So are there genes that predispose certain kinds of things, but there's a lot of other attenuating factors and whatever? Totally. - [Zubin] Yeah. - [Daniel] That's what I think with regard, I think that the anxiety, the depression, the narcissism, the short attention spans, I think those are all conditionable, and I think they're conditionable where, you know, I like to look at positive deviance culturally, like where a whole culture for some period of time had one, or two standard deviations more of some desirable trait. So I like to look at Jains for nonviolence, or Buddhists, or Quakers, and be able to see can you have a whole population, which means all the genetic mutation within that population, and all the kind of variance, but where the population as a whole its median violence is a standard deviation better than everybody else's? - [Zubin] So there's a group dynamic- - [Daniel] Which means that culture, right, actually was able to, with factoring genetics, whatever, attenuate that a lot, and the same as across very different environments, do Jews usually educate their kids better than a lot of other cultures do, and reach higher level of education? It's very clear there's a cultural effect that does that thing, right? And so, then you start to think about could you have something that had Buddhist nonviolence and Jewish education and whatever types of processes in terms of could you have a culture that was developing the, you know, a different set of traits in people that made a different set of civilization possibilities associated with a increased post-cynical possibility? Now, of course, we're also looking at the fact that the technology is developing people itself. As we were saying, just simply the, simply the infinite scroll personalized to me type thing is going to have effects on attention span. It's gonna have effects, and having an effect on attention span also means it's gonna make me more one marshmallow everywhere, including offline. - [Zubin] Mmm-hmm. - [Daniel] Because I don't have delayed gratification built-in. And- - [Zubin] We see that now- - [Daniel] It means democracy will end, because democracy requires a long enough attention span, a long enough working memory that I can hear someone's perspective, hear multiple perspectives, hold them all in working memory, and try I to find a proposition that would meet many of their goals, right? Like if I really wanna be able to do collective intelligence well, it requires that, which is why, you know, Marshall McLuhan showed that not only did the printing press occur as, and the written word being accessible to everybody, everybody could get a newspaper, so you didn't need a specialized knowledge class that had access, and everyone could get textbooks and read, not only was the printing press a prerequisite for democracy, but the written word as the primary type of media was probably required for democracy to work, because it required people to think well enough that they could communicate in writing in long form in a way that could then translate to legal code, right, to really think through things formally, and that they were reading, which meant increased attention span of non-dopaminergic stuff, which also meant enough working memory to hear multiple perspectives, to be able to find something that might work, come up with a good proposition." - [Daniel Schmachtenberger](https://youtu.be/_7aIgHoydP8?t=4866)

> "What we have is we have a massive scale, right, maybe trillion dollar, maybe multi-billion person, massive scale population personal data, AI-optimized behavior mod system with no checks and balances on the power of it. (Zubin laughs) That's not like a company the way Adam Smith thought of companies. - [Zubin] Right. - [Daniel] And when you take that if it has an ad model, where the more time people are spending on site, and the more engaged, the better the ad revenue's gonna do, and it has a fiduciary response way to maximize value to the shareholders, so it has to keep optimizing that thing, the AI's gonna optimize for engagement, and the one-marshmallow sticky shit is just more engaging, right? Because otherwise, I don't plan my day, and say, "I wanna spend seven hours upset scrolling Facebook." I say, "Fuck, I don't wanna spend any time on Facebook. "I'm just gonna check it real quick," and then I get stuck, because something that was hypernormal enough brought me into a rabbit hole that obscured my prefrontal assessment of the amount of time I don't wanna spend on Facebook, right? - [Zubin] You got hijacked. - [Daniel] I got hijacked. - [Zubin] Yeah. - [Daniel] And so, it does not have the incentive to keep me intentional. It has the incentive to capture my intention, right? And so, if you have something that does that, it's going to increase all limbic process, so outrage, and addiction, and et cetera, which also includes polarization, and tribal identities, and certainty, and sanctimony, right? It's gonna increase all those things. So it'll double down on bias, rather than undo bias. It'll double down on tribal in-group kind of stuff, and shorten the attention span, so you couldn't even listen long enough to hear a counter perspective. And it wouldn't be dopaminergic enough to maintain the attention span. So that can't not polarize the population. And so, China was smart to be like, "No, fuck it, we're not gonna let that thing emerge. "It'll ruin our nation." And so, so if you polarize the population with increased certainty, outrage, everybody thinks their thing is an existential risk, if Trump gets elected, it's the end of America, if Trump doesn't get elected, it's the end of America, whatever, right, then they, the people will select more polarized representatives. The more polarized representatives in Congress and Senate like that can't cooperate with each other at all, so everything gets gridlocked. Everybody filibusters each other, and whatever. An increased gridlock system can get slower and slower, and more and more expensive capacity to regulate tech that is moving faster and faster. And if the regulatory system has slower feedback loops than the thing it's trying to regulate, it will just lose the ability to regulate it. And so, a tech that polarizes the population, and polarizes the representative class, that creates gridlock, that decreases the capacity of governance, will make that governmental system lose to another system that doesn't have those problems going on that doesn't have all of its energy going to infighting, that doesn't have gridlock in its decision-making process, and- - [Zubin] Has a longer term outlook, too. - [Daniel] It has a longer term outlook, because you don't think that in four years everything you did will get undone. - [Zubin] Yeah. - [Daniel] And so, in the same way that the printing press kind of ended feudalism and started to make modern democracy possible, this tech is kind of ending democracy as we know it, and orienting towards authoritarianism, unless we start to redesign it in a fundamentally different way." - [Daniel Schmachtenberger](https://youtu.be/_7aIgHoydP8?t=5486)

> "So let's say we built a Facebook-like thing that had lots of different types of content that were being personalized to the individual, but that didn't have a business model that required ads to do it, so it had a different basis of optimization, wasn't trying to maximize time on site, or engagement in that way. Let's say that the thing it was trying to maximize was your Lectical Score. - [Zubin] Hmm. - [Daniel] And so, it was looking at where you were typing in responses, and your general engagement, and it was wanting to see that your ability to, and your disposition to seek and steel man more perspectives, and have more nuanced perspectives, more ability to orient towards empiricism where it was relevant, et cetera, that those were the things it was optimizing for, and it was curating content to you both based on what would be outside of what you were already exposed to, but also in the zone of proximal development that you could grasp it. And again, empirically upregulating in that way, that would produce really different results, right? You could be growing attention span, rather than decreasing it. You could be growing multi-perspective, multi-perspectival kind of capacity through the nature of what that AI pointed at your brain is optimizing for." - [Daniel Schmachtenberger](https://youtu.be/_7aIgHoydP8?t=6597)

> "The thing that is measurable will have externalities. Even a weighted algorithm of N measurable things will have stuff that's really important that's not included in it that if you're optimizing for you'll end up having the externality. So you can optimize, but you want a process that what you're optimizing for is itself being continuously iterated. - [Zubin] A recursive process with the optimization parameters. - [Daniel] Where the externalities of what's being harmed by the optimization are continuously being internalized. But that means you also need a governance system that can do that, which means you can't be bound to something like fiduciary responsibility for profit maximization." - [Daniel Schmachtenberger](https://youtu.be/_7aIgHoydP8?t=6796)

> "How do you internalize externality, and make, and close perverse incentive niches is one of the fundamental things humanity has us to get better at, right? Like we have to fundamentally change our socioeconomic systems to do perverse incentive minimizing much better than they do." - [Daniel Schmachtenberger](https://youtu.be/_7aIgHoydP8?t=6921)

> "But Bohm was looking at the orientation of a mind that mostly thinks in words, of Western mind, you know, in particular, to break reality into parts, and make sure that our word, the symbol that would correspond with the ground there corresponded with the things that it was supposed to, and not the other things, so try to draw rigorous boundaries to, you know, divide everything up, led to us fundamentally relating to everything as parts first. And so, then you get stuff that doesn't make sense. Like you bring parts together, and there's some new property that none of the parts have, and you have to call it emergence, and it seems kind of wacky, but it was only because that property was there from the beginning and you took it into parts- - [Zubin] Parts- - [Daniel] And- - [Zubin] Oh, fascinating! So you call it emergence because you started with the parts, and you built it up, whereas it was a whole to begin with, and ah, so what was missing, you're calling emergence. - [Daniel] Exactly. - [Zubin] Ah, fascinating. (Zubin laughs) - [Daniel] And so, whether you have one country trying to benefit itself at the expense of another country, or all of the countries trying to grow their GDP at the expense of the ecosystem, or a proposition that is benefiting something, but harming something else, and polarizing the population, or a particular metric you're trying to optimize for in healthcare that causes iatrogenic cascades to damaging something else, or whatever, the highly interconnected world where the solution, or what you're optimizing for, is made a narrow subset of everything. The thing that you're doing is still interacting with complexity. So whatever it's affecting outside of what you're intending to affect will be negative externalities. Some people will care about those. They'll respond to those. You'll keep driving conflict, driving externality. With exponential population and exponential tech, that thing self-terminates. So how do we, we can't do exponential externality. So you have to do a better job of not doing externality, which means that the goal is not to optimize for GDP. It's something broader than GDP. It's not just GDP per capita. Okay, we need to add a Gini coefficient. Yeah, but that doesn't include personal happiness, whatever, so we need to add a national happiness index. Yeah, but that doesn't include environmental stuff, so we have to add a CO2 thing, but that doesn't include nitrogen, so- - [Zubin] Parts, parts, parts. - [Daniel] You keep adding, and yet there will always be stuff in some finite set of metrics you're optimizing for that matter that are outside of that set. - [Zubin] Yeah. - [Daniel] So how do you actually relate to the whole, and say the thing we're trying to optimize for is not definable, right? That's what I would say the first verse of the "Tao Te Ching" was about, right? The Tao that is speakable is not the eternal Tao, and that's what I would say the no false idols thing was about, that as soon as you say, "The thing we wanna optimize for is X," it's not really it, right? That's not. The thing you wanna optimize for is the nature of the sacred. You try and define it, you're gonna fuck it up. - [Zubin] Yeah. - [Daniel] But you can sense it progressively better. - [Zubin] Yes. - [Daniel] And you can do a lot of defining around it. But if you think your definition is it, that's a false idol- - [Zubin] I see. - [Daniel] And so, how do we, (Zubin laughs) how do we not have metrics that create optimization systems that then bind us, right, where now the board wants to hold the CEO to quarterly profit metrics to be able to get the money back to the shareholders who invested, so we create a law for the fiduciary responsibility for profit maximization. And now, even if you see there's an externality, you can't do anything about it, because you're already bound to the metrics you're optimizing. - [Zubin] Yeah. - [Daniel] So whatever set of metrics that we're optimizing for, we have to be able to pay attention to things that are outside of those metrics that matter, and be able to progressively internalize that, which means we have to create governance structures that can orient around the ability to do that. - [Zubin] Okay. - [Daniel] Which also means we have to create minds that are oriented to do that, and know that other minds will notice shit that you don't. This is where authentic diversity matters. Other minds will notice shit that you don't, and there's no way to notice all the things they do, which is why you have to be in dialogue." - [Daniel Schmachtenberger](https://youtu.be/_7aIgHoydP8?t=7726)

> "One way that you get over the data singularity of that there's more data than anyone can pay attention to is people don't actually need to make, they don't need all the data to make a choice. They need the meaning, which is like a second, or third derivative on the data, which can I have the AI process a fuckton of data to be able to parse where there's incorrect stuff, where there's high confidence stuff, and put it into the form that is decision informing, and then what is relevant for decision informing is stuff that people can actually keep up with?" - [Daniel Schmachtenberger](https://youtu.be/_7aIgHoydP8?t=8861)

> "Satellite imagery of the earth is a pretty amazing technology. There's a friend of ours who runs a company called [Planet Labs](https://en.wikipedia.org/wiki/Planet_Labs) and they image the entire surface of the Earth every day - 30 terabytes of compressed data - but they're increasing the spectral and temporal resolution of that and spatial resolution sets that it'll be pretty much real time human level video capture of the surface of the Earth in about three years. Which is amazing and one of the things it means is the ability to see where logging is happening and where mining is happening and where dumping is happening and where illegal phishing is happening and even to be able to see in a dead zone in the ocean, the effluent how much of it came from which source, how much came from which port, and all those types of things - the ability to see all that, use machine learning to process it, means that there's a whole bunch of international law that we've never even bothered to create because it'd be no way to know if it was being violated or enforce it. Now we'd have the ability to create international law that says: no, actually you don't have plausible deniability anymore - we know exactly how much of the trash or the nitrogen affluent came from there because we can see the whole thing. It also has the ability to do spectral analysis that can see an invasive species entering an area or soil microbes in an area to be able to actually support the environment when critical issues are starting to happen. But this is itself very concerning, because probably many of you even as I'm describing this are like: wow, that's really hopeful for the environment - to be able to have that level of transparency - that could create law so we could support the environment, but who gets to have access to video level data of the entire surface of the Earth all of the time? That sounds like pretty massive surveillance capability, which it is. So that can prevent certain catastrophes but can totally create dystopias depending upon how it's managed. So how do we create the governance of that information such that it doesn't get used for nefarious purposes and that people get to know what it's being used for? This is this is not trivial, right, because it's easy to deploy the technology to solve those problems - it's actually quite hard to create the governance to ensure that it's used properly." - [Daniel Schmachtenberger](https://youtu.be/6aKI2C61jVE?t=3054)

> "There's a cost to a whole ecosystem: into the people, into the future generations that'll be affected by the pollution, but I don't pay the cost, and because I'm not paying the cost I get to have the profit margins that I have. If I had to pay the cost, which mean I had to employ a technology that currently exists to clean all that up and whatever that costs, my business might be radically not profitable. So then maybe we'll try and create a law to make it to where I can't do that pollution. But I'm not doing the pollution as a person - I have some corporation that has some liability limiting functions of any of the people within the corporation, so the corporation is breaking the law, and you can't put a corporation in jail - so there's a fine. But if the fine is less expensive than processing the waste would be then it's just a cost of doing business. And then the corporation will employ lobbyists to go change the law because laws are going to be created by lobbyists, that are paid for by somebody, and they're going to be created by politicians who have a campaign budget that is controlled by somebody. So basically economics has perverse incentives, we try to create law to bind it, but economics is deeper in the stack of power than law is. So you end up getting this legal system that is supposed to bind the perverse economic incentive that mostly ends up legislating and in the benefit of it. And this is a fundamental problem with the liberal democracy idea." - [Daniel Schmachtenberger](https://youtu.be/_b4qKv1Ctv8?t=3177)

> "We don't even have to deal with protesters with tear gas or beanbags or whatever mostly, because mostly addiction and student debt and information overwhelm and those things deal with the people adequately. So they don't actually understand enough or care enough or have the capacity to organize very meaningfully." - [Daniel Schmachtenberger](https://youtu.be/_b4qKv1Ctv8?t=3787)

> "We keep searching for our own blind spot so that we can do business there, right, and so what it is that we can't measure very often becomes a place to do business because almost everything produces negative externalities. and so it has to be disguised." - [Eric Weinstein](https://youtu.be/_b4qKv1Ctv8?t=3352)

> "The market is a collective intelligence that is eventually self terminating in the same way that a cancer is. Right, the cancer cells are self-replicating and they're growing faster than normal cells but they end up killing the host which kills themselves. And so the reason I'm bringing this up in terms of collective sense making is: those who do the will of capitalism, like, those who do the will of the [paperclip maximizer](https://en.wikipedia.org/wiki/Instrumental_convergence#Paperclip_maximizer), [Moloch](https://slatestarcodex.com/2014/07/30/meditations-on-moloch/), Sauron, or whatever kind of analogy we want to use here - those who do well at the game of power get more power. And then they use that legislative power, media power, capital power... to modify the systems in ways that help them more. Right, those who oppose the system of power also oppose those who are doing well at it, so even though the system is inanimate - the people who are doing well at it are animate, so then they take those people out - which is... we see how Martin Luther King and Gandhi and Jesus and etc. died - people who actually opposed the system of power. And so you end up having a system that is selecting for or is conferring more power to those who are good at getting more power, which ends up meaning who are selecting for conferring power to sociopathy." - [Daniel Schmachtenberger](https://youtu.be/_b4qKv1Ctv8?t=4203)

> "All of these interesting people are simply humans and you can destroy any human reputationally. And so the cheapest thing to do is not to kill anybody, but just as somebody starts to accumulate mindshare - the [gated institutional narrative](https://theportal.wiki/wiki/Gated_Institutional_Narrative_(GIN)) goes into hyperdrive and it just starts pumping out fear, uncertainty, and doubt, which is the... you know [FUD](https://en.wikipedia.org/wiki/Fear,_uncertainty,_and_doubt) is the major tool for destroying an individual's ability to communicate reality." - [Eric Weinstein](https://youtu.be/_b4qKv1Ctv8?t=4600)

> "So their definition of something that translated to schizophrenia: the first symptom was 'had negative feelings about the state' and the second symptoms might take a while to show up. And so what I think happens is that the dominant system ends up eating psychology and saying that the psychology that supports the dominant system is healthy psychology and anything that is dissenting to it is not healthy. It ends up eating spirituality and virtue and ethics and academia and whatever to basically say: the behaviors that support the system are good, so the thinking that supports those behaviors is good, and anything that's dissenting is bad. And like it's so easy to see it in the Crusades or in jihadism or even in Victorian time period - it's just very hard for us to see it about ourselves now. But I think that's actually like one of these fundamental things in terms of you're saying like why don't we have group sense-making is because you have us you have a self-perpetuating system that includes the self perpetuation of the memes that support the system." - [Daniel Schmachtenberger](https://youtu.be/_b4qKv1Ctv8?t=5255)

> "When we come back to the difference between personal incentive and collective incentive you say why aren't we more successful? Obviously it's like: okay, so what is the incentive for someone to agree with us that for the most part expressing these things would make them do less well at politics and their job and maybe even their social club and maybe even be part of the in-group that they're part of whether it's the left or the right or the whatever it is because then they would be saying things that there's almost no in-group that they would be aligned with or very very small? And so you still end up having that there's more selective pressure for the individuals to continue to be part of institutions even an institutional thoughts also doesn't make sense." - [Daniel Schmachtenberger](https://youtu.be/_b4qKv1Ctv8?t=5460)
^^ maybe not a good enough quote...

> "If we ask a question like even what's actually causing coral die-off: how much of it is temperature versus pH versus nitrogen messing up the phosphorous cycle versus trophic cascades - how long do we have before the coral die-off? What are the consequences of that? You know, like, really important questions. Or what are the actual... What really happened in North Korea - like why there was such a change just recently, and what are the actual tactical nuclear capabilities that they have or how much leakage actually occurred at Fukushima or like any of these things - nobody fuckign knows. And you'll hear different narratives and you'll hear kind of equally compelling disagreeable narratives on those and almost no one has the time or the will or the epistemic capacity to really figure that out. So one point is that sense making is actually hard: you have a situation in which a lot of these things are complex enough and there's so much disinformation that when people try to actually figure it out they just get an information overwhelm and then it's very hard for them to continue. So when you're saying like obviously stupid - well there aren't... there's a lot of places where people can hold a train of thought that seems cogent enough even if it's in direct opposition with another cogent train of thought and like just the plausible deniability that it might be one of the true ones since nobody can really sense make seems to be enough. And so this is one of the really tricky things is: in a world where if I have the incentive to disinform at various different levels and then I have exponential information tech so I can do exponential disinformation - now this is... when I say that the system is inanimate I.. abd I give this example: everybody who's seen Tristan Harris's stuff will know this - but if we think about disinformation via the nature... **ERIC:** Tristan Harris is a mutual colleague - he heads a movement called time well-spent and he's trying to show you that your attention has been effectively weaponized against you where the big tech platforms are figuring out how to keep your eyeballs on their system to your detriment. **DANIEL:** Center for humane technology - you can see his stuff, but like I think a lot of people know that news stations as for-profit companies have to make money and they make money by monetizing attention and basically they sell advertising and the advertisers pay more the more people who are watching for more total minutes. So the incentive of the news station is to make stuff that is both inflaming and scary and entertaining and whatever will engage people to spend a lot of time watching in, and to not say things it would not be to the advantage of the advertisers that can afford to pay for them, right, so they have an incentive to not share really complex nuanced things that will have most people click off..." - [Daniel Schmachtenberger](https://youtu.be/_b4qKv1Ctv8?t=5590)

> "I don't believe that this is all being driven by profit - I believe that there is some force that we don't understand that keeps the [gated institutional narrative](https://theportal.wiki/wiki/Gated_Institutional_Narrative_(GIN)) gated. **DANIEL:** Yes, I think profit is one part of it - that's why I say we have to think of profit as one aspect of kind of power or rivalrous dynamic more largely, because it's... I think government or academia or religious or cultural groups or profit can all influence the nature of narrative and information. **ERIC:** I think there's an economy of shame and terror. I believe that the real reason that this works the way it does is we have not even gotten to a very basic point where it is considered acceptable to say: I want immigration restricted. Now I point this out because I think it is very funny: most people who want immigration restricted enjoy food from other cultures, they have friends who come from other places, they enjoy travel - there's nothing xenophobic about them - in general there is xenophilic, and the idea that you can be both xenophilic, fascinated, and interested in the world's cultures, and want immigration to your country restricted, and that this is the generic position that the average person holds this position - is a story that appears nowhere. So nobody has an idea that xenophilic restrictionists might be a plurality or a majority in the country, because there is a rule that says: anyone who calls for a restriction of immigration must be tarred as a xenophobe, and I think it's time to double dog dare the people who are keeping this level of discipline. Say: why is it it impossible to be a xenophilic restriction. What I think is is that the economy of shame is such that whoever acts first to make this point is in such danger for their livelihood, their reputation, that they are going to be tarred and feathered and why one of the things that I'm trying to show people is that you can make these points. Now I can't do this on CNN, but I can do this on pirate radio. This is basically audio [samizdat](https://en.wikipedia.org/wiki/Samizdat) - to take the Russian underground mimeograph movement as a template. We can say things here, but there's only a matter of time before this starts to become problematic to the institutional structure, and it responds by debiting my account. Oh, well that that's that alt-right guy, you know, he seems disgruntled or you know - he seems gloomy and out of touch, and then the fear uncertainty and doubt campaign starts and that's what is actually keeping everybody in line. It's not that there isn't money to be made - there's tons of money to be made - what's happened is that it's been too easy to pick off the initial adopters. **DANIEL:** I agree, and I'm curious what your explanation of how that phenomena emerged. **ERIC:** So let's really get into it. We did have a dissension suppression unit inside of the FBI which was called [COINTELPRO](https://en.wikipedia.org/wiki/COINTELPRO). And it tried to induce Martin Luther King jr. to suicide through a letter from Sullivan who was I think number one or number two - maybe under Hoover - this thing lived inside of the FBI, it probably tried to tell John Lennon that he was traitorous, it tried to humiliate Jean Seberg who is a Black Panther supporter by planting false information inside of mainstream media - Newsweek in the Los Angeles Times, it tried to get la cosa nostra to kill Dick Gregory - the famous comedian and black civil rights leader. So we did have a dirty tricks unit inside of the United States that needs to be known broadly, which was pretty thoroughly investigated in the mid-1970s and once we saw that we were engaged in his dirty tricks against our own people we were kind of shocked and flipped out, and the economy wasn't in great shape, and then Ronald Reagan came riding in and I think he pardoned Mark Felt who had been the head of COINTELPRO after Hoover, but he was also deep throat, and so you had this very strange situation that we got this reboot during the Reagan years where we went back to some sort of more traditional more patriotic imagined version of our country, and my belief is that in part when Bill Clinton decided that he couldn't take yet another loss to the Republican Party and was gonna start experimenting with republicanism inside of the Democratic Party - by that point we had two parties that more or less were two flavors of the same thing. I refer to that collective as the looting party: in the looting party - the neoliberals, the neoconservatives - sort of intergenerational warfare within the country, in the US, and my take on it is that the common ideology is that profit had to be found abroad and so you had to loosen the bonds to your fellow citizens and that's where all of this kind of 'the market always knows best, we need to offshore and downsize and securitize' and what I've called the new gimmick economy. So that right now we're waking up from the new gimmick economy and having never lived in anything really authentic unless we're quite old. So my belief is that during that period of time there was very swift retribution for anyone who dissented - famously a prominent trade theorist who was talking about the benefits of trade restrictions for infant industries let's say apparently got a call from one of the people high up in the field say: 'oh, you seem to be a very bright young man - it would be a shame if anything happened to your career' and so this kind of idea suppression is the hallmark - well it is what I think these two generations - the baby boomers and the Silent Generation - may become best known for in the future, that this was a period in which new corrective ideas had to be suppressed because of the fragility of the system. We saw the fragility breakout in 2008, we saw have vulnerable we were in 2001, and we see that the whole sense making apparatus is breaking down from the Trump election. So these have been the three moments when the gated institutional narrative has broken because it just got overwhelmed by events. But other than that, the key was making sure that people like you, or like me, or like [Peter](https://en.wikipedia.org/wiki/Peter_Thiel), are not mainstream. The cost of listening to us has to be driven to astronomical levels so we have to look wild-eyed, we have to, you know... they can't call me uneducated if I have a Harvard PhD which is one of the funny parts of the system, but the idea is that you have to say: 'well, you know, maybe he used to be smart but he's gone fringe' so the social cost... **DANIEL:** It's amazing how effective such small amounts of that can be. **ERIC:** Well it's also just funny, I mean, it just... There's so many hours of audio of us and I was just astounded, for example, with the number of people who would try to portray let's say my [brother (Bret Weinstein)](https://en.wikipedia.org/wiki/Bret_Weinstein) as right-wing - I mean from my perspective: can you imagine making that decision that a guy as far left as Brett and you're gonna spend your credibility pretending that he's like allied with the Nazis? I just... It doesn't even make sense to me because it's simply to me a way to incinerate your credibility. And yet the way the system works is you incinerate people's viability. It's economic warfare - that if your reputation is damaged you can't be trusted, you know, and that's how this enforcement is working. So you ask me the question how does it work to keep this in line - it's to trivially easy to destroy individuals. And my question has always been: is there a program which I have tentatively called 'no living heroes' - I don't know if you've heard this riff before. [Charles Lindbergh](https://en.wikipedia.org/wiki/Charles_Lindbergh) who was not a great human being almost kept the U.S. out of World War two - he said why is this why is this America's problem? And if you think about it, he had self-minted credibility in that he got into a plane and he flew it over an ocean solo and became a hero, and that level of visibility allowed him to compete with the state. Okay, I think that there was a program after Lindbergh that said: individuals should not be able to amass sufficient mindshare to affect the course of government policy. And this is a question in my mind: is there a program that got started that said we're gonna wait and see if anything starts to bubble up that seems to have integrity, it seems that mindshare, it seems to be opposed to our policies, and if and when we find such a thing - it has to be redirected, co-opted, destroyed reputationally, or made ineffectual. And the phrase that I really appreciated that was used about Jean Seberg who was - you know - one of Hollywood's great leading ladies at the time, was we have to cheapen her image. This is the federal government talking about cheapening the image of a Hollywood star because she was interested in radical black politics." - [Eric Weinstein](https://youtu.be/_b4qKv1Ctv8?t=5830)

> "Imagine if we could create a situation where there was no incentive for disinformation. I'll talk about in a moment how I think we could do that. And not just no incentive for disinformation but also no incentive for information withholding. And something pretty unique about humans is how good we are at being able to add intention to signal - lie - but all the subtle versions, right, which is most of the signal that is coming to me is just bouncing off of stuff and reflecting and doesn't have that much disinformation in it, and obviously animals have camouflage and strategies like that, but every time we're communicating we are usually communicating towards some intention that we have and so I want you to think certain things were you thinking those things I think will advantage me, but then to the extent that you take what I'm saying as adequately informing you - like accurately informing you about reality - or not be, right, like there's a discrepancy between why I'm communicating to you and what would be maximum benefit to you. So... and even if we're not doing spin and [Russell conjugation](https://en.wikipedia.org/wiki/Emotive_conjugation) disinformation - even if it's just IP & trade secrets and information withholding - this lowers our coordination capacity to do interesting things tremendously. And then there's so much coordination cost that goes into the competition. So let's imagine... and I think we can say: up to a tribal scale people could do - I'm not saying they always did it, I don't wanna be romantic - people could do a better job of accurate information sharing, because there was less incentive to disinform each other inside of a tribe because it would probably get found out and we actually depended on each other pretty significantly. But the Dunbar limit seems to be a pretty hard limit on that kind of information sharing. **ERIC:** So do you mean this supposed Dunbar number that is the limit of our ancestral mind or group to track the number of interactions we have, so maybe I can keep track of 200 or 300 people, but not much more? **DANIEL:** Yeah, whether it's a hundred and fifty or 50 or 200 or whatever it is - and you know, I think we've attributed this to different things - why tribes never got beyond a certain scale within a certain kind of organization and if they would start to they would cleave, and then if they were going to get larger they had to have a different kind of organization. I think how... one thing that we commonly think about is that kind of a limit of care and tracking, right, up to that number, up to 150 people or whatever, I can actually know everybody pretty well, they can all know me, and if I were to hurt anybody I'm hurting the people that I've known for my whole life. So something like universal interest of that group or almost like a communalist idea makes sense if there's no anonymous people and there's no very far spaces where I can externalize harm - I basically can't externalize harm in the social commons when I know everybody. I also probably can't lie and have that be advantageous. I think there's another thing which is there's a communication protocol that anyone who has information about something within that setting can inform a choice where that information would be relevant that the tribe would be making, because they can actually communicate with everybody fairly easily. And if there's a really big choice to make everybody can sit around a tribal circle and actually be able to say something about it, and as you get larger you just can't do that. And I think there's a strong cleaving basis for not wanting to be part of a group that would make decisions that I'll be subjected to that I don't get any say in. Unless it's really important to do that, like, we're gonna have... there's a situation where tribal warfare is starting to occur more often, and so having a larger group is really important or you know something like that, in which case the bonding energy exceeds the cleaving energy. But let's say that we could actually have a situation where we had incentive to share - to not disinform - and to share accurate information with each other and it could scale beyond a dunbar size - so now we have something where we don't have fractal disinformation inside of a company, we don't have people competing for cancer cures that aren't sharing information with each other. I think that system would outcompete all the systems that we've had in terms of innovation and in terms of resource utilization, resource per capita utilization so much that if we could do such a thing it'd become the new attractive basin to which civilizations would want to flow. And I think the limit of Dunbar dynamics were communication protocols. And I think we do have technological capacity - and I mean both social technologies and physical technologies to develop systems - and so like this is kind of at the heart of it: to develop systems where there was more incentive to share honest information - and obviously this is an example of anti-rivalrous where I had my well being and your wellbeing and wellbeing of the commons more tightly coupled to each other. That's the first part of it. **ERIC:** Okay, so try to figure out how to get very large-scale human collectives to behave like small scale human collectives. **DANIEL:** Well, yeah... If I think about two groups of people... **ERIC:** That sounds to me like TripAdvisor where I travel to some country I've never been to and I'm never going back again and there's some sort of reputational cost that a hotel would have had if it had gamed their guests so it becomes a bad idea to game your guests because you have a fractional relationship with the world in some sense, where somebody has left a review that says: 'be careful they try to upsell you on the Wi-Fi and it's a scam and here's how to look out for it' and suddenly you have got a problem if you're a dishonest actor because there is this sort of reputational game that is technologically enabled. **DANIEL:** So I think this is why people like blockchain as the idea of an uncorruptible ledger is that dinformation and information withholding that wouldn't be really beneficial to the public and any kind of bad acting does less well with good accounting systems. I have to be able to kind of corrupt the accounting in some way to be able to have it be advantageous. And so can we make systems that make the accounting much better is part of it, but it's not the whole basis, because then of course you still have incentive to figure out how to game the game - whatever it is - as long as we still have separate interests. And the separate interest which is that any in group can advantage itself at the expense of an out group or any individual can advantage itself at the expense of other individuals which is grounded all the way down to like a private balance sheet - I do think is an inexorable basis of rivalry, and I do think that rivalry in a world of exponential tech does self-terminate. And given that I don't think we can stop the progress of tech I do think we have to create fundamentally anti-rivalrous systems and I don't think you can do that with capitalism, or that private property ownership is the primary basis to how we get access to things. I don't think you can do it with communism or socialism or any of the other systems we've had, but I don't think that if we look at how the coordination system of cells or organs inside of a body works - I don't think it's capitalist or communist - I think there's a much more complex way of sharing information and provisioning resources within the system." - [Daniel Schmachtenberger](https://youtu.be/_b4qKv1Ctv8?t=6688)

> "I look at some outliers on both sides of the bell curve of various dimensions of the human condition and let's say we take Buddhism for instance. We have something like three millennia of 10,000,000 fluxing give or take people who mostly don't hurt bugs - across different bioregions and across different languages - and that's really significant when we think about the inexorability of violence in humans. And then we look at say the [Janjaweed](https://en.wikipedia.org/wiki/Janjaweed) or some group of child soldiers where by the time someone's a teenager they've all hacked people apart with machetes. I think that the human condition can do both of those. Human nature can be conditioned to do both of those. But then I see that we have a system where in general as soon as a tribe figured out... as soon as a couple tribes were competing for resources it was generally easier to move than it was to war. Until we had moved everywhere, in which case it started making sense to war and then as soon as any tribe militarized as every other tribe has to militarize or they lose by default and the game of power has begun and in earnest in that way - the human on human game. And I think we've seen that the peaceful cultures largely got killed by the warring cultures and the warring cultures learn from each other how to be more successful at it and so the thing that we have now is something that has emerged through iterations on power dynamics and it's conditioning everyone within it and then we do all of our social studies within that and say this is human nature." - [Daniel Schmachtenberger](https://youtu.be/_b4qKv1Ctv8?t=8207)

> "I see the possibility for a steady-state population that is within the carrying capacity of a closed-loop materials economy, but that is fueled by renewable energy - so you basically have a finite amount of atoms, so you circle the atoms, you don't have a finite amount of energy because you're getting more energy every day but you have a finite amount per day and so you have to be able to cycle the atoms within the energy bandwidths, and you're cycling it from one bit pattern into another bit pattern, right, like from one form into another form, and the forms are stored as a bits. So you have atoms, energy, and bits, and you don't really have a limited number of the bits that you can have. And so we can have an economy where it's getting continuously better but not by getting bigger, but by getting better - we continuously make more and more interesting things with the same fnudamental stuff." - [Daniel Schmachtenberger](https://youtu.be/_b4qKv1Ctv8?t=8464)

> "It's important to say: obviously if I have a situation where valuation is at least largely proportional to scarcity, then I have a basis to continue to manufacture artificial scarcity, and if something becomes abundant enough it loses value - then of course abundance and markets don't go together." - [Daniel Schmachtenberger](https://youtu.be/_b4qKv1Ctv8?t=8837)

> "There are so few people who are attempting to think rigorously about what we actually are and what we must become if we are to have a long term future." - [Eric Weinstein](https://youtu.be/_b4qKv1Ctv8?t=8975)

> "Every branch of the decision tree has gotten hyper weird, and anybody who's not looking at the fact that there is no non-weird branch of the decision tree is missing the story of who we are and what time it is in human history. So I think to not explore the weird, to not dream about what might be is the least responsible, least adult thing we can do. If we don't dream and we don't explore the weird we're doomed." - [Eric Weinstein](https://youtu.be/_b4qKv1Ctv8?t=9056)

> "I think we get something like a certain level of empathy up to the Dunbar number just through mere neuron type effects, through the fact that I know these people, they know me, we've lived together, if they're hurting I am gonna see it because they aren't somewhere far away. And similarly I'm less likely to pollute in an area I'm in then through an industrial supply chain that pollutes somewhere that I'm not. So just a proximity where the cause and effect has a feedback loop as we start to get to much larger scales where I'm having a cause and there's an effect but I don't get a feedback loop on it - the broken open feedback loop is a problem. So I think the Buddhists were able to train abstract empathy - not just empathy for the people who I see hurting, but empathy for all sentient beings throughout time and space, right, feeling their connectedness with them, that the nature of the [vows of the Bodhisattva](https://en.wikipedia.org/wiki/Bodhisattva_vow), and they're not the only one, right, this is... different religions have tried to do this, but it's an example of a group succeeding at it, where they were able to have a sense of positive coupling: of my well-being in the well-being of another rather than inverse coupling: they get ahead and it's decreasing my ability to get ahead. What the other side of the Dunbar number was not just who we care about, but also our ability to coordinate, and I don't think they were able to figure out coordination mechanisms that are adequately effective at scale. I think if we do both of those things we can make a fundamentally different kind of civilization. And rivalry mostly comes down to today: private balance sheets, which is I can get ahead economically and that money equals optionality for most of the things that I want. And I can get ahead economically independent of you getting ahead and even at the expense of you getting ahead or the expense of the Commons. Right, and so my near-term incentive can oftentimes be a long-term disadvantage to others of the whole so now this basis of where my well-being and the well-being of others or the Commons - the Delta between those - is the basis for rivalry. But then dealing with that rivalry keeps increasing coordination costs, keeps - you know - creating disinformation systems where we can't coordinate effectively. So how we deal with the balance sheet part - there's a few things: right now for me to have access to stuff I have to mostly - with a few exceptions - possess the stuff, right, so possession and access are coupled. And if I possess something - I don't have to be using it - I'm just reserving the optionality to use it: the drill that sits in my garage that I might not have used in a couple years but at least it's convenient that when I want it it's there. Right, but me possessing something means that I have access to it and means you don't have access to it, and so with a finite amount of stuff: the more stuff you possess - the less stuff I have access to - rivalrous basis. But we all know library type examples, or shopping carts, where if I have enough shopping carts of the grocery store for peak demand time I don't have to bring my own shopping cart which would be a pain in the ass and would require 10,000 shopping carts per grocery store rather than 300 - everybody bringing them. So what matters is you having access to the shopping cart doesn't decrease my access, and we start to see a potential for this: if we think about something like an Uber and then we think about self-driving Uber that then has a blockchain that disintermediates it being a central company, and being a commonwealth resource where you having access to it doesn't decrease my access - so we're not rivalrous anymore. But then we take the next step and say: if you having access to transportation then also allows you to go to the maker studio that you have access, to the science studio, to the educational places, to the art studios where you then have more access to be creative, but the things that you create you aren't creating for you to get more money and get ahead because you already have access to all the things that you want and you don't differentiate yourself by getting stuff - you differentiate yourself by the things that you offer because you already have access to stuff, so there's a fundamentally different motive structure - then you having access to more resources creates a richer Commons that I have access to. So now we go from rivalrous not just to non-rivalrous, which is uncoupled, but anti-rivalrous - meaning you getting ahead necessarily equals me getting ahead. And so when we look at getting out of the Malthusian type dynamics, part of it is that we can actually get out of the population dynamics, part of it is that we can actually get a closed-loop materials economy with renewable energy that can continue to upcycle, and part of it is that we can utilize our resources much more effectively and much less-rivalrously where we start decoupling access from possession - that'll start easily in some areas & be harder in other areas, but we start with in the areas that it happens, and so we start getting more and more of a situation where I want you to have access to more things because as you're more creative than I get access to more things that are the results of your creativity. So this is an example of removing some of the basis of rivalry associated with balance sheets. I can go to sex underneath that now if you want me to. **ERIC:** You should go where is most natural to take the conversation. I will just try to follow... and the problem is if you go to sex directly from where you are - you are describing the value let's say of prostitution, which is that people do not have to make a commitment to a sexual partner, many people can have the same sexual partner, you start to get into all of these very funny areas where status, for example, is a very weird commodity: do I want you to have more status because somehow that will give me more status, do I stop caring about status if there is exactly one parcel of land which has unequivocally the best view - is that something that I want you to have rather than me having it? **DANIEL:** Yeah, so let's talk about status for a moment. If I'm comparing you and me in terms of who has more dollars or who's taller or who can run faster or some... I can compare us on the same metric. And if status is number of followers on Twitter, then whatever - Kim Kardashian's most interesting human being that's ever lived. And so I think we know that reductionist metrics on status are also gamified and inappropriate. But if we say like [M.C. Escher](https://en.wikipedia.org/wiki/M._C._Escher) or dolly, like, what was more brilliant art? I think it's a meaningless question because they both offered something completely novel to the world and something meaningful and beautiful that neither of the other ones offered or could offer, and I can't compare them because I can't metricize them. And the reduction of... that's the thing: I can't reduce totally unique things to a fungible metric. So one of the problems I think is actually fungibility and metric reduction. And so if you have status associated with unique things that you offer to the world: awesome, I'm not competing with you writ large for more status - I'm going to... people are gonna have a relationship to me for the things that I offer and those are really the people that I want to have a relationship with me, and if you're offering things to the world that people have a relationship to you for and I see that the world is getting better as a result of what you're offering and I have access to more... a better world as a result of it - I'm totally stoked on that. **ERIC:** This is where it starts to feel not real to me. Okay but let's go through the show. **DANIEL:** So here's why it sounds not real. I think... so do we have a slowing in technological progress? Yes. And - you know - less so in some areas than in other areas. But do we still have exponentially growing technology in terms of both cumulative amount associated with number of people in globalization and in terms of just technologies that are still continue to grow? Yes, of course we do. So is it 50 years or hundred years we don't know. But I really like... I have to think of this in a kind of a mythopoetic frame - that's how it occurs to me - as technology is empowering our choices and we are getting something like the power of gods, you have to have something like the love and the wisdom of gods to wield that or you self-destruct. And so when I think about the rapture story or the Mayan calendar or any of those stories in a metaphoric sense as just like: let's say you and I were in the Bronze Age and we had just seen a larger war than had ever happened because there were some new better weapons and they could shoot further distance, and there were deserts where there didn't used to be deserts because we had got new better axes and saws and had been able to cut down more trees, and we just thought about it and we said: we're still developing better weapons, and were developing better economic extraction tools, were using our power in ways that are constructive in a narrow sentence and destructive in a larger sense, but everybody is doing that - this doesn't get to happen forever. So this phase is defined by increasing power on all sides, used in destructive ways, constructive narrowly, but destructive broadly - that phase comes to an end. And there's something like a hard fork where if we keep doing anything similar to that - it'll come to an end cumulatively - whether existential or catastrophic - more likely catastrophic, right, not full everything end, but a lot. And to be able to have that much power and not use it in ways that destroy the system requires being actually good stewards of power. So then the whole question for me becomes: how do we make a social system, like, what is the the Bodhisattva engineering, how do we make a social system that is conditioning not just individual humans, but also collectives to do good choice making - Omni-positive kind of choice making. Well I have to have a sensemaking system that can factor things like externalities ahead of time better and that doesn't have things like multipolar traps where if anybody is doing the fucked up thing that everybody has to do it. And so I can start to think about what architectures such a system would have to have to be able to do sensemaking as to what externalities would be and be able to internalize them, and where then I can actually confer resources to those right choicemaking, and that we're developing humans, so again, think about the the education associated with some religions bringing about less violence, the education associated with some cultures bringing about higher average cognitive capacity, and being able to bring those together - as much as I know this sounds like hippie and silly - I don't actually see anything other than a radical increase in our good stewardship of power that makes it. **ERIC:** I love the idea that you think that there might be something here, but let me come back at with my - and again I'm not trying to be negative: I had an experience at some point... **DANIEL:** Your answer requires a warp drive! So we both recognize the inexorability of this thing and then are saying: okay, so what is the fundamental thing and something... **ERIC:** I'm not making fun of you because what you're saying is insane - what I'm saying is insane, and the people who are saying the most common supposedly adult things are the craziest of us all. So I at least accept the idea that we have to be here and I want you on that branch, and I want other people on other branches because we need to fan out and start exploring or at least start to care. But I guess what this makes me think of: it was a particular moment in my life where one of my closest friends brought his father to dinner, and his father was a guy who was legendary in the film industry, and one of the things he taught his son was never let the other guy get the first punch in and I thought Wow! First strike - you're teaching your child to strike first. Nobody had ever suggested anything remotely like that in all of my upbringing - I never heard anything like this. And I instantly recognized it for what it was: somebody was going to parasitize whatever I had been taught and say: well great, Eric's been taught self-restraint, Eric's been taught to turn the other cheek, to make sure that you de-escalate conflict, and goodie-goodie - more for me - your multipolar trap. Okay. **DANIEL:** There's a way out of it. **ERIC:** Tell me - I'm dying to hear it. **DANIEL:** So do we retrofit the system? No, impossible, foundational axioms are all the wrong axioms. Can we make a situation in which we can raise children quite differently? Yes. Go to see kids who grew up in an Amazonian tribe or - you know - some very different conditioning environment you'll see very different types of human behavior. Can we change already set adults? Much harder - not impossible, but harder. So could we find adults that would be the most likely to be fast adopters of a new system like this and capable - so both kind of at the cutting edge of their capacity to have abstract wide empathy and bind that to their action, and - you know - deeply considerate about actual cause-and-effect dynamics, factor complexity, and work with other people well. Can we find the ones that are closest there and then train them up additionally in some systems that are developed for how to do a different process of collaboration that doesn't lead to... One way of talking about it is that when we go to command and control hierarchy systems to get beyond the Dunbar number we get diminishing returns on collective intelligence as a function of the number of people, which creates an incentive to defect against that system - even internal defection - and so then we get a problem. If we could get collective intelligence scaling linearly we get something radically different. So we get just the number of people that are needed to be able to do something like that, trained to do that, and we build a civilization - a full-stack ground-up civilization - because obviously I'm talking about not private balance sheets, and private property is the dominant system, I'm also going to talk about not democracy because the nature of voting is inherently polarizing to populations - because we make propositions where both voting for it and voting against it suck for somebody for something because they're based on theory of trade-offs where we didn't even tried to figure out what a good proposition for everybody would be in the first place. So better systems of sense-making, in choice making, which we could get to, and so let's say you have a full stack civilization of people who are capable and oriented to implement it, and you have not only much higher quality of life for the people who are there, but innovative capacity to solve certain problems the world can't currently solve well because of no disinformation in the system and better coordination. Well then that system can export solutions that other places in the world that would normally have an enmity relationship with it actually need that they can't solve for themselves. So it can create a dependence relationship rather than an enmity relationship. And then they're like: well why the fuck are you figuring out these pieces of tech and we aren't - we're like: well we figured out a better social system and if you want it you're welcome to use it - we were open sourcing the technology, here's how here's how it works. But given that the technology as a social technology is a social technology of how people share information and share resources and coordinate differently - it can't be weaponized because it is kind of the solvent of weaponization itself, and so any other group using it is just now that kind of social architecture starting to spore or to scale. And so yeah, I think you get out of the multipolar trap by... You don't have to win at the game of power against some external force to avoid losing at the game of power. So far, if people didn't focus on militarizing they lost to whoever militarized, and if they didn't lose to whoever militarizes is because they militarized which means their culture became a culture that supports the ideas of militarization, right, but if I focus on being able to have whoever would militarize against me be able to offer them things that are particularly valuable that are novel to a collective intelligence that can do better innovation - you get out of a multipolar trap that way." - [Daniel Schmachtenberger](https://youtu.be/_b4qKv1Ctv8?t=9123)

> "Let's go protopian not utopian, let's go that there are some... **ERIC:** Say what you mean by protoian? **DANIEL:** Moving in the right direction. Let's say that there are some things that are harder to make adequately abundant than other things, but there's a lot of low-hanging fruit that we can start moving, and as we do it we will discover there's good reason to think that there is a basis to do that in more areas. So in a system where when something is more scarce it is worth more, then if I'm on the supply side of that I have an incentive to manufacture artificial scarcity. And to definitely prevent abundance that would debase the value of the thing that I have. In a world where we remove the association of value and scarcity, then where there are actual scarcities the goal is to engineer the scarcity out of the system. And so if we're talking about limited amount of Oceanfront then this is where we say: well can we do seasteading and create a lot of Oceanfront that is really awesome - where there is actually more to... just like more people are shopping at the store then we need more shopping carts. And so part of the answer is how do we actually increase the abundance, but not an exponential abundance, because we're talking about also steady-state population and using and a lot of shared resources, and it's that coupled with psychologically healthy or more mature people that relate to these things differently - both of those are necessary and neither would be sufficient on their own." - [Daniel Schmachtenberger](https://youtu.be/_b4qKv1Ctv8?t=10550)

> "So it is both how we develop that socially which I don't think will happen uniformly - I think will happen in pockets that become strange attractors that other groups want to then implement once seen, because they're so clearly better at both quality of life and innovation. And how long that takes to develop widely is a while - like this is a multi generation thing. I think that that would not be sufficient on its own, but it's necessary. Better sense making systems where we can actually solve problems without causing worse problems which we're not historically good at is also necessary. And this is both some evolution in our epistemics and our actual processes of collective sense making and collective coordination - so yes, I see level ups in both of those possible." - [Daniel Schmachtenberger](https://youtu.be/_b4qKv1Ctv8?t=10688)

> "Let's try to take some of the stupid fun out of discussing sexuality by talking about it for what it is: a central system that has to be discussed because it is the engine of human behavior." - [Eric Weinstein](https://youtu.be/_b4qKv1Ctv8?t=10827)

> "And it really matters for when we think about resource scarcity, because the resources that people need to deal with the first part - the survival part - are not that much actually, but the resources that people need to deal with the mating part is more than the other guy historically, which is why the guy with the 150-foot yacht might feel bad when the 200-foot yacht pulls up. **ERIC:** And let's say this is closed if... You're not an evolutionary theorist and I'm not, but we could do our best. There is a version of evolutionary theory which states that there needs to be crisis - there needs to be a function for showing that you are better in order to keep individuals max - you know - sort of on that razor's edge of performance, and that mating opportunities means that there's always a crisis - there's never enough abundance because somebody with 13 homes is more desirable than somebody with 9 homes if you're just trying to figure out if there were a crisis who would do better. **DANIEL:** Right, so we have to overcome that because that drives a Malthusian situation of no amount of resource ever bring sufficiency about, and drives a fundamental rivalry which is why you said we have to address it. So what I'm... My take on this as I explored it my process with myself has been asking ok, as soon as I saw that the dynamics of this world that seemed intuitive and natural to most of us as we kind of grew up in and were conditioned by it were self-terminating, and I said any of the things that we think of as normal I'm willing to question deeply. And so how do I think - could I imagine a high-tech civilization that doesn't implode, could I imagine a kind of enlightened planet what would life be like there - all the different things: conflict, emotion, resources, and sexuality is obviously one of the big questions. And I think the book [Sex at Dawn](https://en.wikipedia.org/wiki/Sex_at_Dawn) obviously gets plenty of things wrong - it's trying to make a strong antithesis to the standard evolutionary history of Homo sapiens thesis, but I think there are some key parts to it. When they look at the moss wah people or the Canela people or people that did not have... that had a stable society that was not primarily pair-bonded but had multi-male multi-female dynamics - it's not to say that's how humans mostly were - that doesn't matter - it's to say that it's a possibility. If it's within the possibility set - same Buddhism I'm not saying that's how people mostly have been. **ERIC:** It doesn't have to win - just needs to establish proof of concept and then we can try to scale it up from there. **DANIEL:** It's a positive deviant analysis for proof of concept to then say can we make that actual... is that a viable model for a new center and is that a possible thing to make. And the fact that it didn't make it through evolution so far, like, evolution has a blind quality to it, right, where it'll make an adaptation that makes sense in the moment determined by something like warfare, that is actually not that good long term or is even self-terminating long term. So the argument if it would have been a good system it would have made it - well, the thing that has made it is continuing to up ratchet rivalrous capacity and that itself is gonna self-terminate. **ERIC:** Like metaclass hacking that somehow we've hacked ourselves to a positions where we can keep surviving and so one version says that we can never escape the evolutionary imperatives, the other says we have always escaped whatever our last problem was and so we should be expected that even if there's only the sliver of hope we should exploit it to the fullest. **DANIEL:** Yeah, and so generally this situation happens that we have a near-term incentive to pursue some advantage but where the disadvantage of that thing might happen over a much longer term. and that's like one of the fundamental problems, right, the externality might show up over hundreds or thousands of years but the benefit occurs over this year so I have to do it. So we have to get over that actually, if we're affecting the world in such fundamental ways over the long term we have to actually be factoring that into our decision making now. That's one of the minimum requirements of a GameB if it's going to exist, which also means of a viable civilization at all." - [Daniel Schmachtenberger](https://youtu.be/_b4qKv1Ctv8?t=10900)

> "I think when we really start to think about this clearly we recognize that this direction is self-terminating - the need to get stuff from the world, that when I die it ends with me, that there is actually only a kind of self-transcendence and permanence in the way that I touch the world which does ripple ongoingly. But there's also this thing where - again - I feel almost a little bit shy talking about it even even more than the sex topic in some ways because I'm proposing that there is something like spiritual growth that is actually necessary for civilization to make it, and so people affirming that they are these kind of - to themselves - needy things that need stuff from the world, that need other people's validation and attention and etc. and living life that way where the more of it they get what they're still getting as a self - the affirmation of that sense of self, as opposed to coming from a place of wholeness. And the desire and actual love for the beauty of life and the desire to have their life be meaningful to life - that my life ends but life of the capital L doesn't end, and that life starts to be central to my awareness more than my life is, and my life becomes meaningful in it's coupling to life - this answers the sex question, it also answers all the other questions but I don't think... **ERIC:** There is a there to break through to and the problem that we're having conceiving of it in your mind - now again, I don't think this gets us out of all the issues that I've raised - but I think it's the first point at which I start to see there's something really different about your perspective, so just as a slow learner... **DANIEL:** If we take the kind of [Girardian](https://en.wikipedia.org/wiki/Ren%C3%A9_Girard) idea of all [desire is mimetic](https://en.wikipedia.org/wiki/Mimetic_theory) - and I'm oversimplifying it, but just meaning I want what other people have - and then that inexorably causes conflict and then the conflict will inexorably cause violence. I think there is statistical truth to all three of those steps but not inexorable truth to any of them. I don't only want things that other people have... you know - or that I learned from other people - there are things that are just intrinsically fascinating to me or there are wanting for other people that is not wanting for myself anything in particular - just actually caring about, wanting for other people - there are innate creative impulses." - [Daniel Schmachtenberger](https://youtu.be/_b4qKv1Ctv8?t=11960)

> "I think dominant paradigms co-opted psychology to define healthy psychology as supportive of the paradigm, so what I'm about to say in terms of what I think healthy psychology is is not the current definition of healthy psychology - it is one that would be fit to an actually viable civilization. I think psychologically healthy humans are emotionally coupled to each other, so when you're happy - I'm happy, I'm stoked for you - if you're hurting I feel that, I feel compassion and empathy. I think the worst psychology is the inversion of sadism where I feel joy at your pain rather than joy at your joy and pain at your pain. **ERIC:** I think it's a French expression: it's not sufficient that one succeed in life - one's friends must also fail. **DANIEL:** Yeah, so that is a perfect statement of what is most wrong with the world, right, that is the heart of the worst part of GameA. But I think jealousy is one step away from sadism because if sadism 'is I feel joy at your pain', jealousy is 'I feel pain at your joy or your success', or envy, right, and I don't think that is a psychologically healthy place for people. I think it is a... largely we condition this because we watch movies where we celebrate when the bad guy gets it and we condition the fuck out of we celebrate when the bad guy gets it and we celebrate when our team wins and the other team loses, so we can collectively decouple our empathy from other human beings arbitrarily, so that we can then feel good in a war supporting - you know - when that type of thing occurs. And we get conditioned that second place is the first loser, and all those types of things. But this is conditioning again, and conditioning of a highly neuro plastic species, so I think our intuitions are all bad if we haven't spent time really questioning these things and then also looking at cultural outliers, because I don't think any of this is inexorable - is it ubiquitous? Yes. Is it inexorable? No. But I think what is ubiquitous is psychopathology. **ERIC:** Well Daniel, I think what I've gotten from our conversation is that you've got a lot of examples that are at the proof-of-concept level of things that are under exploited, you've got an observation that we're far off the efficient frontier, that there's one giant overlooked opportunity which is that we are so radically [k-selected](https://en.wikipedia.org/wiki/R/K_selection_theory) that our developmental period from age zero to thirteen could be used for something radically different, which I think is the biggest hope in your whole complex of ideas, together with the idea that there are realms beyond somatic pleasure that most of us spend our entire lives not knowing what it's like to break through the status and wealth and security games, and effectively we have no idea what the top of Maslow's hierarchy when fully realized is, and that it might be possible to at least begin the game to buy us some time to try to figure out what we would do at scale. Now I still don't see any world in which we can defeat all these multipolar traps, but I think what you're really saying to me - again, always correct me if I'm wrong - is that we could potentially change what winning feels like and that when we do that, then these [prisoner's dilemmas](https://en.wikipedia.org/wiki/Prisoner%27s_dilemma) don't look right any longer, because I no longer want to be the one who defected while you cooperated so that I get off scot-free and you wind up with a 20 year jail term. **DANIEL:** And we have to remove the context of the [prisoner's dilemma](https://en.wikipedia.org/wiki/Prisoner%27s_dilemma) as our model for the world, right, like actually change the nature of the context and because that is a fundamentally inexorably rival risk dynamic." - [Daniel Schmachtenberger](https://youtu.be/_b4qKv1Ctv8?t=12320)

> "So if I have a system like a corporation where my playing by the rules fully gets me ahead less than me defecting on the system internally and doing corporate politics or a back-end deal or whatever it is, then I have the incentive to defect on the system and it doesn't have the collective intelligence to notice it, right, because there's a diminishing return on the collective intelligence of the system as a function of more scale. If I could make a system - and I will claim that we can and there are architectures that can achieve it - we could make a system where the collective intelligence scaled with the number of people, then I would always have more incentive to participate with it than to defect. And if I did defect because I had a head injury - the system would have the intelligence to be able to notice that and deal with it. Now this is the place where I'm saying: the Dunbar number was both care and sense making. It was a limit on both - you know - our values generation and our sense making to inform choice making. So if we want better systems of governance i.e. better systems of choice making we need to get both collective values generation and collective sense making down. The conditioning gives us ways to start to work with things like very different value systems, but I can't have a very different value system while still incentivizing - meaning a value equation economically where the whale is worth a lot dead and nothing alive, and it doesn't have adequate sense making to even inform what good choice making for everyone so we can participate with the system is. So that'll have to take more time." - [Daniel Schmachtenberger](https://youtu.be/_b4qKv1Ctv8?t=12583)

> "The only answer out of the oppression or chaos is the comprehensive education of everyone and the capacity to understand at least three things: They have to increase their first person, second person and third person epistemics.
>
> Their third person epistemics is the easiest—philosophy of science, formal logic, their ability to actually make sense of base reality through appropriate methodology, and find appropriate confidence margins.
>
> Second person is my ability to make sense of your perspective. Can I steel-man where you’re coming from? Can I inhabit your position well? And if I’m not oriented to do that, then I’m not going to find the synthesis of a dialectic. I’m going to be… harming something that will actually harm the thing I care about in the long run.
>
> And then first person. Can I notice my own biases and my own susceptibilities and my own group identity issues and whatever well enough that those aren’t the things that run me…?
>
> We need a new cultural enlightenment now where everyone values good sense-making about themselves, about others, about base reality, and good quality dialogue with other people that are also sense-making to emerge to a collective consciousness and collective intelligence that is more than our individual intelligence…. it’s cultural enlightenment or bust as far as I’m concerned." - [Daniel Schmachtenberger](https://www.inspiredhumandevelopment.com/p/why-we-all-dont-make-sense-sometimes#:~:text=The%20only%20answer,as%20I%E2%80%99m%20concerned.)


> "Exponential information technology, in a win-lose context that incentives hoarding useful information and spreading disinformation, has already lead to a post truth world where it is nearly impossible to parse the (intentionally withheld) signal from the (radically amplified) noise. Which means we are making increasingly consequential decisions informed by increasingly poor sense-making." - [New Economic Series: Part 4, by Daniel Schmachtenberger](https://civilizationemerging.com/new-economics-series-4/)

> "We are now finally at the verticalizing part of the exponential curve where the tipping points to system failure are in clear sight. Technology extends human capacity and choice. Exponential technology means exponentially increasing ability to affect the world with our choices. If those choices are consciously or unconsciously causing direct or indirect harm, exponential technology means exponential destruction. In the win-lose context set by private ownership based economics, harm causing behavior of many types is incentivized (see part III of this series for examples). Win-lose game theory, multiplied by exponential technology, is existential. Exponential technology can’t be put back in the bag. So we have to create a post-rivalrous world." - [New Economic Series: Part 4, by Daniel Schmachtenberger](https://civilizationemerging.com/new-economics-series-4/)

> "Simplified value metrics are the foundational source of all externalities, as they get optimized for at the expense of real value that is not being measured and accounted for. This type of abstraction has us relate with models of reality more than reality itself. This is a foundational source of disconnection and decoherence." - [New Economic Series: Part 4, by Daniel Schmachtenberger](https://civilizationemerging.com/new-economics-series-4/)

> "At this point, industrially mediated human extraction has removed 90% of the large fish species from the ocean on a three quarters water planet, has cut down 80% of the land surfaces old growth forests, extincts about 13 species a day, has desertified much of the arable land from over extractive agriculture, and the list goes on. It also extracts people’s attention via neuroscience-informed and optimized media technologies, that extract money from advertisers with each click and impression, so they can extract money from customers that didn’t choose to be advertised to, by selling goods that came from an extractive materials economy and an extractive relationship with labor." - [New Economic Series: Part 4, by Daniel Schmachtenberger](https://civilizationemerging.com/new-economics-series-4/)

> "The extraction, abstraction, and accumulation cycle forms an autopoietic and self-evolving loop. The capacity for each of these increases our ability to further increase these capacities…leading to a classic self-reinforcing exponential curve. We affectionately refer to this autopoetic triplicate as the ring of power. It is figuratively what needs taken back to Mordor and destroyed. Or rather smelted into something else, which we’ll get to shortly. It’s important here to note, that when we look at economics in terms of evolving extraction, abstraction, and accumulation, all economic systems to date (communism, fascism, socialism, and capitalism) have been different instanciations of this same core principle. Capitalism has been the most effective overall, but they have all been part of the search space exploited by the evolutionary dynamics arising from surplus, win-lose game dynamics, and this ring of power." - [New Economic Series: Part 4, by Daniel Schmachtenberger](https://civilizationemerging.com/new-economics-series-4/)

> "Economics is a paperclip maximizer. (Since the extraction, abstraction, accumulation cycle includes the tools that mediate the materials economy, and the computing technology, and media, and education, etc…it’s more accurate to say that what we call civilization is a paperclip maximizer, with economics as the ring of power at the heart of it.) It converts the complexity of the natural world into simple (and complicated) things. Parallel to its maximization of abstract capital. And it increases its capacity to do so exponentially.
>
> Rather than a silica artificial intelligence, economics as we have described it here is a type of collective intelligence system. It mediates complex behavior across large human populations. It affects the behavior of all the humans in the system, without depending upon any of them in particular. The humans that do the bidding of the system (extract and accumulate abstracted value) rise in power within the system and in turn help advance the system. The humans that oppose the system are seen as threats by the humans that are winning at the system and are thus disempowered or taken out. The nature of the system’s valuation dynamics condition the value systems of the humans. Its needs and modes of production condition our philosophical narratives about the nature of reality (the movement from hunter gatherer mythos to agricultural mythos, and correspondingly from animism to theism…beliefs about god and country, economically driven holy wars… then physical materialism with science which proliferated because of its competitive advantages via increased technological capacity, etc.) Education is an economics driven system for conditioning new humans to be good wage earners/ producers. Entertainment is laced with commerce; media has to support the profit streams of the organizations that produce it, etc. War is a great system for creating more capital, getting rid of the humans that oppose the growth of some part of the economic system, refining the power of the humans at the top through competition, etc. There are no parts of human life not shaped by this collective intelligence.
>
> In addition to doing a job, it also increases its ability to do that job: The evolution from the linear through the multiplicative and to the exponential economies…from barter to currency to fiat currency to fractional reserve currency, to complex financial instruments, to digital only currencies…from a hoe to a plough to a tractor to factory farms…from digging by hand to mining by shovels to industrial mining, to space tech asteroid mining… from stone weapons to metal weapons to projectiles to nuclear weapons to decentralized exponential tech weapons…in every developmental line, the economic collective intelligence has been increasing its capacity to do what it does (increase extraction, abstraction, and accumulation), just now getting to the verticalizing part of the exponential curve.
>
> Like the paperclip maximizer that theoretically converts the whole world into paperclips, thereby winning and dying from the win simultaneously….this collective intelligence keeps converting the antifragile complexity of the natural world into an increasingly fragile, complicated built world, with exponentially more movement scaling through an increasingly fragile system, until collapse is imminent. It is not much of a stretch to say that we are being run by an autopoietic but unconscious, effective but eventually self-terminating, collective intelligence.
>
> So how do we stop something with this much momentum? We don’t. We build a new autopoietic system with faster feedback loops that is not self-terminating and it wins. To ensure that the new system doesn’t eventually self-terminate, it has to have the same type of complexity-increasing antifragility of the natural world. It has to be an extension of the symbiosis and novelty maximizing, complex system dynamics of nature. Factoring the inexorability of both exponential technology (more ability to affect the world with our choices) and increasing anthrocomplexity (more agents making higher impact and less predictable choices)…an adequate civilization design must be antifragile in the presence of those realities. This requires a fundamentally anti-rivalrous macro-context. Unsurprisingly, this maps to reversing each of the components of the ring of power: extraction is replaced with contextualization; (value) abstraction with instantiation; and accumulation with distribution and flow dynamics. If you think this would resemble a technologically advanced ecology more than an economy, you are right! (That is the topic of the next part in this series.) To have faster feedback loops so it is more adaptive and creates greater output per unit of input, while being aligned with the long term viability goals…its source of competitive advantage (over the current system) has to come from optimizing coherence – of the agents with each other and with reality. This is a type of competitive advantage, which is needed to take hold and proliferate within the current game theoretic context, that can out-compete the current system while obsoleting pathological competition in the new system. At adequate scale to prototype the full system dynamics, omni-win-win as a new type of collective intelligence outcompetes the win-lose collective intelligence. The end of rivalrous game theory is transcending itself." - [New Economic Series: Part 4, by Daniel Schmachtenberger](https://civilizationemerging.com/new-economics-series-4/)




> "Human cognition is in volume the largest input of raw material into society." - [Bryan Johnson](https://youtu.be/1YbcB6b4A2U?t=3518)




> "We spent most of the 20th century figuring out how to strip mine the physical resources of the planet. Now with these digital tools, we're spending most of the 21st century figuring out how to strip mine the cognitive resources of the planet. If we understand that that's the basic arc of what's been happening, then we can get enough distance to imagine a different way that this could go. If you get too involved in the tiny thing, it's like, "Well, this person got banned off of Twitter and that person got pulled back on, and now I'm going to go fight about that." No, no, no. At the higher level, we got multiple companies that are doing cognitive strip mining, that are basically... The sanctity of your thought processes is now intruded with ads and misinformation and on finite resources, which is, how many coherent thoughts can a person have in a lifetime? It's not infinite, because it takes a certain amount of time for neurons to go fire. The signals in your neurons, at their fastest pace, only move 90 feet per second. There's a actual, physical limit to how quickly one can think and how many actual, skilled, coherent thoughts they can have in a lifetime. We're ruining that resource right now." - [Tom Chi](https://youtu.be/AjGOGfzAvyc?t=7459)

> "Any civilization that is net negative to nature, even a little bit, let's say a civilization is only 0.1% net negative to nature per year. It still has a thousand years, and that's its death date, because nature runs out. When you take away 0.1% per year, in a thousand years, you got nothing left. Literally, the goal construction is also something that obviously must be true, at some point in human history, otherwise we will not survive. Every civilization that has the opposite goal construction, where it's even a little bit net negative, we'll have a death date on civilization." - [Tom Chi](https://youtu.be/AjGOGfzAvyc?t=7949)

> "I can break your regulation in three months, it takes you seven years to do it. Like, you, there's a, there's a concept I call rates not states, right? People always bemoan the state of the world. But they forget that the world is the way that it is because of the rates at which things happen. The reason that we haven't just gotten on top of regulatory for all the damaging things in our environment, including in the food system, you know, like, you know, endocrine disrupting, flame retardants in our clothes, and just on and on. Is because the regulatory thing is like a seven year push five, seven, 10 year. And then the work around molecularly is like a three to four month push. So like rates are more important than states rates will define what the states will become, or they define why the states are the way that they are." - [Tom Chi](https://youtu.be/P-5YBAYcE3g?t=2147)





> "The most difficult thing is to take the burden of evolutionary thinking and the theory of natural and sexual selection and to realize that that is your tool kit and from that tool kit you must build something that doesn't look like evolution has always looked before, because we're now on too crowded of a planet and the toys we've been able to produce from science are too powerful. I think Brett has called this wisely the hard problem - the really hard problem in evolutionary theory - which is: you can't continue to dance with the one that brought you, because evolution gets you here and it almost certainly will end in a self-extinguishing event. If you keep playing the evolutionary game and there is no thought - and this is, you know, I think that this is... Brett is the best person carrying this forward - there is no proof that there is a way to use evolutionary building blocks to avoid the evolutionary fate of having - you know - unlock the [twin nuclei of cell and atom](https://theportal.wiki/wiki/Twin_Nuclei_Problem) - they're just too powerful as tools." - [Eric Weinstein](https://youtu.be/MmXq97do-tQ?t=1925)

> "I never heard anyone say: 'I'm not going to allow my child to have life-saving surgery until we get somebody who's not elitists' - like give me the best effing surgeon you can possibly find. So what we can't have is we can't have our current Elite ruining the concept of elite - the elite looting party? The elite termites that are eating through the infrastructure? Every time I hear the word... I mean my simplest phrase is: 'our Elite are not' period. That is what's true - we need to re-establish the concept of elitism." - [Eric Weinstein](https://youtu.be/zDTdm5ZS7gI?t=4012)

> "Are there equations? Are there new mathematics? Is there new form of analysis that can actually deal with an interacting nonlinear system in which we are both being influenced by media and we are influencing media in return? And now when you have a really complicated feedback loop like that, can you say anything about whether or not the market will tend towards a positive or a negative social outcome? That is, is the market going to efficiently get us to a better place? Or is it going to efficiently get us to a place that we don’t want to be at all? These are the sorts of questions that have been traditionally punted by the academics.
>
> And so I think you may not even understand just how profound a question you’ve asked. We’ve been at this for a very long time. And it’s stunning to us the way in which the economics profession pretends to be incurious about this, there’s a paper by two particular authors, both of whom have received the prize that is frequently referred to as the Nobel Prize in Economics. And although it technically is not, and these authors are Gary Becker, and George Stigler, and they wrote a paper called [De Gustibus Non Est Disputandum](https://www.uvm.edu/~jfarley/EEseminar/readings/StiglerBeckerAER.pdf) (meaning "In matters of taste, there can be no disputes"`), and they argued that tastes should be treated as the same for all men, and do not vary over time, comparing them to the Rocky Mountains. The reason that paper is so bizarre is that the field is terrified of your question. What happens when you ask that question is that the field may in fact collapse and it required two people at the very highest levels of the economics profession to effectively put a tourniquet on the bleeding that you can expect to stem from asking that question, because they didn’t have the mathematics or the sophistication to be able to handle it. And furthermore, it may very well lead to a check on the power of economists, if that question does not have a positive answer. Maybe markets, in fact, lead us right up to the gates of hell.
>
> So what the economics profession did was that they put in a very artificial claim, which is that you don’t need to worry about that because tastes cannot, in fact, be altered. This is positively academic nonsense of the worst kind. You’ll find this paper in the late 1970s, and I have an excellent authority from a member of the economics profession affiliated with the Chicago department, in which both of these gentlemen worked, that, in fact, they did not see economics as a free field so much as as a bulwark against totalitarian Soviet-style communism, given when they were writing. Now, if that’s true, it means that we came up with an artificial position in order to make the claim that capitalism was superior to communism. Communism then was defeated, but modern economists don’t necessarily even know that some of these claims were inflated, specifically as a political Bulwark rather than as an intellectual contribution." - [Eric Weinstein](https://theportal.group/38-mass-media-markets-and-human-malware-a-portal-qa/#:~:text=Are%20there%20equations,an%20intellectual%20contribution.)

> "If a particular leader is referred to as a president, a strong man or a dictator, you’re being told a great deal about the editorial viewpoint at that particular media origin." - [Eric Weinstein](https://theportal.group/38-mass-media-markets-and-human-malware-a-portal-qa/#:~:text=if%20a%20particular%20leader%20is%20referred%20to%20as%20a%20president%2C%20a%20strong%20man%20or%20a%20dictator%2C%20you%E2%80%99re%20being%20told%20a%20great%20deal%20about%20the%20editorial%20viewpoint%20at%20that%20particular%20media%20origin.)

> "I think that, in general, without national projects that we feel great about, it’s very tough to say, “Well, what are you getting out of your country?” If it has a high tax rate, particularly a high marginal tax rate, what does that—what is that buying you? And, here’s a question, did the rich really understand why they might want a high marginal tax rate? I think that’s a very weird question for most rich people. Obviously, they would say, I don’t want a high marginal tax rate and they, individually, should not. But what if they were told, let’s say, you know, we don’t know how to prevent violence. And if we do a good job of a reasonable, although somewhat high marginal tax rates on top earners, we can probably avoid the revolution that may, in fact, threaten your ability not only to earn, but to be unmolested by civil unrest in the future. It’s a very upsetting thing for people to think about, who have 10 or 11 figures worth of wealth. However, it may be that a highly unequal society is not a stable society. So I’m not really sure whether we’ve ever had deep conversations about the essential violence that may be embedded within human organization, and what the very powerful and very wealthy need to fear about becoming ever more unequal, because, in fact, I have no doubt that would have been very hard to have a conversation with Marie Antoinette and King Louie, about their long term interests. I don’t think their long term interests were served in a world in which they were viewed as presiding over an incredibly unequal state. And I don’t know how to begin the conversation with the wealthiest families that what they think may be in their best interest with respect to wealth conservation, they might, in fact, be far better served by making sure that the society on which their success rests is a stable one. So these are fascinating and interesting questions. I don’t know whether that fully answers that but I would say that you want to minimize the violence that might be necessary in the system between your two possible alternatives, and you should also try to get the very wealthy on board and get them to understand exactly why they don’t want to become too wealthy. And why that should best be shared. And if you want to see what can happen, take a look at what happened to the Soviet Union. Take a look at what happened to Communist China. Take a look at what happened to any of these societies that experienced a very violent communist revolution." - [Eric Weinstein](https://theportal.group/38-mass-media-markets-and-human-malware-a-portal-qa/#:~:text=I%20think%20that%2C%20in,very%20violent%20communist%20revolution.)

> "Obviously, capitalism and communism both have to die. You need to hybridize it into something which captures the essence of what capitalism did best, which was to provide for freedom, you have to figure out something, short of communism, that provides for people on the basis of being a soul rather than a pair of hands, so that we can’t have your entire value resting on whether or not jobs will continue to exist. As the economy continues to transform, the new economic system has to take much more into account, the issue of public goods and services, because the market will not be able to associate the proper price to the value provided. So you should expect that we were going to have to have hyper capitalism because people will have to be allowed to sort of invent in an unfettered environment because it’s gotten very difficult. And the individuals on whom we depend are really outliers. They’re determined by very fat tails, power laws, kurtosis, various things that people don’t think about. So when you have an Elon Musk, for example, you probably need to give him a wide berth in order to create as much value as possible, but then you probably need hyper socialism to go with hyper capitalism. And the idea there is that our traditional claim in a capitalist economy is simply through our labor. And, in fact, we have two claims we have one claim as a soul and one claim as a set of hands or a brain, which is what do we what do we provide and what do we need?" - [Eric Weinstein](https://theportal.group/38-mass-media-markets-and-human-malware-a-portal-qa/#:~:text=obviously%2C%20capitalism%20and,do%20we%20need%3F)

> "Every modern economics department represents a fusion of two separate traditions, a bullshit tradition that attempts to rationalize power and an analytic tradition that attempts to understand the world as we have it." - [Eric Weinstein](https://theportal.group/38-mass-media-markets-and-human-malware-a-portal-qa/#:~:text=every%20modern%20economics%20department%20represents%20a%20fusion%20of%20two%20separate%20traditions%2C%20a%20bullshit%20tradition%20that%20attempts%20to%20rationalize%20power%20and%20an%20analytic%20tradition%20that%20attempts%20to%20understand%20the%20world%20as%20we%20as%20we%20have%20it.)

> "With respect to capitalism. I’m a huge fan of what capitalism did. And what I’m concerned about is that people don’t realize that capitalism has a different future than it has a past. It was absolutely the most powerful idea in the 19th and 20th centuries, because it created so much wealth, it lifted so many people out of poverty, but it has various problems. It doesn’t incorporate all of the negative externalities. So for example, the price of a gallon of petrol or gasoline almost certainly doesn’t include all of the costs of belching the waste product into the atmosphere or the despoiling of the environment that was needed to go after that oil.
>
> You have all sorts of situations where it doesn’t deal well with public goods and services. And those are things that are increasingly created by technology from what were private goods and services. I’ve talked about that elsewhere. So capitalism may have been tied to a particular place and time, and people get emotionally invested because they think that it’s always going to function the way that it did function. I’ve called this problem the problem of anthropic capitalism, that is, that capitalism was tied to a particular time and place in history, and it’s now time to move on to the next thing.
>
> And I’ve talked a bunch about the idea of what happens when you graduate from high school, but you keep hanging around year after year, you know fewer and fewer of the people and it becomes more inappropriate that you aren’t moving on with your life. In part, I think that that’s what we have, we have a failure to launch our post capitalist society. So you’re watching capitalism come unraveled. And as I’ve said before, we thought that capitalism and communism were in fact rivals, but I’ve likened them to Thelma and Louise, in the final scene from that film. It doesn’t really matter who hits the ground first, but both capitalism and communism are intrinsically unsustainable. And the fact is, we don’t know what that leaves us with except to invent the future. That’s what Adam Smith had to do. That’s what we did with Bitcoin and crypto. We have to invent the future. And so I don’t know why our economists and our best thinkers aren’t realizing that they’re probably looking at a system on its last legs. We’re going to have to take what worked from capitalism that continues to work, and we’re going to have to fuse it to what we now know about markets and the human condition. It’s a very tall order, and it’s scary, but I don’t understand why we think that the answers are going to be in the past, and not things that we’re going to have to invent for ourselves in the future if we want to have a long term perspective on our own viability." - [Eric Weinstein](https://theportal.group/38-mass-media-markets-and-human-malware-a-portal-qa/#:~:text=With%20respect%20to%20capitalism,on%20our%20own%20viability.)

> "In a democracy, any shared group beliefs in nonsense, and particularly self-serving nonsense, will still beat an incoherent haystack of noise that nevertheless contains the missing needles of truth." - [Eric Weinstein](https://theportal.group/30-the-awakening/#:~:text=in%20a%20democracy%2C%20any%20shared%20group%20beliefs%20in%20nonsense%2C%20and%20particularly%20self%2Dserving%20nonsense%2C%20will%20still%20beat%20an%20incoherent%20haystack%20of%20noise%20that%20nevertheless%20contains%20the%20missing%20needles%20of%20truth.)

> "Because the most aggressive such nonsense has become structural through what must be admitted to be an unexpectedly successful pattern of perseveration over more than four decades, our senior leadership class can be relied upon to engage in magical thinking on just about everything in the world of policy." - [Eric Weinstein](https://theportal.group/30-the-awakening/#:~:text=Because%20the%20most,world%20of%20policy.)

> "A particular form of our five word law, when applied to news media, would be “the headline generates the story”, or “the headline is the story”. Once this has been discovered, we see that increasingly, the purpose of the article in our era is not to inform, but to minimally support the desired headline for wide dissemination." - [Eric Weinstein](https://theportal.group/optics/#:~:text=A%20particular%20form,for%20wide%20dissemination.)

> "There is not only a market for your attention, but one for your inattention as well. Your smartphone may well put all the world’s information at your fingertips as is so often remarked upon, but unlike the fabled Library of Alexandria, it puts all the world’s disinformation, misinformation, noise, and distraction as well. And what our CEOs and technologists have learned is that your emotions are responsive to optics and not substance when there are cat and GoPro videos to be watched." - [Eric Weinstein](https://theportal.group/optics/#:~:text=There%20is%20not,to%20be%20watched.)

> "Right now the main institutions of our society have abdicated their role for public spirited adjudication of what is true based on expertise. And so what you're seeing is people coming to hate experts in coming to hate institutions, because they're realizing that these institutions lie to them at a level that they've never considered unless they were Alex Jones fans to begin with. And so what you're having is you're having a large number of people waking up to the idea that: yeah, there really are organizations and working groups that determine what you hear from a multiplicity of venues - it's the same message relentlessly." - [Eric Weinstein](https://youtu.be/LJxBnSyH0T4?t=2511)

> "Nobody knows what's true. And - you know - if you ask me well Eric how are you dealing with this - I would say I'm failing - I'm just flat out failing, as are all of you - I'm just more honest about it. Some of you have an idea that you've got one lens, which is: fix the money - fix the world - Bitcoin - that's the answer. Yeah, Bitcoin - rock on. But no - that's not the answer. Or somebody else says: you know, I really think that we just need to be open and tolerant and realize it's a big world and we just have to give people their due. Well that doesn't work either - you can't just let everything run riot. Or: we have to go back to our institutions - with these people at the helm - are you kidding? We have to abandon our institutions - wait, what are you saying? We're going to abandon our institutions? Do you know what that looks like? Nobody has an answer." - [Eric Weinstein](https://youtu.be/LJxBnSyH0T4?t=2620)

> "I think Sam is discounting the idea that once people wake up to the concept that they were living in an orchestrated [Truman Show](https://en.wikipedia.org/wiki/The_Truman_Show) that they did not understand - they're not going to have the idea of like: oh sure the vaccines were a little bit more dangerous than claimed, and maybe a little bit less effective, and maybe we knew a little bit more about the lab leak. No way - you spat directly in my face and told me not only that it was raining but that I was a crazy person for thinking that you spat directly in my face and you piled up how many Nobel laureates to defend the idea that any inquiry into the origin of this virus was racism? It's like: you're dead to me." - [Eric Weinstein](https://youtu.be/LJxBnSyH0T4?t=2786)

> "You want a culture in which everyone is allowed to burn the flag and it doesn't even occur to you that that's something you would want to do - that's culture. You've got to load the the inhibiting factor on culture. And people say well that's what cancellation is about. Well but if you misuse the concept of shunning - let's call it by something older than cancellation - if you shun people for good questions, if you shun people for speaking truthfully and decently as if they had done something horrible - then you lose the ability to control bad behavior through social norms. And one of the things that I've now come to understand is: we are either going to restore a culture which shuns only when shunning is really the correct course of action, or we are going to have rules that prohibit what you can and cannot say. And I am absolute in that we should not have rules. We've got to put this on culture and we've got to get a culture in which in general you are very careful about the negative things that you say." - [Eric Weinstein](https://youtu.be/LJxBnSyH0T4?t=11179)

> "When your idea about what a just society is: well let's vindictively punish successful people, let's pretend that male and female have no difference or all the difference according to some set of rules on alternate tuesdays, let's decide that we can redefine what a recession is or the Consumer Price Index, let's decide that we don't need masks - yes we do - no we don't - yes we do, because of the science, science, science - can somebody get rid of these people? We need to be in a society that makes some semblance of sense." - [Eric Weinstein](https://youtu.be/LJxBnSyH0T4?t=11362)

> "Many of the voices that we've been listening to because they got jobs in our organs - whether it was the New Yorker, or the Washington Post, or a professorship at Duke - we have to stop listening to these people wholesale. We have to stop being tolerant of the intolerant. If you come from a position that is sufficiently extreme and your whole point is to try to use and weaponize democracy, to weaponize free speech, to weaponize good faith, to weaponize what it means to hold a debate - you need to not really have a voice at the table because we don't have a solution." - [Eric Weinstein](https://youtu.be/LJxBnSyH0T4?t=11455)

> "The internet needs its own version of a religion - it doesn't have to be a god, but it has to be something that has the word mustn't in its vocabulary." - [Eric Weinstein](https://youtu.be/nz7cheVQ15w?t=797)

> "If your scientists can't tell you to go fuck yourself they're not going to be scientists." - [Eric Weinstein](https://youtu.be/nz7cheVQ15w?t=3711)

> "The great sin with money is not really understood. There's nothing wrong with luxury and there's nothing wrong with wanting status. The great crime when it comes to personal wealth is using money to generate your status." - [Eric Weinstein](https://youtu.be/nz7cheVQ15w?t=3741)

> "I want to see you showing off - I just don't want to see you showing off what you've bought." - [Eric Weinstein](https://youtu.be/nz7cheVQ15w?t=3801)



> "Davos man - it was my current rubber stamp for GameA and its highest manifestation - believes that they can beat down the people, make them reach the 17 united nations sustainable development goals by making them, right, guess what davos man: that ain't gonna work because the problem is GameA has defined their status for them as status through possessions and positional goods. If you just take away their status and their positional goods, their human well-being goes down - they're going to revolt and the result is going to be a right-wing tyrannical dictatorship - a populist right-wing dictatorship. Take that to the bank davos man! The GameB finesse there is: yes, we are well aware that Europeans need to cut their consumption of energy and stuff by 65 percent at least, and Americans by 80 percent, but if we move to GameB as we do this our human well-being can actually increase, because we're not defining human well-being as status through possessions driven by a short-term money on money return loop, but rather building and rebuilding actual human life the way we've lived for hundreds of thousands of years - what I've come to call the meso scale. And the big mistake that modernism made about 100 years ago was moving away from the extended family and the face-to-face community and having the services that were formerly provided by those two instead be provided by the market and the government - two faceless and cold institutions which have their own inherent logic and run away in a classic bureaucratic fashion. And if we can return to a place where humans well-being is designed and operated at the humane scale we can cut back our consumption of stuff massively and have our human well-being go up, and this is to, you know... out-compete them, they come the GameA-ers come to a proto-b on an Airbnb getaway weekend and they say: damn isn't this a better way to live than the rat race where I may be making... have fancier cars and bigger houses, but that's not what life's all about. And so I've now come pretty strongly to the view that the davos man strategy of beating people into submission to fight climate change ain't gonna work - just think of the modest increase in diesel prices in France that produced the yellow jacket movement and that was - you know - yay much of what davos man has to do by his top down beating. The only way we're going to make it to the other side is to redefine how we live such that our actual in the body human well-being is upregulated at the same time our consumption of stuff goes down." - [Jim Rutt](https://youtu.be/byau1SegVqw?t=3144)






> "When you say casually "I don't know what I'm seeing" - you don't mean that there are no words in your head to describe it, you mean you literally can't make sense of what you're seeing. So sense making goes beyond words - it goes to like things like pattern recognition, it goes to a literal gut feeling of confusion or clarity, and so on. These are very basic human experiences and the scaling of these basic human experiences is what helps you produce a dynamic coherence to society. So a society that has sense making does not need to just you know follow the leader's gut feeling - it in fact has something of a shared correctly constructed gut feeling versus one that is to a significant extent very chaotic, oppositional, no premise is followed up by a conclusion, no incorrect premise is ever disproven, you say A on monday - B on tuesday, A is more viral, the virality is rewarded - not the correctness. That's the problem. If you wish to have a somewhat free society the sense making has to be participatory, which means that different levels of society can correct each other, different centers of society can correct each other, and they're even able to find this like commonality of speech and so on. Then there's the question of meaning - how do we evaluate things, do we find meaning in them or do we not find meaning in them, what is motivating us even? The sense of enemy often comes with not just a loss of sense making - there are many people in fact who have fairly coherent world views, they even share these worldviews with others but they're fundamentally depressed, and one of the reasons they're often fundamentally depressed is because of the question "So what?" - you said how it is, tell me how it should be. Or rather "I know how it is but I don't know how it should be". And then finally there's the question of choice making and how are decisions between different possible futures made - again both for individuals and society as a whole. The sort of simple solution is that you have a single center that tries to make decisions. The other alternative is sort of anarchy - there are no real decisions made anywhere, and the ideal coherence is that society builds these decisions together through something like a discourse, something like a deliberative process, where deliberative doesn't just merely mean voting - it goes much beyond voting - it is the shared building of the model of the world and the "what about it" & "so what do we do about it" and finally the details of the implementation." - [Samo Burja](https://youtu.be/bHCg8bhtbqs?t=1530)

> "The example you used was actually of implementing a system of carbon accounting. Tell me: is there any agency in the federal government today that you would trust to implement that system? Is there any organ of the United Nations? Is there even a non-profit organization and is there any hope that such a system could be rationally discussed, optimized, taking into account the considerations of the common citizen, of all relevant groups of society? I think the problem is that to set up a system of carbon accounting you actually first need a system of epistemic accounting - you need the epistemic commons once more to function and the epistemic commons have to function updated to the digital world." - [Samo Burja](https://youtu.be/bHCg8bhtbqs?t=2056)

> "It's one thing to say read a paper on what a North Korean EMP strike might do to America's power grid, it's quite another to evaluate whether the nonprofit that produced that report - are they just producing reports that suggest we should go to war with North Korea? You can't trust just the white paper - you actually have to see what sort of selection effect is at play and if you see - you know - this kind of conflict of interest you have to be careful for subterfuge. The proof might still check out but if a sketchy person is handing you the proof you might want to put extra scrutiny into it." - [Samo Burja](https://youtu.be/bHCg8bhtbqs?t=2417)

> "There's no hope for a tiny country like Estonia to compete with Russia on the dimensions Russia picks, or a tiny island like Taiwan competing with the Chinese mainland on you know whatever dimensions the Chinese mainland picks - they can always build more jet fighters, they can always build more aircraft carriers, they just have 100 times more people - what are you going to do? You have to pursue the asymmetric advantages and because these are both relatively new nations the asymmetric advantages meant integrating digital infrastructure into government, but also integrating digitally native people, staff, talent into government and opening yourself to public discourse as a method of sense-making. You lean into the strength of an open society rather than imitate the strengths of a closed society because if you try to beat China being a close society - well you know it's it's not going to really work out for you especially if China's 100 times larger." - [Samo Burja](https://youtu.be/bHCg8bhtbqs?t=3123)

> "What we did on economics is we took the tiniest slice of human behavior - self-interest - and then we wrapped it with abstract mathematics in the late 1800s. Big chunks of our economic theory has been there ever since. This theory of the self-interested individual wrapped in mathematics is built from the sanctity of the person and personhood and it's kind of all set up to guarantee market equilibrium. It's also over the course of the last hundred+ years a theory that has largely been walled off from other disciplines while growing in influence and in stature and Academia, infecting public policy, business administration, infecting the other social sciences, and even in more recent years affecting the Natural Sciences. When its assumptions are challenged, or when the theory of the rational actor - the self-interested individual - doesn't hold up against other theories or other disciplines, or when the scientific method gets in the way, economists have this very convenient line "it's just a model", or they often quote George Box - the statistician - "All models are wrong, some are useful". I would add one little piece to that: "All models are wrong, some are useful" - I agree - "Useful for whom?" - and that's the big question that we need to ask today." - [Jon David Erickson](https://youtu.be/EC11UQD9q3w?t=369)

> "I don't think our moral compass for the future is very well-developed as human beings because we haven't needed it to get to where we are now. We've needed to worry about the future over the next few days so that we can eat the next few years so that we can raise our kids and maybe we care about our grandchildren. But beyond that, we really just don't deeply care by nature. And that I think is the fundamental problem." - [Sandra Faber](https://youtu.be/04jg5--t8RQ?t=2418)

> "Very deep in human values is the worship of low entropy. Now, what do I mean by low entropy? Entropy is a very elusive question. It's a concept that's hard to explain. But to try to make it as simple as possible, low entropy happens when you develop structure and organization in something. So, I'm looking in my office here, I'm looking around and the air is uniform density everywhere. The molecules have spread out uniformly. That's what entropy wants to do. It wants to increase, it wants to get smooth, it wants to lose its structure, its differentiation. Things basically want to smooth out and lose their organization. An example, drop a teacup. It started by being highly organized with all of its atoms in a particular way. And by the way, it took work to do that. That didn't happen randomly. Somebody had to make that happen or some artificial process. We drop it and the atoms go all over the place and get disorganized and the structure is lost. So that's an increase in entropy. I think human beings intuitively understand that making something out of nothing, getting structure where there was none before is miraculous. And I think that's what we worship and we grieve when that is lost." - [Sandra Faber](https://youtu.be/04jg5--t8RQ?t=2717)

> "I think we need a new religion. I think the religious impulse is very important in human beings and should be put in better service to solve these problems that you and I are talking about today. So I think we have this basic urge to serve a higher purpose. And if we could inculcate people from the very beginning to understand how wonderful Earth is and that our role as human beings, we do have a mission to protect the planet. And at the same time, continue its wonderful story of constantly evolving new and more wondrous things." - [Sandra Faber](https://youtu.be/04jg5--t8RQ?t=2973)

> "One of the things that astronomers are good at is math, and one of the things you learn about in physics is exponential growth... So if everybody could understand exponential growth intuitively, that would be a big step forward to reorienting ourselves to understanding planetary problems." - [Sandra Faber](https://youtu.be/04jg5--t8RQ?t=3602)

> "The other would be I would like to give people the gift, which I feel has been given to me, to have the big picture, to have this understanding of how it all began, how it's evolved, and how we fit in, culminating, and here's the key point, culminating in an understanding of human nature because I think we make a mystery out of human nature. We should be teaching young people where they came from and why they are the way they are and how things are going to work out for them in the future. We just make it a mystery. I would like to change that and make our situation clear." - [Sandra Faber](https://youtu.be/04jg5--t8RQ?t=4848)




> "There are chemical addictions, there are behavioral addictions there. We have both. So, anything that stimulates the nucleus accumbens, anything that stimulates the reward center in the extreme is addictive. So we have chemicals like heroin, cocaine, nicotine, alcohol, sugar. We also have behaviors. We have shopping, gambling, internet gaming, social media, pornography. All of these stimulate the same reward center in the brain. Every one of those has an "aholic" after it. Shopaholics, chocoholic, sexaholic, alcoholic, you pick it. The point is, we have a reward system and it is under fire every day, by not just the food industry, but by virtually any corporate entity, because that's how they get you to buy." - [Robert Lustig](https://youtu.be/onVqjZOYlQs?t=1736)

> "Teach the children. You can do this. This can be done. We are doing this now. Now, there is a problem. It's called time. We have a clock. We have a drop-dead clock. We have a 1.5 centigrade temperature increase on climate beyond which there's the point of no return, and we have to meet it. And, that's the problem. We have to speed this education up. And we're going to have to educate the naysayers too, because we got to fix this problem fast. And that's hard." - [Robert Lustig](https://youtu.be/onVqjZOYlQs?t=4943)

> "Patents were a very important invention in the market, but it's a relatively new invention. It's a bit more than 100 years old and it came from the insight that you can actually speed up technological development if you encourage people to publish their findings, and their inventions. In exchange for making the facts public and putting it in public domain, and allowing other people to build on your ideas instead of keeping them secret, you would be granted a monopoly of use for 10 or 20 years, or something that would be reasonable for you to have the incentive of putting it in a public domain and innovating, but that concept has morphed. Today, of course, when we talk copyrights and patents, we have completely deviated from the idea of having things quickly put in the public domain for reuse and for innovations. For example, when Mickey Mouse was about to celebrate 50 years and fall into the public domain, Disney lobbied to the government to extend copyrights from 50 years to 75 years, and got that. Now, there's even talk now when Mickey Mouse is about to turn 75, that we should extend copyrights into 150 years. Of course, this is just a matter of economic transfer. A market would clear very differently if you had copyrights and patents that would be 10 years, or maximum 20 years, which is really the economic lifetime. If I'm running a corporation and I'm doing an investment calculation, anything today beyond 10 years, definitely beyond 20 years, is discounted to absolutely zero. That does not affect my business decision at all, so it doesn't make any sense to really have any copyrights or patents longer than 20 years. That's just one example of how we have these constitutive rules of the market, that are really the rules that makes the market start working. Then we can have regulations and regulative rules, but we have constitutive rules like what can you own, what can you patent, can you patent human genes? Can you own radio frequencies? Then, the next question is, who can own? That I, as a private individual, can own something, absolutely. But then we have this very strange social innovation like the corporation, that is also not very much more than 100 years old, and are completely dominating the market today. By changing the rules, what can be owned, for how long, for what use, and who can own things, then you can change the constitutive rules of the market, and it could clear completely different." - [Tomas Björkman](https://youtu.be/TJa_6AHjLw0?t=3167)

> "There's no government in the world actually helping you not die. In fact, most of them are enablers of a death economy. They actively allow companies to help you die faster." - [Bryan Johnson](https://youtu.be/PXkhhHPUud4?t=3758)

> "If I could wave a wand, I would have everyone be able to, for just a moment, move beyond the polarization and the partisanship and all the real and imagined differences we have and the voices on both the left and that are exploiting them. And remember that we have two things in common. The first one is we share a common mortality. We're all going to be born, we're all going to die. That's the reality of our existence. And between those two events, we all walk a path, a very individual path, but it goes to the same destination. And I believe in my heart and from my experience, that all of us in our own way want the same things as we walk that path of life. We want to find meaning and purpose and satisfaction. We want to be valued. We want to add value, and we want to all believe that we have an equal opportunity to succeed, to reach our dreams, no guarantee of equal outcomes, but an equitable opportunity to try. If we can remember that, if we can remember those common attributes of being a human being, I don't think there's anything we can't do." - [John Kitzhaber](https://youtu.be/Z4cjl77rj78?t=2807)






> "Pretty much any definition of wisdom that anybody offers usually has restraint as an embedded concept. Wisdom involves what not to do, where you could have personal advantage, where you could have some near term advantage, but it's actually not the right thing to do." - [Daniel Schmachtenberger](https://youtu.be/tmusbHBKW84?t=1109)

> "The, the cancer is not just another  cell having its own individual freedom to    express itself in a slightly different  way, and it should be allowed to have   its own individual expression. The other  cells, like, there's a difference between   the liver cells and the blood cells and the  kidney cells and the, they're all different,   but they all have a shared genome and they're  all working as parts of this larger whole,    and they're constrained by that, and  that's okay, because they would also die. Like, a kidney outside of a body is not that  interesting. It doesn't sustain itself. So all    of the cells are constrained by being a part  of a body to serve the good of the body. So   they get to have individual expression, but  they also have interconnectedness and with   that an obligation. The cancer cell,  it's like, nah, fuck the obligation. I'm going to do my thing and I'm going  to actually consume resources faster and   replicate faster. And if it does  that and metastasizes that idea,    right? Then the rest, the rest of the body,  the immune system has to kill that thing,   or that thing will kill the rest of the system,  including itself, including itself, right?  And that's the thing is that  the cancer cell is having   amazing progress at consumption  and replication. It's betterment for its own goals. Yes, it's, it's  succeeding at its goals. And then    the, there are the most number of copies of itself  right before it kills the host and kills itself." - [Daniel Schmachtenberger](https://youtu.be/tmusbHBKW84?t=2259)

> "We are the descendants,    unavoidably, of the people that scaled empire with  all of the ecological harm, warfare, genocide,    et cetera. We are genetically and mimetically and  culturally the descendants of those processes." - [Daniel Schmachtenberger](https://youtu.be/tmusbHBKW84?t=2424)

> "The first question  with progress is progress for whom?  And then, then we would say progress of what, across what metrics across  what way of assessing what is valuable. And    progress that is progress for some that is totally  bad for others, but also bad for others that that    some depends upon is a very narrow definition  of progress. And even like the cancer cell that    will eventually kill its own host, it's a  definition that is not actually long term even viable for the interest of where the  progress seems to have been true." - [Daniel Schmachtenberger](https://youtu.be/tmusbHBKW84?t=2794)

> "We have lots of    different global catastrophic risks just in  the domain of ecology we're facing, right? We could really mess the biosphere up just  because of PFAS, just because of pesticides,   just because of mining waste, just because  of biodiversity loss, just because of damage   to oceans and dead zones and coral. Like we  have lots of different, from the extraction    side and the pollution side, catastrophic risks  that are the result of our success at progress." - [Daniel Schmachtenberger](https://youtu.be/tmusbHBKW84?t=2853)

> "There are lots of times where we actually know the  harm something is going to cause, whoever it is,   industry, whatever, ahead of time, and do it  anyways, cover it up. That's a known thing.   There are other times where we just don't try  very hard to do an analysis of externalities,    because if we put money and resource into  looking at, is this going to harm things,   and the other competitor doesn't, they're  going to get first mover advantage. They're going to later be able to say,  we couldn't have possibly known. I,    the money that I put into seeing those harms  might just tell me not to do the project. And   now how do I get a return on that money that I  put in? And if it does show me a safer way to    do the project, it's probably so much later  and with less margins than the other thing.  And so at minimum, there's a kind of  negligence of if we do due diligence,   we do this box checking plausible deniability  version, because we know we're going to be able   to privatize the gains and socialize the  losses." - [Daniel Schmachtenberger](https://youtu.be/tmusbHBKW84?t=3336)

> "A corporation does not, a corporation is  a, you can think of it as a cybernetic entity.    Right. The, the operating agreements, the  legal agreements of what it is, plus its   whole operational machinery does not depend on any  particular person because you have an org chart.  And if you lose this assembly line worker or  this chief marketing officer, you replace them    with a kind of market equivalent all the way up  to a CEO. And so the. Entity is controlled by    the cybernetic entity kind of controls itself  aligned with these legal operating agreements,   not controlled by anybody in particular  and recognized as a corporate person.  So it protects the directors from legal  responsibility of what that corporate person does,   even though, of course, it couldn't do it  without running on the people. And then   you have a fiduciary responsibility to  maximize profit, which is a measure of   extraction. And so. And of course, that  corporate person doesn't have empathy.  It cannot. It's not a it's not a sentient  thing, right? It is a cybernetic thing,   but it's not a sentient thing. So it  doesn't have empathy. It does have planning,   i. e. Machiavellianism. It does have my own  growth should continue forever. And I should    be the market dominator. That's narcissism.  And so, yes, it is an obligate sociopath.  And it is actually legally required to maximize  It's, you know, shareholder return on profit by    the directors of the organization. So the idea  that you cannot possibly anticipate externalities    is not true, but it's a useful idea of those who  are going to benefit by causing externalities. And the people who benefit by causing  externalities because they're privatizing all of the gains  to write the narrative in the same way the history was written by the winners of war  previously, like it costs a lot of money to    affect the narrative of the world. You see this  in political campaigns, you see it in marketing   campaigns, but if if an idea is spreading, who is  writing all that stuff and who's up regulating it    and who's paying for the commercials and who's  getting the data to do the personalized micro   targeted ads and who's, so the ideas that spread  are not just spreading through a kind of natural   selection of the goodness of the idea, they  are getting oftentimes amplified by the media.  Interests that want those ideas to spread. Duh,   right? We know this. This is how political  campaigns work. This is how advertising works.    This is how propaganda works. This is how, you  know, on and on. This is how religion works,    right? There's a lot of money that goes into  proselytizing and getting the ideas to spread.  So there are a lot of ideas that are marketing  and or apologism for the dominant class in    terms of power. So the dominant narrative is  usually apologism for the dominant power system. In the same way that, like, when we talk about  externalities, when Facebook was in its early    phases, there were people like, you know, Jared  Lanier famously was saying this very publicly,    but there were people coming from the McLuhan  school and You know, coming from various,    coming from the Mumford School who were saying,  Hey, look, this technology where you're monetizing    people's attention and you're going to race  to effectively monetize their attention. And unlike where TV commercials did  that, but it was the same for everybody,   you now get to have them interact with it  to gain personalized info to split test how    sticky you monetize their attention.  A lot of the things that are going   to engage their attention more  are going to be limbic hijacks. They're going to be things that make the person  scared or horny or distracted or, or in group,    out group identity or whatever it is. And this is  going to be really bad for society. It's not that    no one was saying that then. It was being said,  it was being ignored. It was not being studied   and researched and pursued because, and then  later they get to say, we couldn't have possibly   known it was going to polarize society and break  democracy and decrease everyone's attention spans.  So. The, we couldn't have possibly known as  a bullshit story. If you think about does,    am I saying that you can anticipate everything? Of  course not. But am I saying you can do a million   times better than we even attempt to do now?  Yes, of course. So in the process of developing    a new technology, say, could we proceduralize  thinking through the total set of effects,    not just the intended set of effects  and the market benefits of those,   but thinking through if this technology  really takes off, And goes to its full scale.  What is the pressure of that on all the  supply chains to make it? And what is the   environmental effects of that? What  are the, you know, geopolitical and   et cetera effects? What if people use  it, is it conferring some power? If so,    what other thing is it obsoleting? How  will that change power dynamics, et cetera? You just kind of think it through. Now  we have a process That we've developed   called yellow teaming. Red teaming is,  you know, now become pretty famous,   which is you're wanting to do something. You  want it to succeed. Red teaming is a process   you can do to see how it might fail, how  somebody could beat it or how it might fail. Yellow teaming is if it succeeds, where might  it mess other things up? So could we yellow    team? Well, yes, you're not going to predict  everything, but you predict a lot of the things,   and then you keep watching, and when you notice  other things, you procedurally internalize   them. Now, in the same way all this was the  buildup to the billionaire question, the long  buildup, the people in a  multipolar trap who are at the  front of the race, could stop the multipolar trap,    but they don't want to because  they believe they can win. So they use the multipolar trap as a story of  their own lack of power to do anything else as    plausible deniability. The littler guy  cannot necessarily stop the multipolar trap,    but someone who's at the leading edge of  an arms race, if they wanted to apply the   same energy and same sophistication to  agreements to pursue, because of course,    there's a situation that if my country becomes  more secure relative to other countries,    which means develops better weapons, It  automatically makes everyone else less secure.  So now they have to do the same thing. And  it just means that you have an arms race of   increasing weapons forever and increasing budgets  going to it forever, which is great for defense   contractors. It's actually great for GDP and  it's bad for everything else. Now, if we could    just say how let's make an agreement to all spend  less on weapons, we can be proportionally less.  Right. Proportionally less such that relative  security changes. Well, of course people say,    well, we can't possibly do that. We couldn't  get China. We couldn't get Russia. There's no   way to enforce it, etc. And we're saying that  right now with regard to AI. Well, even if we    wanted to stop this thing from advancing that has  That accelerates every global catastrophic risk.  We couldn't possibly because there's so many  places racing and we couldn't stop China and blah,   blah, blah. Therefore, the only possible answer is  to win the multipolar trap because losing at it is   too bad. If you look at the resources we invest  in figuring out AI, if we invested those same    resources and actually creating healthy diplomacy  where we were not assholes to our international    Neighbors and really tried to create global  coordination to bind the multipolar trap we could.  And so the billionaire that says, well, I don't know  how to solve the problems of the world,   like I'm too small, right in the, it's a hundred  trillion dollar economy. I'm almost nothing. I'm   this little. Guy, I couldn't solve the problems  of the world, therefore me continuing to just    pick up all the game theory tokens I can  under a world of increasing uncertainty. The optionality of that is what's best for  me and my family. Look at how much time you    spent figuring out. How to gather all those  optionality tokens, understanding markets,    understanding how to do lobbying, understanding  your industry, understanding financial markets,   et cetera. And look at how much time you spent  trying to say, if I applied all of that same   energy, time, thoughtfulness, resource to solving  some of the great problems, could I, you have   not put enough time to say that you couldn't  possibly, it's just not in your interest." - [Daniel Schmachtenberger](https://youtu.be/tmusbHBKW84?t=3691)

> "The  system that emerged in the context of power competition selects for people  who are oriented to power competitions and other people who are complicit with  it. Those are the two things it selects for." - [Daniel Schmachtenberger](https://youtu.be/tmusbHBKW84?t=4702)

> "I'm being conditioned by the environment I'm  in in terms of my language, my worldview,   my technological capabilities,  desires, identities, all those things. So, so the civilization is conditioning the  minds. which means patterns of perception,    identity, value, and behavior of  the people. And those minds are,   in turn, creating more of the types of  things that they were conditioned to.    And so there is a feedback loop between  the individuals influencing the whole,   the whole influencing the individuals, and there  is a particular thing that is getting upregulated." - [Daniel Schmachtenberger](https://youtu.be/tmusbHBKW84?t=4750)

> "The people at the top of the power  law distribution explain the shape of  civilization much more than everybody  does, and those people don't come from  the center of the bell curve of  almost any psychological trait." - [Daniel Schmachtenberger](https://youtu.be/tmusbHBKW84?t=5155)

> "So it is this recursion. Now,    the people who are in those top positions are not  only changing the system to be better for them.  They also are obviously invested in that  success. So anyone else who would be    very successfully doing something  that would mess that strategy up,   they have a maximum incentive  to make sure don't succeed." - [Daniel Schmachtenberger](https://youtu.be/tmusbHBKW84?t=5348)

> "Very famously in the  Nuremberg trials of Nazis after World War II,    when the Nazis were being tried for the  war crimes, and they were all asked,    did you believe that everything you were doing  was good? About 90 percent of the Nazis said,    Only at first. At first, we were, you know, we had  been in terrible poverty in the Weimar Republic.  Our kids couldn't eat and, you know, etc.  The Jews had all this wealth. And, you know,    we, we believed that we were getting  supported to be able to, you know,   do well for our people and whatever. But as  time went on, like, no, we did not feel good    about putting kids in gas chambers. And we  didn't feel good about seeing them starving. Like we felt really bad about it.  Like 90 percent of the Nazis said,   no, I did not feel good about it. And then when  they were asked, did you try to stop it? They all    said no. And then they quoted the same German  phrase that translates to officer's orders. I    didn't have a choice. And Yet, of course, if 90  percent of them had all said that simultaneously,    which is a coordination failure here on their  part, there would have been no holocaust.  But anyone on their own is like, if I  try to defect, I'll get thrown in the   gas chamber, too. So it's best for me  and my family to just go along with it. It's kind of a gruesome microcosm of what  we face on so many levels today. Yes.  And so the Ash conformity studies and  the Milgram studies were so important. And I think actually under represent how  deep those principles are, right? The,    the idea that when the authority was telling  the person, the scientific authority, Hey,    you're in a study, do this thing. And  we're doing electroshock therapy, whatever,   that the person following authority  would shock the other guy to death. Because of, I don't have a choice, the authority  is telling me. Or in the other one, in the Ash    ones, that if 10 people in the room were all  saying this line is longer than that line,    the person would defect on their own understanding  to go along with that. These are very powerful insights. " - [Daniel Schmachtenberger](https://youtu.be/tmusbHBKW84?t=5736)

> "I want real progress. I think  it's a, it's a very important  thing to see that we can grow    and that we can add our life energy. to the world in a meaningful way. And  this is why really thinking about what would  constitute actual progress,   that the world is better as a result of us having  done this. Better, the world, not my tiny world,    not better in this metric, but the world  long term. Thinking seven generations ahead." - [Daniel Schmachtenberger](https://youtu.be/tmusbHBKW84?t=6124)

> "The idea of [Ubuntu](https://en.wikipedia.org/wiki/Ubuntu_philosophy),   I am because we are, It was this foundational  concept of human beings before the thing we    call civilization, right? I Am Because We Are  was, like, just at the most prosaic level,    nature did not select for individual sapiens.  It only selected for groups of sapiens. Individual sapiens in evolutionary  environments were all dead. And so    what's best for me that fucks the tribe  is not a concept. That's not a thing,   right? What is best for the tribe that I  can't exist without of? I am because we are,    I would not exist. I'd be dead without  all of us. That's like the basic insight. So I am, because we are obviously  just starts with, I couldn't survive without us. But then it's also deeper,  which is I think in words that I didn't invent.    that all these other people invented. And, but my  own most intimate thing, my thoughts with myself    are in a language that I didn't make. I am, my,  my thoughts were made by other people, right?  The, the, the language of my thoughts, my  understanding of the world was transmitted    to me largely by other people. The tools  that I use, the things that I benefit from,   the, all of that, that I am, almost  all the things I think of as I am,   because we are, right? Because  of things that were created. And it goes deeper, because the we was never, never just meant our  tribe. It also meant nature. the extension to all    our relationships, and all our relationships was  all life, and life didn't just mean biological,    which is why they were animistic. Those cultures  were all animistic. The spirit of the sun,   the spirit of the river, the spirit of everything,  because it was a very clear understanding. What would I be without the tribe? I'd be  dead. What would I be without the sun? I    would have never existed. What would I  be without the galactic center around   which the sun orbits? I wouldn't exist.  What would I be without the gravitational   field? What would I be without the soil  microbes? What would I be without plants? What would I be without all  of that? I wouldn't be. So,   I, that is not the emergent property of we,  isn't even a thing. It's not even thinking." - [Daniel Schmachtenberger](https://youtu.be/tmusbHBKW84?t=6699)

> "So to steward that much  goal achieving power, we must meet it with    what are good goals. What is actually progress?  What is worth maintaining? What is worth for sure    protecting and maintaining? What do what should  be reversed that already harmed things where the    actual progress would come from reversing Some  of the stuff, not just making more new stuff." - [Daniel Schmachtenberger](https://youtu.be/tmusbHBKW84?t=7544)

> "So there's this quote from General Smedley Butler.  And he called war is a racket. It's very  famous. I'll read just the beginning. It's   long and people can go check it out. And,  you know, I'm assuming people know what a   racket is. Racket is like a classic example is  a protection racket where a gang will come Rough    up a store. So the store thinks that they need  protection and the police aren't protecting them. And then other members of that same gang  come offer them security services for   sale. And so they are protecting them from  themselves for a fee. So they are basically    manufacturing the demand and then offering  the supply. The amount, if you, if you  look at  How much of our modern market and market government system meets  the criteria of creating a problem that's a result    of some part of market or technology that some  other part of market and technology will come   to solve, that will then simultaneously create  new problems. The whole thing being a racket is    actually a very But with that definition of a  racket, what he says here is war is a racket.  It always has been. It is possibly the  oldest, easily the most profitable,    surely the most vicious. It is the only  one international in scope. That's not    true anymore. He wrote this in like 18. 81.  Oh no, 19 something. It's the only one which    in which the profits are reckoned in  dollars and the losses are in lives. Racket is best described, I believe, as something  that is not what it seems to the majority of the    people. Only a small inside group knows what it's  really about. It's conducted for the benefit of   the very few at the expense of the very many. Out  of war, a few people always make huge fortunes." - [Daniel Schmachtenberger](https://youtu.be/tmusbHBKW84?t=7621)

> "So there's a lot of    perverse asymmetries like that, like those who  pay more attention to the risks of a technology    up front won't win the technological race and  first mover advantage is those who pretend that   it isn't there or cover it up and make narratives  about how positive it is and scale it rapidly.  Ultimately, we have to overcome all of  those perverse asymmetries." - [Daniel Schmachtenberger](https://youtu.be/tmusbHBKW84?t=9493)

> "We can expand our capacity for wisdom as much as  we expanded for intelligence. We can expand the    scope of our considerations of what a good goal is  as much as we expand our goal achieving. What I'm    saying is we must. Now you're asking, is there a  cultural thing that has to happen? Yes, obviously    our culture, as we already said, is being an  Shaped by our tools and by our social systems.  So our, our superstructure, our culture,  our value systems, our social structures,    our economies and governance systems and  institutions, and our infrastructure,   our tool set are all co influencing each other.  All three of them are confluence co influencing    each other. So obviously we can't, as you,  as you saw when you were in India, you change    your environment and something that no amount  of moralizing yourself to do would ever work.  It was automatic in a different  environment. And so can we achieve    cultural change by just moralizing people  that they should culturally change while   they're still in the environment that is  predisposing the culture that is here? No,   that's not going to work that well. At the  same time, where is the intervention point   is some people who already recognize that  that's not a culture they value enough. They recognize the fail of it. They meditate on  meaningfulness enough that they actually stop    willing to be complicit with it. And not just  to remove themselves, which is a step, which    some people do, but to say, how do I dedicate  my life energy to changing those dynamics,    which should then entail a study of change  efforts that were well motivated and failed.  And or made worse problem so as to not  repeat that to try to understand why   that happens to understand what change that  would change all that could actually would    require and what it would be like now, of  course, to really change culture at scale,    we have to change the two Technology  and what it predisposes, right? We have to change the social systems. As  long as you have an economic system where   putting the externalities are externalized  and cost, then I can't empathize and take,    want to take responsibility for all  the harm that I'm causing if I'm   competing against someone who's  not internalizing those costs,   like economically, you can't, that you're  economically incentivizing sociopathy. Through the cost externality. So of course that  has to change. And of course as that changes,    that makes possible a different value  set. And the same way that like the   algorithm on Facebook could upregulate for  different things, it could upregulate for   exposing people to different worldviews and  different ideas and paying attention to only   upregulating the ideas that drive common  unity rather than, you know, division. So those are places where culture's affected  by technology and social system. But how does   it start? It has to start with a  culture first recognition of the    I am because we are. The version  of progress that is good for I,   that is not for we is actually not real  progress. I, I remove myself from that thing.  I won't participate in the lie of it. And I  will dedicate myself to wanting to understand.  What is, what actually be good for the  whole and make sure my life energy is   in service to that and then progressively that   I am participating in things that have  more agency to be able to affect that?" - [Daniel Schmachtenberger](https://youtu.be/tmusbHBKW84?t=9580)

> "We did talk about restraint. And then we  talked about if someone wants to do   the thing that is more like a cancer cell or  more like cause tribal warfare, they're not   going to be the ones to restrain themselves  from doing it. Other people will have to. That is something like law. Right. That is  something like imposition. And so then we   are right to consider how those systems have  went in the past. And because using force to    curtail someone's liberty has its own problems,  even if what they're wanting to do with their liberty has problems. And that's  already in, in the zeitgeist right now. A lot of people are worried that climate  change is such a thing that will cause   people to eat bugs and not own anything  and all kinds of authoritarian rules.  Yeah, and I think if the people who were  talking about the eating bugs are the    solution and not owning anything were  themselves not major capital owners who   were not applying those things to themselves,  people might feel a little better about it. But like, The dude that is a hunter gatherer  and he eats a lot of crickets and grubs. And    if he says like, bugs are good, like nobody's  freaked out about that. They're freaked out   about a situation of radical wealth  inequality and class warfare and the    class warfare telling more stories of  justifying radical inequality as the,   you know, as a solution while they have  the largest carbon footprints themselves.  So like understandable, right? So  the thing that I want to say is.  The, you, you introduced me to her Vanessa Andrade, who you had on the  show, who I had a conversation with and thought    she was amazing and really respect it's in her  book. She said that her the chief of her tribe,    the, his definition of colonialism,  she probably said that on your show,   but I'll bring it up is that colonialism  was not about taking other people's land,    fundamentally, or about abuse of  land or abuse of people or anything,   that those were epiphenomena, that the core of  it was believing there are separable things.  And you can say even deeper than that is being  conditioned to perceive the world as a bunch   of separable things. Which is what Bohm said  was the underlying cause of all the problems,    which is what Krishnamurti said was the cause of  all the problems, which is what Einstein said.   So if I believe there's a bunch of separable  things and I'm separate from other things,   then I can optimize some things  at the expense of other things. And then I can actually rationalize that  everything is trade offs and that's how it   is and etc. And, you know, then reify social  Darwinism and nonsense like that. So the root  One could say that the root  of the issues is if people  want things that inevitably cause harm to others.  That's the root of the problems. Either because  they know it causes harm and they want it anyway,    so it's some kind of, you know, rivalry  or sociopathy or something like that.   Or because they don't know it causes harm and  it's from, you know, ignorance and externality. They just want what they want and  they're not thinking about what all   the cause and effect would be. Because  if you then say, great, let's let the,   let's let people pursue what they want.  And what they pursue getting causes harm   and then also creates propagating patterns  where to protect themselves against the   harm that other people have to do similar  competitive things and blah, blah, blah. And you have a world defined by arms  races. But if the other answer is don't    let the people pursue what they want,  use some kind of enlightened law that   says that's bad and prevent it by force,  the oppression is inherently also bad.   And the asymmetry of. force tends to lead to  an increasing corruption of the power stack.  And so neither of those are good. So as long  as humans believe that they are separate from    everything else, as long as they perceive the  world separately, you were mentioning language   earlier. And I think similarly, Vanessa was  telling you that English has like 70 percent of   the words are nouns and most indigenous languages,  very small percentage of the words are nouns.  You look at Whitehead as one of the kind  of great philosophers of 20th   century. And the reason he came to process  philosophy is he's like, there's no things   like the things that we think of as things  are processes of interaction of other things,    right? A tree is not a static noun. It's the doing  trillions of metabolic functions every second. It's interacting. biophysically, with the sun  and the air, it's interacting biochemically,    it's interacting biologically, doing gene  transfer with the fungus on its roots and the   soil microbes, like the tree is in a live  process. It's a verb. It's lots of verbs.    And the idea that it's a noun just makes us  think very poorly, makes us very bad thinkers.  And the fact that we're thinking in nouns all  the time and built into our language is making   us bad thinkers at scale that we don't even  realize because we don't know what it's like   to have a language that doesn't see the world  as a bunch of nouns that are all separate." - [Daniel Schmachtenberger](https://youtu.be/tmusbHBKW84?t=9834)

> "Currently, The rates of growth of  the things that are moving in the authentic  progress direction versus the narrow progress harm    externalizing direction are not adequate. Right.  And like I said, many of the things and everybody    that is contributing to the meta crisis thinks  that they are contributing to real progress.  Right. I'm, I'm providing a product or service  that the market wants, which means there's   demand for it, which means it's increasing.  It's solving some problem for someone that   makes their life better. And I'm employing the  tools of science and technology, which is this    awesome system that allows us to understand  the world in a unified way and improve things. And like, that's, that's The story. So it's  like the, and that's why people can come out    in such defensive fossil fuels of look at  all the things they give us. And you know,   and of the market and, and they do, and  they give all of these externalities.    And while that has benefited some and sucked  for others, it also benefits some dimensions    of self and sucks for the dimensions of  self, even for those most being benefited. And it is in the process of self terminating  where it will be a benefit to nobody. No one.    In which case, the, damn, I really don't want to  be complicit with that thing. Damn, I really don't    want to just, what's best for me and my family  is continue to have optionality tokens. And damn,    I don't want to try to make things better where  I end up making them worse because I am coming   from the same type of mind that engages in rivalry  and cause, does a movement in a way that creates    counter movements and that optimizes for one thing  in a way that ends up causing harm elsewhere.  So I want. That the activism, the protection  impulse in me reconnects to the source of reality    deeply enough that I know how to participate, that  I'm guided in how to participate in a way that is    actually meaningful. So I would actually like  to see a slightly slower movement into action,    a deeper movement into withdrawal, and  a deeper understanding of the history of    well intended failed actions more rigorously,  it's very painful, and a deeper being with the    emotions about the whole thing and really taking  it all in and noticing how much of our desire to    make it better is still ego, is still um,  An avoidance mechanism for not wanting to    feel it is still a problem solving mode that is  reductionistic that will end up contributing to it  and like letting that stuff  settle to get to a place  where one can engage in how to shift the system   dynamics of the world in a way  that are actually what's needed." - [Daniel Schmachtenberger](https://youtu.be/tmusbHBKW84?t=11570)

> "" - [Daniel Schmachtenberger]()

> "" - [Daniel Schmachtenberger]()

> "" - [Daniel Schmachtenberger]()

> "" - [Daniel Schmachtenberger]()

> "" - [Daniel Schmachtenberger]()

> "" - [Daniel Schmachtenberger]()

> "" - [Daniel Schmachtenberger]()

> "" - [Daniel Schmachtenberger]()

> "" - [Daniel Schmachtenberger]()

> "" - [Daniel Schmachtenberger]()
