<!DOCTYPE HTML>
<html lang="en" class="sidebar-visible no-js ayu">
    <head>
        <!-- Book generated using mdBook -->
        <meta charset="UTF-8">
        <title>Headjack - the base layer of cyberspace</title>
        <meta name="robots" content="noindex" />


        <!-- Custom HTML head -->
        
        <meta content="text/html; charset=utf-8" http-equiv="Content-Type">
        <meta name="description" content="">
        <meta name="viewport" content="width=device-width, initial-scale=1">
        <meta name="theme-color" content="#ffffff" />

        <link rel="shortcut icon" href="favicon.png">
        <link rel="stylesheet" href="css/variables.css">
        <link rel="stylesheet" href="css/general.css">
        <link rel="stylesheet" href="css/chrome.css">
        <link rel="stylesheet" href="css/print.css" media="print">

        <!-- Fonts -->
        <link rel="stylesheet" href="FontAwesome/css/font-awesome.css">
        <link rel="stylesheet" href="fonts/fonts.css">

        <!-- Highlight.js Stylesheets -->
        <link rel="stylesheet" href="highlight.css">
        <link rel="stylesheet" href="tomorrow-night.css">
        <link rel="stylesheet" href="ayu-highlight.css">

        <!-- Custom theme stylesheets -->

    </head>
    <body>
        <!-- Provide site root to javascript -->
        <script type="text/javascript">
            var path_to_root = "";
            var default_theme = window.matchMedia("(prefers-color-scheme: dark)").matches ? "ayu" : "ayu";
        </script>

        <!-- Work around some values being stored in localStorage wrapped in quotes -->
        <script type="text/javascript">
            try {
                var theme = localStorage.getItem('mdbook-theme');
                var sidebar = localStorage.getItem('mdbook-sidebar');

                if (theme.startsWith('"') && theme.endsWith('"')) {
                    localStorage.setItem('mdbook-theme', theme.slice(1, theme.length - 1));
                }

                if (sidebar.startsWith('"') && sidebar.endsWith('"')) {
                    localStorage.setItem('mdbook-sidebar', sidebar.slice(1, sidebar.length - 1));
                }
            } catch (e) { }
        </script>

        <!-- Set the theme before any content is loaded, prevents flash -->
        <script type="text/javascript">
            var theme;
            try { theme = localStorage.getItem('mdbook-theme'); } catch(e) { }
            if (theme === null || theme === undefined) { theme = default_theme; }
            var html = document.querySelector('html');
            html.classList.remove('no-js')
            html.classList.remove('ayu')
            html.classList.add(theme);
            html.classList.add('js');
        </script>

        <!-- Hide / unhide sidebar before it is displayed -->
        <script type="text/javascript">
            var html = document.querySelector('html');
            var sidebar = 'hidden';
            if (document.body.clientWidth >= 1080) {
                try { sidebar = localStorage.getItem('mdbook-sidebar'); } catch(e) { }
                sidebar = sidebar || 'visible';
            }
            html.classList.remove('sidebar-visible');
            html.classList.add("sidebar-" + sidebar);
        </script>

        <nav id="sidebar" class="sidebar" aria-label="Table of contents">
            <div class="sidebar-scrollbox">
                <ol class="chapter"><li class="chapter-item expanded "><a href="introduction.html"><strong aria-hidden="true">1.</strong> What is Headjack</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="on_off_chain.html"><strong aria-hidden="true">1.1.</strong> On-chain vs off-chain</a></li><li class="chapter-item expanded "><a href="principles.html"><strong aria-hidden="true">1.2.</strong> Guiding principles</a></li><li class="chapter-item expanded "><a href="identity.html"><strong aria-hidden="true">1.3.</strong> Identity & authorization</a></li><li class="chapter-item expanded "><a href="messages.html"><strong aria-hidden="true">1.4.</strong> Messages</a></li><li class="chapter-item expanded "><a href="account_preferences.html"><strong aria-hidden="true">1.5.</strong> Account preferences & graphs</a></li><li class="chapter-item expanded "><a href="addressing.html"><strong aria-hidden="true">1.6.</strong> Content addressing</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="host_centric.html"><strong aria-hidden="true">1.6.1.</strong> Today's web: host-centric</a></li><li class="chapter-item expanded "><a href="data_centric.html"><strong aria-hidden="true">1.6.2.</strong> Data-centric addressing</a></li><li class="chapter-item expanded "><a href="blob_structure.html"><strong aria-hidden="true">1.6.3.</strong> Blob structure & addressing</a></li><li class="chapter-item expanded "><a href="uris.html"><strong aria-hidden="true">1.6.4.</strong> Persistent & provable URIs</a></li><li class="chapter-item expanded "><a href="names_and_paths.html"><strong aria-hidden="true">1.6.5.</strong> Names, paths, & more</a></li></ol></li><li class="chapter-item expanded "><a href="store_and_retrieve.html"><strong aria-hidden="true">1.7.</strong> Storage & retrievability of data</a></li><li class="chapter-item expanded "><a href="web_scale.html"><strong aria-hidden="true">1.8.</strong> Web-scale & UX</a></li><li class="chapter-item expanded "><a href="numbers.html"><strong aria-hidden="true">1.9.</strong> Throughput numbers (scaling)</a></li><li class="chapter-item expanded "><a href="competition.html"><strong aria-hidden="true">1.10.</strong> Headjack vs the competition</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="others_list.html"><strong aria-hidden="true">1.10.1.</strong> List of other projects</a></li></ol></li></ol></li><li class="chapter-item expanded "><a href="motivation.html"><strong aria-hidden="true">2.</strong> Why Headjack</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="problems_with_the_web.html"><strong aria-hidden="true">2.1.</strong> Problems with the current web</a></li><li class="chapter-item expanded "><a href="authenticity.html"><strong aria-hidden="true">2.2.</strong> Authenticity</a></li><li class="chapter-item expanded "><a href="possibilities.html"><strong aria-hidden="true">2.3.</strong> Possibilities with open data</a></li><li class="chapter-item expanded "><a href="infrastructure.html"><strong aria-hidden="true">2.4.</strong> Infrastructure improvements</a></li><li class="chapter-item expanded "><a href="business_models.html"><strong aria-hidden="true">2.5.</strong> Business models</a></li><li class="chapter-item expanded "><a href="feeds_indexes_algorithms.html"><strong aria-hidden="true">2.6.</strong> Feeds, indexes & algorithms</a></li><li class="chapter-item expanded "><a href="metaverse.html"><strong aria-hidden="true">2.7.</strong> The metaverse</a></li><li class="chapter-item expanded "><a href="startup_case_study.html"><strong aria-hidden="true">2.8.</strong> Startup case study</a></li><li class="chapter-item expanded "><a href="mission_ambition.html"><strong aria-hidden="true">2.9.</strong> Mission & ambition</a></li><li class="chapter-item expanded "><a href="ambition.html"><strong aria-hidden="true">2.10.</strong> The ambition</a></li></ol></li><li class="chapter-item expanded "><li class="part-title">⬇⬇⬇ WORK IN PROGRESS ⬇⬇⬇</li><li class="spacer"></li><li class="chapter-item expanded "><a href="execution.html"><strong aria-hidden="true">3.</strong> Implementation of Headjack</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="IDM.html"><strong aria-hidden="true">3.1.</strong> Identity managers (IDM)</a></li><li class="chapter-item expanded "><a href="handles.html"><strong aria-hidden="true">3.2.</strong> Handles (names)</a></li></ol></li></ol>
            </div>
            <div id="sidebar-resize-handle" class="sidebar-resize-handle"></div>
        </nav>

        <div id="page-wrapper" class="page-wrapper">

            <div class="page">
                                <div id="menu-bar-hover-placeholder"></div>
                <div id="menu-bar" class="menu-bar sticky bordered">
                    <div class="left-buttons">
                        <button id="sidebar-toggle" class="icon-button" type="button" title="Toggle Table of Contents" aria-label="Toggle Table of Contents" aria-controls="sidebar">
                            <i class="fa fa-bars"></i>
                        </button>
                        <button id="theme-toggle" class="icon-button" type="button" title="Change theme" aria-label="Change theme" aria-haspopup="true" aria-expanded="false" aria-controls="theme-list">
                            <i class="fa fa-paint-brush"></i>
                        </button>
                        <ul id="theme-list" class="theme-popup" aria-label="Themes" role="menu">
                            <li role="none"><button role="menuitem" class="theme" id="light">Light</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="rust">Rust</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="coal">Coal</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="navy">Navy</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="ayu">Ayu (default)</button></li>
                        </ul>
                        <button id="search-toggle" class="icon-button" type="button" title="Search. (Shortkey: s)" aria-label="Toggle Searchbar" aria-expanded="false" aria-keyshortcuts="S" aria-controls="searchbar">
                            <i class="fa fa-search"></i>
                        </button>
                    </div>

                    <h1 class="menu-title">Headjack - the base layer of cyberspace</h1>

                    <div class="right-buttons">
                        <a href="print.html" title="Print this book" aria-label="Print this book">
                            <i id="print-button" class="fa fa-print"></i>
                        </a>
                        <a href="https://github.com/onqtam/headjack" title="Git repository" aria-label="Git repository">
                            <i id="git-repository-button" class="fa fa-github"></i>
                        </a>

                    </div>
                </div>

                <div id="search-wrapper" class="hidden">
                    <form id="searchbar-outer" class="searchbar-outer">
                        <input type="search" id="searchbar" name="searchbar" placeholder="Search this book ..." aria-controls="searchresults-outer" aria-describedby="searchresults-header">
                    </form>
                    <div id="searchresults-outer" class="searchresults-outer hidden">
                        <div id="searchresults-header" class="searchresults-header"></div>
                        <ul id="searchresults">
                        </ul>
                    </div>
                </div>

                <!-- Apply ARIA attributes after the sidebar and the sidebar toggle button are added to the DOM -->
                <script type="text/javascript">
                    document.getElementById('sidebar-toggle').setAttribute('aria-expanded', sidebar === 'visible');
                    document.getElementById('sidebar').setAttribute('aria-hidden', sidebar !== 'visible');
                    Array.from(document.querySelectorAll('#sidebar a')).forEach(function(link) {
                        link.setAttribute('tabIndex', sidebar === 'visible' ? 0 : -1);
                    });
                </script>

                <div id="content" class="content">
                    <main>
                        <h1 id="headjack---the-base-layer-of-cyberspace"><a class="header" href="#headjack---the-base-layer-of-cyberspace">Headjack - the base layer of cyberspace</a></h1>
<!-- <object width=100% data="images/Untitled-2022-06-08-1154.svg"></object> -->
<!-- <div width=100% style="background-color:green; overflow:auto;"> -->
<!-- add # before include for the preprocessor to work -->
<!-- {{include images/Untitled-2022-06-08-1154.svg}} -->
<!-- </div> -->
<!-- have to manually remove the size of the svg tag from the file after each export -->
<!-- also should replace href="https:// with href=" after each export -->
<!-- https://github.com/rust-lang/mdBook/issues/773 -->
<p>Headjack is a blockchain that links sovereign identities to content at <a href="web_scale.html">web-scale</a>. Key points:</p>
<ul>
<li>Creation is fundamentally different from transfers and exchange of value - the design space around trust &amp; data availability for media and identity is different from finance.</li>
</ul>
<!-- 
It is not about less or more trust but about better trust.

Headjack is about better trust - not trustlessness

Breaking apart identity and media allows for better incentives

it does not deal with storage and neither with routing - any kind of routing can be implemented on top of it with the advantage of addressing content in bulk or by source (publisher or creator)

 -->
<ul>
<li>
<p>Following the <a href="https://en.wikipedia.org/wiki/Unix_philosophy">UNIX philosophy</a> - in Headjack identity is simply an identifier (unique number) and anything orthogonal (KYC, profiles, privacy) can be layered on top of it. <!-- through data associations --></p>
</li>
<li>
<p>It solves single sign-on and allows for user experience similar to Web2 through <a href="identity.html">hierarchical authorization management</a> - keypairs are not required by default and even those with keys bound to their accounts may choose to not explicitly sign every interaction.</p>
</li>
<li>
<p>Consensus is reached on the absolute bare minimum - the history of authorizations, names, keys &amp; off-chain content anchors (merkle roots) - the simplest mental model for developers.</p>
</li>
<li>
<p>Headjack can support <strong>billions</strong> of accounts and link <strong>unlimited</strong> amounts of off-chain activity to them. The <a href="web_scale.html">entire web</a> can be rebuilt on top of it - a claim that is <a href="numbers.html">easily provable</a>.</p>
</li>
<li>
<p><a href="addressing.html">Content addressing</a> is with persistent &amp; human-readable URIs (instead of hashes) - the link between identity and data is cryptographically provable even if keys &amp; names have changed.</p>
</li>
<li>
<p>It doesn't deal with off-chain data storage and retrievability - those are separate problems and Headjack simply lets entities point to ways for others to retrieve addressable content.</p>
</li>
</ul>
<!-- - The move from the current [host-centric](host_centric.md) web towards [data-centric](data_centric.md) addressing represents a paradigm shift around data ownership & access - an architectural reset of the internet. -->
<h1 id="book-structure"><a class="header" href="#book-structure">Book structure</a></h1>
<ul>
<li>
<p><strong>What is Headjack</strong> - How the protocol technically works, how it compares with other projects, and how things like DMs, social graphs, preferences, etc. could be implemented - the building blocks necessary to recreate anything from Web2 and beyond.</p>
</li>
<li>
<p><strong>Why is Headjack necessary</strong> - What's broken with the web and a blueprint of what could be possible - services, business models, infrastructure, algorithms, markets, metaverse, etc.</p>
</li>
<li>
<p><strong>Implementation of Headjack</strong> - A detailed specification of the implementation.</p>
</li>
</ul>
<h1 id="introduction-what"><a class="header" href="#introduction-what">Introduction (what)</a></h1>
<!-- The following sub-chapters convey the idea (**what**) and a high-level view of how it works: -->
<ol>
<li><a href="on_off_chain.html">On-chain vs off-chain</a></li>
<li><a href="principles.html">Guiding principles</a></li>
<li><a href="identity.html">Identity &amp; authorization</a></li>
<li><a href="messages.html">Messages</a></li>
<li><a href="account_preferences.html">Account preferences &amp; graphs</a></li>
<li><a href="addressing.html">Content addressing</a>
<ol>
<li><a href="host_centric.html">Today's web: host-centric</a></li>
<li><a href="data_centric.html">Data-centric addressing</a></li>
<li><a href="blob_structure.html">Blob structure &amp; addressing</a></li>
<li><a href="uris.html">Persistent &amp; provable URIs</a></li>
<li><a href="names_and_paths.html">Names, paths, &amp; more</a></li>
</ol>
</li>
<li><a href="store_and_retrieve.html">Storage &amp; retrievability of data</a></li>
<li><a href="web_scale.html">Web-scale &amp; UX</a></li>
<li><a href="numbers.html">Throughput numbers (scaling)</a></li>
<li><a href="competition.html">Headjack vs the competition</a>
<ol>
<li><a href="others_list.html">List of other projects</a></li>
</ol>
</li>
</ol>
<div style="text-align: center;">
    <img src="images/logo.png">
</div>
<p>Inspired by the <a href="https://matrix.fandom.com/wiki/Headjack">data port at the back of the head</a> of synthetically-grown humans in the Matrix.</p>
<!-- https://www.youtube.com/watch?v=DoUQhYDz-Ys -->
<div style="break-before: page; page-break-before: always;"></div><h1 id="on-chain-vs-off-chain"><a class="header" href="#on-chain-vs-off-chain">On-chain vs off-chain</a></h1>
<p>TODO: rework this page</p>
<p>Due to practical limitations, it is <a href="web_scale.html">impossible</a> to put everything on a blockchain so we have to make a key distinction:</p>
<ul>
<li>The importance of user data is on a spectrum with identity &amp; connections being the most valuable - a clear example is <a href="https://en.wikipedia.org/wiki/Substack">Substack</a> (basically <a href="https://en.wikipedia.org/wiki/Medium_(website)">Medium</a> but you own the mailing list for your audience). The <a href="https://en.wikipedia.org/wiki/Interest_graph">interest graph</a> is the subscription layer for information propagation - a forward-looking &amp; ever-evolving data structure that gets reused over and over again each time content is created. It is the <a href="https://twitter.com/balajis/status/1162539429484871681">essential crown jewel</a> that needs preservation - the global <a href="https://en.wikipedia.org/wiki/Publish%E2%80%93subscribe_pattern">pub-sub</a>. The data availability (DA - storage &amp; retrievability) for identity &amp; the interest graph needs to be guaranteed with cryptoeconomics on a permissionless ledger so anyone can build around it.</li>
<li>Content should be stored off-chain (<a href="https://en.wikipedia.org/wiki/InterPlanetary_File_System">IPFS</a> and other protocols) because of the sheer volume - it's ephemeral and its relevance fades with time. Most of it doesn't have to be stored forever but any piece can be backed up through third-party archival services. It gets anchored with cryptographic <a href="https://en.wikipedia.org/wiki/Merkle_tree">Merkle roots</a> in the main chain so that permissions, inclusion &amp; sequence are provable - that way even if content goes dark it can later resurface and be deduplicated by linking it to previous instances (as long as Merkle proofs are present).</li>
</ul>
<p>The terms <a href="messages.html">message</a>/event/action/data/content are used interchangeably in this book and refer to any type of event/content a user might have generated - post/comment/reaction/etc.</p>
<blockquote>
<p>&quot;When identities become portable, backends become liquid&quot; - <a href="https://twitter.com/coconidodev/status/1504850437727571974">@balajis</a></p>
</blockquote>
<p>The game theory behind why competing applications (presentation layers/interfaces/views - probably operated by a company with a business model) would freely share the activity of their users with others to display is that if they don't they would be effectively denying reach - users would migrate to a competitor because the cost to do so is 0 - <a href="https://en.wikipedia.org/wiki/Exit,_Voice,_and_Loyalty_Model"><code>voice and exit</code></a>. Current social media platforms are monopolies because identities are not portable and the network effects are in private database silos - a problem practically insurmountable for incumbents.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="guiding-principles"><a class="header" href="#guiding-principles">Guiding principles</a></h1>
<p>There are 5 guiding principles when aiming for mass adoption &amp; parity on convenience &amp; UX with Web2 services:</p>
<ul>
<li>
<p>Aggregation and scale cannot be an afterthought - must be scalable to billions of users and that must be <a href="numbers.html">obvious &amp; provable</a> if entrepreneurs are expected to jump on the opportunity. The easiest mental model will win over developers - opinionated frameworks with a concrete direction are much simpler than a sea of standards, libraries &amp; chains.</p>
<ul>
<li>
<blockquote>
<p>&quot;Developers care about risk.&quot; - <a href="https://haseebq.com/why-decentralization-isnt-as-important-as-you-think/">Haseeb</a></p>
</blockquote>
</li>
</ul>
</li>
<li>
<p>Must be simple and familiar - abstracting the complexity away. Users shouldn't have to manage keypairs on multiple devices &amp; explicitly sign every interaction - by default they'll be logging into identity managers (<a href="IDM.html">IDMs</a>) using email &amp; pass / <a href="https://en.wikipedia.org/wiki/Single_sign-on">SSO</a> (<code>&quot;login with Google&quot;</code>) and would then be using these IDMs as <a href="https://en.wikipedia.org/wiki/Single_sign-on">SSO</a> to authorize applications to post on their behalf. RSS was <a href="https://twitter.com/mgsiegler/status/311992206716203008">too technical</a> and it failed - <a href="https://www.vice.com/en/article/a3mm4z/the-rise-and-demise-of-rss"><code>&quot;people jumped ship as soon as something better came along&quot;</code></a>.</p>
<ul>
<li>
<blockquote>
<p>&quot;With consumer products, simple and “wrong” beats complicated and “right.”&quot; - <a href="https://twitter.com/naval/status/1542651322532384768">@naval</a></p>
</blockquote>
</li>
</ul>
</li>
</ul>
<img src="images/meme_make_them_learn.png" align="right" style="margin-left: 8px; width: 30%">
<ul>
<li>Users shouldn't have to think about and pay for the storage of their data &amp; blockchain interactions by default - costs &amp; complexity should be shifted to services.</li>
<li>Users should be able to own their identity &amp; connections in a sovereign way with a keypair <strong>even if by default</strong> their activity is managed by something resembling a custodial service.</li>
<li>Anyone should be able to have a pseudonymous identity, operate an <a href="IDM.html">IDM</a>, or serve media through an application. Anyone must be able to publish &amp; broadcast through Headjack using their identity - <a href="moderation.html">moderation &amp; censorship</a> will happen at the application level.</li>
</ul>
<!-- TODO: key pillar: must not be worse than current web2 -->
<!-- "Sign-in with ethereum" will always be limited -->
<!-- TODO: key pillar: should make it hard for monopolies to form and data to be hoarded -->
<p>Nobody wants to deal with keypairs.
Its ok to trust by default as long as there is a fallback option</p>
<!-- TODO: Designed to stand the test of time - best crypto-economic guarantees, capital efficiency, and scalability. -->
<div style="break-before: page; page-break-before: always;"></div><h1 id="identity--authorization"><a class="header" href="#identity--authorization">Identity &amp; authorization</a></h1>
<p>There are 3 types of roles in Headjack (although a single entity may play all 3):</p>
<ul>
<li>Normal accounts - represented by an integer ID on-chain - keypair association is optional.</li>
<li><a href="IDM.html">IDMs</a> - a superset of normal accounts - required to have a keypair - can manage other accounts by submitting changes for them (name handle, updating keypairs) &amp; acting as <a href="https://en.wikipedia.org/wiki/Single_sign-on">SSO</a> - authorizing applications to post on behalf of users (&amp; ability to revoke the authorization). They will also be responsible for handling DMs as discussed <a href="IDM.html#dms">here</a>.</li>
<li>Applications - a superset of normal accounts - required to have a keypair - they are the media presentation layer. Users can authorize them through the use of an <a href="IDM.html">IDM</a> to post on their behalf without having to explicitly sign every interaction (follow, post, comment, react).</li>
</ul>
<p>All authorizations are represented &amp; submitted on-chain as simple integer pairs (<code>2131 =&gt; 83253, 6331 =&gt; 14415</code>) that get aggregated in compact blobs &amp; signed in bulk by <a href="IDM.html">IDMs</a> - achieving a very high signal-to-noise ratio (few signatures) ==&gt; improving the throughput in the valuable block space.</p>
<img src="images/sequenced_integer_relations.png">
<p>With this foundation we achieve the following range of usage scenarios:</p>
<ul>
<li>Costs for using the blockchain can be shifted to <a href="IDM.html">IDMs</a> &amp; applications with business models to support that - users won't care that there's an underlying token (they'll always be able to interact with it directly through the mempool &amp; pay for transactions if they wish).</li>
<li>Users won't need wallets &amp; keypairs - risky and cumbersome with multiple devices. Most will create accounts through <a href="IDM.html">IDMs</a> &amp; use email/pass or Web2 <a href="https://en.wikipedia.org/wiki/Single_sign-on">SSO</a> (<code>&quot;login with Google&quot;</code>) which will create on-chain integer IDs for them without associated keypairs - &quot;owned&quot; by the custodian. Users will be able to &quot;log in&quot; to applications using their IDM as <a href="https://en.wikipedia.org/wiki/Single_sign-on">SSO</a> for Headjack which will authorize the application with a few bytes on-chain to post actions on behalf of users - all without requiring a single signature by the user - neither on-chain for the identity/authorizations (tiny bits of data - just integers &amp; bit flags submitted by the <a href="IDM.html">IDM</a>) nor for their off-chain content (posts, comments, reactions).</li>
<li>Users can revoke permissions to applications and even retroactively invalidate activity generated on their behalf by an application by saying <code>&quot;discard activity generated through application А from block X forward&quot;</code> through a small on-chain message published by their IDM because everything is sequenced. This is acceptable because in this blockchain <a href="https://twitter.com/VitalikButerin/status/1530268923848839173">such data is non-financial</a> and fake activity has smaller consequences - it is still an enormous improvement compared to the current Web2 status quo.</li>
<li>At any point in time users can regain full sovereignty over their identities by binding a keypair through their <a href="IDM.html">IDM</a>. Then they'll be able to cut that IDM off (revoke access) &amp; even retroactively invalidate actions from it through another IDM or direct on-chain transactions.</li>
<li>Users can be completely anonymous by directly creating an identity with a keypair &amp; paying for an on-chain transaction. They'll be able to use <a href="IDM.html">IDMs</a> without having to sign with email/pass or a Web2 <a href="https://en.wikipedia.org/wiki/Single_sign-on">SSO</a> - not revealing anything.</li>
<li>Applications will be usable by users that don't use an <a href="IDM.html">IDM</a> but all their off-chain activity (posts, comments, reactions) will need explicit signatures.</li>
</ul>
<img src="images/authorizations.png">
<p>So at the core of it all is just sequencing relations between integers &amp; Merkle roots for content.</p>
<img src="images/meme_integers_and_relations.jpg">
<p>In practice, we expect that only cypherpunks &amp; people that have something to lose (big audience/reputation) will go through the trouble to manage a keypair. Almost everyone will use <a href="IDM.html">IDMs</a> - even most crypto natives don't want to explicitly sign every action and have their keys in hot wallets ready to get hacked. This way 99.9% of the user activity on-chain (mostly authorizations) ends up going through authorized services and gets batched in a compact way - requiring only that the service signs the aggregated payload and thus reducing the amount of signatures on-chain.</p>
<p>The vast majority of users will be lightweight: consumers &amp; curators of content (through interactions &amp; reactions) with very little creation on their part and little to no audience. At any point in time, they could shift to a more vocal role and start caring about archiving their off-chain data and not relying on the good grace of the infrastructure that sits beneath applications.</p>
<blockquote>
<p>&quot;The internet is the computer but it's missing identity and <a href="https://en.wikipedia.org/wiki/Access-control_list">acls</a>.&quot; - <a href="https://news.ycombinator.com/item?id=25734612">koalaman</a>.</p>
</blockquote>
<p>Key &amp; session management (rotation, authorization &amp; revocation) <a href="https://blog.ceramic.network/key-revocation-in-self-certifying-protocols/">require</a> ordering that is <a href="https://medium.com/@VitalikButerin/the-meaning-of-decentralization-a0c92b76a274">logically centralized</a>. It is compatible with any type of <a href="https://www.w3.org/TR/did-core/">DID</a> - anything could be associated with an integer ID. The on-chain authorization has incredible synergy with the human-readable &amp; persistent <a href="addressing.html">addressing</a> for off-chain content.</p>
<!-- meme: oprah - you get an identity, you get an identity, everyone gets an identity! -->
<!-- TODO: talk about per device key revocation - or how IDMs will be able to track which devices are logged in and they should handle such revocation - as in the traditional Web2 -->
<div style="break-before: page; page-break-before: always;"></div><div style="text-align: center;">
    <img src="https://png.pngitem.com/pimgs/s/207-2073499_translate-platform-from-english-to-spanish-work-in.png">
</div>
<h1 id="messages"><a class="header" href="#messages">Messages</a></h1>
<!-- TODO: take stuff form the other messages.md doc

signal/noise ratio - message types & why we shouldn't wait for AI classification

- fallback/default presentation/rendering - how to display content if an application doesn't support a new activity type

tag type: disprove/correct - to combat misinformation & help crowdsource truth?

Why Headjack won't fall victim to stagnation and being stuck in time with this open standard and sort-of federation
https://signal.org/blog/the-ecosystem-is-moving/
- because messages will have default renderability
- because you'll always be able to click on items that your application cannot display properly and go to the application that produced them and see them properly

message type/format: price predictions with percentage possibilities, so that later reputations can be plotted based on the message type

tag type idea: prediction, and later with oracles credibility & track records could be automated



https://en.wikipedia.org/wiki/Resource_Description_Framework
https://en.wikipedia.org/wiki/RDFa



https://spec.dsnp.org/DSNP/Announcements.html

- protobuf for message types?
- apache thrift? https://thrift.apache.org/



Activity Streams formats?
https://spec.dsnp.org/ActivityContent/Overview.html



revisions of messages (edit/delete)
https://github.com/regular/ssb-revisions

New polling/info contribution ways

TODO: look at Data models in ceramic!

“pit X vs Y”

tombstone message
https://spec.dsnp.org/DSNP/Identity.html#retroactive-revocation-of-delegation

subreddits would be implemented by a special message type with a tag for the subreddit that people are posting into

updates to old post...
    - how would old unique URLs to the original posts get updated?
multiple edit events in parallel to the same original message? a fork? :|


update to post - as a diff, with different kinds of diff algos?

dislike button/protocol/spec? ⇒ reactions

https://en.wikipedia.org/wiki/Ontology_(information_science)
https://en.wikipedia.org/wiki/Web_Ontology_Language

https://en.wikipedia.org/wiki/Resource_Description_Framework

https://en.wikipedia.org/wiki/Microformat

https://en.wikipedia.org/wiki/Media_type

Post/rt/tag/mention/comment/quote/reply

concern: message standards...

https://schema.org/


new types of messages get an on-chain ID so subscriptions are integer-based


messages contain their URIs and also a local timestamp - although that could be spoofed. It is however useful for ordering things in certain cases

also contain the current block height in addition to a unix timestamp

the <application_id>/<application_nonce> is embedded in a message that's being signed through an application/IDM such that it cannot suffer from a replay attack

-->
<div style="break-before: page; page-break-before: always;"></div><div style="text-align: center;">
    <img src="https://png.pngitem.com/pimgs/s/207-2073499_translate-platform-from-english-to-spanish-work-in.png">
</div>
<h1 id="account-preferences--graphs"><a class="header" href="#account-preferences--graphs">Account preferences &amp; graphs</a></h1>
<!--
how it gets managed by IDMs (so they will also touch IPFS?!)

public vs private

interest graph & how it works off-chain

TODO: change interest graph related things in other pages & pictures

- per account graph state? a materialized tree of the current state based on all prior events - both off-chain & on-chain?

- remove the focus on the interest graph - it will be off-chain!
    - also from all graphics!




1 of N requirement for keeping the interest graph intact & being able to recover it from somewhere


the graph could be moved on-chain if there are many MB/s of DB throughput (possibly sharding) but that would put a lot of strain on the 


myspace-like page  (or linktree-like) where you paint the picture of you - as a map or as whatever - but content shouldn't be owned by separate platforms


Connections can be multidimensional with explicit filtering & exclusion of content based on its type/tag or application that it originates from - all of which will also be represented by integers.




In Headjack all connections in the [interest graph](https://en.wikipedia.org/wiki/Interest_graph) are asymmetric and also visible & on-chain as it is geared towards [public discourse](https://www.quora.com/Will-the-future-of-social-graph-relationships-be-asymmetric-following-e-g-Quora-Twitter-or-symmetric-friending-e-g-Facebook/answer/David-O-Sacks) but private ones for a social graph can also be achieved through encryption - handled & stored by [IDMs](IDM.md) with greater trust assumptions. However, being public by default (as is the case with Twitter) and focusing on that aspect first greatly improves discoverability and the chances to bootstrap the network effect - propagation & reach are sought after. Identities will have their own customized landing pages off-chain through an IDM.



- `follows` (`array[integer]`) - list of accounts that it follows
    - `followers` (`array[integer]`) - a list of accounts that follow it (redundant - can be reconstructed by scanning all accounts - for faster queries of the other sort)

- Twitter: 400M users (220 MAU), average connections: 700
- 1.1 TB for arrays of arrays with 4 byte integers (the graph)
    - 2.2 TB (x2) if storing connections both ways for faster lookups (who do I follow & who follows me)
    - 4.4 TB (x2) if using long long int (8 bytes) - infinite indexes
- Metadata (pubkey, handle, description) per index would be O(1)
    - Less than the bytes required for 700 connections on average
- Realistic state size: ~20TB - database overhead & merkle roots
- The entire Twitter graph can be populated in a month with 1 MB/s of blockchain bandwidth



- private connections, posts & user data
    - see 4.2.2 Privacy (basically encrypted connections/actions and secrets shared/delegated to applications to operate on behalf of actor)
    even encrypted direct messaging could be implemented on top of this
    5.4.3 & 5.4.4
    https://unfinished.com/wp-content/uploads/dsnp_whitepaper.pdf
    - TODO: store off-chain?
    centralized connection graph is not incompatible with data pods as thought by in Solid, or Ceramic, etc.
        - can be stored & managed by ID managers
    - GDPR...
    https://matrix.org/~matthew/Response_to_-_Notes_on_privacy_and_data_collection_of_Matrix.pdf
    https://gitlab.com/libremonde-org/papers/research/privacy-matrix.org
    https://developer.litprotocol.com/docs/WhatIsLit/whatIsLitProtocol



muted keywords & preferences
https://twitter.com/AltcoinPsycho/status/1547203030185017344


-->
<div style="break-before: page; page-break-before: always;"></div><h1 id="content-addressing"><a class="header" href="#content-addressing">Content addressing</a></h1>
<p>The move from host-centric to data-centric addressing is a complete paradigm shift by itself but Headjack intertwines that with names and on-chain authorization &amp; sequencing of anchors resulting in the best possible <a href="https://en.wikipedia.org/wiki/Uniform_Resource_Identifier">URIs</a> in terms of human-readability &amp; persistence - perhaps the most important aspect of the project. This chapter is broken down into a few sub-chapters:</p>
<ol>
<li><a href="host_centric.html">Today's web: host-centric</a></li>
<li><a href="data_centric.html">Data-centric addressing</a></li>
<li><a href="blob_structure.html">Blob structure &amp; addressing</a></li>
<li><a href="uris.html">Persistent &amp; provable URIs</a></li>
<li><a href="names_and_paths.html">Names &amp; paths</a></li>
</ol>
<!--
handle redirects? twitter.com => twitter, so that all content URLs use twitter and the .com one is just used for convenience? or wtf?

shortcuts/links/references?

user nonces per application :( - or maybe no need? or needed only for signed messages?

Unexpirable URIs > unstoppable domains

what about URIs starting with block numbers? under a specific protocol schema?





content = "aaa"
URL = twitter.com/223/tommy/4

hash_content = hash(content) ==> 0xaf12ad7126
hash_URL = hash(URL) ==> 0x1627af2

hash_final = hash(hash_content + hash_URL) ==> 0x6617af0af122
URL_final = URL + hash_final ==> twitter.com/223/tommy/4/0x6617af0af122


-->
<div style="break-before: page; page-break-before: always;"></div><h1 id="todays-web-host-centric"><a class="header" href="#todays-web-host-centric">Today's web: host-centric</a></h1>
<p>Today's web revolves around hosts &amp; <a href="https://en.wikipedia.org/wiki/Unicast">unicast</a> communication - we query <a href="https://en.wikipedia.org/wiki/Domain_Name_System">DNS</a> to get the IP of servers and open direct connections with them to retrieve the data that they host. But domains, URI paths on servers &amp; the actual files all change &amp; go away which leads to <a href="https://en.wikipedia.org/wiki/Link_rot">link rot</a> &amp; content drift. Guidance such as <a href="https://www.w3.org/Provider/Style/URI">&quot;Cool URIs don't change&quot;</a> is just that - guidance - and the <a href="https://en.wikipedia.org/wiki/Internet_Archive">Internet Archive</a> is just a bandaid that can hardly keep up with the digital <a href="https://en.wikipedia.org/wiki/Memory_hole">memory hole</a>. In the host-certified paradigm URLs at best point to a location at which a document may have been available at a point in time - devoid of any cryptographic proofs regarding the contents, the creator, or the time of publication (as opposed to <a href="https://en.wikipedia.org/wiki/Self-authenticating_document">self-authenticating</a> data) and everything lives in <a href="https://en.wikipedia.org/wiki/Information_silo">silos</a> with no interoperability which severely limits the possible innovation and composability on the web and leads to fragmentation of the public discussion (if any). In fact <a href="https://a16z.com/2020/07/13/a16z-podcast-preserving-digital-history-how-to-close-the-webs-memory-hole/">&quot;more than 98% of the information on the web is lost within 20 years&quot;</a>.</p>
<blockquote>
<p>&quot;The problem is that the foundations are shifting sands, and we need something that has significantly more integrity at the bottom layer, we can't just bolt <a href="https://en.wikipedia.org/wiki/Uniform_Resource_Name">URNs</a> on as an afterthought. Some organizations are able to maintain persistent data over time, but it is in spite of the technology, not because of it.&quot; - <a href="https://news.ycombinator.com/item?id=27691442">tgbugs</a>.</p>
</blockquote>
<p>Information is fragile without an ecosystem of identity, reputation, references, context &amp; liability - our digital history lacks a solid foundation. We can't expect everyone to be like <a href="https://twitter.com/balajis">Balaji</a> - linking to articles from the Internet Archive (<a href="https://balajis.com/synthesis/">Example</a>: look what <code>&quot;Prussian&quot;</code> in that text is <a href="https://archive.ph/O2D45">pointing to</a>) - this doesn't scale, data is not self-authenticating and is still reliant on a central point of failure. The internet is a <a href="https://cyber.harvard.edu/sites/default/files/2019-06/2019-06_zittrainIP.pdf">collective hallucination</a> and is rotting.</p>
<blockquote>
<p>&quot;Society can’t understand itself if it can’t be honest with itself, and it can’t be honest with itself if it can only live in the present moment.&quot; - <a href="https://www.theatlantic.com/technology/archive/2021/06/the-internet-is-a-collective-hallucination/619320/">source</a></p>
</blockquote>
<blockquote>
<p>&quot;People tend to overlook the decay of the modern web, when in fact these numbers are extraordinary—they represent a comprehensive breakdown in the chain of custody for facts.&quot; - <a href="https://www.theatlantic.com/technology/archive/2021/06/the-internet-is-a-collective-hallucination/619320/">source</a></p>
</blockquote>
<blockquote>
<p>&quot;If a Pulitzer-finalist 34-part series of investigative journalism can vanish from the web, anything can.&quot; - <a href="https://www.theatlantic.com/technology/archive/2015/10/raiders-of-the-lost-web/409210/">source</a></p>
</blockquote>
<!-- 99.9% of content on the web is implicitly or explicitly contractually owned by platforms and host-certified - practically everything. -->
<div style="break-before: page; page-break-before: always;"></div><h1 id="data-centric-addressing"><a class="header" href="#data-centric-addressing">Data-centric addressing</a></h1>
<p><a href="https://en.wikipedia.org/wiki/Data-centric_computing">Data-centric computing</a> is an emerging concept that has relevance in information architecture and data center design - data is stored independently of the applications, which can be upgraded without costly and complicated data migration. This is a radical shift in information systems that will be needed to address organizational needs for storing, retrieving, moving, and processing exponentially growing data sets. It increases agility by prioritizing data transfer and data computation. Applications become short-lived, constantly added, updated, or removed as algorithms come and go.</p>
<blockquote>
<p>&quot;Data is the center of the universe; applications are ephemeral.&quot; - <a href="http://datacentricmanifesto.org/">The Data-Centric Manifesto</a></p>
</blockquote>
<hr />
<p><a href="https://en.wikipedia.org/wiki/Content-addressable_storage">Content-addressable storage</a> (CAS) is a way to store information so it can be retrieved based on its content (not its location/name) and is a key piece of the puzzle. Identifiers are based on content and any change to a data element will necessarily change its content address. The most famous example of CAS is <a href="https://en.wikipedia.org/wiki/InterPlanetary_File_System">IPFS</a> but it suffers from non-human-friendly addresses (hashes), performance issues, and extreme latency (tens of minutes) if content is not widely cached/pinned because of the global <a href="https://en.wikipedia.org/wiki/Distributed_hash_table">DHT</a>.</p>
<p><a href="https://en.wikipedia.org/wiki/Self-authenticating_document">Self-authenticating data</a> moves authority from hosts to users. The three components that enable it are <a href="https://en.wikipedia.org/wiki/Public-key_cryptography">cryptographic identifiers</a>, <a href="https://en.wikipedia.org/wiki/Content-addressable_storage">CAS</a>, and an emerging area of research called <a href="https://en.wikipedia.org/wiki/Verifiable_computing">verifiable computation</a> which is yet to be applied in any meaningful scale.</p>
<hr />
<p><a href="https://en.wikipedia.org/wiki/Information-centric_networking">Information-centric networking</a> (ICN) is an approach to evolving the Internet infrastructure away from a host-centric paradigm, based on perpetual connectivity and the <a href="https://en.wikipedia.org/wiki/End-to-end_principle">end-to-end principle</a>, to a network architecture in which the focal point is identified information (or content or data). Data becomes independent from location, application, storage, and means of transportation, enabling in-network caching and replication. The expected benefits are improved efficiency, better scalability with respect to information/bandwidth demand, and better robustness in challenging communication scenarios. In information-centric networking, the cache is a network-level solution, and it has rapidly changing cache states, higher request arrival rates, and smaller cache sizes.</p>
<hr />
<p><a href="https://en.wikipedia.org/wiki/Named_data_networking">Named Data Networking</a> (NDN) is a <a href="https://en.wikipedia.org/wiki/Future_Internet">Future Internet</a> architecture that builds on top of the previous ideas (&amp; an incarnation of ICN) and in which data is requested by name and routed by the network. However, there are many unsolved challenges with it like the need to reimplement foundational routing infrastructure to make it stateful and hierarchically structured names which require a root name authority to link them to keypairs - outside of its scope. Here's <a href="https://www.youtube.com/watch?v=oCZMoY3q2uM">a great lecture</a> on the topic.</p>
<h1 id="enter-headjack"><a class="header" href="#enter-headjack">Enter Headjack</a></h1>
<p>Headjack is a weird amalgamation inspired by everything above - it provides human-readable &amp; persistent <a href="https://en.wikipedia.org/wiki/Uniform_Resource_Identifier">URIs</a> for self-authenticating data (with <a href="https://medium.com/crypto-0-nite/merkle-proofs-explained-6dd429623dc5">Merkle proofs</a> &amp; the blockchain) along with the means for its retrieval without forcing a specific way (<a href="https://en.wikipedia.org/wiki/InterPlanetary_File_System">IPFS</a> is just one option). It acts as the web-scale global index used to check the authenticity of documents (requires consulting with the chain), ownership of names, key management &amp; sequence of events throughout time. It is an addressability layer on top of the current host-centric internet technologies.</p>
<!-- 
TODO: look at:

tls-n
Look at ct
Openid connect
Tos evidence extensions
Google amp - signed caches
Chainlink authenticated data origination
 -->
<div style="break-before: page; page-break-before: always;"></div><h1 id="blob-structure--addressing"><a class="header" href="#blob-structure--addressing">Blob structure &amp; addressing</a></h1>
<p>Applications accumulate off-chain activity from users which they cryptographically anchor in batches with a <a href="https://en.wikipedia.org/wiki/Merkle_tree">Merkle root</a> on-chain and they determine how often to do so (it doesn't have to be on every block) - those with little activity may submit only once per minute or even less often - the frequency is determined by applications based on the volume of activity and the on-chain publishing costs.</p>
<p>When enough activity has been collected it is time for the application to finalize the batch: it is packed in a blob and all the events generated since the last anchored batch are sorted &amp; grouped by accounts in some deterministic way (perhaps accounts based on index and actions based on the type/sequence) with some schema with the following steps:</p>
<ol>
<li>The intra-blob index (offset table) for lookup of content of specific accounts is generated.</li>
<li>A <a href="https://en.wikipedia.org/wiki/Merkle_tree">Merkle root</a> that touches every event is deterministically constructed following a schema.</li>
<li>The <a href="https://docs.ipfs.io/concepts/content-addressing/">IPFS CID</a> (hash) for the blob is generated and it is pinned for others to download.</li>
</ol>
<p>The only 2 things that are signed &amp; submitted on-chain are thus the Merkle root and the IPFS CID for the next nonce (auto-increment counter) associated with the application account.</p>
<img src="images/blob_structure.png">
<!-- <object width=100% data="images/blob_structure.svg"></object> -->
<h1 id="stable-intra-blob-addressing-before-publishing"><a class="header" href="#stable-intra-blob-addressing-before-publishing">Stable intra-blob addressing before publishing</a></h1>
<p>Applications maintain the logical order of events for the future batch in maps in order to provide intra-blob addressing even before it is fully constructed - as an example if a user posts an article and immediately after that comments on their own post - the comment should be able to refer to the post which is not yet committed on-chain. Applications will also display activity by other accounts that is not yet anchored and the interactions can still use the proper addressing when referring to the yet-to-be-anchored messages (the next nonce number is known in advance). Any type of interaction is addressable and sequenced in the blobs - including reactions (likes, etc).</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="persistent--provable-uris"><a class="header" href="#persistent--provable-uris">Persistent &amp; provable <a href="https://en.wikipedia.org/wiki/Uniform_Resource_Identifier">URIs</a></a></h1>
<p>Each account has an associated auto-increment counter (nonce) for every time they submit an anchor for off-chain content. So if an application has submitted 2 times already, then the next submission will be with <code>nonce == 3</code>. The blockchain keeps a mapping in its state for each previous nonce value to the block number when it changed so that <code>&lt;application_id&gt;/&lt;nonce&gt;</code> can be translated to which block has the Merkle root anchor &amp; <a href="https://docs.ipfs.io/concepts/content-addressing/">IPFS CID</a> for the blob that corresponds to that nonce for that account.</p>
<!-- The 2 can be extracted from the block. -->
<img src="images/blob_URI.png">
<p>Once a blob is fetched through the <a href="https://docs.ipfs.io/concepts/content-addressing/">IPFS CID</a> (hash) we can address specific events by using the offset index in the blob header so a URI like <code>&lt;application_id&gt;/&lt;nonce&gt;/&lt;user_id&gt;/&lt;content_id&gt;</code> can point to a specific post, comment or even reaction (activity is grouped by users). The content ID for a specific user is usually a small single-digit number and is necessary only if there has been more than 1 interaction by that user through that application for the given nonce (maybe rare). This is what events with URIs referring to each other looks like:</p>
<img src="images/content_references.png">
<p>The blockchain can be queried if the application was allowed to post content on behalf of the user with an on-chain authorization (which probably happened through an <a href="IDM.html">IDM</a>) when that specific block was published in order to determine if the activity is authentic - the state keeps information for each account such as since what block number a given application was authorized to post on behalf of a user (and until when - all ranges). Users may avoid using IDMs and explicitly sign their actions in which case their data will be accompanied by signatures within the data blobs and the only check required will be for the user keypair used for the specific block number.</p>
<h1 id="steps-to-prove-the-authenticity-of-a-uri"><a class="header" href="#steps-to-prove-the-authenticity-of-a-uri">Steps to prove the authenticity of a URI</a></h1>
<p>To recap - to prove the authenticity of any event with a URI:</p>
<ul>
<li>First check if the data is actually part of an anchored blob with a <a href="https://medium.com/crypto-0-nite/merkle-proofs-explained-6dd429623dc5">Merkle proof</a> to a block. This requires either just the piece of data + a Merkle proof for inclusion in the blob or the entire blob in order to reconstruct the Merkle tree &amp; proof.</li>
<li>Then check if the user actually submitted the event:
<ul>
<li>Either if at that point the application was authorized to post on behalf of the user which would require a Merkle proof for a part of the blockchain state (authorization ranges).</li>
<li>Or by checking for an explicit signature &amp; the public key of that account at that time which would also require a Merkle proof for a part of the blockchain state (account key history).</li>
</ul>
</li>
</ul>
<p>This is what makes URIs persistent - as long as someone hosts either the content + the Merkle proof or the entire blob and knows in which block it was anchored (from the <code>&lt;application_id&gt;/&lt;nonce&gt;</code> =&gt; <code>&lt;block_number&gt;</code> mapping). The <a href="names_and_paths.html">following chapter</a> shows how names in the URI paths are persistent too (even if user/application names change ownership at some point).</p>
<h1 id="a-few-other-notes"><a class="header" href="#a-few-other-notes">A few other notes</a></h1>
<ul>
<li>There can be many different &amp; valid proofs for the same URI from different block heights.</li>
<li>Even private <a href="https://en.wikipedia.org/wiki/Intranet">intranet</a> data may be anchored but not retrievable by the public if the blob IPFS CID is never published or pinned/hosted - unified addressing for public &amp; private.</li>
<li>Users should be able to see the URI of content even if created through another application and the origin should be displayed by default - acting as <a href="business_models.html">attribution for other applications</a>.</li>
<li>Edits &amp; updates to content come as <a href="messages.html">messages</a> with new unique URIs that reference the older message URIs and it is up to applications to properly handle this - either by showing that there have been changes and a newer version or automatically redirect to the latest. &quot;Forks&quot; are possible but they represent application failure to detect that an old version is being edited.</li>
</ul>
<!--
# On proof permanence

One thing to consider is if a user revokes the authorization of an application to post on their behalf retroactively - not just going forward but also invalidating all anchored content & follow/unfollow events for the last couple of days through that application. This would mean that cached Merkle proofs for such invalidated content will no longer be valid and the latest state of the blockchain will refuse to produce new such proofs, but the cached proofs could mislead someone. Retroactive revocation can happen only up to `X` days to limit the scope of changes to cached proofs & what infrastructure would need to handle but still give enough time for anyone to react in case an application has posted fraudulent activity on their behalf - a **mostly theoretical concern**. Proofs for blocks older than `X` days are therefore considered permanent.
--><div style="break-before: page; page-break-before: always;"></div><h1 id="names--paths"><a class="header" href="#names--paths">Names &amp; paths</a></h1>
<p>Headjack is also a name registry - accounts can own a handle and be identified with it. There have been other attempts to decentralize <a href="https://en.wikipedia.org/wiki/Domain_Name_System">DNS</a> such as <a href="https://en.wikipedia.org/wiki/Namecoin">Namecoin</a> and <a href="https://handshake.org/">Handshake</a> but a much stronger network effect is necessary in order to succeed. Headjack is a confluence of multiple interrelated things (identity, names, authorization &amp; addressing) and has the potential to truly decentralize DNS. For specifics around the details (constraints, subdomains, auctions, distribution, hoarding, leasing, etc.) please refer to <a href="handles.html">their dedicated page</a>.</p>
<hr />
<p>Users and applications don't need a name and can operate as an integer index just fine, but the preferred case will be with handles. Names can change ownership but the blockchain will be able to translate <code>&lt;application_name&gt;/&lt;nonce&gt;/&lt;user_name&gt;/&lt;content_id&gt;</code> with strings into the canonical integer form discussed <a href="uris.html">previously</a> by substituting the application &amp; user names with account IDs.</p>
<p>Every name has an associated auto-increment nonce (just like account IDs) for every time they submit an anchor for off-chain content and the blockchain records maps of <code>&lt;name&gt;/&lt;nonce&gt;</code> to <code>&lt;id&gt;/&lt;nonce&gt;</code> which can then be used to resolve the URI as discussed in the <a href="uris.html">previous chapter</a>.</p>
<img src="images/account_name_state.png">
<p>But we need to be able to translate not just the application name but also the user name which may have changed ownership at any point - for that the blockchain keeps track of the account ID ownership of every name historically as ranges (from block X to block Y name N was owned by account A) so when we determine the block number for a given data blob we'd be able to check to which account ID does a name in a URI correspond to at that time.</p>
<!-- Alternatively the user name <=> account ID mapping at the time of the blob could be embedded within the blob header (along with proofs) so that fewer queries are necessary to the blockchain. -->
<p>And thus we're able to have URIs such as <code>twitter.com/55212/johnny/3</code> to identify any event by any actor - all we'd need to do is a few lookups and we'll be able to use Merkle proofs for any piece of content to prove authenticity. Most URIs could even omit the 4th part because probably there won't be more than 1 action by a user for a given batch by an application.</p>
<p>Note that the canonical form (numbers instead of names) of <code>twitter.com/55212/johnny/3</code> could be something like <code>42/783/523/3</code> where only the last number would be the same and the nonce would most likely be different. Also <code>twitter.com</code> might no longer be owned by account <code>42</code> but what matters is that the blockchain can correctly determine who owned it at nonce <code>55212</code>. Multiple names can be owned by an account but their nonces for one event will probably be different.</p>
<h1 id="what-to-ask-the-blockchain-about-a-uri"><a class="header" href="#what-to-ask-the-blockchain-about-a-uri">What to ask the blockchain about a URI</a></h1>
<p>To recap: we can ask the following questions about this URI: <code>twitter.com/55212/johnny/3</code>:</p>
<ol>
<li>To which application account ID &amp; nonce does <code>twitter.com/55212</code> correspond?</li>
<li>To which block does the applicationID/nonce map correspond?</li>
<li>What is the <a href="https://docs.ipfs.io/concepts/content-addressing/">IPFS CID</a> &amp; Merkle root of the anchored blob at that block?</li>
<li>What account ID does <code>johnny</code> correspond to in the block where this blob was anchored?</li>
<li>Once we download the blob or just the blob header (using the IPFS CID or any other means):
<ol>
<li>We can ask the offset table where within the blob is <code>johnny</code>'s content № <code>3</code>?</li>
<li>Once we fetch the actual data &amp; depending on whether it is explicitly signed or not:
<ol>
<li>either if the application was authorized to post on behalf of <code>johnny</code> at that time,</li>
<li>or if the signature matches the keypair that's been bound to <code>johnny</code>'s account at the time of the anchored block.</li>
</ol>
</li>
</ol>
</li>
</ol>
<h1 id="web3-uris-interoperable-in-web2"><a class="header" href="#web3-uris-interoperable-in-web2">Web3 URIs interoperable in Web2</a></h1>
<p>Application accounts can point on-chain to a host with an IP address which can be used to display content published through them. Application names can also resemble traditional domain names so it will be possible to copy-paste such URIs directly into your browser and as long as they own the same domain in the traditional <a href="https://en.wikipedia.org/wiki/Domain_Name_System">DNS</a> they should be able to serve a webpage displaying the piece of content - enabling seamless interoperability during the transition from one paradigm to the other.</p>
<h1 id="content-titles-in-uris"><a class="header" href="#content-titles-in-uris">Content titles in URIs</a></h1>
<p>Most Web3 platforms <a href="https://twitter.com/hasufl/status/1537388439259291649">suffer from unreadable URIs</a> but we've done a lot better - note the brevity and lack of hashes &amp; hexadecimal symbols (<code>0xf56a0...</code>) - in fact, this is as good as it gets...</p>
<p><strong>Or is it?!</strong> What about headlines of articles - can we have them included as well - something like <code>twitter.com/55212/johnny/3/how-I-went-from-vegan-to-keto-and-back-again</code>? Absolutely! The string is not at all necessary to resolve the piece of content (just like in StackOverflow where the database key for a question is just a number (example: <a href="https://stackoverflow.com/questions/4">question 4</a>) but the page router always changes the URL when loading the page to include the title too). <a href="messages.html">Message types</a> for posts with titles will have a dedicated field which will get included in the content hash and thus spoofing the title will be rejected by conforming applications as it would be a trivial check.</p>
<h1 id="addressing-within-content"><a class="header" href="#addressing-within-content">Addressing within content</a></h1>
<p>Different schemas could be used for addressing within pieces of content (like a paragraph from an article or a clip from audio/video - without losing the context of the whole) and message types could have by default associated on-chain schemas (or the schema of choice could be embedded within the header of the message). For example, when <code>medium.com/12475/elvis/0/learn-to-code/121/66</code> is being loaded the associated schema will be looked up depending on the type of message (in this case - an article) and used to interpret the last part (<code>121/66</code>) which could mean a character selection with an offset from the start and length. The embedded schema could be overridden by explicitly stating which one to use within the URI. As an example, <code>medium.com/12475/elvis/0/learn-to-code/schema/42/121/187</code> could mean <code>&quot;use on-chain schema number 42&quot;</code> which could interpret the last part (<code>121/187</code>) as start offset and end offset instead of start &amp; length - resulting in the same selection as before. Even <a href="https://twitter.com/dwr/status/1544001073844731904">individual pages &amp; paragraphs of books</a> should be referencable in such a manner and could be composed of multiple separate posts - and this is just scratching the surface!</p>
<p>For big types of content (audio/video) the message could be broken down into chunks so that users can load only the message header and then depending on the schema used and the addressing within the content - only the necessary chunks could be requested.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="storage--retrievability-of-data"><a class="header" href="#storage--retrievability-of-data">Storage &amp; retrievability of data</a></h1>
<p>Off-chain blobs with data will be fetched, processed and stored immediately after they are published in more optimal database formats for content to be later directly served by application infrastructure. Most of the cryptography checks will be happening instantly during this process but the proofs don't need to be stored. Users will always be able to request proofs for any event at any time (&amp; cache them locally) because they can be regenerated on the fly as necessary.</p>
<h1 id="hierarchical-data-blobs--partial-fetches"><a class="header" href="#hierarchical-data-blobs--partial-fetches">Hierarchical data blobs &amp; partial fetches</a></h1>
<p>Blobs may be in a hierarchy such that the on-chain IPFS hash points only to the &quot;root&quot; blob that contains the header and the actual indexed data could be in child IPFS blobs (whose <a href="https://docs.ipfs.io/concepts/content-addressing/">IPFS CIDs</a> are contained in the root blob or header) so entities listening for events by specific accounts on Headjack may download only these headers and determine which &quot;leaf&quot; blobs they need to fetch for the data they are interested in (if any).</p>
<img src="images/root_child_blob_separation.png">
<h1 id="direct-ipfs-connections--horizontal-scaling"><a class="header" href="#direct-ipfs-connections--horizontal-scaling">Direct IPFS connections &amp; horizontal scaling</a></h1>
<p>Applications can advertise the multiaddress of their IPFS nodes on-chain so that each blob of content that gets published can be downloaded by others instantly by manually connecting with IPFS’s <a href="https://medium.com/pinata/speeding-up-ipfs-pinning-through-swarm-connections-b509b1471986">“swarm connect” functionality</a> - avoiding the use of the <a href="https://en.wikipedia.org/wiki/Distributed_hash_table">DHT</a> for each new blob CID which may take tens of minutes. They can provide addresses to multiple IPFS nodes as a cluster for horizontal scaling and use <a href="https://ipfscluster.io/">Pinset orchestration</a> - designed for Automated data availability and redundancy.</p>
<p>Applications may choose not to use IPFS at all - what they must do is anchor their blobs with a Merkle root and provide some on-chain advertised means to retrieve the data (example: REST/RPC endpoints in their on-chain account). We expect that IPFS will be the lowest common denominator and will always be used no matter what other solutions are also available.</p>
<h1 id="sharing-data-before-anchoring-it"><a class="header" href="#sharing-data-before-anchoring-it">Sharing data before anchoring it</a></h1>
<p>Applications can talk to each other directly by using their on-chain advertised REST/RPC endpoints and may ask for the events &amp; messages that are not yet published by the other applications. This way they could display &quot;remote&quot; events locally while they are still in the &quot;mempool&quot; and allow their own users to interact with those events from other applications. This is possible because URIs are stable even before publication - see <a href="blob_structure.html#stable-intra-blob-addressing-before-publishing">Stable intra-blob addressing before publishing</a>. High activity applications can interoperate and no longer be a slave to the block time. However:</p>
<ul>
<li>Applications should display events that are not yet anchored in the UI differently - especially if coming from another application.</li>
<li>Events that refer to each other but are from different applications and have not yet been anchored on-chain could end up committed in the wrong order (if one of the applications skips a few blocks and commits at a later one) - such that an event from the past is referring to an event from the future. However, <a href="messages.html">messages</a> will have a timestamp field and could also have the current block height at the time of creation which could be used for sorting data.</li>
</ul>
<h1 id="how-to-retrieve-data-for-a-random-uri"><a class="header" href="#how-to-retrieve-data-for-a-random-uri">How to retrieve data for a random URI</a></h1>
<p>There are multiple options:</p>
<ul>
<li>The entire original blob with an <a href="https://docs.ipfs.io/concepts/content-addressing/">IPFS CID</a> might still be retrievable from the original application account that posted it or anyone else that has pinned the data.</li>
<li>The user account might be using an archival service for all their activity and they can point to that archival service on-chain in their account for others to retrieve their messages.</li>
<li>Other well-known players without a direct on-chain connection to the application/user in a URI could be asked if they have the content:
<ul>
<li>Infrastructure companies that do the heavy lifting for applications and store everything.</li>
<li>The analog of the <a href="https://en.wikipedia.org/wiki/Internet_Archive">Internet Archive</a> in this ecosystem that also stores everything.</li>
</ul>
</li>
<li>IPFS can be forked &amp; reused with the following change: instead of delivering content based on the <a href="https://docs.ipfs.tech/concepts/content-addressing/">CID</a> hash it can deliver the data + the necessary proofs based on Headjack URIs or their hash (they are unique) - any individual off-chain message that's been anchored would be retrievable as long as someone is hosting it in this p2p network (which needs bootstrapping - could be part of Headjack nodes). However, this won't be very performant due to the granular nature of individual messages with a URI and the use of a global <a href="https://en.wikipedia.org/wiki/Distributed_hash_table">DHT</a>.</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="web-scale--ux"><a class="header" href="#web-scale--ux">Web-scale &amp; UX</a></h1>
<p>People grossly underestimate the size of the web and the type of infrastructure that's required - what is going on within a single minute of 2021 is <a href="https://www.techspot.com/news/91513-visualizing-minute-internet-2021.html"><ins>truly mind-boggling</ins></a> (this is an incomplete picture).</p>
<img src="images/web_scale_techspot.webp">
<!-- <img src="https://static.techspot.com/images2/news/bigimage/2021/09/2021-09-30-image-32-j.webp"> -->
<!-- infographic generated from these guys:
https://www.domo.com/learn/infographic/data-never-sleeps-9 -->
<p>Here are some <a href="https://www.internetlivestats.com/twitter-statistics/">twitter</a>, <a href="https://www.internetlivestats.com/google-search-statistics/">google</a> and <a href="https://www.internetlivestats.com/">other</a> statistics from a <strong>decade</strong> ago. A peek behind what it takes to run Twitter is a good case in point: <a href="http://highscalability.com/blog/2009/10/13/why-are-facebook-digg-and-twitter-so-hard-to-scale.html">1</a>, <a href="http://highscalability.com/blog/2013/7/8/the-architecture-twitter-uses-to-deal-with-150m-active-users.html">2</a>, <a href="https://blog.twitter.com/engineering/en_us/topics/infrastructure/2016/the-infrastructure-behind-twitter-efficiency-and-optimization">3</a>, <a href="https://blog.twitter.com/engineering/en_us/topics/infrastructure/2017/the-infrastructure-behind-twitter-scale">4</a>, <a href="https://blog.twitter.com/engineering/en_us/topics/infrastructure/2021/processing-billions-of-events-in-real-time-at-twitter-">5</a>. All of this infrastructure is not just about handling enormous amounts of data but also about great UX &amp; responsiveness: <code>&quot;Latency is not an option anymore&quot;</code> - Amazon <a href="https://www.gigaspaces.com/blog/amazon-found-every-100ms-of-latency-cost-them-1-in-sales">found</a> that every 100ms of latency cost them 1% in sales. Google <a href="http://glinden.blogspot.com/2006/11/marissa-mayer-at-web-20.html">found</a> an extra 500ms in search page generation time dropped traffic by 20% - 16 years ago - our irritable nature probably hasn't changed.</p>
<img src="images/meme_web2_web3.jpg" align="right" style="margin-left: 8px; width: 40%">
<p>It is highly improbable that the masses (and even most crypto natives) would tolerate services that are much worse (slow, limited &amp; cumbersome) and <a href="competition.html">most of the competing attempts for decentralizing media</a> are nowhere close. We need to be realistic and focus on the essence - Headjack decentralizes only the most important part of monopolies - identity - and thus leveling the playing field for competition. It accomplishes this by avoiding the need for keypairs &amp; signatures by default through an on-chain authorization mechanism while maintaining the optionality for anyone to be fully self-sovereign &amp; explicit - acting as a base layer for competing &amp; interoperable services. It also facilitates data-centric addressing of content under a global namespace which further disincentivizes hoarding data in silos. But Web2 isn't going anywhere - <a href="https://moxie.org/2022/01/07/web3-first-impressions.html"><code>&quot;market dynamics and the fundamental forces of centralization&quot;</code></a> dictate that the best services will be running on huge server racks in data centers with sophisticated caches &amp; batch processing infrastructure behind familiar UX. The difference will be that users will be able to cryptographically prove content and will be able to leave any of these applications for better ones if their offering degrades.</p>
<p>Anyone would still be able to run software locally, browse the ecosystem, and fetch content &amp; interactions from entities they've subscribed to (although quite bandwidth-intensive), but their experience will be extremely limited in that they won't be able to run any sort of query/filtration/feed algorithm at scale nor aggregate the activity of billions of people in real-time.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="throughput-numbers-scaling"><a class="header" href="#throughput-numbers-scaling">Throughput numbers (scaling)</a></h1>
<p>Everyone claims to be scalable, but here we'll prove that Headjack can handle billions of accounts and anchor unlimited amounts of off-chain content tied to identity with simple napkin math.</p>
<!-- measuring performance, throughput & latency is hard but here we will provide a simplistic view
https://a16zcrypto.com/why-blockchain-performance-is-hard-to-measure/ -->
<!-- We believe a credible path to billions and worldwide adoption is necessary as part of the story -->
<h1 id="how-big-is-a-headjack-transaction"><a class="header" href="#how-big-is-a-headjack-transaction">How big is a Headjack transaction</a></h1>
<p>Applications post anchors to off-chain content with an IPFS CID hash and a merkle root. IDMs also anchor off-chain content (mainly user preferences &amp; updates to social graph), but they also post authorizations to other accounts (applications) to post on behalf of users as integer pairs.</p>
<p>So the fields for a transaction by an application/IDM (which will be the majority) are:</p>
<ul>
<li>version: <code>4 bytes</code></li>
<li>signature: <a href="https://ethvigil.com/docs/eth_sign_example_code/#recovering-the-message-signer-in-the-smart-contract"><code>65 bytes</code></a></li>
<li>blob IPFS address: <a href="https://proto.school/anatomy-of-a-cid/01"><code>32 bytes</code></a></li>
<li>blob merkle root: <a href="https://www.mycryptopedia.com/merkle-tree-merkle-root-explained/"><code>32 bytes</code></a></li>
<li>nonce: <code>4 bytes</code> auto-increment integer associated with the account - to prevent reordering of anchored off-chain blobs (which would mess up internal addressing based on that nonce)</li>
<li>value: <code>4 bytes</code> amount of native token paid to validators for transaction inclusion</li>
</ul>
<p>So far that is <code>141 bytes</code> which almost every transaction by an application or IDM contains. IDMs also submit a list of authorizations (or revocations) as integer pairs. For example, 1000 accounts authorizing 15 different applications to post on their behalf would be 1000 integer pairs. Assuming 8 byte integers (up to 2^64) that would be 8 * 2 * 1000 = 16k bytes.</p>
<h1 id="naive-scenario"><a class="header" href="#naive-scenario">Naive scenario</a></h1>
<p>The initial version will target block bandwidth of up to 100 kb/s. This is not a problem for <a href="https://twitter.com/eshita/status/1546911451125649408">validium ZK rollups</a> as there are already DA solutions that offer <a href="https://twitter.com/apolynya/status/1517137629334056960">10 mb/s or even much more</a>.</p>
<p>Assuming:</p>
<ul>
<li>1 MB block size &amp; 10 second block time (100 kb/s of block bandwidth)</li>
<li>1000 applications posting in every block</li>
<li>100 IDMs authorizing as much users as possible - filling the remaining block space</li>
<li>no on-chain actions such as keypair &amp; name changes, account creation &amp; direct interaction with the chain by end users</li>
</ul>
<p>We get:</p>
<ul>
<li>1100 actors (1000 applications + 100 IDMs) that post in every block at least <code>141</code> bytes for their transactions, which is <code>155100</code> bytes</li>
<li>the remaining <code>893476</code> bytes (1048576 (1MB) - 155100) can be filled with authorizations and since an authorization is <code>16</code> bytes (8 * 2) that would be 55842 authorizations/revocations every 10 seconds or 5584 authorizations/revocations per second</li>
<li>for 1 billion accounts that would be 0.557 authorizations/revocations per person per day which is actually quite good - people on average do way less <a href="https://en.wikipedia.org/wiki/Single_sign-on">single sign-ons</a> per day</li>
</ul>
<table><thead><tr><th>completely different goals - comparing the 2 protocols just to put things into perspective</th><th>Headjack</th><th>Ethereum</th></tr></thead><tbody>
<tr><td>block size</td><td>1 MB</td><td><a href="https://etherscan.io/chart/blocksize"> ~80 kb </a></td></tr>
<tr><td>block time</td><td>10 seconds</td><td><a href="https://ycharts.com/indicators/ethereum_average_block_time"> ~13 seconds </a></td></tr>
<tr><td>blockchain bandwidth per second</td><td>100 kb/s (x16 more than Ethereum)</td><td>~6.15 kb/s</td></tr>
<tr><td>blockchain bandwidth per day</td><td>8640 mb/d</td><td>~528 mb/d</td></tr>
<tr><td>transactions/authorizations per second</td><td>5584 APS</td><td><a href="https://blockchair.com/ethereum/charts/transactions-per-second"> ~14 TPS </a></td></tr>
<tr><td>transactions/authorizations per day</td><td>482,457,600 APS</td><td>1,209,600</td></tr>
<tr><td>transactions/authorizations per person per day for 1 billion accounts</td><td>0.482 (x400 more than Ethereum)</td><td>0.0012096</td></tr>
</tbody></table>
<!-- Ethereum
- transactions per block: ~180
- single transaction size on average including calldata: 300-700 bytes -->
<h1 id="realistic-scenario"><a class="header" href="#realistic-scenario">Realistic scenario</a></h1>
<p>The naive scenario does not include on-chain actions for specific accounts such as:</p>
<ul>
<li>keypair changes (new pubkey (32 bytes) + signature (65 bytes) if there is an older key)</li>
<li>account creation (if done by an IDM then this is just a few bytes - no pubkey)</li>
<li>name registration &amp; ownership changes (see the <a href="handles.html">dedicated page</a> for more details)</li>
<li>updating account fields such as a URI pointing towards an off-chain account directory (which could point to archived posts) or pointing to another account index for such services</li>
<li>signed transactions by individual accounts that want to directly interact with the chain
<ul>
<li>authorizing an IDM, rotating keys, or even publishing off-chain content as an application</li>
</ul>
</li>
</ul>
<p>However, the realistic scenario will not be far from the naive because:</p>
<ul>
<li>Only a % of all accounts will have keypairs (even though 100% could) and will make just a few signed actions per year - leaving most block throughput for authorizations through IDMs.</li>
<li>Large % of accounts will rarely even be authorizing new applications - many people don't sign in to new services through <a href="https://en.wikipedia.org/wiki/Single_sign-on">SSO</a> every single day. There could also be 2 types of log-ins: passive (viewing only - nothing on-chain) and authorized (allowing services to post on behalf of users).</li>
<li>Many applications that don't generate a lot of off-chain activity will publish less often than on every block in order to minimize on-chain block space costs.</li>
<li>The chain throughput can be further optimized &amp; scaled by multiple orders of magnitude.</li>
</ul>
<h1 id="optimizations--scaling"><a class="header" href="#optimizations--scaling">Optimizations &amp; scaling</a></h1>
<ul>
<li>Throughput of 100 kb/s is just the start &amp; can easily go to 1-10 mb/s as a ZK rollup.</li>
<li>The chain &amp; state can be trivially sharded - there aren't problems such as fracturing liquidity or preventing composability because accounts don't care about each other - they mostly contain authorization block numbers &amp; keypair history.</li>
<li>Integer indexes that only need 4 bytes can be compressed/batched together - it'll take many years to go beyond 4 billion accounts so the actual throughput is <strong>2x</strong> of what is listed here.</li>
<li>A fee market can develop that tunes the cost of different actions so that actors don't just pay for on-chain bytes - the ways the system is used can be guided through incentives.</li>
<li>Other optimizations not listed here - this is just the starting point.</li>
</ul>
<h1 id="state-growth"><a class="header" href="#state-growth">State growth</a></h1>
<p>Headjack's main value proposition is keeping historical records of the sequence of authorizations, key changes &amp; off-chain content anchors and being able to generate proofs for any specific piece of off-chain content.</p>
<p>TODO: finish this</p>
<p>https://ethereum.stackexchange.com/questions/268/ethereum-block-architecture</p>
<p>numbers - state - one difference from other cryptos is that this one is append-only and could be designed to be easier on memory access patterns</p>
<p>One difference with other blockchains is that accounts in Headjack are numbers and thus the state tree could be different.</p>
<p>All on-chain changes just append data to one of the few attributes of:</p>
<ul>
<li>accounts:
<ul>
<li>public keys: a map of keys and block height integer ranges (non-overlapping)<!-- - could be a different data structure -->
</li>
<li>authorizations: a map of indexes and arrays of block height integer ranges</li>
<li>nonces: an array that maps autoincrement indexes to block numbers
<ul>
<li>appended only when publishing off-chain content (usually an application/IDM)</li>
</ul>
</li>
</ul>
</li>
<li>names:
<ul>
<li>owners: a map of owner indexes and block height integer ranges (non-overlapping)</li>
<li>nonces: an array that maps autoincrement indexes to account index &amp; nonce pairs
<ul>
<li>appended only when publishing off-chain content (usually an application/IDM)</li>
</ul>
</li>
</ul>
</li>
</ul>
<p>TODO: should IPFS hashes &amp; merkle roots be saved in the state?
- no?</p>
<img src="images/account_name_state.png">
<!-- 

The growth of the chain and the state will differ by a few things:


One difference between Headjack and financial blockchains is that they don't force historical records into the state whereas that is the main value proposition of Headjack.



This is a solution that is provably possible and better and can only get better in time with further innovation and scaling


The goal is to avoid congestion and provide enough bandwidth in a predictable way for web scale



This could be a concern when Headjack takes over the world - if blocks are 10 mb once every 10 seconds the chain would grow by 86 gb/day. However, 

The processing of the state machine is minimal - orders of magnitude less complexity & compute compared to generalized smart contract platforms

The state growth will be slower than the blockchain growth because:

- an on-chain authorization is a pair of integers while only 1 integer goes into the state


goal: no congestion


a tiny core on which we have consensus can be used to cryptographically anchor & link unlimited amounts of data - the entire web - a few terabytes (tiny is relative - compared to the data) of materialized blockchain state including the absolute bare minimum of historic.

- state doesn't need to store the merkle roots & IPFS hashes - merkle proofs can contain block numbers & block hashes -->
<p>TODO: light clients? in addition to merkle proofs for inclusion of content they would need merkle proofs for the state of which applications a user has authorized to post on their behalf in a given block</p>
<!-- 

Reducing merkle proof sizes with Verkle Tries
"It’s a constant size proof regardless of the width."
https://members.delphidigital.io/reports/the-hitchhikers-guide-to-ethereum
Guide to the Ethereum Roadmap | Jon Charbonneau of Delphi Digital
https://www.youtube.com/watch?v=xuLyZaty9iI
vector commitments (Merkle proofs)
https://blog.ethereum.org/2021/12/02/verkle-tree-structure/
https://www.youtube.com/watch?v=RGJOQHzg3UQ
https://vitalik.ca/general/2021/06/18/verkle.html
 -->
<h1 id="off-chain-content"><a class="header" href="#off-chain-content">Off-chain content</a></h1>
<p>There are no limits for off-chain content as it is all just anchored with merkle roots - it could be as high as hundreds of terabytes per second. There isn't a more minimal design that can link unbounded amounts of off-chain data to billions of identities that can change keys &amp; names and yet still provide the guarantees &amp; mental model simplicity of Headjack - it achieves consensus on the absolute bare minimum.</p>
<!-- validium

This design for a specialized blockchain can scale practically as much as necessary due to the compactness of service messages and the triviality of sharding the blockchain as there would be close to 0 cross-shard communication (`"X follows Y"` only affects `X`) and that is [provable with easy to grasp napkin math](numbers.md).

data availability guarantees don't need to be as strong as for finance - it won't be fatal to revert a few blocks of activity if data is unavailable -->
<!--
If handles are permanent to shards then their allocation to shards can be managed in the beacon chain and it can be consulted when following urls to content - so that the shard idx doesn't have to be in the urls
--><div style="break-before: page; page-break-before: always;"></div><h1 id="headjack-vs-the-competition"><a class="header" href="#headjack-vs-the-competition">Headjack vs the competition</a></h1>
<p>This chapter focuses only on the disadvantages of some of the more high-profile competing solutions in the space when compared to Headjack and doesn't list any of their positives as it would be too long (so not exhaustive by any means) but many of them have served as an inspiration for Headjack in one way or another. Corrections for any inaccuracies are welcome!</p>
<h1 id="what-others-get-wrong"><a class="header" href="#what-others-get-wrong">What others get wrong</a></h1>
<p>A list of problems with the contenders in the decentralized identity/media space:</p>
<ul>
<li>
<p>No credible path to <a href="web_scale.html">web-scale</a> - some will hit a wall even at 1 million users. Most are vague around their scalability &amp; data structures and don't put it <a href="numbers.html">front and center</a> - obfuscating the most important bit. Instead of focusing on NFTs &amp; developer APIs, start with the data and work up from that. Fake it till you make it is not a viable strategy with the wrong foundation.</p>
</li>
<li>
<p>Complexity &amp; lack of clarity - distributed systems engineers should easily figure out how they work &amp; what the limitations are. Why build on something that others are probably having a hard time understanding as well and may not be around in the future?</p>
<ul>
<li>
<blockquote>
<p>&quot;Developers care about risk.&quot; - <a href="https://haseebq.com/why-decentralization-isnt-as-important-as-you-think/">Haseeb</a></p>
</blockquote>
</li>
</ul>
</li>
<li>
<p>Too financialized &amp; trying to do too much - profiles &amp; posts as NFTs, microtransactions, marketplaces, fan coins, tipping, content creator incentives.</p>
<ul>
<li>
<blockquote>
<p>&quot;However, a downside I’ve observed in social networks where content is monetized is that user behavior becomes transparently driven by monetary incentives in ways that feel less genuine. This applies to influencer culture on Instagram as well, but cryptocurrency social networks bake it in from the start.&quot; - <a href="https://medium.com/decentralized-web/blockchain-social-networks-c941fb337970">Jay Gerber</a></p>
</blockquote>
</li>
</ul>
</li>
<li>
<p>Users shouldn't need to use a token, use a wallet, or self-host to benefit from decentralized identity &amp; an open social graph. Most people will always use custodial services.</p>
<ul>
<li>
<blockquote>
<p>&quot;People don’t want to run their own servers, and never will.&quot; - <a href="https://moxie.org/2022/01/07/web3-first-impressions.html">Moxie</a></p>
</blockquote>
</li>
</ul>
</li>
<li>
<p>Linking online identity to public financial accounts on Ethereum/Solana/etc will have unintended consequences - a bad default.</p>
</li>
<li>
<p>Federated ones lack <a href="https://medium.com/@VitalikButerin/the-meaning-of-decentralization-a0c92b76a274">logical centralization</a> which leads to fragmentation and <a href="https://github.com/mastodon/mastodon/issues/9529">no discoverability</a>.</p>
</li>
<li>
<p>Some are solving just identity &amp; the graph - without easy &amp; persistent <a href="addressing.html">content addressing</a>.</p>
</li>
<li>
<p>Social media is about aggregated views at scale - not p2p and direct comms.</p>
<ul>
<li>
<blockquote>
<p>&quot;The emphasis of a social network is on &quot;propagation&quot; aka, propaganda.&quot; - <a href="https://news.ycombinator.com/item?id=25735773">didibus</a></p>
</blockquote>
</li>
</ul>
</li>
<li>
<p>Some use chains such as Ethereum for <a href="https://medium.com/@VitalikButerin/the-meaning-of-decentralization-a0c92b76a274">logical centralization</a> &amp; store vector commitments (Merkle roots) for events around <a href="https://blog.ceramic.network/key-revocation-in-self-certifying-protocols/">key management</a> (rotations, authorizations, sessions &amp; revocations) but the data availability problem for whatever is committed is unsolved.</p>
<ul>
<li>The complexity is not encapsulated - there are many open questions, edge cases &amp; failure scenarios and it would inevitably lead to assumptions &amp; trust.</li>
</ul>
<!-- - Many focus just on the latest keypairs and don't sequence the signed actions throughout time  - much harder to prove that content generated with an older keypair was indeed legitimate at the time of creation and generated back in time instead of fraudulently constructed later on if the keypair is compromised. -->
<ul>
<li>Some anchor to Bitcoin but the time to finality matters a lot for UX - 10-minute block times with probabilistic finality is horrendous.</li>
</ul>
</li>
<li>
<p>Some lack an economic incentive layer.</p>
<ul>
<li>
<blockquote>
<p>&quot;Show me the incentive and I will show you the outcome.&quot; - <a href="https://quotefancy.com/quote/1561882/Charlie-Munger-Show-me-the-incentive-and-I-will-show-you-the-outcome">Charlie Munger</a></p>
</blockquote>
</li>
</ul>
</li>
</ul>
<!-- other projects lack a vision of what could be built and what it would look like
https://twitter.com/liron/status/1547225903176028160 -->
<!-- What you don't want is for these identifiers to be fractured between many platforms with different standards & formats. -->
<h1 id="what-headjack-gets-right"><a class="header" href="#what-headjack-gets-right">What Headjack gets right</a></h1>
<ul>
<li>
<p>A specialized blockchain is required. Finance is mostly about specific accounts &amp; energy preservation - no double-spends (example: UTXOs care only about other UTXOs). Media is about data storage, retrievability, aggregation, indexing, discoverability, addressing, interlinking &amp; archiving on a massive scale - it shouldn't be built on financial infrastructure.</p>
</li>
<li>
<p><a href="numbers.html">Napkin math for web-scale</a> is clear and front and center.</p>
</li>
<li>
<p>Best <a href="https://en.wikipedia.org/wiki/User_experience">UX</a>/<a href="https://en.wikipedia.org/wiki/User_experience#Developer_experience">DX</a> because of the <a href="https://medium.com/@VitalikButerin/the-meaning-of-decentralization-a0c92b76a274">logical centralization</a> and the use of identity managers (<a href="IDM.html">IDMs</a>) for on-chain authorization of applications. A global <a href="https://en.wikipedia.org/wiki/Singleton_pattern">singleton</a> solves a lot of problems.</p>
<ul>
<li>Users don't need keys &amp; signatures and also don't care about the costs either.</li>
<li>Encapsulates the complexity in <a href="https://en.wikipedia.org/wiki/User_experience">UX</a> &amp; <a href="https://en.wikipedia.org/wiki/User_experience#Developer_experience">DX</a> - the simplest mental model will win.</li>
<li>Full historical record of authorizations &amp; ability to prove anything throughout time.</li>
</ul>
</li>
<li>
<p><a href="https://en.wikipedia.org/wiki/Unix_philosophy">UNIX philosophy</a>: focuses only on identity &amp; linking data to it without trying to do everything. It doesn't impose constraints on what could be built around it - <a href="https://en.wikipedia.org/wiki/Separation_of_concerns">separation of concerns</a>.</p>
</li>
<li>
<p>Integers are the most well-known, compact, and easy to work with data type - faster/easier indexing &amp; querying versus content addressing, hashes, keypairs &amp; signatures.</p>
</li>
<li>
<p><a href="addressing.html">Content addressing</a> with human-readable &amp; persistent URIs with provable authenticity.</p>
</li>
</ul>
<!-- <div style="text-align: center;">
    <img src="images/meme_one_does_not_simply.jpg">
</div> -->
<!-- one does not simply solve media
without logically centralizing identity, names, connections & anchoring through batching and custodial services
https://imgflip.com/memegenerator/One-Does-Not-Simply -->
<!-- <div style="text-align: center;">
    <img src="images/meme_expanding_brain.jpg">
</div> -->
<!-- trust centralized companies with your identity & data
use blockchains, self-host all your data, and sign every action
manage many keypair wallets and isolate risk
use a blockchain with hierarchical trust & don't require keypairs by default
https://imgflip.com/memegenerator/Expanding-Brain -->
<div style="break-before: page; page-break-before: always;"></div><h1 id="competing-projects-list"><a class="header" href="#competing-projects-list">Competing projects (list)</a></h1>
<!-- If project Bluesky, Farcaster and DSNP had a baby it would be Headjack -->
<h1 id="bluesky"><a class="header" href="#bluesky"><a href="https://en.wikipedia.org/wiki/Bluesky_(protocol)">Bluesky</a></a></h1>
<p>Their architecture: <a href="https://github.com/bluesky-social/adx/blob/main/architecture.md">link</a></p>
<ul>
<li>
<p>Email as username ==&gt; resolve to a <a href="https://www.w3.org/TR/did-core/">DID</a> with <a href="https://webfinger.net/">WebFinger</a></p>
<ul>
<li>Centralization point - relies on DNS for the part after <code>@</code>.</li>
</ul>
</li>
<li>
<p><strong>Consortium</strong> of nodes &amp; a transparency log manage the DID registry.</p>
<ul>
<li>Centralization point (not just <a href="https://medium.com/@VitalikButerin/the-meaning-of-decentralization-a0c92b76a274">logical</a>) - users can be kicked off.</li>
<li>This should have been a credibly neutral &amp; self-sustaining blockchain.</li>
</ul>
</li>
<li>
<p>Content addressing with hashes (versus Headjack's <a href="addressing.html">human-readable &amp; persistent URIs</a>).</p>
</li>
<li>
<p>Requires the use of keypairs which is worse UX compared to Headjack and would hinder mass adoption - although they do talk about <a href="https://github.com/bluesky-social/adx/blob/main/architecture.md#root-private-key-management">custodial solutions</a>.</p>
</li>
</ul>
<!-- - When users post content they update their Personal Data Repositories managed by their Personal Data Servers (PDS) which play somewhat similar roles to [Farcaster](#farcaster)'s managed hosts and Headjack's [IDMs](IDM.md). -->
<!-- - Since such events aren't publicized anywhere, whoever is interested will have to be proactively polling for updates and sending requests. -->
<!-- - Users can lose their interest graph if the PDS they are using loses their data. -->
<!-- - The Personal Data Repositories would be a lot less compact than Headjack because accounts and links between them are not simple integers and every piece of data and relationship comes along with a signature. -->
<p>Overall a solid effort and could work - some similarities to <a href="others_list.html#farcaster">Farcaster</a> but the DID registry is centralized by a consortium and the usernames are email-like (DNS - centralization point) instead of handled by the DID registry. Neither solution anchors content like Headjack does.</p>
<h1 id="farcaster"><a class="header" href="#farcaster"><a href="https://www.farcaster.xyz/">Farcaster</a></a></h1>
<!--
https://farcasterxyz.notion.site/farcasterxyz/Farcaster-v2-43b105e4699847518b1d89996c20d564
-->
<p>Their architecture: <a href="https://github.com/farcasterxyz/protocol">link</a>. The account registry is on a blockchain and everything else is off-chain.</p>
<ul>
<li>
<p>Registry on Ethereum L1 - for new accounts, name/host changes &amp; key management.</p>
<ul>
<li>No plans on moving to an L2 or their own chain. Also, state rent could eventually be introduced to Ethereum which would lead to further costs &amp; complexity.</li>
</ul>
</li>
<li>
<p>Keypairs &amp; wallets required - harder mass adoption. Authorizations still <a href="https://github.com/farcasterxyz/protocol#45-signer-authorizations">require a signature from the root key</a>.</p>
</li>
<li>
<p>Revocations invalidate all prior activity from a delegate:</p>
<blockquote>
<p>&quot;Unfortunately, this means that all messages signed by that signer will be lost since we cannot tell which ones were signed by the attacker.&quot; - <a href="https://github.com/farcasterxyz/protocol#71-signer-compromise">source</a></p>
</blockquote>
<ul>
<li><a href="https://github.com/farcasterxyz/protocol#46-root-signer-revocations">Root signer revocations</a> are even more impactful.</li>
</ul>
</li>
</ul>
<!-- - Cast timestamps are self-reported and can be manipulated - no true cryptographic total ordering - which leads to a lot of complexity in the node software. Not sure what happens to old casts that were signed with obsolete keypairs and how the history of keys is handled. -->
<!-- message ordering, timestamps & authenticity can be manipulated which requires more logic in the software to keep track of previous hashes
https://github.com/farcasterxyz/protocol#message-ordering -->
<ul>
<li>The <a href="https://github.com/farcasterxyz/protocol#5-peering">p2p network</a>'s ability to scale by passing around granular casts is questionable - they are already discussing possible flooding and nodes having to shadow ban and flag accounts based on behavior.</li>
</ul>
<!-- TODO: problem with farcaster - you cannot save content from others forever with authentic proofs if the person removes completely their history of key changes & content signatures. Correct? -->
<!-- Directly polling accounts & their hosts for new events is more scalable but has tradeoffs compared to broadcasting messages & ingesting them into DBs & indexes (pull vs push). -->
<ul>
<li>
<p>Focus is on <a href="https://github.com/farcasterxyz/protocol#47-sharding">partial views of the network</a> as opposed to mass scale aggregation &amp; indexing - although that could easily be implemented.</p>
</li>
<li>
<p><a href="https://github.com/farcasterxyz/protocol/pull/1/files">Cast URIs</a> will look something like <code>farcaster://id:8789213729/cast:0xf00b4r</code> which is less readable than what Headjack will be offering with <a href="addressing.html">its addressing</a>.</p>
</li>
</ul>
<p>Overall good intuition about the concept of <a href="https://www.varunsrinivasan.com/2022/01/11/sufficient-decentralization-for-social-networks">sufficient decentralization</a> (putting only what is absolutely necessary on a blockchain) but the p2p node implementation takes on too much <a href="https://github.com/farcasterxyz/protocol#7-security-considerations">responsibility, complexity &amp; assumptions</a> (consensus, CRDTs, trees, ordering, flooding &amp; replay attacks, etc.) and is lacking in other areas.</p>
<!-- perhaps the best product team in the space and a good attempt to bootstrap a community -->
<h1 id="tbd"><a class="header" href="#tbd"><a href="https://www.tbd.website/">TBD</a></a></h1>
<p>Jack Dorsey's new <a href="images/meme_web5.jpg">&quot;web5&quot;</a> project - <a href="https://docs.google.com/presentation/d/1SaHGyY9TjPg4a0VNLCsfchoVG1yU3ffTDsPRcU99H1E">slides</a>, <a href="https://twitter.com/namcios/status/1535302090360250368">announcement</a>.</p>
<ul>
<li>
<p>Only anchors DID events to Bitcoin with vector commitments (Merkle roots) using <a href="https://github.com/decentralized-identity/ion">ION</a> &amp; the <a href="https://medium.com/decentralized-identity/the-sidetree-scalable-dpki-for-decentralized-identity-1a9105dfbb58">Sidetree</a> protocol.</p>
<ul>
<li>10-minute block times with probabilistic finality. Factor in the loading times for the anchored content around key management that's on IPFS - not great at all if you want to log in/authorize a service or revoke access quickly.</li>
</ul>
</li>
<li>
<p>The ION DID network is <a href="https://github.com/decentralized-identity/ion/blob/master/docs/Q-and-A.md#q-what-are-the-availability-guarantees-of-ion">not incentivized</a> (just like IPFS) and the anchored content around key management, rotations &amp; revocations depends on the current cluster of ION nodes. They state not having a consensus mechanism as a plus - which is debatable - logical centralization, uptime, adequate finality &amp; DA guarantees matter a lot when dealing with identity.</p>
</li>
<li>
<p>Doesn't have a human-readable global name registry - lacks discoverability.</p>
</li>
<li>
<p>Doesn't have human-readable content addressing.</p>
</li>
<li>
<p>Focus is on users self-hosting their own data, running software locally &amp; handling keypairs.</p>
</li>
<li>
<p>Developing their own Decentralized Web Nodes (DWN) software that would be relaying messages p2p - can't handle <a href="web_scale.html">web-scale</a> on such a granular level and aggregation is not even in the picture.</p>
</li>
</ul>
<h1 id="project-liberty"><a class="header" href="#project-liberty"><a href="https://www.projectliberty.io/">Project Liberty</a></a></h1>
<p>TODO: separate page for this?</p>
<div style="text-align: center;">
    <img src="https://png.pngitem.com/pimgs/s/207-2073499_translate-platform-from-english-to-spanish-work-in.png">
</div>
<p>One of the few solutions with their <a href="https://www.frequency.xyz/">own chain</a> in the space that makes sense. Their work (the <a href="https://github.com/LibertyDSNP/papers/blob/main/whitepaper/dsnp_whitepaper.pdf">DSNP whitepaper</a>) has had the most influence over Headjack's design but the two have diverged in some key respects - the biggest of which are scalability and content addressability. This idea is too important to leave to a single player without competition.</p>
<ul>
<li>
<p><a href="https://philanthropynewsdigest.org/news/project-liberty-launched-with-100-million-from-frank-mccourt">100m$ of funding</a> (so far) from just 1 person - <a href="https://www.youtube.com/watch?v=xgPZnOulBCE">Frank McCourt</a>.</p>
</li>
<li>
<p>Good research, good direction, but slow execution.</p>
</li>
</ul>
<!-- 
- Some good ideas in their [DSNP whitepaper](https://github.com/LibertyDSNP/papers/blob/main/whitepaper/dsnp_whitepaper.pdf) but not nearly enough emphasis on compactness. Too much on-chain & using smart contracts for identities - cannot truly scale. -->
<ul>
<li>
<p>Keypairs required even for delegated entities (although that can be reworked)
https://spec.dsnp.org/DSNP/Identity#delegation
if delegation also happens through keys then they would also have to go into the blockchain state - making it much bigger. In Headjack an authorized application is simply a few on-chain integers kept in the state (block ranges &amp; account IDs) - no need to keep block ranges for delegated keys.
https://forums.projectliberty.io/t/shorts-one-public-key-is-not-enough/215/3
1 key per device? bloat. inefficient.
&quot;Thus, we can only trust one thing: The actor signing this data had access to the private key.&quot;
all data is expected to be signed with a key - suboptimal.</p>
</li>
<li>
<p>broadcast announcements refer to the content with a URL &amp; HTTP - <a href="https://spec.dsnp.org/DSNP/Types/Reply.html#url">host-centric</a>, not in the blob, worse hosting guarantees</p>
<ul>
<li>also profile related stuff - https://spec.dsnp.org/DSNP/Types/Profile.html#url</li>
<li>not really - IPFS possible too:
https://forums.projectliberty.io/t/04-batching-source-dependent-messages-with-delegation/216#where-to-get-the-batch-file-5</li>
</ul>
</li>
<li>
<p>big reliance on hashes for announcement addressing</p>
</li>
</ul>
<!-- 
- They haven't managed to form a real community yet (although it is still early) and haven't moved as fast as others in the crypto industry for the past 2 years since their inception. -->
<ul>
<li>
<p>No names within the project - just integer IDs for accounts. Content addressing URIs are based on hashes and there's no connection to the batch / service that published it which makes indexing harder - <a href="https://spec.dsnp.org/DSNP/Identifiers.html#dsnp-content-uri">example</a>. So addressing content is much worse compared to Headjack's <a href="addressing.html">human-readable &amp; persistent URIs</a>.</p>
</li>
<li>
<p>a difference: DMs as announcements (&amp; public - leaking metadata) vs IDM-based (direct IDM-IDM comms) &amp; not anchored to the chain &amp; not announced to the world at all (TODO: revisit this)</p>
</li>
<li>
<p>no hierarchical delegation - keypairs required, every delegation goes on-chain and requires a signature (bulky) - limited throughput.</p>
</li>
</ul>
<h1 id="cyberconnect"><a class="header" href="#cyberconnect"><a href="https://cyberconnect.me/">CyberConnect</a></a></h1>
<p>Built on the <a href="https://github.com/ceramicnetwork/ceramic/blob/main/SPECIFICATION.md">Ceramic protocol</a>.</p>
<ul>
<li>
<p>Requires the use of keypairs &amp; wallets.</p>
</li>
<li>
<p>Every user has their own Ceramic data stream on top of IPFS - it is yet to be proven that the DHT &amp; p2p layers can scale to hundreds of millions or billions of people.</p>
</li>
<li>
<p>The persistence of the social graph is handled by pinning IPFS data on nodes operated by them without any cryptoeconomic incentive for the data availability - it will grow into the tens/hundreds of terabytes for web-scale (Twitter scale: 400M users with 700 connections on average) - especially because they don't have a compact integer-based representation and everything is based on big individually signed actions. The upcoming Ceramic blockchain does not seem to be geared towards storage incentivization and will not be the solution to that.</p>
<blockquote>
<p>&quot;Long-term data retention is guaranteed through Ceramic's blockchain anchoring and our custom data pinning service.&quot; - <a href="https://docs.cyberconnect.me/protocol/technical-framework/#storage">their docs</a></p>
</blockquote>
</li>
<li>
<p>Addressability of content is full of <a href="https://cerscan.com/testnet-clay/stream/kjzl6cwe1jw1474gby1buhqw8xbnvfmfphpvrs0n01n6jls9kvdx7hu41w0sp1m">hashes/pubkeys</a> - not human-readable.</p>
</li>
</ul>
<h1 id="lensxyz"><a class="header" href="#lensxyz"><a href="https://lens.xyz/">lens.xyz</a></a></h1>
<ul>
<li>
<p>Keypairs &amp; wallets required.</p>
</li>
<li>
<p>Even the content is stored on-chain instead of just the accounts. This cannot scale even to a few million users with any real usage despite being on Polygon. Even if they move to their own chain it will have to be EVM-compatible because of their smart contracts - suboptimal.</p>
</li>
<li>
<p>Hashes &amp; pubkeys in content addressing - no <a href="addressing.html">human-readable &amp; persistent URIs</a>.</p>
</li>
</ul>
<h1 id="deso"><a class="header" href="#deso"><a href="https://www.deso.org/">DeSo</a></a></h1>
<ul>
<li>
<p>It requires wallets &amp; users to pay for every interaction.</p>
</li>
<li>
<p>It puts everything on-chain and their plans to scale are with bigger blocks &amp; sharding (see <a href="https://docs.deso.org/about-deso-chain/readme">&quot;Phase 4: Sharding&quot;</a>) which is simply not practical for the <a href="https://www.techspot.com/news/91513-visualizing-minute-internet-2021.html">true scale of the public web</a>.</p>
</li>
<li>
<p>It financializes as much as possible (creator coins, etc.).</p>
</li>
<li>
<p>Their initial growth was fueled by huge sums of VC money but by now it has <a href="https://www.openprosper.com/stats/deso-dashboard">flatlined</a>. It did reach <a href="https://www.coingecko.com/en/coins/deso">1.66$ billion market cap</a> on the 2nd of October 2021 shortly after being listed.</p>
</li>
</ul>
<h1 id="others"><a class="header" href="#others">Others</a></h1>
<p>For details about ActivityPub, Matrix, Diaspora, Mastodon, Secure Scuttlebutt, Solid &amp; others please refer to the excellent <a href="https://twitter.com/bluesky/status/1352302821140549632">ecosystem review</a> by the Bluesky project. Other good resources include:</p>
<ul>
<li><a href="https://medium.com/decentralized-web/decentralized-social-networks-e5a7a2603f53">Decentralized Social Networks</a> - Jay Gerber</li>
<li><a href="https://medium.com/decentralized-web/blockchain-social-networks-c941fb337970">Blockchain Social Networks</a> - Jay Gerber</li>
<li>There are <a href="https://mirror.xyz/shreyjain.eth/TyBzMOegl3rMNxpAFoJ36MjE0pGfdLcrVCBgy-x3qS8">many other projects</a> in this space.</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="motivation-why"><a class="header" href="#motivation-why">Motivation (why)</a></h1>
<p>The web is broken on many fronts - this chapter explores many problematic aspects and how they can be either improved or even completely solved. Headjack's paradigm is an architectural reset of the web &amp; opens doors to things which weren't possible before.</p>
<!--






Different systems with their own cryptoeconomics can be implemented on top of this addressing - adding guarantees for services while still under the same global addressing namespace

--><div style="break-before: page; page-break-before: always;"></div><h1 id="problems-with-the-current-web"><a class="header" href="#problems-with-the-current-web">Problems with the current web</a></h1>
<p>This is a non-exhaustive list of some of the most obvious problems.</p>
<h1 id="the-host-centric-web"><a class="header" href="#the-host-centric-web">The host-centric web</a></h1>
<p>One major problem of the current internet architecture is that documents are host-certified and communication happens through the <a href="https://en.wikipedia.org/wiki/End-to-end_principle">end-to-end principle</a> - we refer to data by location instead of contents. The consequences are explained in the <a href="host_centric.html">host-centric</a> page (contrast that to <a href="data_centric.html">data-centric</a>).</p>
<p>TODO: mention the lack of authenticity as a major problem</p>
<p>TODO: Surveillance capitalism</p>
<h1 id="lack-of-composability--interoperability"><a class="header" href="#lack-of-composability--interoperability">Lack of composability &amp; interoperability</a></h1>
<!--


> "Asset titles, licenses, and certificates can't live on the internet easily in a truly meaningful and native way. If you do put them online, there’s very little one can do to ensure they are authentic or valid, especially if you want them to remain authentic across platforms without building special-purpose APIs and integrations." - [source](https://mirror.xyz/0xE4f646F0Be4fF5ce185540F5366295f91d75b65D/-xpmr7ceHmi5Hqsl7zRtig9ph_dtCvWjZOoWOVN0bcg)

composability

> "Problem: The data for {X} is under the total control of company {X}. If a user wants to migrate to a new service, they can’t bring their history with them in a way that retains its legitimacy. Company {X} doesn’t want to let them, and even if they did, it wouldn’t be easy to do this at scale in a way so {X} doesn’t maintain total control. See: Twitter API being public with companies built on it, only to be shut down by Twitter." - [source](https://mirror.xyz/0xE4f646F0Be4fF5ce185540F5366295f91d75b65D/-xpmr7ceHmi5Hqsl7zRtig9ph_dtCvWjZOoWOVN0bcg)

<img src="images/twitter_as_protocol.webp">

> "I think it might make the world more efficient if we were able to instantly verify the authenticity of assets, licenses, and certificates, without the need for every issuer to run massive APIs and authentication services. All one needs to do to ensure the authenticity of an asset is verify the identity and history of the issuer" - [source](https://mirror.xyz/0xE4f646F0Be4fF5ce185540F5366295f91d75b65D/-xpmr7ceHmi5Hqsl7zRtig9ph_dtCvWjZOoWOVN0bcg)


https://mirror.xyz/0xE4f646F0Be4fF5ce185540F5366295f91d75b65D/-xpmr7ceHmi5Hqsl7zRtig9ph_dtCvWjZOoWOVN0bcg

-->
<h1 id="black-boxes--algorithmic-bias"><a class="header" href="#black-boxes--algorithmic-bias">Black boxes &amp; algorithmic bias</a></h1>
<p>The recommendation algorithms &amp; the social graph are the architecture of virality - the dynamics of amplification &amp; interaction dictate how ideas surface, propagate, compound &amp; evolve. The people writing the algorithmic feeds are the most powerful in the world - <a href="https://youtu.be/3qHkcs3kG44?t=3616">@naval</a>.</p>
<p>Ephemeral experiences such as search suggestions &amp; results leave no trace and it's extremely hard to prove bias as <a href="https://en.wikipedia.org/wiki/Robert_Epstein#Contributions_to_Internet_Studies">Dr. Robert Epstein</a> would <a href="https://open.spotify.com/episode/4q0cNkAHQQMBTu4NmeNW7E">attest</a> - there is 0 accountability.</p>
<blockquote>
<p>&quot;But we believe the issue of advertising causes enough mixed incentives that it is crucial to have a competitive search engine that is transparent and in the academic realm.&quot; - <a href="https://perma.cc/8GDJ-K6AX">the original Google search engine whitepaper</a></p>
</blockquote>
<p>Does such a search engine exist today? Competition &amp; a lower barrier to entry are direly needed.</p>
<p>The explicit user preferences such as subscriptions &amp; the social graph (following/connections) are routinely discounted in our feeds in favor of algorithm recommendations - platforms optimize for engagement &amp; attention and not for utility &amp; value to end users. We all respond to outrage &amp; enjoy the occasional viral cat video but we should be able to tune &amp; filter what gets shown to us. Have you ever heard a YouTuber tell you to hit the notification bell in addition to subscribing?</p>
<blockquote>
<p>&quot;I'm in an ongoing relationship with a moody, sensitive, grudge-holding, and generally crazy girlfriend called the Twitter algorithm. Everything will be going fine and then suddenly I'm getting the cold-shoulder and I don't even really know what I did and just have to wait it out.&quot; - <a href="https://twitter.com/waitbutwhy/status/1506755880578166788">Tim Urban</a></p>
</blockquote>
<!-- addictive social media - toxic -->
<h1 id="vertical-integration-vs-specialization--competition"><a class="header" href="#vertical-integration-vs-specialization--competition">Vertical integration vs specialization &amp; competition</a></h1>
<p>Platforms do almost everything in-house in a closed way as providing access to third-party companies to their data to solve specific problems is hard due to complications around data privacy/regulation and the need to safeguard their competitive advantages &amp; trade secrets.</p>
<p>This leads to:</p>
<ul>
<li>lack of cooperation, interoperability, duplicated effort &amp; stifled innovation</li>
<li>competition for scarce talent which leads to sub-par solutions</li>
<li>company bloat &amp; inefficiencies
<ul>
<li>companies are harder to manage as they are way bigger than what they could be</li>
<li>bigger size demands higher revenue - pricing out many business models</li>
</ul>
</li>
<li>differences in functionality between platforms =&gt; complexity for users</li>
</ul>
<p>Contrast that to open protocols &amp; exportable data where anyone can specialize, innovate &amp; provide the best possible service for a specific vertical &amp; sell it to others. The move from <a href="host_centric.html">host-centric</a> to <a href="data_centric.html">data-centric</a> addressing and open blockchains enable <a href="https://balajis.com/yes-you-may-need-a-blockchain/">interoperability</a> and composability.</p>
<h1 id="growth-network-effects--monopolies"><a class="header" href="#growth-network-effects--monopolies">Growth, network effects &amp; monopolies</a></h1>
<p>Social media platforms are growth-at-all-costs stories because the goal is to achieve a network effect first and become a monopoly with a <a href="https://www.investopedia.com/ask/answers/05/economicmoat.asp">MOAT</a> at which point the user <a href="https://twitter.com/cdixon/status/1473859531343949824">value extraction</a> and cannibalization of ecosystems built on top of APIs can ramp up (<a href="https://www.siliconrepublic.com/enterprise/twitter-apis-ending">1</a>, <a href="https://nordicapis.com/twitter-10-year-struggle-with-developer-relations/">2</a>, <a href="https://techcrunch.com/2015/05/06/meerkat-founder-on-getting-the-kill-call-from-twitter/">3</a>, <a href="https://techcrunch.com/2018/04/02/instagram-api-limit/">4</a>, <a href="https://mashable.com/article/gmail-ifttt-shutdown-google">5</a>). At that point innovation is less necessary (+ is harder due to inertia) and even the quality of service may degrade. User data is the most valuable commodity and scale enables the best AI models &amp; efficiency of value extraction in the advertising model which comes with a slew of problems &amp; perverse incentives.</p>
<div style="text-align: center;">
    <img src="images/meme_data_most_valuable.jpg">
</div>
<p>Users are usually locked-in and effectively have no <a href="https://twitter.com/balajis/status/1548725591687303168">voice and exit</a> either because:</p>
<ul>
<li>the network effects are insurmountable for incumbents and there are no alternatives</li>
<li>or if they leave for an alternative service they'd lose all their connections, audience &amp; reputation and would have to start from scratch</li>
</ul>
<blockquote>
<p>&quot;I think it might be reasonable to believe that single monolithic companies shouldn’t have monopolies on certain data that practically guarantees user lock-in. And that the internet might be better if some data were made completely open and available to any developer who wants to build on it while ensuring that the data can’t be edited by anyone that isn’t supposed to be able to edit it.&quot; - <a href="https://mirror.xyz/0xE4f646F0Be4fF5ce185540F5366295f91d75b65D/-xpmr7ceHmi5Hqsl7zRtig9ph_dtCvWjZOoWOVN0bcg">source</a></p>
</blockquote>
<blockquote>
<p>&quot;Twitter was supposed to be a protocol allowing anyone to build products and services on top of it that drive value back to the parent company and investors. But it wasn’t a real protocol. It only pretended to be. As soon as the people behind the scenes changed their minds about what they wanted Twitter to be, the “protocol” side of Twitter got shut down. While this ruined a lot of businesses built on top of it at the time, it was perfectly predictable. Before web3, it was near impossible to build real application-specific protocols on the internet. And counter to the beliefs of the biggest web3 critics, web3 does allow you to build real, open, and neutral protocols.&quot; - <a href="https://mirror.xyz/0xE4f646F0Be4fF5ce185540F5366295f91d75b65D/-xpmr7ceHmi5Hqsl7zRtig9ph_dtCvWjZOoWOVN0bcg">source</a></p>
</blockquote>
<h1 id="centralized--fragmented-identitypreferences"><a class="header" href="#centralized--fragmented-identitypreferences">Centralized &amp; fragmented identity/preferences</a></h1>
<p>Convenience &amp; simplicity sought by users has lead to extreme levels of centralization of identity in just a few centralized players with network effects &amp; <a href="https://en.wikipedia.org/wiki/Single_sign-on">single sign-on</a> functionality.</p>
<blockquote>
<p>&quot;as of 2018 the consolidation of power and control over the social web by a few large corporations seems unparalleled&quot; - <a href="https://hal.inria.fr/hal-01966561/document">Decentralizing the Social Web</a></p>
</blockquote>
<p>But despite the concentration of SSO services a lot of identity-related activity is fragmented between platforms due to the lack of standards &amp; interoperability: settings/preferences, <a href="https://twitter.com/jonwu_/status/1524886818725847040">direct messages</a>, bookmarks, playlists, progress bars, etc.</p>
<blockquote>
<p>&quot;Identity on the internet today is fragmented across many centralized services, each with its own set of user data. Signing up for a new service requires making a brand new identity and re-entering all of your information. This is not only tedious but also means that a user’s identity is going to be inconsistent between services because they are not always going to update key information on every single service every time that something changes.&quot; - <a href="https://blog.sia.tech/skyid-how-to-make-decentralized-identity-using-skynet-2b282682f5b3">source</a></p>
</blockquote>
<p><a href="https://en.wikipedia.org/wiki/Linktree">Linktree</a> is just a bandaid for today’s fragmentation of identity (<a href="https://techcrunch.com/2022/03/16/linktree-link-in-bio-series-c-valuation/">valued at 1.3B$</a>) - it is a symptom.</p>
<p>Contrast that to a world with interoperable &amp; exportable identity/data:</p>
<blockquote>
<p>“each time we go from one social network to another we do not need to restate who we are, what our interests are, or who we know” - <a href="https://hal.inria.fr/hal-01966561/document">Decentralizing the Social Web</a></p>
</blockquote>
<h1 id="the-cold-start-problem-for-startups"><a class="header" href="#the-cold-start-problem-for-startups">The cold start problem for startups</a></h1>
<p>The barrier to entry for most types of platforms is very high:</p>
<ul>
<li>kickstarting a network effect &amp; attracting a critical mass is very difficult</li>
<li>need to reinvent the wheel &amp; <a href="problems_with_the_web.html#vertical-integration-vs-specialization--competition">vertically integrate</a> many aspects instead of composing a service from already existing solutions</li>
</ul>
<p>And thus few companies are started and even fewer are successful - leading to little innovation, slow progress &amp; sub-par services.</p>
<!-- TODO: data network effects -->
<p>Check out the <a href="startup_case_study.html">startup case study</a> expanding on why it would be easier with Headjack.</p>
<h1 id="infrastructure-centralization"><a class="header" href="#infrastructure-centralization">Infrastructure centralization</a></h1>
<p>Google is way more than just a search engine even though the majority of their revenue comes from advertising - they control large percentages of the plumbing of the web - key choke points such as submarine cables, routing, data centers, browsers, DNS, etc. <a href="https://twitter.com/DavidVorick"><code>David Vorick</code></a> puts this perfectly into perspective in <a href="https://blog.sia.tech/the-worrying-depth-and-scope-of-censorship-on-the-internet-ffd4bc5a5486"><code>The Worrying Depth and Scope of Censorship on the Internet</code></a> - some quotes:</p>
<blockquote>
<p>&quot;If Google decides they don’t like you, then for 65% of the world you simply stop existing. You have no recourse.
The terrifying thing about this is that Google is not an elected entity. Google has turned themselves into unelected regulators of the Internet, and they are held accountable only to their own share price.&quot;</p>
</blockquote>
<blockquote>
<p>&quot;As our economy and services become more deeply intertwined, an increasing number of players have more influence and ability to de-platform a greater number of businesses and users. And these requirements compound against each other. If one service provider is particularly opinionated and quick to de-platform, everybody else is forced to give them a large amount of breathing room and become more oppressive towards their users to avoid potential conflict.&quot;</p>
</blockquote>
<blockquote>
<p>&quot;This does not scale. The end result will be a global monoculture where everybody is afraid to take risks or break the status quo because nobody can afford to upset even a single of the hundreds of services that they depend on. Our culture gets established and defined by giants like Facebook and Google rather than users and creators, because only Facebook and Google have the resources to bully everyone else into allowing changes to happen.&quot;</p>
</blockquote>
<blockquote>
<p>&quot;The only way to avoid this endgame is to demand infrastructure that remains neutral. At the scale of today’s Internet and global economy, infrastructure that does not remain neutral will inevitably turn on its users and coerce them into a set of moral standards that are both arbitrary and enforced without consent.&quot;</p>
</blockquote>
<h1 id="cultural-fragmentation--filter-bubbles"><a class="header" href="#cultural-fragmentation--filter-bubbles">Cultural fragmentation &amp; filter bubbles</a></h1>
<p>The same document may be published through different platforms and because of the host-certified web of today it will get multiple different URLs. Discussion around it becomes fragmented &amp; shallow in the different platforms with separate comment sections and there isn't a way to de-duplicate &amp; unify it. This facilitates polarization as separate echo chambers can form without seeing the opinion of other types of people.</p>
<!-- Alienating large parts of the population & pushing them to alternative closed platforms is not a net benefit. -->
<blockquote>
<p>&quot;Echo chambers are intellectual oppression - as opposed to idea labs where ideas are treated as experiments.&quot; - <a href="https://www.youtube.com/watch?v=ivDwzBYsED4">Tim Urban</a></p>
</blockquote>
<p>Instead imagine being able to view the entire discussion around a specific event by tracing &amp; aggregating all of the re-publications, references &amp; re-tweets &amp; quotes of it from anywhere and applying any type of filter to that.</p>
<p>That is what interoperable identity, content-addressing &amp; broadcasted data enables - we can connect and de-duplicate everything and allow anyone to build tools around that - constructing a much bigger graph that what Google have created for themselves.</p>
<h1 id="moderation--censorship"><a class="header" href="#moderation--censorship">Moderation &amp; censorship</a></h1>
<p>This is an incredibly hairy topic with many aspects - here are just a few of them:</p>
<ul>
<li>No clear rules for moderation &amp; censorship - the terms of service are ambiguous and an ever moving goal post. Platform accountability is practically non-existent:
<ul>
<li>account reach can be down-regulated through opaque techniques like <a href="https://shadowban.yuzurisa.com/">shadow banning</a></li>
<li>accounts can be removed subjectively (case in point: earlier Twitter accounts tracking Nancy Pelosi's public stock trades)</li>
</ul>
</li>
<li>There is no way for users to &quot;fork&quot; a Reddit community if they no longer agree with the way moderation is happening - they have to recreate a new subreddit from scratch.</li>
<li>There is no market for solving certain types of spam such as financial scams - Twitter &amp; YouTube are riddled with templatized messages and their internal <a href="problems_with_the_web.html#vertical-integration-vs-specialization--competition">vertically integrated</a> teams are unable to deal with yet another problem in a world-class manner. In an open system such as e-mail the competition &amp; innovation for solving spam has been tremendous.</li>
</ul>
<h1 id="problems-with-specific-platforms"><a class="header" href="#problems-with-specific-platforms">Problems with specific platforms</a></h1>
<p>A non-exhaustive list of additional problems (beyond what's already listed) with some platforms:</p>
<ul>
<li>
<p>YouTube:</p>
<ul>
<li>there is no longer a down vote count &amp; like/dislike ratio</li>
<li>subscriptions are by now almost meaningless without the notification bell icon</li>
<li>the comment section is just an afterthought - they don't care about it
<ul>
<li>the presentation is extremely basic &amp; limiting</li>
<li>you cannot even link to a specific comment with a URL</li>
<li>financial scams in comments are abundant - moderation is non-existent</li>
</ul>
</li>
</ul>
</li>
<li>
<p>Twitter:</p>
<ul>
<li>we can't even sort the tweets of someone based on engagement</li>
<li>we pin threads of threads on our profiles and sequence them with X/YY numbers</li>
<li>cannot sort quotes/replies of a tweet based on engagement/age</li>
<li>no unrolled thread view option even though it's a no-brainer at this point</li>
<li>filtering &amp; tuning what is shown in lists is nonexistent
<ul>
<li>lists don't show replies that are not to accounts in that list</li>
<li>can't display likes in lists</li>
</ul>
</li>
<li>we <a href="https://twitter.com/waitbutwhy/status/1502846781150822402">can't see other people's feeds</a> (although there's this <a href="https://vicariously.io/">third-party app</a>)</li>
<li>no way to opt-out of recommendations in the main feed for topics you don't care about or unrelated activity such as <code>X received a reply from someone you don't follow</code></li>
<li>find the beginning of <a href="https://twitter.com/lopp/status/1531668215541145601">this thread</a> - is that readable &amp; usable? There should be an alternative Reddit-style application</li>
</ul>
</li>
</ul>
<!-- tweets & comments without tagging is primitive and inefficient -->
<p>when twitter decide engagement is low they shove down your throat nonsense algorithmic &quot;recent tweets&quot; notifications you can't turn off - that's what it has devolved into. &quot;See less often&quot; from the dropdown menu does nothing.</p>
<blockquote>
<p>&quot;Unfortunately, you cannot turn off recent tweets. This is because the feature drives up “user engagement”, which is a key metric that shareholders pay attention to.&quot; - <a href="https://thisinterestsme.com/recommended-tweets/">source</a></p>
</blockquote>
<div style="break-before: page; page-break-before: always;"></div><h1 id="authenticity"><a class="header" href="#authenticity">Authenticity</a></h1>
<p>In the current web documents are <a href="problems_with_the_web.html#the-host-centric-web">host-certified</a> and we refer to data by location instead of contents. Here we'll further expand on problems with the status quo and list the benefits of building a <a href="https://en.wikipedia.org/wiki/Web_of_trust">web of trust</a> at web-scale through <a href="data_centric.html">data-centric</a> addressing &amp; <a href="https://en.wikipedia.org/wiki/Self-authenticating_document">self-authenticating</a> documents in an open ecosystem with freely shared public data tied to identity.</p>
<h1 id="the-ledger-of-record"><a class="header" href="#the-ledger-of-record">The ledger of record</a></h1>
<p>We'll be able to computationally verify the authenticity of any document &amp; tie it to an identity as long as we also have the proofs for it - giving birth to the <a href="https://twitter.com/balajis/status/1459140902144729088">ledger of record</a> where argument from cryptography begins superseding argument from authority.</p>
<p>Anyone might have saved a specific document (&amp; updates to it) locally along with the necessary proofs for authenticity even if most infrastructure no longer stores/serves it. There is a <code>1 of N</code> guarantee which allows documents that someone wants buried to be passed around with proofs and resurface in the public at a later point - improving accountability.</p>
<!-- 
TODO:
In such an environment controversial and false claims are much easier to prove.
If even intranets and corps move to this addressing then whistpeblowing will be much more authentic. This is the mechanism for the biggest crimes to bubble up
-->
<hr />
<p>Using screenshots of tweets in case the originals get deleted does not constitute evidence. The lack of authenticity is being routinely exploited - <a href="https://today.law.harvard.edu/shedding-light-on-fraudulent-takedown-notices/">&quot;Shedding light on fraudulent takedown notices&quot;</a>.</p>
<blockquote>
<p>&quot;For example, thanks to the site’s record-keeping both of deletions and of the source and text of demands for removals, the law professor Eugene Volokh was able to identify a number of removal requests made with fraudulent documentation—nearly 200 out of 700 “court orders” submitted to Google that he reviewed turned out to have been apparently Photoshopped from whole cloth. The Texas attorney general has since sued a company for routinely submitting these falsified court orders to Google for the purpose of forcing content removals.&quot; - <a href="https://www.theatlantic.com/technology/archive/2021/06/the-internet-is-a-collective-hallucination/619320/">source</a></p>
</blockquote>
<h1 id="the-history-of-document-updates"><a class="header" href="#the-history-of-document-updates">The history of document updates</a></h1>
<p>Today's web puts authenticity &amp; certification of documents in the <a href="host_centric.html">hands of hosts</a> which can <a href="https://news.ycombinator.com/item?id=27690525">do whatever they want</a> and rarely provide the option to see previous versions if edits have been made. The <a href="https://en.wikipedia.org/wiki/Internet_Archive">Internet Archive</a> is hardly a mainstream tool which doesn't provide any cryptographic authenticity guarantees and can be compromised.</p>
<blockquote>
<p>&quot;It is really tempting to cover for mistakes by pretending they never happened. Our technology now makes that alarmingly simple&quot; - <a href="https://www.theatlantic.com/technology/archive/2021/06/the-internet-is-a-collective-hallucination/619320/">source</a></p>
</blockquote>
<blockquote>
<p>&quot;Society can’t understand itself if it can’t be honest with itself, and it can’t be honest with itself if it can only live in the present moment. It’s long overdue to affirm and enact the policies and technologies that will let us see where we’ve been, including and especially where we’ve erred, so we might have a coherent sense of where we are and where we want to go.&quot; - <a href="https://www.theatlantic.com/technology/archive/2021/06/the-internet-is-a-collective-hallucination/619320/">source</a></p>
</blockquote>
<p>In Headjack updates to URIs are broadcasted but the previous versions remain - applications ought to display the latest state but should allow browsing the entire history of changes - like using Git.</p>
<h1 id="deduplicating-documents--traceability"><a class="header" href="#deduplicating-documents--traceability">Deduplicating documents &amp; traceability</a></h1>
<p>An open paradigm with content addressing where data is shared between services would enable us to de-duplicate re-uploads as long as they are the same documents in terms of bytes because of the open nature of data - based on their hash. We'll be able to see when something first appeared &amp; the discussion will be much less fractured between platforms and posts - leading to greater depth.</p>
<p>We'll be able to more easily <a href="names_and_paths.html#addressing-within-content">address parts of documents</a> and share ranges of entire videos without having to re-upload them as separate clips which breaks the contextual link. If this becomes as easy as (or even easier than) it currently is to crop &amp; re-upload, then it will become the norm - we'll all prefer not losing the context. In this paradigm <a href="https://en.wikipedia.org/wiki/Deepfake">deepfakes</a> will be easier to spot &amp; fight - tracing the source of content authentically to identity is important &amp; desirable.</p>
<p>TODO: regarding deepfakes - only official statements could be traced - unofficial leaks will still be unprovable</p>
<h1 id="verifiable-credentials"><a class="header" href="#verifiable-credentials">Verifiable credentials</a></h1>
<p>Entities can sign messages that attest facts about other accounts - the creation of such <a href="https://en.wikipedia.org/wiki/Verifiable_credentials">verifiable credentials</a> doesn't have to happen on-chain - they can be issued off-chain with a message that's only anchored on-chain and has a URI. <a href="https://vitalik.ca/general/2022/06/12/nonfin.html#modifying-and-revoking-attestations"><code>&quot;issuance is common, revocation is rare&quot;</code></a> - later revocations &amp; updates can be handled in one of 2 ways:</p>
<ul>
<li>On-chain revocation/updates: if the attestations are uniquely numbered with a counter from the issuer using a <a href="https://en.wikipedia.org/wiki/Cryptographic_nonce">nonce</a>, then the Headjack state can be extended to support a special <code>revocation list</code> field in which the chain can record revocations at specific blocks - then the validity of said attestations will be checkable with a single query to the blockchain state. For updates there would be a second list and in order to check the validity for an attestation after an update has been recorded for its nonce, users would need to fetch the off-chain anchored message corresponding to the update at the block at which it was flagged. The blockchain may charge periodic fees for state rent for these lists.</li>
<li>Fully off-chain: in which case there will be some liveness assumptions around the issuer for checking if an attestation has been revoked/updated.</li>
</ul>
<!-- TODO: POAP
https://www.google.com/search?q=poap&oq=poap&aqs=chrome..69i57j0i512l9.912j0j7&sourceid=chrome&ie=UTF-8 -->
<h1 id="reputation-systems"><a class="header" href="#reputation-systems">Reputation systems</a></h1>
<p>We don't need oracles, tokens, automatic on-chain settlement &amp; markets through smart contracts to build reputation systems for predictions &amp; promises - all we need is to immutably sequence predictive messages that are authentically linked to identity and plot the results - the open nature of the data would disincentivize platforms to display it incorrectly which is enough - we trust block explorers after all.</p>
<p>Take the <a href="https://www.tipranks.com/">Tipranks</a> platform as an example - we can generalize it for anyone in the world - not just for certified financial advisors. The reality is that millions of people are effectively guilty of shilling, despite some preficing it with the infamous <a href="https://twitter.com/DegenSpartan/status/1552968186605490176"><code>&quot;this is not financial advice&quot;</code></a>. We can self-regulate the crypto &amp; financial industries bottom-up in a decentralized way - steps:</p>
<ol>
<li>come up with the base set of extensible prediction message types</li>
<li>build the tools that plot predictions versus a price feed</li>
<li>demand that influencers use the specific types of messages for predictions</li>
<li>refuse to listen to accounts that don't use that format and build the habit to check track records before listening to someone - this can (and will) become a social norm</li>
<li>let the <a href="https://twitter.com/TSLAgang/status/1433896307702353921">chips fall where they may</a></li>
</ol>
<p>Message types can be in an extensible inheritance hierarchy and have &quot;fallback&quot; translation mechanisms defined in their on-chain schema for platforms that don't support specific leaf types. As an example: on-chain schema <code>42</code> can have the following template for serialization: <code>&quot;{asset} has an {probability} chance of being {above_or_below} {price} by {date}&quot;</code>, and thus a basic application that encounters <code>{message_type: &quot;42&quot;, asset: &quot;$BTC&quot;, date: &quot;2025.02.12&quot;, above_or_below: &quot;above&quot;, price: &quot;100000$&quot;, probability: &quot;80%&quot;}</code> could render <code>&quot;$BTC has an 80% chance of being above 100000$ by 2025.02.12&quot;</code>. Or there could be a message type with spline curves. This way the system can evolve even if applications move at different pace and there's no consensus on the evolution of messages - it will naturally happen. Rigidness and/or lack of consensus for such standards has been the bane for many open systems.</p>
<p>The argument that specialized message types are unnecessary because AI will eventually be able to classify things properly is mute - lets get something that is unambiguous and working now - structure is good. The use case for reputation goes beyond finance.</p>
<!-- Perhaps the reputation system can be abused - by making 100 accounts and building different prediction timelines throughout time and then using only the winners - this page should be treated just as a starting point and isn't trying to provide all the answers. -->
<blockquote>
<p>&quot;Finally, self-authenticating data provides more mechanisms that can be used to establish trust. Self-authenticated data can retain metadata, like who published something and whether it was changed. Reputation and trust-graphs can be constructed on top of users, content, and services. The transparency provided by <a href="https://en.wikipedia.org/wiki/Verifiable_computing">verifiable computation</a> provides a new tool for establishing trust by showing precisely how the results were produced. We believe verifiable computation will present huge opportunities for sharing indexes and social algorithms without sacrificing trust, but the cryptographic primitives in this field are still being refined and will require active research before they work their way into any products.&quot; - <a href="https://blueskyweb.xyz/blog/3-6-2022-a-self-authenticating-social-protocol">bluesky</a></p>
</blockquote>
<!-- > "The public’s interest in seeing what’s changed—or at least being aware that a change has been made and why—is as legitimate as it is diffuse. And because it’s diffuse, few people are naturally in a position to speak on its behalf." - [source](https://www.theatlantic.com/technology/archive/2021/06/the-internet-is-a-collective-hallucination/619320/) -->
<div style="break-before: page; page-break-before: always;"></div><h1 id="possibilities-with-open-data"><a class="header" href="#possibilities-with-open-data">Possibilities with open data</a></h1>
<p>Tying data to identity and making it freely available &amp; outside of silos through content-centric addressing enables tons of composability, functionality &amp; innovation.</p>
<h1 id="unified-data---different-views"><a class="header" href="#unified-data---different-views">Unified data - different views</a></h1>
<p>The public conversation shouldn't be fractured between platforms such as Twitter, YouTube &amp; Reddit - instead it should be one but viewed through different lenses (based on moderation / indexing / visualization). The Twitter view of a discussion is basically the same as just the top level comments (without the children) in a Reddit thread. Segregated discussion in the open web serves nobody - there should be canonical IDs for events &amp; information that we can all refer to. It doesn't make sense that comments can be arbitrarily disabled for some document on one platform (YouTube) but enabled on another one where a URL from the first is shared. All content could be interlinked, deduplicated, referencable, quotable, commentable &amp; shareable.</p>
<!-- Data hoarding and interoperability leads to tool & widget incompatibility. -->
<h1 id="event-streams"><a class="header" href="#event-streams">Event streams</a></h1>
<!-- Our minds filter out inconsequential sensations by default but we may tune them in with focus - we should have even greater levels of control in the digital realm. The stream of events for whatever we are interested in needs the most sophisticated filtering and configuration possible and anyone should be able to plug into the global event bus and develop new tools. -->
<p>In an open data environment anything could become an event stream as long as someone is willing to pay for the processing costs (filtration, transformation, storage):</p>
<ul>
<li>edits to a specific document identified by a URI</li>
<li>references/mentions of an account/entity/word/URI in public documents</li>
<li>any other type of filtration criteria - thresholds, exclude lists, etc.</li>
<li>complicated streams can be constructed by transforming/joining others - similar to Kafka</li>
</ul>
<p>If someone implements speech-to-text and starts transcribing audio episodes and publishing the output it would immediately become available to anyone and would automatically end up being parsed, indexed &amp; pushed through data pipelines. Composability. This is not possible with closed platforms - even if someone was willing to pay the processing costs.</p>
<h1 id="notifications--subscriptions"><a class="header" href="#notifications--subscriptions">Notifications &amp; subscriptions</a></h1>
<p>Twitter decided that it needs to boost engagement and forced &quot;recent tweet&quot; notifications on us <a href="https://www.reddit.com/r/Twitter/comments/qwvhhb/how_do_you_disable_recent_tweets_from_x/">without the ability to turn them off</a> - that needs to stop - explicit preferences should be honored.</p>
<blockquote>
<p>&quot;Notifications are just alarm clocks that someone else is setting for you.&quot; - <a href="https://twitter.com/NavalismHQ/status/1556179585347112961">@naval</a></p>
</blockquote>
<p>When identity is decoupled from the presentation layer we could have IDMs that align with our needs - we could fine-tune how and when we want to be notified. The incentive for an IDM is not to suck all of our attention (as opposed to applications that usually serve ads) - there are other ways to monetize. We'd be able to set a threshold or filter on anything. Subscriptions can be granular &amp; multi-dimensional for any type of event stream - like <code>&quot;show me everything from X unless from application A or message type T&quot;</code>. Some IDMs could even offer the feature to show notifications only in specific time ranges of the day - for those addicted to dopamine hits.</p>
<h1 id="bookmarks--playlists"><a class="header" href="#bookmarks--playlists">Bookmarks &amp; playlists</a></h1>
<p>Universal bookmarks - they can have a single repository (your IDM) and work for any type of document from any application. They will be persistent and you could even cache the actual contents that a URI points to along with proofs - in case it is no longer hosted by anyone in the future.</p>
<p>Your personal knowledge base could be built with something like <a href="https://logseq.com/">Logseq</a> with URI references to external documents that can be locally cached. Looking up the discussion/commentary for a resource with a URI would be just 1 click away.</p>
<p>Playlists are lists of bookmarks and could work even with heterogeneous audio/video providers which anchor the tracks and provide URIs for them. Spotify could be just an application that uses your IDM for account storage and is paying to other media hosting providers for the streaming.</p>
<h1 id="intra-document-addressing"><a class="header" href="#intra-document-addressing">Intra-document addressing</a></h1>
<p>In Medium you can tweet a selection (sentence/word/paragraph) but when going back to the article from the tweet you don't get shown the original selection. With some archival services you can point to a text selection - for example <a href="https://archive.ph/O2D45#selection-635.4-635.18">this link has <code>&quot;Prussian Model&quot;</code></a> selected from the title when you open the page and you can change the selection which also changes the URL, but that's possible only because there's a specific hash in the URL and the document is guaranteed not to change in the archive - however that's not the case with Medium where the authenticity of documents is host-certified and they can change in time.</p>
<p>With Headjack URIs point to a specific version of a document and as explained in the <a href="names_and_paths.html#addressing-within-content">addressing chapter</a> we could point to parts of documents in the URIs. If a document has been changed, updates will have their own new URIs and when an application is showing an old URI with intra-document addressing it could:</p>
<ul>
<li>either show a label that there's a newer version of the document and the user can switch</li>
<li>or directly show the new version if it's possible to transfer the selection without conflicts</li>
</ul>
<p>Headjack's intra-document addressing is universal - it works for audio &amp; video too and the application from the <a href="startup_case_study.html">startup case study</a> could display this clip with this quote in a much better way:</p>
<blockquote>
<p>&quot;The internet creates 1 giant aggregator for everything&quot; - <a href="https://youtube.com/clip/UgkxphJhihcVY-U-PLFEvDl1m7Rb-iq4CGgo">@naval</a></p>
</blockquote>
<p>This can be pushed further - any composition/remix/meme of media could contain the references to the original text/pictures/audio/video so the sources of something can be traced and credited - imagine something like a movie maker that composes from other clips and all metadata is retained.</p>
<h1 id="code-as-addressable-data"><a class="header" href="#code-as-addressable-data">Code as addressable data</a></h1>
<p>Frontend code served by applications can be published and have its own URI. Updates to it would happen by broadcasting the next version along with a new URI and then pointing on-chain to it as the latest to use for viewing media. This way presentation layers could be cached locally and in a distributed way with proofs for authenticity - improving redundancy, latency, and throughput. Checking for a newer version would be a small query to the chain if there is a new URI - version control for frontends. This can work even for more dynamic applications that serve different versions depending on region/locale or which are A/B testing - the dynamic part could be served from a centralized host while smaller chunks of code could be referenced through URIs.</p>
<!-- 
# The global [Git](https://en.wikipedia.org/wiki/Git)

We can intertwine Wikipedia, open source code, science & peer review globally and in public - tied to identity and with complete and unambiguous history of changes. Well... not only them - everything! We should be able to view changes of pages with a diff view - similarly to what [The Internet Archive provides](https://blog.archive.org/2019/10/18/the-wayback-machine-fighting-digital-extinction-in-new-ways/) - see [this as an example](https://web.archive.org/web/diff/20170118202526/20170120040337/https://www.ice.gov/speeches).


Any step of the process should be a referencable event that others can comment on.




a slider for filtering/jumping through time like in discourse
https://meta.discourse.org/t/change-right-gutter-to-vertical-timeline-topic-controls/44096/231 -->
<!-- https://twitter.com/radicle
https://twitter.com/gitopiaDAO -->
<!-- 
# wikipedia

Wikipedia needs to be rebuilt on this - imagine a q&a section like twitter for every paraphrase and also a git slider to see the history for each paragraph. This index can also be moved interplanetary

wikipedia needs to be git-like. everything can be git-like. new action type: grant ability to someone to "edit" & publish a new version of an item

fork wikipedia?


- imagine wikipedia being rebuilt on top of this
    - dead links? thing of the past - can be cached locally & preserved with merkle proofs
    - imagine wikipedia being forked with a different set of moderators - like in git
    - imagine rebuilding wikipedia on top of this graph and being able to reference each paragraph/change


# science and peer review

- peer review can (and should) be reimplemented on top of infrastructure like this

12. Science. Same essay:
https://slatestarcodex.com/2014/07/30/meditations-on-moloch/


- the ledger of record - science
    peer review & citations can be encoded with tags/messages

    How does crypto realign science with reproducibility?
    https://twitter.com/manveerbasra_/status/1555405612506157056

    Composable science is reproducible science.
    https://twitter.com/balajis/status/1555458319070167040

    the digital part of scientific papers can be replicatable locally

    digital chain of custody for papers & science

    science should be like open source - replicated & verified many times like code is compiled & ran

    Laws should be referable and commentable. They should be written in public & made available in the same way as open source code is

    https://twitter.com/balajis/status/1557247912874086400
    https://twitter.com/bensprecher/status/1557351733382225920

    on-chain papers
    https://twitter.com/balajis/status/1556579944754384897
 -->
<h1 id="the-semantic-web-aka-the-original-web3"><a class="header" href="#the-semantic-web-aka-the-original-web3">The <a href="https://en.wikipedia.org/wiki/Semantic_Web">Semantic Web</a> (a.k.a. the original &quot;Web3&quot;)</a></h1>
<p>The biggest hurdle for its adoption has been the <a href="host_centric.html">host-centric</a> paradigm and the hoarding of data in silos with no incentive for exporting &amp; interoperability - Headjack changes that through <a href="data_centric.html">data-centric addressing</a> &amp; broadcasting by default. While there will always be companies that enrich &amp; tag data privately with their own ontologies and vocabularies to construct knowledge graphs for themselves, with open data by default and persistent URIs that always point to the same documents anyone will be able to broadcast similarly annotated versions of content with new URIs and relate them to the originals in a stable way for reuse by others. We can give birth to the public <a href="https://en.wikipedia.org/wiki/Giant_Global_Graph">Giant Global Graph</a> outside of large centralized systems such as Google and Facebook. Machine learning for processing unstructured data has its place but it can only go so far - structuring through the use of different <a href="messages.html">message types</a> and further annotations will make everything a lot more machine-readable.</p>
<!-- crowdsourced annotation -->
<h1 id="query-anything"><a class="header" href="#query-anything">Query anything</a></h1>
<p>There are no limits to the types of queries we should be able to make - some simple examples:</p>
<ul>
<li><code>&quot;Plot a timeline for all references to an event and filter based on some criteria.&quot;</code></li>
<li><code>&quot;Show me responses/references from high-trust individuals to the top 5 controversial statements of person X and sort them somehow.&quot;</code></li>
<li><code>&quot;When has person X talked about the gut microbiome and have they recommended/mentioned a product or company?&quot;</code></li>
<li><code>&quot;Has anyone I follow or is connected up to N degrees of separation with me shared/mentioned X in the last Y days?&quot;</code></li>
</ul>
<p>Companies with complex indexes &amp; private knowledge graphs could charge for running queries.</p>
<h1 id="forking-media--communities"><a class="header" href="#forking-media--communities">Forking media &amp; communities</a></h1>
<p>Most applications will have some kind of moderation &amp; filtration but at any point in time anyone will be able to create a competitor with a different set of rules and/or functionality. Migration can be seamless and the activity of accounts could (and in most cases will) be displayed in both at the same time - but the preferred application will be signaled through the URIs of public actions.</p>
<p>Content coming from competitors could be completely banned but that would be shortsighted - data coming from somewhere else should be displayed as long as it is properly structured and actions from banned accounts can simply be shown as deleted in reply threads. Migration can be gradual with little fracturing of communities &amp; the conversation.</p>
<h1 id="the-future-of-publishing-knowledge--learning"><a class="header" href="#the-future-of-publishing-knowledge--learning">The future of publishing, knowledge &amp; learning</a></h1>
<p>Books as a medium imply transmissionism as the learning model - <code>&quot;people absorb knowledge by reading sentences&quot;</code> - which is wildly incorrect and inefficient. Let's ask this question:</p>
<blockquote>
<p>&quot;How might we design mediums which do the job of a non-fiction book—but which actually work reliably?&quot; - <a href="https://andymatuschak.org/books/">Andy Matuschak - “Why books don’t work”</a></p>
</blockquote>
<!-- Non-interactive linear PDFs are incredibly limiting and a thing of the past. -->
<p>Here's a good start:</p>
<ul>
<li>Outlines as hierarchical expandable trees (like a <a href="https://worldaftercapital.gitbook.io/worldaftercapital/">GitBook</a>) and fractal reading (each chapter summarized in 1 paragraph, expandable on several levels if you want to dig deeper)<!-- > "Books should be structured as expandable trees. One paragraph summary of each chapter, expandable into summaries of component points/stories, expandable into the full text. Can read the whole book in 5 minutes or 5 hours." - [Fred Ehrsam](https://twitter.com/FEhrsam/status/1304217384962592769) -->
</li>
<li>Interactive <a href="https://en.wikipedia.org/wiki/Project_Jupyter">executable programs</a> with exercises &amp; examples embedded in documents.</li>
<li>Note taking, flash cards, etc.</li>
</ul>
<p>But that's just scratching the surface - deduplicated open data, persistent URIs linked to identity, <a href="possibilities.html#intra-document-addressing">intra-document addressing</a>, and the ability to cache resources with proofs enables a lot more:</p>
<ul>
<li>View the discussion and comment on anything referenced externally with a URI - or parts of the book itself as they could also have their own URIs - or even paragraphs!</li>
<li>Use tools like <a href="https://logseq.com/">Logseq</a>, <a href="https://roamresearch.com/">Roam Research</a> &amp; <a href="https://obsidian.md/">Obsidian</a> but on top of stable URIs &amp; the <a href="possibilities.html#the-semantic-web-aka-the-original-web3">semantic web</a> to build your own knowledge base as <a href="possibilities.html#bookmarks--playlists">bookmarks</a> &amp; a graph and share it if you want.</li>
<li>Publications can be self-contained and permanent by including everything external for offline use with proofs for authenticity - that's how journalism should be done.</li>
<li>Visualize your progress of going through an interconnected book as a color-coded map - an overview of what you've already looked at, how much time you've spent, and what's left.</li>
</ul>
<!-- We can leverage what we know about human cognition and drastically improve books and articles as a medium for knowledge transfer & retention - multi-level content (short vs detailed), different presentations (text, diagrams, graphs, knowledge maps), etc. -->
<!-- see [Francis Miller's work](https://www.francismiller.com/) - or don't - too much repetition and not that much insight -->
<p><strong>Imagine constructing stories as interconnected documents, concepts &amp; entities while wearing a VR headset by pulling from the semantic web &amp; the open internet and publishing that as a self-contained &amp; authentic package that anyone can save offline, explore &amp; build upon.</strong></p>
<blockquote>
<p>&quot;The most powerful person in the world is the story teller. The storyteller sets the vision, values and agenda of an entire generation that is to come&quot; - <a href="http://jovanabanovic.com/2020/08/06/the-most-powerful-person-in-the-world-is-the-story-teller-the-storyteller-sets-the-vision-values-and-agenda-of-an-entire-generation-that-is-to-come-steve-jobs/">Steve Jobs</a></p>
</blockquote>
<p>Let's empower them.</p>
<div style="break-before: page; page-break-before: always;"></div><div style="text-align: center;">
    <img src="https://png.pngitem.com/pimgs/s/207-2073499_translate-platform-from-english-to-spanish-work-in.png">
</div>
<!-- # Infrastructure improvements -->
<h1 id="infrastructure"><a class="header" href="#infrastructure">Infrastructure</a></h1>
<h1 id="redundancy"><a class="header" href="#redundancy">Redundancy</a></h1>
<p>TODO: Multiple points to retrieve content - redundancy</p>
<p>Self-authenticating data provides a scalability advantage by enabling store-and-forward caches. Aggregators in a self-authenticating network can host data on behalf of smaller providers without reducing trust in the data's authenticity. With <a href="https://en.wikipedia.org/wiki/Verifiable_computing">verifiable computation</a>, these aggregators will even be able to produce computed views – metrics, follow graphs, search indexes, and more – while still preserving the trustworthiness of the data. This topological flexibility is key for creating global views of activity from many different origins.
https://blueskyweb.xyz/blog/3-6-2022-a-self-authenticating-social-protocol</p>
<h1 id="search-engines"><a class="header" href="#search-engines"><a href="https://scribe.rip/p/what-every-software-engineer-should-know-about-search-27d1df99f80d">Search engines</a></a></h1>
<ul>
<li>Building indexes would be greatly simplified as they will be plugged to the global message bus and update only on events (push) - instead of periodic batch crawling of the public web (pull). The history of changes will be much more granular, precise, complete, structured &amp; authenticated.</li>
<li>Message schemas will greatly aid in the indexability and information extraction from dynamic websites.</li>
<li>The move to data-centric addressing and the desegregation of data will lead to a lot less duplicates and more rich &amp; precise context around any event/message.</li>
<li>Currently ephemeral experiences such as search suggestions leave no trace and it's extremely hard to prove bias as <a href="https://en.wikipedia.org/wiki/Robert_Epstein#Contributions_to_Internet_Studies">Dr. Robert Epstein</a> would attest - competition &amp; a lower barrier to entry are direly needed.</li>
<li>The range of sophistication of search engines would span the full spectrum - from the data center scale to software that you can run locally at home and most will be specialized - <a href="https://future.a16z.com/the-future-of-search-is-boutique">The Future of Search Is Boutique</a>.</li>
</ul>
<p>TODO: link to the section about the semantic web and how search engines would have an easier job</p>
<!-- There will be multiple competing versions of something like Google's Page Rank algorithm on this global dataset. -->
<h1 id="the-internet-archive"><a class="header" href="#the-internet-archive">The <a href="https://en.wikipedia.org/wiki/Internet_Archive">Internet Archive</a></a></h1>
<h1 id="the-next-step-in-library-science"><a class="header" href="#the-next-step-in-library-science">The next step in <a href="https://en.wikipedia.org/wiki/Library_science">library science</a></a></h1>
<!-- The archivability of the web will be greatly improved - fighting back the [sand mandala](https://en.wikipedia.org/wiki/Sand_mandala) effect due to the current [host-centric](host_centric.md) web. -->
<p>Let's take the <a href="https://en.wikipedia.org/wiki/Internet_Archive">Internet Archive</a> as an example:</p>
<ul>
<li>
<p>It will no longer need to actively poll all websites on earth periodically &amp; check for changes and save snapshots - instead it will just watch &amp; save all incoming events and have a complete history without any redundant data &amp; inefficiencies.</p>
</li>
<li>
<p>Actual content &amp; presentation HTML can be decoupled and only the essential could be saved. There could be a new message type for applications to signal a change in what they serve to browsers for presentation &amp; rendering of content which the Internet Archive could save throughout time as well to provide the historical views. Redundancy of snapshots can be driven to 0.</p>
</li>
<li>
<p>Content that is no longer accessible through the original application that published it and is not explicitly archived by the user that posted it would still be accessible by anyone with the same persistent URIs if archival services are queried <!-- - even though they won't be directly linked to the application/user IDs -->.</p>
</li>
<li>
<p>Web infrastructure:</p>
<ul>
<li>SaaS infrastructure companies that host plugin apps and deal with the heavy lifting of data processing</li>
<li>Your startup idea cant afford the infrastructure to process 100mb/s of ephemeral data? Pay a service a small fee for a subset of data you’re interested in for your PoC</li>
<li>Market for intermediate processed results &amp; indexes so that not everyone needs to reinvent the wheel and build the same set of algorithms and infrastructure over and over again - creating a market for the information pipeline by division of labor &amp; specialization. Any intermediate data structure could be checked for validity based on the inputs - albeit slow. Test but verify - opaque processing rules. No more algorithmic black boxes. Batch processing - web-scale services do that all the time and plenty of work is done on results that are minutes or even hours outdated</li>
</ul>
</li>
</ul>
<!-- Networking can gradually evolve as it is orthogonal to the actual identities and anchoring of content. -->
<div style="break-before: page; page-break-before: always;"></div><div style="text-align: center;">
    <img src="https://png.pngitem.com/pimgs/s/207-2073499_translate-platform-from-english-to-spanish-work-in.png">
</div>
<h1 id="business-models"><a class="header" href="#business-models">Business models</a></h1>
<img src="images/infrastructure_companies.png">
<h1 id="ads"><a class="header" href="#ads">Ads</a></h1>
<p>The goal is democratized access, competition &amp; innovation - not the end of the ad model which is a pipe dream.</p>
<p>The goal is not to kill the ad model - it is to make everything authentic and allow for better UI and choice and enable the web to step on this</p>
<p>the ad model isn't going anywhere but we are in a &quot;take it or leave&quot; situation without choice - the goal is to fix that</p>
<blockquote>
<p>&quot;Internet monetization is somewhat like a Soviet election: It doesn’t matter who clicks and where, it’s who counts those clicks that matters. The technology and business of that counting of clicks (and everything else you do online besides) goes by the dull-sounding name of attribution, and it determines the fate of trillion-dollar companies.&quot; - <a href="https://www.thepullrequest.com/p/attribution-rules-the-world-and-itll">source</a></p>
</blockquote>
<blockquote>
<p>&quot;A recent example of questionable attribution: I tweeted about my e-mountain bike, Jason Calacanis (of all people) saw it and asked about the model. Someone posted a review from bikeradar.com, and Jason (I don’t know if this is true) probably googled for it and maybe bought it. Who deserves the attributions credit? According to Google (surprise, surprise), it’ll be Google … and they’ll take all the credit, which is why Google is worth so much and Twitter so little.&quot; - <a href="https://www.thepullrequest.com/p/attribution-rules-the-world-and-itll">source</a></p>
</blockquote>
<p>de-duplication through content addressing &amp; adding traceability of content helps paint the picture what happened when and by who - aiding attribution. Infrastructure companies on which applications get deployed on can handle such tracking within them but since all the data is openly broadcasted competing services could offer alternative business models.</p>
<blockquote>
<p>&quot;Whether it be circulation numbers for 19th-century newspapers (the start of the printed ads business), or Nielsen ratings for pre-cable TV that determined ads rates there, there’s never been a media ecosystem that didn’t have attribution.&quot; - <a href="https://www.thepullrequest.com/p/attribution-rules-the-world-and-itll">source</a></p>
</blockquote>
<blockquote>
<p>&quot;If you had to conjure some collective mechanism for storing aggregated data that was selectively shareable between publisher and advertiser, it would look much like a blockchain.&quot; - <a href="https://www.thepullrequest.com/p/attribution-rules-the-world-and-itll">source</a></p>
</blockquote>
<p>^^ this can be done through verifiable computation &amp; sharing indexes between publishers &amp; advertisers within index infrastructure.</p>
<p><a href="https://www.thepullrequest.com/p/attribution-rules-the-world-and-itll">This article</a> posits that attribution has to go on-chain but Headjack offers an alternative - through the infrastructure companies.</p>
<p>such infrastructure </p>
<p>The same infra company could have multiple sets of indexes with different filtration criteria</p>
<blockquote>
<p>&quot;For as long as humans have crafted disembodied versions of their voices, whether it be Pompeiian graffiti or the latest tweet, there have been attempts to both guide user attention in some remunerative direction, and measure the effectiveness of that attention-gathering.&quot; - <a href="https://www.thepullrequest.com/p/everything-is-an-ad-network">source</a></p>
</blockquote>
<blockquote>
<p>&quot;The attention economy has always had its ledger and its cash register, and Web 3 will be no different.&quot;</p>
</blockquote>
<h1 id="client-attribution"><a class="header" href="#client-attribution">Client attribution</a></h1>
<p>the way for a startup application to get noticed</p>
<p>the persistent URL of content is an advertisement of the application by itself
similar to twitter's client attribution</p>
<p>platforms that can't properly display a message type natively will direct users to the application that published it</p>
<p>Ads themselves are not the root evil - it's the lack of choice &amp; ability to exit in the current monopolistic world due to the benefits of vertical integration in the current host-centric paradigm</p>
<h1 id="idms--storage---the-new-cloud"><a class="header" href="#idms--storage---the-new-cloud">IDMs &amp; storage - the new cloud</a></h1>
<p>https://twitter.com/ZeMariaMacedo/status/1554041365754945537</p>
<!--
the open nature of data leads to a shared data network effect where anyone can train ML models at scale with high quality data
https://mattturck.com/the-power-of-data-network-effects/


creators will need to shift how they monetize because there won't be platform lock-in & attribution :/
or actually the application attribution for content naturally leads to users checking it out - creators can and should be paid to generate content through them and based on virality of content they could get paid out? omg.


Value chain


point of view: creating an application without the ability to lock-in users is daunting - but what if most aspects of an application are commercialized & offered as a service so creating a new application is just the frontend? Substack lets you leave & take your subscribers with you - that's a conscious choice and they have decided to compete on the quality of service

Todo: takerate - what it is for other platforms and how it fits in headjack beyond youtube


TODO: think about creator monetization and how google currently gets the lions share of the ad revenue
What if some platforms don't freely provide the content but just anchor it and provide APIs like embedding youtube?


How to create a view of the discussion with only paid subscribers?



== transition from web2 to web3
traditional web2 companies/apps/websites will be able to gradually transition and anchor their content into this namespace - cost of entry would be marginal and the first to do so would get indexed and start getting shown in search results in this ecosystem first
No other solution has a seamless way to address content on http and bridge with traditional dns




copyright infringement is beneficial for youtube
https://www.youtube.com/watch?v=4IaOeVgZ-wc



platform attribution - advertising 
Application names that were used to publish content can serve as advertising (application attribution) for the platform that was chosen by a user when content is viewed through other applications because the original URIs will be shown and users will be able to click to view each piece of content through the originating application if they choose to (if they've never heard of it before & are curious or if their current application doesn't fully support a given message type).

==> discoverability of new applications!

There will be a marketplace for every vertical - we need to democratize specialization & competition




Markets, markets everywhere!
algorithmic transparency & choice
https://www.ribbonfarm.com/2019/02/28/markets-are-eating-the-world/


business models - who will host the content?
how does The Graph fit into this?! omg?!

incentive for infrastructure companies to do proper filtration of bots - apps can leave for other infrastructure - whereas within twitter there has been conflict of interest for executives as their bonuses counted on counts of users - so why diagnose the bot problem really? TODO: source - or be more vague and don't directly point to twitter




-->
<div style="break-before: page; page-break-before: always;"></div><div style="text-align: center;">
    <img src="https://png.pngitem.com/pimgs/s/207-2073499_translate-platform-from-english-to-spanish-work-in.png">
</div>
<h1 id="feeds-indexes--algorithms"><a class="header" href="#feeds-indexes--algorithms">Feeds, indexes &amp; algorithms</a></h1>
<p>We can build the classifiers in public - the ml models.
We can see which indexes other people prefer in terms of applications. The network state is 100% digital and is publicly expressed through client attribution - choice</p>
<p>the world dashboard
https://twitter.com/balajis/status/1442863553497554944</p>
<p>the public shouldn't be using black-box recommendation algorithms at scale - we can actually have a choice and choose the transparent ones and they can be really good - we can make a functioning market for those and they can be verifiable</p>
<p>computed &amp; verifiable views?
https://blueskyweb.xyz/blog/3-6-2022-a-self-authenticating-social-protocol
link to authenticity page</p>
<p>promotion of videos will no longer be dominated just by the recommendation algorithm - when an influencer comments on a video his followers will see it and watch the said video too</p>
<p>We will be able to study the effects of recommendation algorithms for virality because all content has an application where it came from</p>
<p>Applications will compete on the algorithms they let people use to filter and sort information - to look for signal through the noise.</p>
<h1 id="transparency--choice-of-algorithms"><a class="header" href="#transparency--choice-of-algorithms">Transparency &amp; choice of algorithms</a></h1>
<p>Imagine seeing both the data and the algorithms running on that data &amp; being able to check the results for yourself</p>
<p>&quot;Rather, many, many different individuals and organizations would be able to tweak the system to their own levels of comfort and share them with others—and allow the competition to happen at the implementation layer, rather than at the underlying social network level.&quot;
https://knightcolumbia.org/content/protocols-not-platforms-a-technological-approach-to-free-speech</p>
<p>https://twitter.com/disclosetv/status/1557800191700393984</p>
<p>https://ground.news/</p>
<p>with open data &amp; transparent algorithms we could leverage AI to surface human collective intelligence at scale in a permissionless way - anyone could analyze the data and prove their results
https://www.youtube.com/watch?v=WVEP0zAK-xQ&amp;t=3951s</p>
<p>https://twitter.com/disclosetv/status/1557800191700393984</p>
<p>https://twitter.com/balajis/status/1561032192947458048</p>
<p>one problem with twitter is the immediacy - the feed promotes recent engagement ONLY. and there's no good way to dig through history</p>
<p>We need control over feeds</p>
<p>Instead of a feed the home page could be a dashboard that shows areas of interest of your social graph and being able to selectively dive deeper in whatever you decide - feeds are primitive and extremely limiting</p>
<p>what if reactions from reputable people were taken into account by recommendation algorithms so that untrue things get downregulated that way?</p>
<div style="break-before: page; page-break-before: always;"></div><div style="text-align: center;">
    <img src="https://png.pngitem.com/pimgs/s/207-2073499_translate-platform-from-english-to-spanish-work-in.png">
</div>
<h1 id="the-metaverse"><a class="header" href="#the-metaverse">The metaverse</a></h1>
<!-- 
Games will be able to check your wallet and change your experience depending on what you’ve acquired in other games. Games built by third-party indie devs could be built around the objects of other games, in a literal way extending the game's universe.
https://mirror.xyz/0xE4f646F0Be4fF5ce185540F5366295f91d75b65D/-xpmr7ceHmi5Hqsl7zRtig9ph_dtCvWjZOoWOVN0bcg


the visual metaverse could be built on top of headjack and nvidia's omniverse
omniverse usd (universal scene description)


the early web was built on open protocols - and so will the metaverse


> "The “metaverse” as I like to envision it, is a globally shared and permanent digital reality not owned by any single entity that any company, platform, or person can plug into, regardless of where they are or what device they’re using." - [source](https://mirror.xyz/0xE4f646F0Be4fF5ce185540F5366295f91d75b65D/-xpmr7ceHmi5Hqsl7zRtig9ph_dtCvWjZOoWOVN0bcg)


metaverse page
- This is what the metaverse will be built on
- The metaverse is about provable activity linked to identity beyond the confines of any specific platform
- The metaverse is fully addressable and people create more than they transact
- The metaverse is being able to refer to anything and anyone.
- The metaverse is about agency in creation
- TODO: read this from "The Coming Evolution of Games" onward:
https://future.com/metaverse-infrastructure-technology-games/

We need to persistently link activity with identity to build reputation systems


> "We think of the metaverse as the entirety of all composable and interoperable resources, identities, applications, platforms, services, and protocols that exist in cyberspace."
https://blog.ceramic.network/into-the-dataverse/



you need to be able to pull and reference anything from any part of the metaverse


https://twitter.com/punk6529/status/1448399827054833668
https://twitter.com/punk6529
https://6529.io/ 


https://decrypt.co/105791/new-interoperability-alliance-launches-dao-to-develop-metaverse-standards


instance/nonce/collections from an identity - perhaps 100% off-chain issuance with on-chain integer-only updates to facilitate off-chain "namespaces" & libraries of objects

How would marketplaces for off-chain items from a collection work?


Look at improbable for metaverse and M2 - Herman Narula

the metaverse will be built as a layered stack

the metaverse is experiences with shared data linked to identity


The metaverse is digital creation tied to identity - not 3d


-->
<div style="break-before: page; page-break-before: always;"></div><h1 id="startup-case-study"><a class="header" href="#startup-case-study">Startup case study</a></h1>
<p><strong>Problem statement</strong>: Long-form media is the present (&amp; future) and audio/video are preferred over text by many. We should be able to comment &amp; annotate it at specific points in time on the timeline.</p>
<p>But not like SoundCloud where <a href="https://soundcloud.com/liluzivert/for-fun-prod-by-beatsbyjeff">tiny overlapping rectangles</a> with profile pictures are rendered on the timeline that you can just hover with the cursor to see the comment nor like YouTube where you can write a timestamp (<code>hh:mm:ss</code>) in a comment which becomes a clickable link that fast-forwards the player and then fighting it out with the other 20 000 comments in the single linear vertically scrollable section of a 3 hour long podcast and hoping to be noticed - both are horribly insufficient and unusable. For both of them comments are just an afterthought - it is extremely hard to discuss specific parts of long-form media &amp; for good localized signal to actually surface &amp; be noticed.</p>
<hr />
<p>Instead why not just show a histogram of where most of the comments are and provide a resizable window as an additional widget on the timeline (in addition to the progress cursor) which can filter comments &amp; annotations based on the range and display the threads below Reddit-style with sorting &amp; filtration options? Here's a screenshot of precisely that (ignore the colors &amp; bad style):</p>
<img src="images/startup_case_study.png">
<p>The ultimate audio/video player can offer a lot more than just a comment histogram - it has the potential to be a vibrant social experience like any other:</p>
<ul>
<li>1-click repositioning &amp; resizing of the filter window to timestamp ranges for different topics plotted as horizontal bars (already done &amp; visible in the screenshot)</li>
<li>sharing links to specific ranges - as clips, but without losing the context
<ul>
<li>many channels re-upload clips from longer videos - this should instead be a simple &quot;retweet&quot; of the original material with a range as a parameter</li>
</ul>
</li>
<li>different types of comments: annotations, questions, personal (private) notes</li>
<li>search field for within the comments that are in the current filter window</li>
<li>crowdsourced annotations (tagging resources/events/concepts/entities)</li>
<li>plotting/toggling different types of histograms (not just comment density):
<ul>
<li>plotting different types of reactions</li>
<li>where other users spend most of their time</li>
<li>where the user has already played the episode</li>
<li>comments that have more than X upvotes or up/down ratio</li>
<li>where the most controversy or facts requiring a crowdsourced check are</li>
<li>highlighting comments that match the current search filter/query/regex</li>
</ul>
</li>
</ul>
<p>Here's an <a href="https://www.youtube.com/watch?v=xsJvFr9v7Nk">older video</a> showcasing this UI (can't resize the window with the mouse yet).</p>
<h1 id="challenges-in-the-current-web2-world"><a class="header" href="#challenges-in-the-current-web2-world">Challenges in the current web2 world</a></h1>
<p>How would this work as a web2 company?</p>
<ul>
<li>
<p>For it to provide value it would need many users commenting on the same video or otherwise there will be no histogram and the whole interface will be pointless. It needs a network effect.</p>
</li>
<li>
<p>Discoverability is hard - it would require that users actively share links to it on other platforms.</p>
</li>
<li>
<p>What if YouTube/Spotify cut it off &amp; disallows embedding their players &amp; using the APIs?</p>
</li>
<li>
<p>Unclear if it should try to be its own platform or just a (browser) plugin to other platforms:</p>
<ul>
<li>The platform way is more ambitious but requires a ton more work &amp; <a href="problems_with_the_web.html#vertical-integration-vs-specialization--competition">vertical integration</a>: direct messages, a social graph, notifications, a feed &amp; recommendation systems, etc. Would it need to compete with YouTube &amp; Spotify at some point? The likely <a href="images/startup_failure_outcome.jpg">outcome</a>.</li>
<li>The plugin way is a much more limited experience. How would users share links to comments &amp; timeline ranges to others that don't have the plugin installed? How will users be notified for comments &amp; replies? You'd be completely beholden to the platforms.</li>
</ul>
</li>
</ul>
<h1 id="how-headjacks-paradigm-fosters-innovation"><a class="header" href="#how-headjacks-paradigm-fosters-innovation">How Headjack's paradigm fosters innovation</a></h1>
<p>Contrast that to a web built around Headjack:</p>
<ul>
<li>
<p>The amount of work for this UI would be minimal - reusing components already present:</p>
<ul>
<li>Identity &amp; <a href="https://en.wikipedia.org/wiki/Single_sign-on">single sign-on</a>, DMs, notifications, progress bars, preferences &amp; connections will all be handled by <a href="IDM.html">IDMs</a>.</li>
<li>The heavy lifting (processing &amp; indexing all broadcasted events, perhaps moderation &amp; even ad serving) will be handled by infrastructure services which will charge the application just the right amount for the sets of API calls &amp; indexes that it needs - pay-as-you-go. There will be different competing infrastructure providers and applications will be able to migrate to the one with the best service or it may even utilize multiple ones at the same time - offering users the choice which indexes &amp; filters to use.</li>
<li>The costs &amp; team required to implement this UI will be minimal and - focus is on delivering value to users. This will lower the barrier to entry and unlock better UX &amp; functionality - many more niche needs will be addressed.</li>
</ul>
</li>
<li>
<p>Application discoverability - the moment someone with a following posts a comment through it that comment would immediately be visible to their audience on applications like Twitter and the URI for the comment will contain the name of the application that was used for its generation - serving as client attribution &amp; advertisement of the alternative application. No need for influencers to explicitly share <code>&quot;hey! check out this platform where I made a comment and make sure to follow me there&quot;</code> to their audience - it'll be automatic &amp; implicit.</p>
</li>
<li>
<p>No risk of platforms cutting access to their APIs to third-party apps &amp; changing their <a href="https://en.wikipedia.org/wiki/Terms_of_service">ToS</a> because in this ecosystem everything is a third-party app around unified identity and data is no longer host-certified - addressing is <a href="data_centric.html">data-centric</a>. There are no <a href="https://www.investopedia.com/ask/answers/05/economicmoat.asp">MOATs</a> &amp; lock-in - everyone focuses on their niche and competes on competency &amp; offering the best possible service.</p>
</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="mission--ambition"><a class="header" href="#mission--ambition">Mission &amp; ambition</a></h1>
<p>The ability to cooperate flexibly in large numbers has led us to an evolutionary advantage - first through stories and then <a href="https://www.ribbonfarm.com/2019/02/28/markets-are-eating-the-world/">markets, clocks</a> &amp; <a href="https://a16z.com/2011/08/20/why-software-is-eating-the-world/">bits</a>. Any mechanism that makes those more efficient will benefit the species. Evolution is 99.9% memetic &amp; accelerating exponentially - media is fundamental.</p>
<p>our biggest problems stem from lack of coordination
https://slatestarcodex.com/2014/07/30/meditations-on-moloch/</p>
<p>hivemind.</p>
<p>At the root of the greatest challenges to humanity lie coordination failures</p>
<blockquote>
<p>technology increases the efficiency of manufacturing consent in the same way it increases the efficiency of manufacturing everything else
Coordination is what’s left. And technology has the potential to seriously improve coordination efforts.
https://slatestarcodex.com/2014/07/30/meditations-on-moloch/</p>
</blockquote>
<p>crowdsource</p>
<p>We are like an ant colony with a malfunctioning central brain suffering from multiple personality disorder - trapped in multipolar traps, segregated into fabricated factions, oblivious to game theory/markets/economics/history, plagued by short-sightedness &amp; nihilism, playing status games, and running exponential experiments in a finite world.</p>
<p>If the internet is the information super highway, blockchains are the cooperation super highways and can play a major role in upgrading our systems of trust. We are just neurons - let's bootstrap the hivemind by organizing in a global &amp; borderless super intelligence.</p>
<blockquote>
<p>&quot;Society, business &amp; money are downstream of technology, which is itself downstream of science. Science applied is the engine of humanity.&quot; - <a href="https://twitter.com/naval/status/790443306886926337">@naval</a></p>
</blockquote>
<h1 id="mission"><a class="header" href="#mission">Mission</a></h1>
<blockquote>
<p>&quot;Our mission is to organize the world's information and make it universally accessible and useful.&quot; - <a href="https://about.google/">Google</a></p>
</blockquote>
<p>Headjack's mission is to end network effect monopolies &amp; data silos by making identity sovereign and data interoperable. The status quo is just a local maximum. Goals:</p>
<ul>
<li><a href="https://twitter.com/balajis/status/1554228316181127169">distribute power</a> and let people have a choice - identity should belong to no one</li>
<li>add <a href="authenticity.html">authenticity</a> to information and build the <a href="https://twitter.com/balajis/status/1459140902144729088">ledger of record</a> for greater accountability</li>
<li>revive the semantic web, <a href="authenticity.html#deduplicating-documents--traceability">deduplicate content &amp; enable traceability</a></li>
<li>improve transparency - <a href="https://en.wiktionary.org/wiki/sunlight_is_the_best_disinfectant">&quot;Sunlight is the best disinfectant&quot;</a>
<ul>
<li>virality needs to be politically &amp; content-neutral</li>
</ul>
</li>
<li>break the <a href="problems_with_the_web.html#vertical-integration-vs-specialization--competition">vertical integration</a> through interoperability &amp; markets - allow for specialization
<ul>
<li>lower the barrier to entry for innovation - the design space is limitless</li>
<li>enable alternative business models - the monopolistic ad economy is a paperclip maximizer with huge cultural repercussions</li>
</ul>
</li>
<li>empower super users to separate signal from noise through open data &amp; better tooling</li>
<li>make infrastructure <a href="https://decrypt.co/107293/taiwan-turns-to-ipfs-tech-to-thwart-cyberattacks-from-china">more resilient</a> through <a href="infrastructure.html#redundancy">redundancy</a> and p2p content-addressing</li>
</ul>
<!-- lowest common denominator UX is fine but the power users should be able to go crazy - let them separate signal from noise on a global level -->
<ul>
<li>empower storytellers by <a href="possibilities.html#the-future-of-publishing-knowledge--learning">improving books and publications</a></li>
</ul>
<!-- Mission: minimize friction, complexity, and uncertainty -->
<!-- slay moloch
https://slatestarcodex.com/2014/07/30/meditations-on-moloch/ -->
<h1 align=center>
    Link actions & events to identity
</h1>
<div style="text-align: center;">
    <img src="images/one_chain_to_link_them_all_small.jpg">
</div>
<h1 id="bottom-up-media--the-decentralized-town-square"><a class="header" href="#bottom-up-media--the-decentralized-town-square">Bottom-up media &amp; the decentralized town square</a></h1>
<blockquote>
<p>&quot;Throughout history, decentralization has been a remarkably effective evolutionary strategy. Just ask the Fungi Kingdom, which has continuously thrived for over 1.3 billion years. Uniquely adaptive masters of survival, fungi forgo a central “brain” in favor of a mycelium network: a branching, underground root system that distributes control throughout the organism. Mycelium networks efficiently allocate resources, respond to external stimuli, and remain functional even if one part of the organism is destroyed.&quot; - <a href="https://guide.getzion.com/inspiration-for-zion">source</a></p>
</blockquote>
<p>Headjack makes identity sovereign and no 2 entities can be prevented from communicating both privately and in public - allowing for <a href="https://publications.hse.ru/en/articles/135571129">gossip</a>. Authenticity enables global <a href="https://en.wikipedia.org/wiki/Common_knowledge_(logic)">common knowledge</a>. <a href="https://en.wikipedia.org/wiki/Information_wants_to_be_free">&quot;Information wants to be free&quot;</a> - the entire web can be turned into a crowdsourced Wikipedia where anything is provable, interlinked &amp; commentable. We can reimplement peer review &amp; intertwine it within the global public namespace and make everything visualizable through dashboards.</p>
<blockquote>
<p>&quot;Engelbart’s dream was to use computers to connect individuals in a network that would allow them to share and update information in “real time.”&quot; - <a href="https://www.britannica.com/biography/Douglas-Engelbart">Douglas Engelbart</a></p>
</blockquote>
<!-- > "gossip is simply more important in larger, more stratified, and more institutionalized societies" - [source](https://publications.hse.ru/en/articles/135571129) -->
<!-- > "The general trajectory of institutionalization associated with steadily increasing specialization, urbanization, and bureaucracy may mean that mass media will continue to rise in importance, playing the role of the juicy gossiper in our increasingly separated existence from one another." - [source](https://publications.hse.ru/en/articles/135571129) -->
<!-- 
> "If someone has the fight in them, I think a great step would be to start documenting the power structure. Build a GitHub repo of all the laws. Discover who wrote which part of each bill. Track the financial relationships and flow of money. Build a Wikipedia to document our oligarchs. Reverse engineer their schedules. Trace their lineage. Document the behaviors in real time, do not let the regime continue to hide."
https://geohot.github.io/blog/jekyll/update/2021/12/18/the-fourth-estate.html
 -->
<p>JBP: Why Twitter Is Insane
https://www.youtube.com/watch?v=Yg0qlnh5I38</p>
<p>Any of the mentioned articles or quotes by ppl like balaji should have been a notification or reference - everything should be interlinked</p>
<p>there's no solid foundation and thus we can't agree on what's true.</p>
<p>visualize the global HEATMAP of interests</p>
<h1 id="culture-war"><a class="header" href="#culture-war">Culture war</a></h1>
<p>The aggregate sentiment on twitter’s backend is analogous to a liquidity order book - we should want to see the Overton window.
We could have a completely different understanding of society, history, and politics.
https://youtu.be/FV5SqIm5e90?t=883
https://www.youtube.com/watch?v=FV5SqIm5e90</p>
<p>we cannot see the &quot;border&quot; between twitter and facebook in terms of users - even they (the companies) cannot because the data and backends are private and closed/siloed. This can change and we can have greater insights
https://youtu.be/FV5SqIm5e90?t=4631</p>
<p>Finance is the <a href="https://anthonyleezhang.substack.com/p/the-market-for-promises">market for promises</a>, media is the battleground of ideas.</p>
<p>We can build systems that show the overlap of communities and not focus only on the differences - bridging the gap and making “the others” less foreign</p>
<p>A public backend would be a societal mirror
The information asymmetry needs to be fixed - the twitter backend should be open</p>
<p>Imagine saying hey lets say all together to choose the filters we want</p>
<p>Imagine being able to select prisms 2, r and 7 - as filters. Clients can be competing chains of filters for the web. - we can choose what subset to use and advertise through attribution</p>
<p>We need to collectively regulate what is in our media - by choice. By competing public algo and by client attribution.</p>
<p>Client attribution is the killer feature.</p>
<p>Moderation filters will simply be that - collections of preferences that users can choose to amplify or die down</p>
<p>the way to end polarization is by allowing us to choose and display what unites us</p>
<blockquote>
<p>&quot;Even a billion dollars of capital cannot compete with a project having a soul.&quot; - <a href="https://vitalik.ca/general/2020/12/28/endnotes.html">@VitalikButerin</a></p>
</blockquote>
<p>████████████████████████████████████████████████</p>
<p>There's no global megaphone that would keep all information globally accessible &amp; indexable.</p>
<p>We should be connecting echo chambers and taking notes from Taiwan's civic hacktivism &amp; innovation in social media facilitating public discourse, but on a global level.</p>
<p>We haven't really had a market for ideas</p>
<p>Our inability to trust and coordinate leads to inefficiencies and duplication</p>
<p>A global web of trust and authenticity could help with multipolar traps</p>
<p>We need to rebuild &amp; scale up trust through authenticity</p>
<p>The ability to do specific verifiable attribution to where a harm is coming from can increase our capacity to serve justice
Forced transparency !!!</p>
<p>We can do a lot better with systems of collective intelligence</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="the-ambition"><a class="header" href="#the-ambition">The ambition</a></h1>
<p>Web3 is often associated with user ownership of networks/services/data, governance, NFTs &amp; micropayments, and while all of them will play a part in it, the main aspect is the distribution of power around identity and <a href="https://twitter.com/balajis/status/1162401646258749441">making it sovereign</a> - the metaverse is about connected entities that interact with information under a common global namespace and surf the web through competing applications &amp; views that present &amp; filter commonly addressable data in any way imaginable.</p>
<!-- 

TODO: take this metaverse thing out of here and into the other page

It is an informational gravity well with a strong network effect that would suck all data to be cryptographically anchored to it

Headjack has an ecosystem effect - a product network effect, and identity is at the core of it. Case Study: Dropbox vs. Google Drive
https://blog.niraj.io/the-ecosystem-effect

-->
<p>Think of Headjack as an <a href="https://www.cs.cornell.edu/courses/cs614/2003sp/papers/OPS93.pdf">information bus</a> on top of which any type of distributed system can be architected thanks to the minimal semantics, self-describing messages, dynamically definable message types &amp; permissionlessness. The service objects that deal with identity &amp; authorization are on-chain and have guaranteed storage &amp; retrievability whereas all data objects are just cryptographically anchored and stored off-chain (<a href="https://en.wikipedia.org/wiki/InterPlanetary_File_System">IPFS</a>) for which durability &amp; retrievability is on a <a href="https://en.wikipedia.org/wiki/Best-effort_delivery">best-effort</a> basis without guarantees. It can <a href="numbers.html">scale</a> practically as much as necessary. Another way to look at it is as a global <a href="https://en.wikipedia.org/wiki/Publish%E2%80%93subscribe_pattern">publish-subscribe</a> messaging network similar to <a href="https://kafka.apache.org/intro">Kafka</a> where accounts are treated as topics to which anyone can subscribe to - a notification highway. It is the manifestation of Jack's <a href="https://twitter.com/jack/status/1204766078468911106">vision for decentralizing Twitter</a>.</p>
<!-- TODO: browser in the driver/filesystem/OS analogy? -->
<p><a href="https://en.wikipedia.org/wiki/InterPlanetary_File_System">IPFS</a>, <a href="https://en.wikipedia.org/wiki/Filecoin">Filecoin</a>, <a href="https://sia.tech/">Sia</a> &amp; <a href="https://arwiki.wiki/">Arweave</a> are the drivers, Headjack is the filesystem, and the collection of media &amp; services built on top will be the global OS. Moving to a data-centric model where everything is addressable under a common global namespace would force applications to be <a href="https://balajis.com/yes-you-may-need-a-blockchain/">interoperable</a>.</p>
<blockquote>
<p>&quot;Composability is to software as compounding interest is to finance&quot; - <a href="https://twitter.com/cdixon/status/1451703067213066244">@cdixon</a></p>
</blockquote>
<p>Headjack <a href="https://boxkitemachine.net/posts/zero-to-one-peter-thiel-definite-vs-indefinite-thinking/">definitively</a> aims to be the backbone of the entire public web - the <a href="https://twitter.com/balajis/status/1459140902144729088">ledger of record</a> where all content is cryptographically anchored and totally ordered. The confluence of human-readable &amp; persistent addressing, indexing, identity, names, and the interest graph results in a winner-take-all network effect with unprecedented gravity that can organize the world's data - <a href="https://youtu.be/3qHkcs3kG44?t=3527"><code>@naval: &quot;The internet creates 1 giant aggregator for everything&quot;</code></a>. It can succeed in completely decentralizing <a href="https://en.wikipedia.org/wiki/Domain_Name_System">DNS</a> and disaggregating traditional platforms such as Twitter, Reddit, YouTube &amp; Instagram through unbundling, reconstruction &amp; interoperability on top of Headjack's building blocks by mixing and matching various presentation layers, architectures, business models, content moderation policies, etc. <a href="https://www.goodreads.com/quotes/20103-the-whole-is-greater-than-the-sum-of-its-parts"><code>&quot;The whole is greater than the sum of its parts.&quot;</code></a></p>
<blockquote>
<p>&quot;The web is like an ever-growing library with billions of books and no central filing system.&quot; - <a href="https://perma.cc/9HE2-VZF9">how Google works (archived)</a>, already <a href="https://www.google.com/search/howsearchworks/how-search-works/organizing-information/">changed</a></p>
</blockquote>
<p>Headjack is the <a href="https://xkcd.com/927/">15th and final</a> standard for decentralized identity and media - just because it's a lot of work doesn't mean we shouldn't be building on the right foundation. It is the supermassive digital gravity well and is going after the entire web as the coordination substrate of <a href="https://www.eff.org/cyberspace-independence">cyberspace</a>.</p>
<p>The outcome is binary - <strong><code>success</code></strong> or <strong><code>failure</code></strong> and is worth trying despite the odds for world domination - it's all up to the execution.</p>
<!-- The end of information & network effect silos -->
<div style="break-before: page; page-break-before: always;"></div><div style="text-align: center;">
    <img src="https://png.pngitem.com/pimgs/s/207-2073499_translate-platform-from-english-to-spanish-work-in.png">
</div>
<h1 id="execution-how"><a class="header" href="#execution-how">Execution (how)</a></h1>
<p>How the blockchain &amp; ecosystem are actually implemented (full specification).</p>
<!--
TODO: document with a "why not a rollup" section - or in the FAQ
https://twitter.com/KirilovVik/status/1531184971896999936
https://polynya.medium.com/the-sustainability-checklist-d620549425dc


Aside from the scalability properties rollups can possess, they also solve both fundamental problems. Rollups don’t need their own validators, only a set of sequencers to produce blocks. The base layer provides the secure validator set. Rollups that share a settlement layer can build trust-minimized bridges between them because their state transitions can be easily verified through the settlement layer.
https://www.alexbeckett.xyz/composability-in-a-rollup-ecosystem/

TODO: read these on rollups

https://celestia.org/learn/

https://www.alexbeckett.xyz/secure-light-nodes-and-the-scalability-trilemma/
https://www.alexbeckett.xyz/the-economics-for-rollup-fees/
https://www.alexbeckett.xyz/the-path-toward-scaling-rollups/
https://www.alexbeckett.xyz/the-benefits-of-optimistic-rollups-compared-to-zk-rollups/
https://www.alexbeckett.xyz/a-snapshot-of-the-current-rollup-ecosystem/
https://www.alexbeckett.xyz/decentralized-sequencers-where-do-we-go-next/

https://www.alexbeckett.xyz/stateless-rollups/

https://twitter.com/musalbas/status/1545060322842533890

https://twitter.com/apruden08/status/1542189323906326528
https://www.youtube.com/watch?v=oc8M1-pNuXk
https://twitter.com/bkiepuszewski/status/1540793333295075329

https://l2beat.com/?view=risk

https://medium.com/starkware/volition-and-the-emerging-data-availability-spectrum-87e8bfa09bb
https://medium.com/starkware/data-availability-e5564c416424

https://twitter.com/epolynya/status/1533833479896453120

https://eth.wiki/sharding/Sharding-FAQs


The theoretical ideal stack to build on would be
https://twitter.com/lukedelphi/status/1539192716915007490


https://twitter.com/ZeMariaMacedo/status/1543601695048998918


You go to rollups with your capital to transact and exchange - with Headjack you wont be able to take your state back with you to L1 because the entirety of headjack is the state

Why not a rollup? There is nothing to steal - there will not be 100x times TVL more than the mcap of the protocol


The more I think about it, the less need I see to try to attach my chain to Ethereum - it will not benefit from financial liquidity & interoperability since its focus is quite different and it will most likely require it's own token for PoS consensus

A big reason to want to attach to Ethereum is securely bridged financial liquidity so my use case will benefit a lot less from trying to integrate with Eth because of it's non-financial use case

No composability is broken if not linked to ethereum & is sharded - as is the case with financial blockchains

I think that because this is not a very financial use case that the incentive to link it strongly with Ethereum is smaller.

finance cares mostly about the present whereas an index is there to provide information about the past - different data availability & retrievability needs
the historical part is much more important - each block & the hashes that are contained in there - or they should enter the state...

Finance is about preservation of energy - the double spend problem
And thus scalability there is different from media scalability which is a data problem

Media is about data access and sequence



- ZK rollup?
- eth2 danksharding?
- mina snapp?
- unbounded state growth.



- look into aggregate/multi/threshold signatures, ZK tech & other certificates:
    https://github.com/jarradh/zk-compact-certificates



- ECDSA vs eddsa
https://support.mycrypto.com/how-to/getting-started/how-to-sign-and-verify-messages-on-ethereum/
https://medium.com/mycrypto/the-magic-of-digital-signatures-on-ethereum-98fe184dc9c7
https://ethvigil.com/docs/eth_sign_example_code/

https://vomtom.at/ethereum-private-and-public-keys/
https://betterprogramming.pub/understanding-ethereum-cryptography-3ef7429eddce
https://ethereum.stackexchange.com/questions/3542/how-are-ethereum-addresses-generated


https://doc.libsodium.org/
http://ed25519.cr.yp.to/
https://keybase.io/
https://docs.joinmastodon.org/spec/webfinger/
https://docs.joinmastodon.org/spec/activitypub/


why libp2p sucks
https://twitter.com/tomaka17/status/1547529377277173761
https://github.com/matrix-org/pinecone

Skynet interop with IPFS:
https://twitter.com/DavidVorick/status/1412080832286584844
https://docs.skynetlabs.com/developer-guides/moving-from-ipfs-to-skynet
https://skynet.guide/tech/sia-layer-one.html
https://skynet.guide/tech/skynet-layer-two.html


reading on IPFS, Filecoin & Sia/Skynet
https://www.reddit.com/r/siacoin/comments/lg9qr0/what_is_skynet_why_should_i_build_on_it_and_how/gmr7u5v/
https://www.reddit.com/r/ipfs/comments/jf073z/filecoin_isnt_an_incentivization_network_for_ipfs/



how big are bloom filters
https://en.wikipedia.org/wiki/Bloom_filter
https://www.geeksforgeeks.org/bloom-filters-introduction-and-python-implementation/
https://github.com/RoaringBitmap/CRoaring
https://github.com/RoaringBitmap/RoaringBitmap#faq
https://en.wikipedia.org/wiki/Bitmap_index




-->
<div style="break-before: page; page-break-before: always;"></div><div style="text-align: center;">
    <img src="https://png.pngitem.com/pimgs/s/207-2073499_translate-platform-from-english-to-spanish-work-in.png">
</div>
<h1 id="identity-managers-idm"><a class="header" href="#identity-managers-idm">Identity managers (IDM)</a></h1>
<!--
# DMs

https://twitter.com/session_app

- DMs without keys - how?
    maybe rely on the identity providers - ACMs?
    https://twitter.com/elonmusk/status/1519469891455234048
    https://www.reddit.com/r/signal/comments/9k42k3/integrate_messaging_into_other_apps/
    https://www.youtube.com/watch?v=DXv1boalsDI
    https://www.youtube.com/watch?v=L2kuipP3lxk


Identity managers can still be compromised and wreack havok, but this is an improvement to the status quo

users should be able to point to their own personal ceramic stream instead of relying on applications
    they would need to post on-chain to timestamp their new activity for it to be sequenced & addressable with /user/nonce/...


an IDM may also use a social recovery wallet instead of email as login - or just a normal wallet/keypair authorization

the more you rely on IDMs for features and data storage, the less sovereign you are.


If an IDM does not let users bind keypairs then they will be boycotted

IDMs never get access to your private key


query IDMs directly for content by person X - polling mechanics like RSS


Permissions for different actions could be separated - for example requiring signatures for content while not requiring for updating follow connections.


access control

The future of mass-market crypto experiences lies within apps that provide familiar, custodial experiences with the ability to graduate into non-custodial experiences.
If the goal is to onboard first-time crypto users, the experience must be custodial — at least to start.
https://future.a16z.com/missing-link-web2-web3-custody-wallets/

https://www.portis.io/
https://twitter.com/toruslabs
    https://tor.us/
https://twitter.com/Web3Auth



IDM - pay to cold-DM someone and be seen


- Blocking - through the IDM?
- how to keep progress bars for played audio/video? IDM?
- notifications - what is seen - managed between applications - IDM?

edge case: what happens if a big application suddenly becomes malicious? How can millions of ppl invalidate activity posted through it without clogging the network?
    - force applications to bond tokens (proportional to the # of delegators) so that if a fork is necessary, they get penalized.
    - some zero-knowledge way to aggregate signatures for millions that want to batch a transaction delegation event?


SOLVING THIS PROBLEM DeSo have thought about:
https://twitter.com/nadertheory/status/1480628981942525953
https://twitter.com/nadertheory/status/1480649481792024578


sessions as a concept? expiration of delegation?
https://github.com/ethereum/EIPs/blob/master/EIPS/eip-4361.md
https://eips.ethereum.org/EIPS/eip-4361



Merging IDs from multiple IDMs if created without keys





These are [accounts](accounts.md) that can grant the ability to applications to post on behalf of accounts that are under the control of the ACM in question.


2 types of delegation: follow events and posting


TODO: problem: what happens if an ACM with control of millions of accounts stops behaving properly?
- users without keypairs are screwed
- users with keypairs will be sending on-chain messages but those will be huge and will clog the network
    - possible solution: batch them off-chain into 1000 batches, construct BLS aggregate sigs, sign a msg & transmit that along with a bitmap for which keys participated in the batching to a block.
    Users will need to coordinate off-chain & decide from which block to revoke the access, which other ACM should be approved, etc. This can be used in other scenarios too.
    https://ethresear.ch/t/2105
    https://ethresear.ch/t/pragmatic-signature-aggregation-with-bls/2105
    https://ethresear.ch/t/5427
    https://our.status.im/fastest-bls-signature-implementation/
    OR use some ZK magic





https://fission.codes/blog/auth-without-backend/
https://ucan.xyz/
https://jwt.io/
 -->
<div style="break-before: page; page-break-before: always;"></div><div style="text-align: center;">
    <img src="https://png.pngitem.com/pimgs/s/207-2073499_translate-platform-from-english-to-spanish-work-in.png">
</div>
<h1 id="handles-names"><a class="header" href="#handles-names">Handles (names)</a></h1>
<!-- A global mapping of `handle` (`string`) to X helps resolve queries. X contains:


subdomains.

- maybe they should not be properties of accounts but a separate map structure that just maps handles to IDs and on which block were they acquired? What would be traded - handles on IDs?

if a handle changes hands that shouldn't affect the ID & all the connections (no need to shuffle that much database numbers around)

- `handle` (`string`) - the name of the account
    - currently no idea how to 
    - TODO: https://en.wikipedia.org/wiki/Zooko%27s_triangle
- `handle_change`





handles can be sold without affecting the interest graph - handles are not accounts.
entire accounts can be also sold with the transition to a new keypair

gradually lowering the cost for new handles, such that it costs 10k$ initially for a handle, and going lower slowly.


https://farcasterxyz.notion.site/Registry-Deep-Dive-4f4c74646bf24e8e905780719136f172

Names must be between 1 and 16 characters and can only be made of letters (a-z), numbers(0-9) and underscores (_).
^[a-zA-Z0-9-]{1,16}$
https://en.wikipedia.org/wiki/IDN_homograph_attack

UTF-8 support for handles opens handle users up to homograph attacks, not to mention case-sensitivity issues. This issue is of ongoing discussion both for the DSNP as well as in for ICANN domain names and other projects working with internationalization support.
https://spec.dsnp.org/Ethereum/Registry.html#homograph-attack-mitigation


**Register** 
Users acquire a name by making two transactions — the first is to commit a secret hash of the username, and the second is to reveal the secret and claim the username to the address. During the reveal phase it also:

commit-reveal scheme prevents frontrunning

- giving/leasing the names properly & orderly is a hard problem

https://medium.com/coinmonks/understanding-the-handshake-airdrop-and-reserved-names-428d9e90b560


TODO: maybe this should be together with addressing?

backwards-compatibility of the handles - can mimic typical DNS like "twitter.com"

TODO: strategy: reserve all handles that have 1-1 twitter & instagram versions

TODO: think about namespaces & hierarchies like in DNS & also ENS - is ENS a namespace?

!!!
https://farcasterxyz.notion.site/The-Identity-System-b5e320826b33460b845ccc9ada63e904


!!!
https://handshake.org/faq/
https://hsd-dev.org/
Another key differentiator is that Handshake is the first to pre-reserve names for existing trademark name holders.
TODO: DNS & TLS stuff...
Why is Handshake pre-reserving the top tens of thousands of domain names according to Alexa.com?
TODO: maybe also reserve the top 100k twitter handles?
TODO: Vickrey auction
    not that goot actually because humans aren't perfectly rational - "VCG mechanism"
    https://vitalik.ca/general/2021/09/26/limits.html#finance-is-the-absence-of-collusion-prevention
TODO: name renewals?
https://blog.sia.tech/handshake-retrospective-after-the-first-year-c197e49749c9
"The other major problem with Handshake auctions is that they are Vickrey auctions."
"Handshake would be a lot better if it had a bidding system that assumed users were unskilled and naive, and attempted to optimize the outcome for users assuming that they made bad or uninformed decisions."
"Proposed Improvements to the Domain Buying Process"


Web3 Leads to Cybersquatting 2.0: Here's What Brands Can Do
https://decrypt.co/104319/ethereum-name-web3-cybersquatting


"The mint happens over a two-phase commit reveal to prevent front-running registrations."
"Farcaster Names are ERC-721 tokens that are fully composable with the NFT ecosystem."
https://github.com/farcasterxyz/protocol

https://medium.com/@jgm.orinoco/domainsale-an-on-chain-secondary-ens-market-b3330f6e5dda

 -->

                    </main>

                    <nav class="nav-wrapper" aria-label="Page navigation">
                        <!-- Mobile navigation buttons -->


                        <div style="clear: both"></div>
                    </nav>
                </div>
            </div>

            <nav class="nav-wide-wrapper" aria-label="Page navigation">

            </nav>

        </div>

        <!-- Livereload script (if served using the cli tool) -->
        <script type="text/javascript">
            const wsProtocol = location.protocol === 'https:' ? 'wss:' : 'ws:';
            const wsAddress = wsProtocol + "//" + location.host + "/" + "__livereload";
            const socket = new WebSocket(wsAddress);
            socket.onmessage = function (event) {
                if (event.data === "reload") {
                    socket.close();
                    location.reload();
                }
            };

            window.onbeforeunload = function() {
                socket.close();
            }
        </script>



        <script type="text/javascript">
            window.playground_copyable = true;
        </script>


        <script src="elasticlunr.min.js" type="text/javascript" charset="utf-8"></script>
        <script src="mark.min.js" type="text/javascript" charset="utf-8"></script>
        <script src="searcher.js" type="text/javascript" charset="utf-8"></script>

        <script src="clipboard.min.js" type="text/javascript" charset="utf-8"></script>
        <script src="highlight.js" type="text/javascript" charset="utf-8"></script>
        <script src="book.js" type="text/javascript" charset="utf-8"></script>

        <!-- Custom JS scripts -->

        <script type="text/javascript">
        window.addEventListener('load', function() {
            window.setTimeout(window.print, 100);
        });
        </script>

    </body>
</html>
