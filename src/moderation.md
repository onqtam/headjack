<div style="text-align: center;">
    <img src="https://png.pngitem.com/pimgs/s/207-2073499_translate-platform-from-english-to-spanish-work-in.png">
</div>


content moderation from minds.com
https://www.minds.com/content-policy

shadow banning

a bit on content moderation from DeSo
https://docs.deso.org/about-deso-chain/readme#the-future-of-moderation

Platform rules should have more scrutiny because of the game theory - more accountability when censoring speech

https://steemit.com/community/@baah/a-solution-to-the-downvoting-flagging-problems-on-steemit

https://techcrunch.com/2021/01/15/twitters-vision-of-decentralization-could-also-be-the-far-rights-internet-endgame

on bots & spam - see "So what’s prohibited?"
https://blog.twitter.com/en_us/topics/company/2020/bot-or-not


by default, if you don't have a handle, your comments aren't seen by everyone but only by the ones who own the content. They get to see everything and only if they quote-retweet you do others se your activity. and if they follow you they will see your posts always


https://blog.twitter.com/en_us/topics/company/2022/introducing-our-crisis-misinformation-policy


[`@balajis: "When identities become portable, backends become liquid"`](https://twitter.com/coconidodev/status/1504850437727571974)
this is making not only backends but also moderation lists & users liquid


- TODO: read this:
    https://gitlab.com/spritely/ocappub/blob/master/README.org

https://firstmonday.org/article/view/10868/10067

https://www.clamav.net/




!!! READ THIS !!!
https://blueskyweb.xyz/blog/4-13-2023-moderation



https://twitter.com/sarahemclaugh/status/1645522677229125656


https://blog.sia.tech/the-worrying-depth-and-scope-of-censorship-on-the-internet-ffd4bc5a5486
The most common suggestion we received in regards to our CSAM problem was to connect our website to Facebook and send them every single file that our users upload, so that Facebook can scan the file and tell us whether the file should be allowed on our website. A similar service is offered by Microsoft, and I believe Apple and Google each have something as well.


hope for spam & moderation: if there is a market for it it could be solved faster as compared when a monopoly has to deal with that - like with spam and email - anyone can build tools to fight spam in email

everyone can be free to have their own fact checkers
https://twitter.com/disclosetv/status/1643992886244147201

this project doesn't have all the answers for moderation & spam protection but it is the base layer that can support anything on top.

https://jaygraber.medium.com/designing-decentralized-moderation-a76430a8eab

https://techblog.bozho.net/on-disinformation-and-large-online-platforms/

https://www.youtube.com/watch?v=Y-W0CBOGnnI


Curation/upvote mechanic - every upvote costs a little of the token that goes to the creator, but the first to upvote get a % of the profits - incentivizing upvoting quality content


Web Spam Taxonomy
http://airweb.cse.lehigh.edu/2005/gyongyi.pdf

Jonathan Haidt: The Case Against Social Media | Lex Fridman Podcast #291
https://www.youtube.com/watch?v=f0un-l1L8Zw
Social Media and Political Dysfunction: A Collaborative Review
https://docs.google.com/document/d/1vVAtMCQnz8WVxtSNQev_e1cGmY9rnY96ecYuAj6C548/edit
something like the jail mechanism in dota where users need to play X games with other jailed ppl without many new reports in order to get out of that - Relisten 1:11:30+ from haidt


Customizable moderation (like uBlock Origin)
https://carter.sande.duodecima.technology/decentralized-wishlist/

!!! shared blocklists Twitter
https://www.google.com/search?q=shared+blocklists+Twitter&oq=shared+blocklists++Twitter&aqs=chrome..69i57.2267j0j7&sourceid=chrome&ie=UTF-8


https://news.ycombinator.com/item?id=25731963

https://en.wikipedia.org/wiki/Eternal_September

https://en.wikipedia.org/wiki/Astroturfing


https://danieljeffries.substack.com/p/why-well-hate-section-230s-repeal


https://twitter.com/ummjackson/status/1531651884288647170

https://www.pnas.org/doi/10.1073/pnas.2025334119
https://www.sciencedirect.com/science/article/pii/S2405844020323835


> "Separating speech and reach gives indexing services more freedom to moderate."
https://github.com/bluesky-social/adx/blob/main/docs/architecture.md


https://github.com/bluesky-social/adx/blob/main/docs/architecture.md#moderation


https://arxiv.org/abs/2109.13046

https://twitter.com/Snowden/status/1545728037341171713






Of course freedom of reach is freedom of speech. Speech without reach isn’t free speech; it’s just mumbling to yourself.

"Do you think freedom of speech includes the right to say and believe obnoxious stupid shit that’s almost certainly false, or do you feel platforms have the responsibility to arbitrate truth and regulate online behavior for the sake of some supposed greater good?"
That’s the real question here, and everything else is either willfully (or accidentally) naive online posturing.
https://www.thepullrequest.com/p/freeze-peach-and-the-internet
^^ good read - especially after the first 1/3



https://philpapers.org/rec/NGUHTG

https://www.eugenewei.com/blog/2019/2/19/status-as-a-service

https://a16zcrypto.com/social-network-status-traps-web2-learnings/

gini coeficient
https://twitter.com/dwr/status/1592557080573280257
https://arxiv.org/pdf/1601.07200.pdf

PROPOSAL: Transparent content moderation
https://twitter.com/sriramk/status/1599137490417635328
https://sriramk.com/transparent-content-moderation


Yishan's point: it's about user behavior and not so much about content
https://twitter.com/yishan/status/1586955288061452289
https://news.ycombinator.com/item?id=33449791


https://slashdot.org/faq/metamod.shtml


18+ content?



hope for spam & moderation: if there is a market for it it could be solved faster as compared when a monopoly has to deal with that - like with spam and email - anyone can build tools to fight spam in email


crowdsourced fact checking on Twitter
https://twitter.github.io/birdwatch
https://twitter.com/birdwatch
https://github.com/twitter/birdwatch/blob/main/birdwatch_paper_2022_10_27.pdf
https://news.ycombinator.com/item?id=33478845
https://news.ycombinator.com/item?id=33480904
https://news.ycombinator.com/item?id=33479530
Bridging-Based Ranking - Author: Aviv Ovadya | May 17, 2022
How Platform Recommendation Systems Might Reduce Division and Strengthen Democracy
https://www.belfercenter.org/publication/bridging-based-ranking
twitter birdwatch uses it
https://www.wired.com/story/elon-musk-embraces-twitters-radical-crowdsourcing-experiment/
"Birdwatch today is like a little baby version of something like an integrated oracle. Wisely, Birdwatch has given itself a much easier job, because it is designed to be wide rather than deep—to rapidly surface undisputed information at scale, not to deeply analyze disputed questions."
https://graymirror.substack.com/p/designing-the-ministry-of-truth



> "Fact-checkers therefore affect not just what people believe, but what they can believe." - [Fact-Checking the Fact-Checkers](https://gurwinder.substack.com/p/why-you-cant-trust-fact-checks#:~:text=Fact%2Dcheckers%20therefore%20affect%20not%20just%20what%20people%20believe%2C%20but%20what%20they%20can%20believe.)

> "fact-checkers, like the priests of old, are only pretending to have divine access to truth. In reality, they’re just as perplexed as the rest of us, and their verdicts are based less on what’s true than on what they’d prefer us to believe. As such, fact-checking should be understood not as the pursuit of truth, but the pursuit of power." - [Fact-Checking the Fact-Checkers](https://gurwinder.substack.com/p/why-you-cant-trust-fact-checks#:~:text=fact%2Dcheckers%2C%20like,pursuit%20of%20power.)





BS Asymmetry Principle
https://twitter.com/SahilBloom/status/1563528417785458689

https://www.theguardian.com/technology/2022/sep/01/cloudflare-defends-providing-security-services-to-trans-trolling-website-kiwi-farms
===> followup:
https://blog.cloudflare.com/kiwifarms-blocked/

https://blog.cloudflare.com/cloudflares-abuse-policies-and-approach/

https://compdemocracy.org/Moderation/

"pay to get indexed and not left out"?

https://knightcolumbia.org/content/protocols-not-platforms-a-technological-approach-to-free-speech

Why stop at just blue checks? Many different badges for verification!


Youtube has some serious issues... - flagging, moderation, etc.
https://www.youtube.com/watch?v=_IuqFlWovGQ

https://twitter.com/hivedotone
https://hive.one/
https://maciek.blog/dit/
https://maciek.blog/influence/
https://maciek.blog/attention-as-a-source-of-scarcity-for-decentralized-identity-systems/


https://en.wikipedia.org/wiki/Goodhart%27s_law


> "the unaffiliated individual reporting some as-yet unseen fact, and the citizenry, en masse, discovering truth, together, IS the new media. this is the manifestation of the promise of the open internet. and it is vital." - [@friedberg](https://twitter.com/friedberg/status/1587118917213777920)

> "i believe that platforms must create tools that shift responsibility from the citizen journalist (no policing of content) to the reader - with strong tools for filtering, preference, and influence selection being the core offering of the platform. not viral engagement." - [@friedberg](https://twitter.com/friedberg/status/1587118926340554752)

> "by shifting responsibility to the reader, to clearly state what they do, and do not, want to see and read, and revealing to them what other readers "think" about particular content, perhaps we can engage people to think differently and have a more rounded discourse." - [@friedberg](https://twitter.com/friedberg/status/1587118928123158528)





https://twitter.com/FFO_Freedom/status/1590529363942203392




== detecting bots:
- President Trump makes a tweet -- how was his tweet retweeted during the first few minutes afterwards? This method would help to detect bot-like activity on Twitter by scanning time blocks right after a specific account makes a tweet to see if the same accounts are active each time.
    https://docs.google.com/document/d/1xVrPoNutyqTdQ04DXBEZW4ZW4A5RAQW2he7qIpTmG-M/edit



> "As I've said for a long time, I don't mind moderation, I just want to be in charge of what I see. Give me the tools that the moderators have, let me be able to filter out bots at some confidence level; let me see "removed" posts, banned accounts; don't mess with my searches unless I've asked for that explicitly. Power to the people." - [source](https://news.ycombinator.com/item?id=33447848)


> "Community moderation works. This was the overwhelming lesson of the early internet. It works because it mirrors the social interaction of real life, where social groups exclude people who don’t fit in. And it works because it distributes the task of policing the internet to a vast number of volunteers, who provide the free labor of keeping forums fun, because to them maintaining a community is a labor of love. And it works because if you don’t like the forum you’re in — if the mods are being too harsh, or if they’re being too lenient and the community has been taken over by trolls — you just walk away and find another forum." - [source](https://noahpinion.substack.com/p/the-internet-wants-to-be-fragmented)

